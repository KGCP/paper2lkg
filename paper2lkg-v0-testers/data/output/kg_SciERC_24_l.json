{
  "iri": "Paper-24",
  "title": "CVPR_2006_10_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-24-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-24-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-1",
              "text": "In this paper we discuss object detection when only a small number of training examples are given ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-2",
              "text": "Specifically , we show how to incorporate a simple prior on the distribution of natural images into support vector machines ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-3",
              "text": "SVMs are known to be robust to overfitting ; however , a few training examples usually do not represent well the structure of the class ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-4",
              "text": "Thus the resulting detectors are not robust and highly depend on the choice of the training examples ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-5",
              "text": "We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin , but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB- ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-6",
              "text": "Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples , and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples ."
            }
          ]
        }
      ]
    }
  ],
  "summary": "In this paper we discuss object detection when only a small number of training examples are given . Specifically , we show how to incorporate a simple prior on the distribution of natural images into support vector machines . SVMs are known to be robust to overfitting ; however , a few training examples usually do not represent well the structure of the class . Thus the resulting detectors are not robust and highly depend on the choice of the training examples . We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin , but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB- . Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples , and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples .",
  "kg2text": [
    "We show how to incorporate a simple prior on the distribution of natural images into support vector machines, which results in a more robust detector. This approach assumes that there exists some structure or pattern in the background of natural images and uses this as a constraint to improve object detection when only a small number of training examples are given. The resulting detectors are not robust due to dependence on the choice of the training examples, but they can be used with prior knowledge about the distribution of natural images to obtain more accurate results."
  ],
  "times": [
    6.200843334197998
  ]
}