{
  "iri": "Paper-Modeling_Actuations_in_BCI-O_A_Context-based_Integration_of_SOSA_and_IoT-O",
  "title": "Modeling Actuations in BCI-O: A Context-based Integration of SOSA and IoT-O",
  "authors": [
    "Sergio Jos\u00e9 Rodr\u00edguez M\u00e9ndez"
  ],
  "keywords": [
    "Brain-Computer Interaction",
    "BCI Ontology",
    "Actuation Model",
    "Context-based",
    "Internet of Things",
    "Semantic Interoperability"
  ],
  "sections": [
    {
      "iri": "Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-1-Paragraph-1-Sentence-1",
              "text": "Recent technological developments in Brain-Computer Interfaces (BCI) will largely enable BCI as a powerful, natural and intuitive mainstream human-computer interaction (HCI) in real-world activities, especially throughout actuators connected to the Internet."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-2",
              "text": "As a type of sensor-actuator system, BCI will integrate novel interfaces that will be fully interoperating with IoT-based systems."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-3",
              "text": "An ontological metadata overlay for BCI systems in real-world applications is defined in the BCI Ontology (BCI-O), which formalizes and integrates BCI-domain-specific Sense and Actuation Models along with a novel Context Model for describing any kind of real/virtual environments."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-4",
              "text": "This paper presents the design principle of BCI-O's Actuation Model, which integrates SOSA and SAN (IoT-O) axioms for actuations and actuators along with the BCI-O's Context Model."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-5",
              "text": "This model will become relevant in the degree as context-based semantic interoperability will become a core pre-requisite for any context-aware BCI actuation application with real-time collaboration in IoT environments."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-2",
      "subtitle": "Introduction",
      "paragraphs": [
        {
          "iri": "Section-2-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-1-Sentence-1",
              "text": "Brain-Computer Interfaces (BCI) are systems that determine a user's brain states by collecting and analyzing her neurophysiological signals (which are highly situational, individual dependent, and non-stationary in characteristics) and then actuating specific responses, for example to drive her wheelchair autonomously."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-2",
              "text": "Key developments in wearable sensors, wireless networks, and distributed computing will largely enable BCI as a powerful, natural and intuitive mainstream human-computer interaction (HCI) in real-world activities."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-3",
              "text": "In a not too far future, BCI will be regarded as the ultimate HCI system, integrating novel interfaces that will be fully interoperating with Internet-of-Things- (IoT)-based systems."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-4",
              "text": "In this scenario, context-based semantic interoperability will be a core pre-requisite for any context-aware BCI application with real-time collaboration in IoT environments."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-5",
              "text": "The BCI Ontology (BCI-O) [1] is the first OWL 2 ontology that formalizes relevant metadata for BCI data capture activities by integrating BCI-domain-specific Sense and Actuation Models along with a novel Context Model for describing any kind of real/virtual environments."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-6",
              "text": "Due that BCI is a type of sensor-actuator system, as an ontological metadata overlay for BCI systems in real-world applications, BCI-O is properly aligned with the W3C Semantic Sensor Network (SSN) and Sensor, Observation, Sample, and Actuator (SOSA) [2] upper ontologies."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-7",
              "text": "Because many BCI devices, especially actuators, are connected to the Internet, BCI-O is also aligned with the core actuation semantic model for the IoT ontology (IoT-O) [3]: the Semantic Actuator Network (SAN) [5]."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-8",
              "text": "BCI-O makes an important contribution: the introduction of the concepts of context and contextual relations [1]."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-9",
              "text": "This puts the architectural description of any context as a first-class semantic model that enables BCI applications to be context-aware, laying the foundations of meaningful interactions with IoT-based systems."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-10",
              "text": "This paper presents the structure and design principle of BCI-O's Actuation Model, which integrates SOSA and SAN (IoT-O) axioms for actuations and actuators along with the BCI-O's Context Model."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-11",
              "text": "A use case for this model is explained in a subsequent section."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-12",
              "text": "Lastly, the main contribution is summarized in the conclusions."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-3",
      "subtitle": "Actuations in the BCI Ontology",
      "paragraphs": [
        {
          "iri": "Section-3-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-1-Sentence-1",
              "text": "BCI-O origins, purpose, core models, global overview, public access (spec and examples), design principles, and applications are described in [1]."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-2",
              "text": "At its core, BCI-O defines the conceptual components in any BCI through a bidirectional subject-context interaction model (a BCI session with sensors/actuators): a Sense Model (context to subject) and an Actuation Model (subject to context), as depicted in Fig. 1."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-3",
              "text": "Its Actuation Model is based on the"
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-2-Sentence-1",
              "text": "Two distinct conceptual domains are found in this interaction model: BCI domain (observations, actuations, and interactions) and context domain (surroundings)."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-2",
              "text": "Following, a brief description of BCI-O's core modules related to actuations are presented:"
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-3-Sentence-1",
              "text": "Session: represents the interaction between a bci:Subject and a bci:Context while performing (bci:Session) a single bci:Activity."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-2",
              "text": "A bci:Session groups both observations (multimodal records: bci:Record) and actuations (bci:Actuation)."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-4-Sentence-1",
              "text": "Context: captures the architectural description of any physical/virtual environment."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-2",
              "text": "Its conceptual components enable the structural, functional, and temporal complexity definitions of any environment (Fig. 4)."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-3",
              "text": "Under the bci:Context.Event classification, BCI-O defines three key concepts that bind the contextual integration (including with its Actuation Model): bci:StimulusEvent (a stimulus to the bci:Subject), bci:Action (issued by a bci:Subject while performing a bci:Activity), and bci:ActuationEvent (an effect -change of state- in bci:Context as the result of bci:Actuation)."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-5",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-5-Sentence-1",
              "text": "Observations: describes the contextual input data and events to the subject [3]."
            },
            {
              "iri": "Section-3-Paragraph-5-Sentence-2",
              "text": "Specific concepts aligned to the SOSA/SSN axioms [2] are defined for modeling observations."
            },
            {
              "iri": "Section-3-Paragraph-5-Sentence-3",
              "text": "These are related to bci:Record (a single observation, and input to an actuator), bci:Modality types, aspects (bci:Aspect), channeling specs (bci:ChannelingSpec), sensor output (bci:RecordedData), and bci:StimulusEvent."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-6",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-6-Sentence-1",
              "text": "Actuation: integrated concepts aligned to the SOSA and SAN (IoT-O) axioms for modeling actuations and actuators."
            },
            {
              "iri": "Section-3-Paragraph-6-Sentence-2",
              "text": "This model depicts how the bci:Subject can interact with the bci:Context [3]."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-4",
      "subtitle": "Actuations in the BCI Ontology",
      "paragraphs": [
        {
          "iri": "Section-4-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-1-Sentence-1",
              "text": "This model was developed based on the following premises:"
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-2",
              "text": "Aims to integrate and reconcile SOSA and SAN axioms for modeling actuations and actuators (Fig. 2 and Fig. 3)."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-3",
              "text": "Follows closely the proposed Actuation-Actuator-Effect (AAE) ontology design pattern [4]: a core model for the IoT Ontology (IoT-O)1 [3] (Fig. 3)."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-2-Sentence-1",
              "text": "3.1 Core Abstractions"
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-2",
              "text": "Actuation: Carries out a procedure to change the state of the context using an actuator."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-3",
              "text": "The relationships from and to actuation and other concepts are the ones defined at [2]."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-4",
              "text": "bci:Actuation is aligned to both sosa:Actuation and san:Actuation."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-3-Sentence-1",
              "text": "Actuation Event: Represents a transition (something that has changed from a state to a different one: actuation target) \u2500 a modification (impacted property, as a consequence of an actuation effect) \u2500 in the context as the result of an actuation (actuation result involves actuation event)."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-2",
              "text": "From the context perspective, this concept is a context event (triggered by an actuator) that changes the impacted property of the actuation target."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-3",
              "text": "bci:ActuationEvent is aligned to both bci:Context.Event and san:Effect."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-4",
              "text": "Following the AAE ODP [4], this concept is taken from the following relationships involving the san:Effect definition [5]:"
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-5",
              "text": "san:Actuator - (triggers) -> san:Effect"
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-6",
              "text": "san:Actuation - (involves) -> san:Effect"
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-7",
              "text": "san:Effect - (impacts) -> bci:ImpactedProperty"
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-4-Sentence-1",
              "text": "Actuation Result: It represents the result of an actuation [2], i.e. an entity representing the \u201ceffect\u201d of the actuation, which involves an actuation event."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-2",
              "text": "bci:ActuationResult is aligned to both sosa:Result and san:ActuationValue."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-3",
              "text": "Following the AAE ODP [4], this concept expands the following relationship:"
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-4",
              "text": "san:Actuation - (involves) -> san:Effect"
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-5",
              "text": "Actuation Target: Its modeling depiction is based on the composition of three concepts."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-6",
              "text": "The first, as a sosa:FeatureOfInterest [2]: the thing (actuation target) whose property (impacted property) is being manipulated by an actuator."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-7",
              "text": "The second, related from a sosa:Actuation via the property sosa:hasFeatureOfInterest [2]: a relation between an actuation and the entity (actuation target) whose property (an impacted property as a consequence of an actuation effect) was modified."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-8",
              "text": "And the third one, a bci:Context.Object: a thing (object) in the contextual interaction of the bci:Session."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-9",
              "text": "bci:ActuationTarget is aligned to both bci:Context.Object and sosa:FeatureOfInterest."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-10",
              "text": "Following the AAE ODP [4], this concept captures the definition of sosa:FeatureOfInterest from the following relation:"
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-11",
              "text": "bci:ImpactedProperty - (is property of) -> sosa:FeatureOfInterest"
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-5",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-5-Sentence-1",
              "text": "Actuator: A device that is used by, or implements, an actuation that changes the state of the context."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-2",
              "text": "According to [3], actuators are devices that transform an input signal into a physical output, making them the exact opposite of sensors."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-3",
              "text": "bci:Actuator is aligned to both sosa:Actuator and san:Actuator."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-6",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-6-Sentence-1",
              "text": "Command: Represents a specific order (based on a bci:Record) to an actuator to perform an actuation."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-2",
              "text": "Typically, it depicts an instruction (or signal) that causes an actuator to perform (executes) one of its basic functions, and thus, triggering an actuation."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-3",
              "text": "A command defines the input for a set of actuators from a specific source: a set of bci:Record."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-4",
              "text": "bci:Command is aligned to both dul:Method and san:ActuatorInput."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-5",
              "text": "Following the AAE ODP [4], this concept is based on the following definition:"
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-6",
              "text": "[AAE::Actuator] - (AAE::consumes) -> [AAE::Input]"
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-7",
              "text": "bci:Actuator - (bci:executes) -> bci:Command"
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-7",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-7-Sentence-1",
              "text": "Impacted Property: Represents an actuatable quality (property or characteristic) of an actuation target."
            },
            {
              "iri": "Section-4-Paragraph-7-Sentence-2",
              "text": "An actuator connects to an impacted property (as a consequence of an actuation effect) via the object property ssn:forProperty [2], i.e., an actuator triggers an actuation event that causes an effect (modification) on the actuation target: impacted property [4]."
            },
            {
              "iri": "Section-4-Paragraph-7-Sentence-3",
              "text": "bci:ImpactedProperty is aligned to sosa:ActuatableProperty."
            },
            {
              "iri": "Section-4-Paragraph-7-Sentence-4",
              "text": "Following the AAE ODP [4], this concept captures the definition of Impacted Property (linked to san:Effect) from the following relationships:"
            },
            {
              "iri": "Section-4-Paragraph-7-Sentence-5",
              "text": "san:Effect - (impacts) -> bci:ImpactedProperty"
            },
            {
              "iri": "Section-4-Paragraph-7-Sentence-6",
              "text": "bci:ImpactedProperty - (is property of) -> sosa:FeatureOfInterest"
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-8",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-8-Sentence-1",
              "text": "3.2 Modeling Integration: BCI-O Context Model with SOSA and SAN Alignments"
            },
            {
              "iri": "Section-4-Paragraph-8-Sentence-2",
              "text": "As a broad application domain ontology for BCI activities, BCI-O integrates and refines some modeling considerations of the SOSA and SAN concepts regarding actuations and actuators."
            },
            {
              "iri": "Section-4-Paragraph-8-Sentence-3",
              "text": "The \u201ccontext-aware\u201d domain level concepts were aligned initially to SOSA/SSN."
            },
            {
              "iri": "Section-4-Paragraph-8-Sentence-4",
              "text": "Afterwards, they were integrated with proper alignments to SAN (IoT-O), following closely their axiomatization satisfiability."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-9",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-9-Sentence-1",
              "text": "The main modeling integration was done with the actuation event alignment to san:Effect (or san:ActuatorOutput)."
            },
            {
              "iri": "Section-4-Paragraph-9-Sentence-2",
              "text": "san:Effect is defined in [5] as \u201cconcept bound to the definition of an actuator as an agent having an effect on the physical world."
            },
            {
              "iri": "Section-4-Paragraph-9-Sentence-3",
              "text": "Therefore, an effect is any kind of physical modification induced by an actuator\u201d."
            },
            {
              "iri": "Section-4-Paragraph-9-Sentence-4",
              "text": "In order to be more semantically precise, and based on the SOSA/SSN definitions aligned with Dolce-Ultralite (DUL) in [2] (Vertical Segmentation: DUL alignment module), the concept san:Effect is described distinctively by the following combined ontological notions along with BCI-O's Context Model:"
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-10",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-10-Sentence-1",
              "text": "A happening that impacts a quality (dul:Quality), or property (ssn:Property), with the capability of an actuation to act on it (sosa:actsOnProperty), that is, a type of sosa:ActuatableProperty, i.e. the bci:ImpactedProperty."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-11",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-11-Sentence-1",
              "text": "An event (dul:Event) triggered by an actuator, that modifies (changes) the physical world (actuation target): a type of bci:Context.Event; the actuation event."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-12",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-12-Sentence-1",
              "text": "(An effect is seeing as...) Any kind (of an impacted property) of physical modification (an effect on the physical world \u2014 context) as the result of an actuation (an actuation result involves an actuation event), induced by an actuator (a characteristic of its nature, as an agent that has an effect on the context)."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-13",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-13-Sentence-1",
              "text": "An actuation event is a bci:Context.Event triggered by an actuator that changes the state of the actuation target (which is a bci:Context.Object) (see Fig. 4)."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-14",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-14-Sentence-1",
              "text": "Another inherited modeling perspective for BCI, comes from the definition of san:impacts object property: san:Effect - ( san:impacts ) -> oldssn:Property."
            },
            {
              "iri": "Section-4-Paragraph-14-Sentence-2",
              "text": "Also, BCI-O's alignment to SAN allows the following inferred relationship:"
            },
            {
              "iri": "Section-4-Paragraph-14-Sentence-3",
              "text": "bci:ActuationEvent - (\u00b7san:impacts\u00b7) -> bci:ImpactedProperty"
            },
            {
              "iri": "Section-4-Paragraph-14-Sentence-4",
              "text": "Last, in order to be consistent in the BCI-O's overall structure and intention, direct alignments to DUL were considered carefully evaluating the scope and constraints for each concept, which led to properly define class hierarchies and disjoint axioms, especially for its Actuation Model."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-5",
      "subtitle": "Use Case: Automated Wheelchair Driving",
      "paragraphs": [
        {
          "iri": "Section-5-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-1-Sentence-1",
              "text": "The following use case depicts how to define related BCI-O actuation concepts (its description and source code is available online in the spec's human-readable version [1])."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-2",
              "text": "Its purpose is to use an actuator capable to control a wheelchair based on the input from a BCI/EEG record (obtained directly from the subject's head)."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-3",
              "text": "In this use case, Alice is driving a wheelchair throughout a human interface composed of three major components: (1) an EEG sensor capable of reading brain signals, (2) a computing system capable to process and analyze (classify) the brain signals collected from the EEG sensor, and (3) an actuator capable to control the wheelchair's movement (such as direction and acceleration) based on the input from the EEG recordings."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-4",
              "text": "The actuator is a device that implements the procedure (actuation) to control the wheelchair, which triggers a series of steps aimed to change the wheelchair's state, such as to decelerate its wheels."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-5",
              "text": "The input to the actuator are the observed and processed brain signals that issue specific movement commands."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-6",
              "text": "For example, the \u201cslow down\u201d command with the parameters (and values) of \u201cdirection\u201d (\u201cgo forward\u201d -no change in the direction-) and \u201cacceleration\u201d (-10.5 cm/s\u00b2 -change in the speed-)."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-7",
              "text": "The modeled concepts involved in this scenario (see Fig.5), excluding those from the observation component (except EEG-Record and EEG-Device), are listed below:"
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-2-Sentence-1",
              "text": "bci:Subject (1 individual = x1): \u201cAlice\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-2",
              "text": "bci:Session (x1): \u201ca situation where the EEG recording and actuation happened\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-3",
              "text": "bci:Activity (x1): \u201ccontrolling the automated wheelchair\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-4",
              "text": "bci:Context (x1): \u201cat home\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-5",
              "text": "bci:Context.Scene (x1): \u201cspecific indoors situation\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-6",
              "text": "bci:EegRecord (x1): \u201cEEG observation that serves as the input of the actuations\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-7",
              "text": "bci:EegDevice (x1): \u201cEEG device that made the EEG recordings\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-8",
              "text": "bci:Command (x1): \u201cslow down\u201d, actuators' input from the EEG record."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-9",
              "text": "bci:Actuator (2 individuals = x2): \u201cthe devices that perform the actuations\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-10",
              "text": "bci:Actuation (x2): \u201cprocedures that change the state of the wheels via actuators\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-11",
              "text": "bci:ImpactedProperty (x2): \u201cthe speed of the wheels (their state)\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-12",
              "text": "bci:ActuationEvent (x2): \u201creduce the speed of wheels\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-13",
              "text": "bci:ActuationResult (x2): \u201cslowing down\u201d (\u201ceffect of decelerating the wheels\u201d)."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-14",
              "text": "bci:ActuationTarget (x2): \u201ctwo rear wheels\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-15",
              "text": "bci:Context.Object (composite) (x1): \u201cwheelchair\u201d."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-16",
              "text": "bci:Context.Method (x1): \u201cdeceleration of a wheel\u201d."
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-3-Sentence-1",
              "text": "BCI-O's Actuation Model provides a mechanism to correlate the observed/analyzed raw data [1], with the contextual components that the subject interacts with, through actuators (IoT devices), identifying how the actuations affect the context."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-2",
              "text": "This is useful in BCI context-aware applications to model how subjects use actuators and interact with the environment, for \u201cintelligent\u201d subject-context personalization."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-6",
      "subtitle": "Conclusion",
      "paragraphs": [
        {
          "iri": "Section-6-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-1-Sentence-1",
              "text": "BCI-O's Actuation Model integrates carefully both standard axiomatization models for actuations, developed by W3C/OGC [2] and IoT [3] [5] communities, based on its Context Model."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-2",
              "text": "Thus, its structure follows closely the AAE ODP [4], while aligning to SOSA/SSN and SAN (IoT-O) concepts, based on contextual notions."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-3",
              "text": "The SOSA-SAN integrated Actuation Model of BCI-O represents a major contribution to the IoT and BCI communities, especially because its structure includes contextual notions that enables its usage in context-aware BCI-IoT integrated applications."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-4",
              "text": "Semantically-enabled BCIs will play a key role in the future \u201cInternet of Brains\u201d interoperating completely with IoT [6]."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-5",
              "text": "Under this vision, where one could semantically model, interoperate and control real life objects throughout BCIs connected to the Internet, BCI-O's Actuation Model would become a core semantic structure that integrates BCI, IoT, and contextual concepts in real-world scenarios."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-6",
              "text": "It is important noting that as part of the BCI-O's Actuation Model development, the author raised the issue to the W3C Spatial Data on the Web Working Group [7], regarding the mapping of SOSA/SSN to AAE ODP, due of their structural resemblance."
            }
          ]
        }
      ]
    }
  ],
  "summary": "Recent technological developments in Brain-Computer Interfaces (BCI) will largely enable BCI as a powerful, natural and intuitive mainstream human-computer interaction (HCI) in real-world activities, especially throughout actuators connected to the Internet. As a type of sensor-actuator system, BCI will integrate novel interfaces that will be fully interoperating with IoT-based systems. An ontological metadata overlay for BCI systems in real-world applications is defined in the BCI Ontology (BCI-O), which formalizes and integrates BCI-domain-specific Sense and Actuation Models along with a novel Context Model for describing any kind of real/virtual environments. This paper presents the design principle of BCI-O's Actuation Model, which integrates SOSA and SAN (IoT-O) axioms for actuations and actuators along with the BCI-O's Context Model. This model will become relevant in the degree as context-based semantic interoperability will become a core pre-requisite for any context-aware BCI actuation application with real-time collaboration in IoT environments.\n\nBrain-Computer Interfaces (BCI) are systems that determine a user's brain states by collecting and analyzing her neurophysiological signals (which are highly situational, individual dependent, and non-stationary in characteristics) and then actuating specific responses, for example to drive her wheelchair autonomously. Key developments in wearable sensors, wireless networks, and distributed computing will largely enable BCI as a powerful, natural and intuitive mainstream human-computer interaction (HCI) in real-world activities. In a not too far future, BCI will be regarded as the ultimate HCI system, integrating novel interfaces that will be fully interoperating with Internet-of-Things- (IoT)-based systems. In this scenario, context-based semantic interoperability will be a core pre-requisite for any context-aware BCI application with real-time collaboration in IoT environments. The BCI Ontology (BCI-O) [1] is the first OWL 2 ontology that formalizes relevant metadata for BCI data capture activities by integrating BCI-domain-specific Sense and Actuation Models along with a novel Context Model for describing any kind of real/virtual environments. Due that BCI is a type of sensor-actuator system, as an ontological metadata overlay for BCI systems in real-world applications, BCI-O is properly aligned with the W3C Semantic Sensor Network (SSN) and Sensor, Observation, Sample, and Actuator (SOSA) [2] upper ontologies. Because many BCI devices, especially actuators, are connected to the Internet, BCI-O is also aligned with the core actuation semantic model for the IoT ontology (IoT-O) [3]: the Semantic Actuator Network (SAN) [5]. BCI-O makes an important contribution: the introduction of the concepts of context and contextual relations [1]. This puts the architectural description of any context as a first-class semantic model that enables BCI applications to be context-aware, laying the foundations of meaningful interactions with IoT-based systems. This paper presents the structure and design principle of BCI-O's Actuation Model, which integrates SOSA and SAN (IoT-O) axioms for actuations and actuators along with the BCI-O's Context Model. A use case for this model is explained in a subsequent section. Lastly, the main contribution is summarized in the conclusions.\n\nBCI-O origins, purpose, core models, global overview, public access (spec and examples), design principles, and applications are described in [1]. At its core, BCI-O defines the conceptual components in any BCI through a bidirectional subject-context interaction model (a BCI session with sensors/actuators): a Sense Model (context to subject) and an Actuation Model (subject to context), as depicted in Fig. 1. Its Actuation Model is based on the\n\nTwo distinct conceptual domains are found in this interaction model: BCI domain (observations, actuations, and interactions) and context domain (surroundings). Following, a brief description of BCI-O's core modules related to actuations are presented:\n\nSession: represents the interaction between a bci:Subject and a bci:Context while performing (bci:Session) a single bci:Activity. A bci:Session groups both observations (multimodal records: bci:Record) and actuations (bci:Actuation).\n\nContext: captures the architectural description of any physical/virtual environment. Its conceptual components enable the structural, functional, and temporal complexity definitions of any environment (Fig. 4). Under the bci:Context.Event classification, BCI-O defines three key concepts that bind the contextual integration (including with its Actuation Model): bci:StimulusEvent (a stimulus to the bci:Subject), bci:Action (issued by a bci:Subject while performing a bci:Activity), and bci:ActuationEvent (an effect -change of state- in bci:Context as the result of bci:Actuation).\n\nObservations: describes the contextual input data and events to the subject [3]. Specific concepts aligned to the SOSA/SSN axioms [2] are defined for modeling observations. These are related to bci:Record (a single observation, and input to an actuator), bci:Modality types, aspects (bci:Aspect), channeling specs (bci:ChannelingSpec), sensor output (bci:RecordedData), and bci:StimulusEvent.\n\nActuation: integrated concepts aligned to the SOSA and SAN (IoT-O) axioms for modeling actuations and actuators. This model depicts how the bci:Subject can interact with the bci:Context [3].\n\nThe BCI-O (Brain-Computer Interface Ontology) integrates SOSA and SAN axioms to model actuations and actuators. It follows the Actuation-Actuator-Effect ontology design pattern, aligning with IoT-ontology. The main concepts include: Actuation, which carries out a procedure using an actuator; Actuation Event, representing a transition in context as a result of an actuation; Actuation Result, representing the effect of an actuation; and Impacted Property, representing an actuatable quality of an actuation target.\n\nThe following use case depicts how to define related BCI-O actuation concepts (its description and source code is available online in the spec's human-readable version [1]). Its purpose is to use an actuator capable to control a wheelchair based on the input from a BCI/EEG record (obtained directly from the subject's head). In this use case, Alice is driving a wheelchair throughout a human interface composed of three major components: (1) an EEG sensor capable of reading brain signals, (2) a computing system capable to process and analyze (classify) the brain signals collected from the EEG sensor, and (3) an actuator capable to control the wheelchair's movement (such as direction and acceleration) based on the input from the EEG recordings. The actuator is a device that implements the procedure (actuation) to control the wheelchair, which triggers a series of steps aimed to change the wheelchair's state, such as to decelerate its wheels. The input to the actuator are the observed and processed brain signals that issue specific movement commands. For example, the \u201cslow down\u201d command with the parameters (and values) of \u201cdirection\u201d (\u201cgo forward\u201d -no change in the direction-) and \u201cacceleration\u201d (-10.5 cm/s\u00b2 -change in the speed-). The modeled concepts involved in this scenario (see Fig.5), excluding those from the observation component (except EEG-Record and EEG-Device), are listed below:\n\nbci:Subject (1 individual = x1): \u201cAlice\u201d. bci:Session (x1): \u201ca situation where the EEG recording and actuation happened\u201d. bci:Activity (x1): \u201ccontrolling the automated wheelchair\u201d. bci:Context (x1): \u201cat home\u201d. bci:Context.Scene (x1): \u201cspecific indoors situation\u201d. bci:EegRecord (x1): \u201cEEG observation that serves as the input of the actuations\u201d. bci:EegDevice (x1): \u201cEEG device that made the EEG recordings\u201d. bci:Command (x1): \u201cslow down\u201d, actuators' input from the EEG record. bci:Actuator (2 individuals = x2): \u201cthe devices that perform the actuations\u201d. bci:Actuation (x2): \u201cprocedures that change the state of the wheels via actuators\u201d. bci:ImpactedProperty (x2): \u201cthe speed of the wheels (their state)\u201d. bci:ActuationEvent (x2): \u201creduce the speed of wheels\u201d. bci:ActuationResult (x2): \u201cslowing down\u201d (\u201ceffect of decelerating the wheels\u201d). bci:ActuationTarget (x2): \u201ctwo rear wheels\u201d. bci:Context.Object (composite) (x1): \u201cwheelchair\u201d. bci:Context.Method (x1): \u201cdeceleration of a wheel\u201d.\n\nBCI-O's Actuation Model provides a mechanism to correlate the observed/analyzed raw data [1], with the contextual components that the subject interacts with, through actuators (IoT devices), identifying how the actuations affect the context. This is useful in BCI context-aware applications to model how subjects use actuators and interact with the environment, for \u201cintelligent\u201d subject-context personalization.\n\nBCI-O's Actuation Model integrates carefully both standard axiomatization models for actuations, developed by W3C/OGC [2] and IoT [3] [5] communities, based on its Context Model. Thus, its structure follows closely the AAE ODP [4], while aligning to SOSA/SSN and SAN (IoT-O) concepts, based on contextual notions. The SOSA-SAN integrated Actuation Model of BCI-O represents a major contribution to the IoT and BCI communities, especially because its structure includes contextual notions that enables its usage in context-aware BCI-IoT integrated applications. Semantically-enabled BCIs will play a key role in the future \u201cInternet of Brains\u201d interoperating completely with IoT [6]. Under this vision, where one could semantically model, interoperate and control real life objects throughout BCIs connected to the Internet, BCI-O's Actuation Model would become a core semantic structure that integrates BCI, IoT, and contextual concepts in real-world scenarios. It is important noting that as part of the BCI-O's Actuation Model development, the author raised the issue to the W3C Spatial Data on the Web Working Group [7], regarding the mapping of SOSA/SSN to AAE ODP, due of their structural resemblance.",
  "kg2text": [
    "The Brain-Computer Interface (BCI) Ontology, or BCI-O, integrates Sense and Actuation Models from SOSA and SAN for describing real-world environments. This integration enables context-based semantic interoperability between BCIs and IoT-based systems. The design principle of the Actuation Model is based on the Context Model, which formalizes and integrates domain-specific models. The BCI Ontology also includes a novel Context Model that describes actuations and actuators in Brain-Computer Interface applications. Furthermore, the degree as context-based semantic interoperability will become a core pre-requisite for any context-aware BCI actuation application with real-time collaboration in IoT environments.",
    "The SOSA- SAN entity integrates the design principle of BCI-O's Actuation Model, which formalizes and integrates domain-specific Sense and Actuation Models along with a novel Context Model. This model enables semantic interoperability in context-aware applications by integrating actuations and actuators from SOSA and IoT Ontology (SAN). The BCI-Ontology (BCI-O) is an ontological metadata overlay for Brain-Computer Interfaces systems, formalizing relevant metadata to describe real-world environments. It integrates the Actuation Model of BCI-O with its Context Model, enabling context-based semantic interoperability between BCIs and IoT-based systems. Furthermore, it describes various applications that integrate Sense and Actuation Models with a Context Model for describing real-world environments.",
    "The Brain-Computer Interface (BCI) Ontology, or BCI-O, defines its description and source code online. It integrates Sense and Actuation Models from SOSA and SAN axioms for actuations and actuators along with a novel Context Model. This integration enables context-based semantic interoperability between BCIs and IoT systems. The ultimate HCI system will integrate the BCI Ontology to enable natural interactions. Novel interfaces allow seamless communication, formalizing domain-specific models of brain-computer interfaces.",
    "The design principle of BCI-O's Actuation Model integrates An ontological metadata overlay, which formalizes and integrates Sense and Actuation Models with a novel Context Model for describing real-world environments. This model combines SOSA-SAN axioms for actuations and actuators along with the BCI-O's Context Model to describe brain-computer interfaces in IoT applications. The integration of these models enables semantic interoperability, which is crucial for context-aware BCI-IoT integrated applications. In fact, achieving high-level contextual understanding and seamless data exchange between BCI systems and IoT devices will become a core prerequisite for any context-aware BCI actuation application with real-time collaboration in IoT environments.",
    "BCI systems in real-world applications integrate This model, which formalizes and integrates Sense and Actuation Models with a novel Context Model. The design principle of BCI-O's Actuation Model enables context-based semantic interoperability, allowing for novel interfaces to emerge. The SOSA-SAN integrated Actuation Model of BCI-O aligns actuations and actuators from both ontologies, formalizing relevant metadata for Brain-Computer Interface systems. As a result, applications are described in [1], which describe various real-world environments where BCIs operate.",
    "The BCI Ontology (BCI-O) describes a standardized framework for formalizing and integrating domain-specific models of brain-computer interfaces. Its design principle enables the ultimate HCI system, which integrates novel interfaces with IoT-based systems to enable natural interactions. The Actuation Model of BCI-O enables various applications, including BCIs in real-world scenarios that integrate Sense and Actuation Models with a Context Model for describing environments. SOSA-SAN aligns actuations and actuators from both ontologies, enabling context-aware BCI-IoT integrated applications. As the degree of context-based semantic interoperability becomes crucial for any context-aware BCI application, an ontological metadata overlay formalizes relevant metadata to describe real-world environments.",
    "BCI systems in real-world applications enable context-based semantic interoperability, integrating novel interfaces with IoT-based systems. An ontological metadata overlay formalizes and integrates domain-specific Sense and Actuation Models along with a novel Context Model for describing real/ virtual environments. The BCI Ontology (BCI-O) defines BCIs that integrate SOSA and SAN axioms for actuations and actuators, enabling seamless communication between Brain-Computer Interfaces (BCI) and Internet of Things (IoT)-based systems in real-time. In the future, a novel Context Model will become a core pre-requisite for any context-aware BCI actuation application with real-time collaboration in IoT environments.",
    "The Actuation Model of BCI-O, which integrates SOSA and SAN axioms for actuations and actuators along with the BCI-O's Context Model, formalizes relevant metadata for Brain-Computer Interface (BCI) systems. This paper presents the design principle of BCI-O's Actuation Model, which enables context-based semantic interoperability between BCI and IoT-based systems. The integration of SOSA and SAN axioms in the Actuation Model allows for seamless communication between brain-computer interfaces and Internet-of-Things devices. Furthermore, novel interfaces integrate seamlessly with a bci to enable natural and intuitive interactions.",
    "The integration of BCI-Ontology (BCI-O) with SAN, specifically aligning actuation concepts and axioms from both ontologies. The degree as context-based semantic interoperability will become a core pre-requisite for any context-aware BCI actuation application with real-time collaboration in IoT environments. This model integrates SOSA and SAN axioms for actuations and actuators along with the BCI-O's Context Model, enabling seamless communication between Brain-Computer Interfaces (BCI) and Internet-of-Things (IoT)-based systems in real-time. Novel interfaces enable novel forms of human-computer interaction.",
    "The ultimate HCI system will become a context-awared BCI actuation application with real-time collaboration in IoT environments. Its Actuation Model integrates This model, which describes how the BCI subject interacts with its context. The SOSA-SAN integrated Actuation Model of BCI-O integrates An ontological metadata overlay and defines the BCI Ontology's Context Model. The Actuation Model of BCI-O enables context-based semantic interoperability, while novel interfaces enable applications described in [1].",
    "The Actuation Model of BCI-O integrates The SOSA-SAN integrated Actuation Model of BCI-O, which describes various applications that integrate Sense and Actuation Models with a Context Model for describing real-world environments. This model enables context-based semantic interoperability, allowing brain-computer interfaces to seamlessly communicate with Internet-of-Things systems in real-time. Furthermore, the ultimate HCI system will integrate this actuation model, enabling novel forms of human-computer interaction. The BCI-O's Context Model describes how actuators interact with their contexts and integrates SOSA and SAN axioms for actuations and actuators. This context-aware framework enables personalized interactions through brain-computer interfaces.",
    "The SOSA-SAN integrated Actuation Model of BCI-O integrates and aligns with BCIO's alignment to SAN, enabling context-aware interactions. This model describes how brain-computer interfaces (BCI) integrate seamlessly with Internet-of-Things (IoT)-based systems, allowing for novel forms of human-computer interaction. The ultimate HCI system will integrate this actuation model, which enables seamless communication and novel interfaces. A use case is explained in a subsequent section for this model.",
    "The SOSA-SAN integrated Actuation Model of BCI-O integrates Its Actuation Model, which will enable novel interfaces to seamlessly integrate with IoT-based systems. The ultimate HCI system will be a context-aware application that leverages brain-computer interfaces and Internet of Things technologies. BCIs have broader terms in the form of ABCs, while context-semantic interoperability is crucial for BCI applications. The architectural description of any context as a first-class semantic model enables meaningful interactions with IoT-based systems. W3C Semantic Sensor Network (SSN) and Sensor, Observation, Sample, and Actuator (SOSA) ontologies align with the SOSA-SAN integrated Actuation Model of BCI-O, which integrates Sense and Actuation Models.",
    "The development of Brain-Computer Interface (BCI) technology has been significantly enabled by recent advancements, such as wearable sensors and wireless networks. The BCI Ontology (BCI-O), an open-source brain-computer interface system or technology, makes a crucial contribution to the introduction of context-aware interactions with IoT-based systems. This ontology formalizes and integrates domain-specific Sense and Actuation Models along with a novel Context Model. As part of this framework, actuations refer to the process or event that enables interaction between a BCI subject and its context. The architectural description of any context as a first-class semantic model lays the foundations for meaningful interactions with IoT-based systems. Brain-Computer Interfaces (BCIs) are technologies that enable communication between humans and computers through direct neural activity, allowing control of devices or acquisition of cognitive data.",
    "The bidirectional subject-context interaction model, defined by BCI-O, enables brain-computer interfaces to adapt and respond to changing user contexts. This context-awareness is crucial for personalized interactions between humans and machines. The actuation concepts developed in this framework allow for control of devices or systems using brain signals, as seen in the use case where Alice controls a wheelchair. Furthermore, BCI-O's Actuation Model represents a major contribution to the IoT and BCI communities by providing a comprehensive overview of brain-computer interfaces' origins, purpose, core models, global design principles, and applications.",
    "In the context of brain-computer interfaces, this architectural description enables meaningful interactions with IoT-based systems. Semantically-enabled BCIs have a broader term as BCIs, which are used to connect humans and machines. The BCI domain has a broader term as Brain-Computer Interfaces (BCI), encompassing observations, actuations, and interactions. A brain-computer interface application is enabled by this description, allowing users to interact with digital applications. As context-based semantic interoperability becomes a core pre-requisite for any context-aware BCI actuation application with real-time collaboration in IoT environments, the requirement of achieving high-level contextual understanding and seamless data exchange between BCIs systems and IoT devices enables effective real-time collaboration.",
    "Recent technological developments have enabled Brain-Computer Interface (BCI) systems to become powerful, natural and intuitive mainstream human-computer interactions. BCI context-aware applications adapt and respond to changing user contexts, enabling personalized interactions with IoT-based systems. The SOSA-SAN entity refers to the integrated actuation model of Brain-Computer Interface Ontology (BCI-O), which combines Sense and Actuation Model for actuators and IoT-based systems with contextual notions. BCIs are technologies that enable communication between humans and computers through direct neural activity, allowing for control of devices or acquisition of cognitive data.",
    "In the realm of novel interfaces, Brain-Computer Interfaces (BCIs) seamlessly integrate with Internet of Things (IoT)-based systems. These interfaces enable real-time collaboration and meaningful interactions between humans and machines. The BCI-O's Actuation Model integrates SOSA/SSN and SAN (IoT-O) axioms for actuations and actuators, allowing for context-aware applications. The architectural description of any context as a first-class semantic model enables BCIs to interact with IoT-based systems in real-time. Furthermore, the BCI- domain encompasses observations, actuations, and interactions between humans and machines.",
    "The BCI-O Context Model integrates Sense and Actuation Models from SOSA and IoT- Ontology (SAN) for describing real-world environments, enabling context-based semantic interoperability between Brain-Computer Interfaces (BCI) and Internet of Things (IoT)-based systems. A set of bci:Record serves as inputs to define commands for multiple actuators in a BCI session with sensors/actuators. The Actuation Model (subject to context) enables interactions between subjects and their contexts, while the architectural description of any context as a first-class semantic model that enables BCI applications to be context-aware lays the foundations of meaningful interactions with IoT-based systems.",
    "Brain-Computer Interfaces (BCI) determine user brain states, which are then used to control actuators. The design principle of BCI-O's Actuation Model integrates Sense and Actuation Models with a novel Context Model to describe real/virtual environments. A set of bci:Record serves as input for controlling multiple actuators based on EEG recordings from the subject's head. BCIs, IoT devices, and brain signals all work together seamlessly through semantic interoperability.",
    "In this context, core models define the interaction between brain-computer interfaces (BCIs) and their environments. The degree of semantic interoperability will become a crucial requirement for any BCI actuation application with real-time collaboration in IoT settings. Wearable sensors enable BCIs to be powerful, natural, and intuitive human-computer interactions. This model integrates SOSA and SAN axioms for actuations and actuators along with the BCI-O's Context Model. The main modeling integration reconciles these concepts to formalize relevant metadata for BCI systems. Actuations carry out procedures to change states using actuators, while distributed computing enables novel interfaces like BCIs.",
    "The Standard Ontology for Semantic Annotation (SOSA) formalizes and integrates Sense and Actuation Models in Brain-Computer Interface (BCI) systems. SOSA, along with SAN (IoT-O), enables context-based semantic interoperability between BCI applications and IoT environments. The SOSA-SAN integrated Actuation Model of BCI-O describes how the BCI subject interacts with its context. This model is based on the architectural description of any context as a first-class semantic model that enables BCI applications to be context-aware, laying the foundations for meaningful interactions with IoT-based systems. Wireless networks will enable BCIs as powerful, natural and intuitive mainstream human-computer interaction (HCI). The SOSA- SAN integrated Actuation Model of BCI-O is an open-source brain-computer interface system or technology that integrates principles from SOSA, SAN (IoT-O), and its Context Model for actuation purposes. This model has a broader term as 'modeled concepts'.",
    "Brain-Computer Interfaces (BCI) devices are connected to the Internet, enabling communication between humans and machines. BCI-O actuation concepts have a broader term of modeled concepts, which formalize principles for controlling or manipulating brain-computer interfaces. The procedure (actuation) has a broader term of actuations, referring to processes that trigger changes in state through actuators. A set of bci:Record serves as input to define commands for multiple actuators. Actuator alignment with san:Effect (or san:ActuatorOutput) is crucial for modeling integration. BCI-ontology integrates SOSA and SAN axioms for actuations, aligning context-aware domain level concepts to SOSA/SSN and refining them with proper alignments to SAN (IoT-O).",
    "The BCI-ontology (BCI-O) provides an open-source brain-computer interface system or technology. It has a broader term, 'modeled concepts', which are abstract representations or notions that have been created to describe a particular idea, thought, or notion. The use case depicts how to define related BCI-O actuation concepts, specifically focusing on actuators, commands, and actuations that control a wheelchair's movement based on brain signals from an EEG record. Actuations represent the concept of Actuations, referring to a process or event that enables interaction between a Brain-Computer Interface (BCI) subject and its context. The SOSA ontology definitions aligned with Dolce-Ultralite (DUL) in [2] have been integrated into BCI-O's Actuation Model for modeling actuations and actuators. This model aims to integrate and reconcile SOSA and SAN axioms, representing the outcome or state that results from an action or process. The context domain refers to the surroundings or environment within which something exists or operates.",
    "The use case demonstrates how Brain-Computer Interfaces (BCI) can be used to control a wheelchair autonomously. This actuation concept relies on Sense and Actuation Models, which formalize domain-specific representations of sensory perception and motor control processes. The BCI drives her wheelchair using brain signals from an EEG record, showcasing the application of modeled concepts in real-world scenarios. In this context, the bidirectional subject-context interaction model enables a seamless exchange between internal states or intentions and external actions. Actuation models are crucial for understanding how devices like bci:Actuator execute commands to produce specific responses. The BCI- O's Context Model represents a research framework that captures contextual information from IoT environments, which can be used to analyze the effectiveness of actuations in changing the state of the context.",
    "The BCI-ontology's Actuation Model integrates SOSA and SAN axioms for modeling actuations and actuators, defining relationships between actuation events, results, targets, and impacted properties. This model aligns with san:Effect, which represents a physical modification induced by an actuator on its target. The IoT communities developed standard axiomatization models for actuations, formalizing SOSA and SAN axioms for actuations and actuators. In the context of real/virtual environments, this integration enables bidirectional subject-context interaction modeling, where brain signals recorded using EEG sensors control a wheelchair's movement. This framework also encompasses multimodal records containing both observational data and actuator interactions within a Brain-Computer Interface session.",
    "In a Brain-Computer Interface (BCI) session, a subject interacts with its context through actuations and observations. The BCI subject refers to an individual or agent that receives stimuli from its environment. A stimulus event can trigger an actuation, which produces a desired outcome or effect. Actuations are controlled by actuators, which modify the state of their targets. In this framework, standard axiomatization models for actuations formalize and structure SOSA and SAN axioms for actuations and actuators. The sense model maps contextual information to subjects or vice versa, facilitating bidirectional interactions.",
    "In a brain-computer interface (BCI) session, core models define the interaction between subjects and context. Actuations are controlled by actuators that produce desired outcomes or effects. Sense models represent relationships between internal states and external environments. Stimulus events trigger actuation targets, which impact properties or qualities. IoT-based systems utilize devices to collect data autonomously. The AAE ODP formalizes actuations and actuators in the context of BCI. Context captures architectural descriptions of physical/virtual environments.",
    "In a Brain-Computer Interface (BCI) system, channeling specs define how data from sensors to actuators are processed. Actuators perform actions or operations based on control signals. The Context captures architectural descriptions of physical and virtual environments, while bci:Aspect represents characteristics of BCI records. AAE ODP formalizes axioms for actuators and their connections to the internet. Internet of Brains enables real-time collaboration in IoT environments. Brain signals are processed by a computing system capable of classifying them, issuing specific movement commands that control wheelchair movements.",
    "In the context of Brain-Computer Interfaces (BCI), specific concepts align with SOSA/SSN axioms, used to model observations. The bci:Context provides a conceptual framework for interactions between subjects and their environments. Integrated concepts build upon SOSA and SAN axioms to describe actuations and actuators. Another inherited modeling perspective for BCI considers the context perspective from which something is evaluated or understood. A computing system capable of processing brain signals collected from EEG sensors enables control over wheelchair movement, with commands like 'slow down' providing direction. Direct alignments to DUL ensure proper definition of class hierarchies and disjoint axioms in Actuation Models. The bci:Actuator transforms input signals into physical outputs, while the san:ActuatorInput provides data for actuator execution.",
    "The concept of brain-computer interfaces (BCI) enables communication between the human brain and external devices or computers. In this context, an actuator capable to control a wheelchair's movement based on EEG recordings plays a crucial role in implementing procedures that change its state. This process is facilitated by BCI-O's Context Model, which represents a research model used to understand contextual information. The concept of san:Effect describes any kind of physical modification induced by an actuator triggered by an event and impacting a quality or property. Furthermore, SOSA/SSN and SAN (IoT- O) concepts provide standard axiomatization models for actuations developed by W3C/OGC and IoT communities based on contextual notions.",
    "Standard axiomatization models for actuations, which formalize and structure SOSA and SAN axioms for actuations and actuators, have been carefully integrated. Modeled concepts refer to abstract representations or notions that describe a particular idea, thought, or notion. A subject participating in an interaction with its context represents the relationship between them during a specific activity or session. IoT environments are networks of interconnected devices, sensors, and actuators that collect and exchange data to enable smart interactions. The concept of san:Effect refers to an event triggered by an actuator that modifies a quality or property, resulting in physical modification induced by the actuation. Recent technological developments have enabled natural and intuitive human-computer interactions through actuators connected to the internet.",
    "The actuation target, which can be an actuator capable of controlling wheelchair movement based on EEG recordings, interacts with brain signals to produce a desired outcome. This process involves modeling concepts such as Sense and Actuation Models, which formalize sensory perception and motor control processes. The context event triggered by the actuator induces changes in the physical world, resulting from the interaction between the subject's intentions and the environment. These events are represented by bci:Context.Event, which has a broader term of 'event'.",
    "The future 'Internet of Brains' envisions a network that enables direct communication and information exchange between human brains, potentially integrating them into a collective intelligence. This concept is described distinctively by combined ontological notions along with BCI-O's Context Model. The devices that perform the actuations are connected to actuators, which control physical effects such as movement or control. Actuation events involve changes in state of an actuator target, typically initiated by external agents. In this context, a model is used to simulate and predict behavior, while san:Actuators trigger specific effects when triggered.",
    "The actuation model integrates SOSA and SAN axioms for modeling actuations and actuators, defining relationships between actuation events, results, targets, and impacted properties. Actuators trigger context events that modify qualities or properties of their targets. The procedure (actuation) implemented by an actuator device changes the state of its wheels via control mechanisms. Brain-controlled interfaces use SAN to standardize components for controlling devices like wheelchairs. In this domain, actuatable qualities are modified through procedures performed by actuators.",
    "In this context, Alice controls her automated wheelchair using brain signals and EEG recordings at home. The slow down command is an action that carries out a procedure to change the state of the context using an actuator. This process induces physical modification in the environment, which can be modeled as concepts such as san:Effect. The devices performing these actuations are actuators that transform input into physical outputs. An EEG sensor capable of reading brain signals is used to obtain direct input from Alice's head, allowing her to control the wheelchair through an actuator.",
    "The actuator, capable of controlling a wheelchair, manipulates 'the first' to change its state. This process aligns with the concept of san:Actuation, which represents an event triggered by an actuator that modifies a quality or property. The broader context is defined as bci:Context.Scene, where various modalities are channelled through specifications like bci:ChannelingSpec and bci:Modality types. In this scenario, 'Carries out a procedure to change the state of the context using an actuator' represents a specific event that initiates or modifies an action. The architectural description outlines the structure and features of this system.",
    "In this scenario, Alice controls her wheelchair using an actuator based on brain signals recorded by an EEG sensor. The command represents a specific order to perform an actuation, which the actuator executes. This process involves changing the state of the context, such as slowing down the wheelchair's movement. The impacted property is modified as a consequence of this actuation effect. The author raised the issue of axiomatization satisfiability for SOSA and SAN concepts regarding actuations and actuators to ensure semantic interoperability.",
    "In this context, Sense Model represents a conceptual framework that relates internal states to external environments. Modeled concepts are abstract representations of ideas or notions. An actuation event can initiate or modify an action, process, or state. Actuators are devices that cause physical changes in response to their actions. The subject's brain signals recorded by EEG control the wheelchair through specific movement commands. This interaction is facilitated within a context that provides a framework for understanding and analyzing something.",
    "In a specific indoors situation, Alice controls her wheelchair using brain signals and actuators. This concept involves an actuation event triggered by an actuator that changes the state of the actuation target. The relationships between these concepts include has a broader term, perform, represents a specific order based on, and modifies. For instance, san:Actuator performs one of its basic functions, while Command: Represents a specific order (based on a bci:Record) to an actuator to perform an actuation is a command that provides direction or control over an action. The execution of this command triggers an actuation event, which involves any kind of physical modification induced by an actuator.",
    "The actuation process involves an actuator capable of controlling a wheelchair, which carries out procedures to change its state using brain signals recorded by wearable sensors. This event triggers a modification in the physical environment, inducing changes in the context's properties. The relationships between these events and their effects on the context are modeled as concepts that represent abstract notions or ideas. These concepts can be applied to real-world activities such as controlling devices that perform actuations, which have broader terms like applications. In this sense, the Context Model provides a framework for understanding how actuators induce changes in properties of an actuation target.",
    "The concept of actuation and actuators revolves around the idea that an Actuator, whether mechanical or electronic, implements a procedure to change the state of its surrounding context. This process involves physical modification induced by the actuator, which can be triggered by various events such as EEG recording and actuation happening. The relationships between these concepts are defined at [3], where it is noted that san:Effect represents any kind of physical modification induced by an actuator on its target. Furthermore, this concept has a broader term in 'concepts', highlighting the abstract nature of actuations and actuators.",
    "The Context Model for describing any kind of real/virtual environments has modeled concepts as its broader term. SAN, a conceptual framework or system, also falls under this category. The actuation event 'reduce the speed of wheels' is an instance of a more general concept - an actuation result that involves an actuation event. Similarly, ActuationEvent and in the context as the result of an actuation are both instances of events. Context.Method (x1) and bci:Context.Method (x1) represent specific methods for slowing down or reducing speed within modeled concepts. The process of recording and interpreting data - modeling observations - is a type of observation, which can be influenced by actuators and their actions. Actuations and actuators are agents that have an effect on the physical world, inducing changes in response to their actions. A Command represents a specific order for an actuator to perform an actuation, while any physical/virtual environment encompasses various settings or spaces. The concept SAN:Effect is a type of event that modifies the state of the context as a result of an actuation.",
    "In various contexts, commands are used to initiate specific actions or functions. For instance, a command can be an instruction that provides direction or control over an action, system, or process. In sessions, core modules play a crucial role in facilitating communication and information exchange between entities. The concept of san:Effect represents any kind of physical modification induced by an actuator, which is triggered by an event and modifies the state of the context as a result of an actuation. Actuation events can cause effects on various properties of actuation targets, leading to changes in their states.",
    "The concept of EEG recording and actuation happened, which involves both data collection and motor control or feedback. This idea expands on the relationship between san:Effect definition [5] and modeled concepts. An entity representing the 'effect' of the actuation, which involves an actuation event, is a broader term for this concept. The Actuator device causes changes in its environment through mechanical, electrical, or other means. In the context domain, at home, Alice controls the automated wheelchair using her brain signals and EEG recordings. An Actuation Event represents a transition from one state to another triggered by an actuator that modifies an impacted property as a consequence of an actuation effect. The san:Effect concept refers to an event triggered by an actuator that modifies a quality or property, resulting in physical modification induced by the actuation.",
    "The actuation event triggered by an actuator changes the state of the impacted property of the actuation target. This process can be controlled through a command, which has a broader term that encompasses various concepts. The san:Effect concept refers to an event triggered by an actuator that modifies a quality or property, resulting in physical modification induced by the actuation. Similarly, observations are instances that combine multiple modes and have a broader term of modeled concepts. An actuator is defined as an agent having an effect on the physical world, inducing any kind of physical modification in response to its actions. The multimodal records represent a collection of data points or instances that combine multiple modes, which also fall under the category of modeled concepts. Its conceptual components define the structure and functionality of a physical or virtual environment at the domain level. In this context, an actuation target is referred to as 'thing', whose property can be manipulated by an actuator.",
    "The concept of physical modification induced by an actuator has its roots in the broader term 'actuation to perform an action'. This process can be triggered by a stimulus event, which represents a change or occurrence that initiates a response. The impacted property being manipulated is part of an actuation target, whose state can be modified through various means such as reducing the speed of wheels. These concepts are defined within the context of modeling observations and are represented in architectural descriptions.",
    "The actuation target, which can be controlled or manipulated to achieve a desired state, has its conceptual components that enable the structural, functional, and temporal complexity definitions of any environment. An action, as a deliberate movement or operation performed by a subject, can result in an actuation event, representing a transition from one state to another with modifications to impacted properties. The outcome of this process is reflected in the actuation result, which has its broader term defined within modeled concepts. Additionally, there are various entities involved, including dul:Quality and san:Effect, which represent types of actuatable qualities that can be modified by an actuator as a consequence of an actuation effect.",
    "Alice drives her wheelchair throughout the human interface, which consists of three major components. The actuation target, represented by the Impacted Property, can be modified by an actuator as part of its effect on the physical world. This model captures the definition of Impacted Property, linked to san:Effect, and is a fundamental concept in understanding how actuators interact with their targets. In this scenario, Alice's command to reduce the speed of her wheelchair's wheels has a broader term under Action. The happening triggered by this actuation event impacts a quality (dul:Quality) of the Impacted Property.",
    "The occurrence of an event can bring about change to modeled concepts, which are abstract representations or notions that have been created to describe a particular idea. This change can be triggered by various properties, such as physical modification induced by actuation effects. In order to understand these complex systems, we need to consider the structural, functional, and temporal complexity definitions of any environment. For instance, Alice's EEG observations serve as input for actuations that modify her brain activity state. Similarly, architectural descriptions provide a framework for understanding conceptual components and their relationships. The speed of wheels is an example of an impacted property that can be modified by actuators. This concept captures the definition of Impacted Property linked to san:Effect, which represents a type of physical change or outcome resulting from a cause.",
    "According to another inherited modeling perspective, modeled concepts can be influenced by quality (dul:Quality), which defines an object or concept. When instructed to slow down, a physical modification occurs as a result of actuation, leading to changes in the state of the actuation target. This process is triggered by parameters and values defining direction, with no change in the direction indicated. The speed of wheels can be impacted by property (impacted property), resulting in deceleration or slowing down. Any kind of physical modification induced by an actuator can have a broader term as 'physical modification'.",
    "The EEG device that made the recordings has a broader category of EegDevice, which refers to an electroencephalography (EEG) recording apparatus. Additionally, modifications can be categorized under physical modification, describing changes or alterations resulting in something being different from its previous state."
  ],
  "times": [
    452.7037899494171
  ]
}