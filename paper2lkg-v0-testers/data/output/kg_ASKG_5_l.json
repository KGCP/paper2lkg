{
  "iri": "Paper-A_Pipeline_For_Analysing_Grant_Applications",
  "title": "A Pipeline For Analysing Grant Applications",
  "authors": [
    "Shuaiqun Pan",
    "Sergio J. Rodr\u00edguez M\u00e9ndez",
    "Kerry Taylor"
  ],
  "keywords": [
    "Grant applications",
    "Random Forest classifier",
    "TF-IDF algorithm"
  ],
  "sections": [
    {
      "iri": "Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-1-Paragraph-1-Sentence-1",
              "text": "Data mining techniques can transform massive amounts of unstructured data into quantitative data that quickly reveal insights, trends, and patterns behind the original data."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-2",
              "text": "In this paper, a data mining model is applied to analyse the 2019 grant applications submitted to an Australian Government research funding agency to investigate whether grant schemes successfully identifies innovative project proposals, as intended."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-3",
              "text": "The grant applications are peer-reviewed research proposals that include specific 'innovation and creativity' (IC) scores assigned by reviewers."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-4",
              "text": "In addition to predicting the IC score for each research proposal, we are particularly interested in understanding the vocabulary of innovative proposals."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-5",
              "text": "In order to solve this problem, various data mining models and feature encoding algorithms are studied and explored."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-6",
              "text": "As a result, we propose a model with the best performance, a Random Forest (RF) classifier over documents encoded with features denoting the presence or absence of unigrams."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-7",
              "text": "In specific, the unigram terms are encoded by a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, which only implements the IDF part of TF-IDF."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-8",
              "text": "Besides the proposed model, this paper also presents a rigorous experimental pipeline for analysing grant applications, and the experimental results prove its feasibility."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-2",
      "subtitle": "Introduction",
      "paragraphs": [
        {
          "iri": "Section-2-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-1-Sentence-1",
              "text": "In the 21st century, the importance of developing cutting-edge scientific research is self-evident for every country."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-2",
              "text": "Therefore, each country's government research funding agencies are willing to provide much scientific research funding to support essential and cutting-edge scientific research each year."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-3",
              "text": "Determining whether a scientific research project is worthy of funding is a significant and rigorous step for funding agencies."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-4",
              "text": "To obtain financial support, scientists and researchers always write research proposals to present their research plans and explain the significance of the project to the funding agencies."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-5",
              "text": "Usually, the government research funding agencies receive thousands of research proposals each year, which are reviewed only by expert panels."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-6",
              "text": "However, with the increase in the number of research proposals and the development of data mining techniques, funding agencies are increasingly using data mining models to assist in the manual review of research proposals."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-7",
              "text": "At the same time, it must be made clear that relying solely on data mining models to replace manual checks is not reliable."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-2-Sentence-1",
              "text": "Applying data mining models to a research proposal has several benefits."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-2",
              "text": "First, data mining models can briefly introduce the essential features of the research proposals to help human evaluators better screen the excellent research proposals, such as the influential features of the data mining models across all the research proposals."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-3",
              "text": "Second, an effective data mining model can help human evaluators understand the research proposals\u2019 strengths and weaknesses during the manual review process."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-4",
              "text": "Next, a high-quality data mining model can be applied to develop procedures and guidelines for human assessors to evaluate future research proposals to improve the quality of assessments."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-5",
              "text": "Fourth, for government or funding agencies, different funding projects should be established to improve the quality of various types of research."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-6",
              "text": "Data mining models can better understand how to ensure that human evaluators respond to these necessary qualities."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-3-Sentence-1",
              "text": "Based on the benefits and motivations mentioned above, we hope to apply a data mining model with an appropriate feature extraction technique to predict high IC-score research proposals based on the IC scores assigned by the expert reviewers."
            },
            {
              "iri": "Section-2-Paragraph-3-Sentence-2",
              "text": "Meanwhile, the other primary goal of the project is to develop a predictive vocabulary for contemporaneous proposals and to understand how the model inferred research proposals with high IC scores from the data features."
            },
            {
              "iri": "Section-2-Paragraph-3-Sentence-3",
              "text": "In addition, we focus on proposing an efficient feature extraction technique rather than the choice of classifiers, so we choose the very common Decision Tree (DT) and RF classifiers for experimental comparison."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-4-Sentence-1",
              "text": "The contributions of this paper are listed as follows:"
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-2",
              "text": "A strict experimental pipeline for analysing grant applications is given, and the experimental results prove its feasibility."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-3",
              "text": "A model is proposed with a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-4",
              "text": "The unigram terms are encoded by a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, which only implements the IDF part of TF-IDF."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-5",
              "text": "The proposed model for predicting high IC-score research proposals can achieve an accuracy of 84.17% across all types of grant applications."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-6",
              "text": "This paper is divided into six sections."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-7",
              "text": "In the first section, the project's motivation and problem statement are briefly introduced."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-8",
              "text": "In section 2, the background and related work of this project are introduced."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-9",
              "text": "The methodology section mainly describes the pipeline we apply for this research project."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-10",
              "text": "Section 4 brings the overall design of the project."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-11",
              "text": "Then, the experimental settings and implementations with the hardware platforms are introduced in this section."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-12",
              "text": "The fifth section gives the experimental results of this project and carries on the further analysis."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-13",
              "text": "Conclusions and future work are described in section 6."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-3",
      "subtitle": "Related Work",
      "paragraphs": [
        {
          "iri": "Section-3-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-1-Sentence-1",
              "text": "2.1 Computer science in evaluating grant applications."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-2",
              "text": "Oztaysi et al. [2] proposed a multi-criteria approach to evaluate research proposals based on interval-valued intuitionistic fuzzy sets."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-3",
              "text": "In this method, a fuzzy preference relation matrix was used to determine the relative importance of criteria."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-4",
              "text": "The Preference Selection Index (PSI) was another interesting method to evaluate research grant applications [3]."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-5",
              "text": "One advantage of applying the PSI method was that the researcher did not need to determine the weight criteria."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-6",
              "text": "Another similar and recently related work was the research paper classification system built based on the TF-IDF and LDA schemes [4]."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-7",
              "text": "This system used a Latent Dirichlet allocation (LDA) scheme to extract representative keywords from the abstract of each paper [5]."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-8",
              "text": "The K-means clustering algorithm [6] was applied to group papers with similar topics based on the TF-IDF vector encoding of each paper."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-9",
              "text": "The results showed that the LDA with 30 keywords using TF-IDF obtained the best F-score compared with the LDA with fewer keywords."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-2-Sentence-1",
              "text": "2.2 Term vectors and statistical measures in text representation."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-2",
              "text": "TF-IDF is commonly used in data mining and information retrieval."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-3",
              "text": "TF indicates the frequency of a word in a document or a collection of documents."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-4",
              "text": "When calculating TF, all the words from documents are treated as equally important."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-5",
              "text": "However, in practice, people only pay attention to a certain of words."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-6",
              "text": "For example, \u201cthis\", \u201care\", and \u201cit\" usually do not represent important in most cases."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-7",
              "text": "Then, the IDF is implemented to adjust the term weights in documents which can increase the weights of those rare but important words and weigh down those frequent words but less important."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-8",
              "text": "In 2016, Guo and Yang [7] analysed the shortcomings of the TF-IDF algorithm."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-9",
              "text": "Then, an intra-class dispersion algorithm based on TF-IDF was proposed."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-10",
              "text": "Chen et al. [8] proposed a new term weighting technique called Term Frequency & Inverse Gravity Moment (TF-IGM), which was mainly used to measure the class discrimination of a term."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-11",
              "text": "The experimental results showed that the TF-IGM performed better than the traditional TF-IDF in three standard corpora."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-12",
              "text": "Das and Chakraborty [9] proposed a text sentiment classification technique based on the TF-IDF algorithm and Next Word Negation (NWN)."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-13",
              "text": "In addition, this study also compared the binary bag of words, TF-IDF, and TF-IDF with NWN algorithms."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-14",
              "text": "Fan and Qin [10] proposed another improved TF-IDF algorithm, TF-IDCRF, which focused on the relationship between classes in the classification model."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-15",
              "text": "In 2019, an improved TF-IDF algorithm based on classification discrimination strength was proposed for text classification [11]."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-3-Sentence-1",
              "text": "2.3 Data mining models in text classification."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-2",
              "text": "In the field of data mining, the DT classifier is widely welcome for its advantage of showing how models make decisions according to the data features [12]."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-3",
              "text": "RF classifier is another popular data mining model."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-4",
              "text": "The term forest can be interpreted to mean that each classifier in the ensemble is a DT classifier, while all combinations of classifiers are a forest [13]."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-5",
              "text": "In the RF classifier, each decision tree also selects the optimal attribute based on the Attribute Selection Measures (ASM)."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-6",
              "text": "At the same time, each decision tree depends independently on a random sample."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-7",
              "text": "The RF classifier votes on each tree in specific classification problems and selects the most popular category as the final result."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-4-Sentence-1",
              "text": "In 2016, a news classification method was proposed based on the TF-IDF algorithm and Support Vector Machine (SVM) [14]."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-2",
              "text": "Based on a different number of n-grams and various data sets, five data mining classifiers were built and compared [15]."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-3",
              "text": "The results can guide researchers to select an appropriate data mining model according to the size of the data set."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-4",
              "text": "Four different data mining models were implemented with five different ensemble methods, and the experimental results showed that the RF classifier with the Bagging ensemble method achieved the best performance [16]."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-5",
              "text": "Wongso et al. [17] applied TF-IDF and SVD algorithms [18] to the feature selection step and compare the two algorithms."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-6",
              "text": "At the same time, the Multivariate Bernoulli Naive Bayes [19], and SVM were compared in this study."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-7",
              "text": "Finally, with the combination of TF-IDF and Multivariate Bernoulli Naive Bayes, news articles in the Indonesian Language corpus were classified, and the best result was obtained [17]."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-4",
      "subtitle": "Methodology",
      "paragraphs": [
        {
          "iri": "Section-4-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-1-Sentence-1",
              "text": "This section details the workflow of our proposed pipeline and the data mining model."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-2",
              "text": "Fig. 1 shows the pipeline of analysing grant applications."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-3",
              "text": "3.1 Data set."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-4",
              "text": "The data set used to analyse the grant applications is the 2019 grant applications submitted to an Australian Government research funding agency."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-5",
              "text": "3,805 research proposals are given in this data set with peer-reviewed IC scores (1 - 7)."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-6",
              "text": "In addition, the entire data set contains different types of grant applications, such as Synergy Grants, Standard Project Grants, and Ideas Grants."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-7",
              "text": "Besides the IC score, reviewers also score several other assessment scores, such as \u201cFeasibility Score\u201d or \u201cSignificance Score.\u201d"
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-8",
              "text": "Since all research proposals are saved in PDF format, extracting the text from PDF files is necessary."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-9",
              "text": "A Metadata Extractor & Loader (MEL) [20] tool is applied to extract text from PDF research proposals and save it in a JSON file with metadata sets and content."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-10",
              "text": "By default, all JSON files are stored in CouchDB database [21] based on the proposal index."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-11",
              "text": "Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-12",
              "text": "At the same time, some fundamental values are also the basis of designing the entire pipeline, such as the median IC score and mode IC score."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-13",
              "text": "Table 1 shows a statistic of IC scores, showing that 3,693 research proposals have valid IC scores."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-14",
              "text": "In addition, 99 research proposals do not contain an IC score, 13 of which have an IC score below 1.0, and these research proposals therefore not be used in this project."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-15",
              "text": "Table 1 also shows the median IC score, 5.0, the most frequent IC score."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-2-Sentence-1",
              "text": "3.2 Text pre-processing for grant applications."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-2",
              "text": "HaCohen-Kerner et al. [22] proved that text pre-processing techniques could make the model achieve better performance than without the text pre-processing step."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-3",
              "text": "After all the text is extracted, all characters, whether uppercase or lowercase, are converted to lowercase."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-4",
              "text": "Then, the numbers are also removed because the numbers in the research proposals are not relevant for future analysis."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-5",
              "text": "Thirdly, removing punctuations and tokenizing by whitespace are also adopted, which make the text into small pieces called tokens."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-6",
              "text": "In addition, the deletion of stop words is one of the most crucial text pre-processing techniques."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-7",
              "text": "Fani et al. [23] have shown that deleting stop words can improve the performance of data mining tasks."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-8",
              "text": "Therefore, we create a list of custom stop words according to the IDF formula and delete the IDF value of the term from the text lower than 1.0."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-9",
              "text": "The reason for choosing 1.0 is that after implementation some preliminary experiments, we confirm that the feature words considered as important by DT and RF classifiers will less than 1000 words."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-10",
              "text": "Meanwhile, the words whose IDF value are less than 1.0 only account for 0.2% of the total words, and they are all common words such as \u201cnext\u201d, \u201cshift\u201d and \u201cother\u201d."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-11",
              "text": "We believe that these words appear too frequently and have no influence on the experimental results."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-12",
              "text": "Finally, text stemming is the last technique we apply in the text pre-processing step."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-13",
              "text": "Text stemming is a technique for reducing each word to its root format [24]."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-14",
              "text": "It helps to reduce the vocabulary and surface syntax to get closer to the meaning of each term, and the Porter Stemming algorithm [25] is implemented in this step."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-3-Sentence-1",
              "text": "This section details the workflow of our proposed pipeline and the data mining model."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-2",
              "text": "Fig. 1 shows the pipeline of analysing grant applications."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-3",
              "text": "3.1 Data set."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-4",
              "text": "The data set used to analyse the grant applications is the 2019 grant applications submitted to an Australian Government research funding agency."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-5",
              "text": "3,805 research proposals are given in this data set with peer-reviewed IC scores (1 - 7)."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-6",
              "text": "In addition, the entire data set contains different types of grant applications, such as Synergy Grants, Standard Project Grants, and Ideas Grants."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-7",
              "text": "Besides the IC score, reviewers also score several other assessment scores, such as \u201cFeasibility Score\u201d or \u201cSignificance Score.\u201d"
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-8",
              "text": "Since all research proposals are saved in PDF format, extracting the text from PDF files is necessary."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-9",
              "text": "A Metadata Extractor & Loader (MEL) [20] tool is applied to extract text from PDF research proposals and save it in a JSON file with metadata sets and content."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-10",
              "text": "By default, all JSON files are stored in CouchDB database [21] based on the proposal index."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-11",
              "text": "Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-12",
              "text": "At the same time, some fundamental values are also the basis of designing the entire pipeline, such as the median IC score and mode IC score."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-13",
              "text": "Table 1 shows a statistic of IC scores, showing that 3,693 research proposals have valid IC scores."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-14",
              "text": "In addition, 99 research proposals do not contain an IC score, 13 of which have an IC score below 1.0, and these research proposals therefore not be used in this project."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-15",
              "text": "Table 1 also shows the median IC score, 5.0, the most frequent IC score."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-4-Sentence-1",
              "text": "3.4 Design and apply the feature extraction technique."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-2",
              "text": "We propose a modified TF-IDF algorithm, which only implements the IDF part of TF-IDF as the feature extraction technique."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-3",
              "text": "In specific, if the term exists at least once in the documents, specify the IDF value for this term directly."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-4",
              "text": "In addition, if a term does not exist in the documents, then the term is assigned a value of 0."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-5",
              "text": "The design of this modified feature extraction algorithm follows the idea that rare terms can define innovativeness."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-6",
              "text": "The experiment also considers the n-grams [26]."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-7",
              "text": "Unigram is the most common choice for text classification tasks, but bigram and trigram may better represent scientific terms, where bigram is two consecutive words in a sentence, and trigram is three consecutive words in a sentence."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-8",
              "text": "At the same time, when collecting proposals, we also consider deleting the words that only exist once or twice, because very rare terms tend not to be predictive."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-9",
              "text": "In addition, the bigram mentioned in this paper denotes a combination of the unigrams and bigrams."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-10",
              "text": "The trigram denotes a combination of the unigrams, bigrams, and trigrams."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-5",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-5-Sentence-1",
              "text": "3.5 Apply data mining models with grant applications."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-2",
              "text": "This paper uses DT and RF classifiers for text classification because we would like to find out the most influential terms and understood how the data mining model predicts high and low IC-score research proposals."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-3",
              "text": "The DT and RF classifiers are convenient to present this valuable information."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-4",
              "text": "Based on the experimental result of the high and low IC-score research proposals selection, all experiments are conducted with the low IC-score research proposals (IC score 0~15%) and the high IC-score research proposals (IC score 85%~100%)."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-5",
              "text": "In the comparison study of feature extraction techniques, 400 research proposals for each low and high IC score are randomly selected for model training, and the training data is 85%, and the test data is 15%."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-6",
              "text": "In order to analyse the proposed model in the end, the 100 most influential terms from the collections of research proposals are extracted by the function from scikit-learn library [27], which bring us an intuitive understanding of how much each term contributes to reducing the weighted impurities."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-6",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-6-Sentence-1",
              "text": "3.6 Analyse moderate IC-score grant applications."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-2",
              "text": "We also conduct several experiments to analyse moderate IC-score research proposals based on the proposed model."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-3",
              "text": "The purpose of this series of experiments is to determine whether there is a relation between proposals with moderate IC scores and that of high and low IC scores."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-4",
              "text": "Since the proposed model is trained based on the low IC-score proposals of 0~15% and high IC-score proposals of 85~100%, the range of research proposals with moderate IC score is 15%~85%."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-5",
              "text": "Based on the median IC score, the selection range of testing moderate IC score by testing several cut-off options, such as 20, 25, 30, 35, 40, 45, and 50."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-6",
              "text": "Table 4 shows a list of experiments used to analyse the research proposals of moderate IC score."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-7",
              "text": "Considering the symmetric distribution of the IC scores, new research proposals with low and high IC scores are selected in each experiment, and performance analysis is conducted based on the proposed training model."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-8",
              "text": "In addition to the experiments in Table 4, another experiment is designed to check the median IC-score research proposals (IC score = 5.0) to predict the proportion of high or low IC-score research proposals rather than calculate the test accuracy."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-5",
      "subtitle": "Experimental Settings",
      "paragraphs": [
        {
          "iri": "Section-5-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-1-Sentence-1",
              "text": "This section describes all experimental settings for this paper."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-2",
              "text": "Initially, MEL [20] is implemented through a set of Python-based methods to extract metadata for all supported file types."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-3",
              "text": "To extract metadata from the PDF version of a file, the Tesseract-OCR method [28] and pdftotext tool [29] are applied."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-4",
              "text": "In the statistical analysis of grant applications, the Python language and Numpy library [30] are used to calculate the median, mode, and other statistical measurements of IC score."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-5",
              "text": "In the experiments of selecting high, low, and moderate IC-score research proposals and implementing the data mining models, the scikit-learn library [27] is applied to implement the DT and RF classifiers."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-6",
              "text": "The python library gensim [31] is used to implement the TF-IDF algorithm and the newly proposed modified TF-IDF algorithm."
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-2-Sentence-1",
              "text": "Hyper-parameter tuning is a significant step in applying data mining models, and the Bayesian Optimization tool [32] is applied."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-2",
              "text": "The first step to implement Bayesian Optimization is to define the data mining model, such as the RF classifier and its parameters and corresponding bounds."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-3",
              "text": "In addition, we also need to implement the scoring method and the cross-validation setup."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-4",
              "text": "Secondly, the maximize method is used to run the technique with n_iter and init_points parameters."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-5",
              "text": "The n_iter is defined for the number of steps to run the optimization function."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-6",
              "text": "The more steps, the easier it is to find the best accuracy value."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-7",
              "text": "The init_points is defined for random exploration on the parameter space, which helps to explore the diversity of the space."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-8",
              "text": "Finally, the parameter values for each accuracy are listed, highlighting the best combination of the parameter and the target value."
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-3-Sentence-1",
              "text": "To find the hyper-parameters of the RF classifier, the range of each parameter is set as follows: max_depth = (5, 60), min_samples_split = (10, 100), max_features = (0.1, 0.999), max_samples_leaf = (10, 50) and n_estimation = (100, 400)."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-2",
              "text": "For the DT classifier, the range settings for finding hyper-parameters are as follows: max_depth = (3, 10), min_samples_split = (3, 10), max_features = (0.1, 0.999),and max_samples_leaf = (3, 10)."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-3",
              "text": "The max_depth parameter indicates the maximum depth of the tree, and the max_features denotes the number of features to consider when finding the best split [27]."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-4",
              "text": "The parameters min_samples_leaf, min_samples_split, and n_estimators are defined as the minimum number of samples needed on a leaf node, the minimum number of samples needed to split an internal node, and the number of trees in the forest, respectively."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-5",
              "text": "All experiments related to RF classifier and DT classifier adopt the same setting of the hyper-parameter range."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-6",
              "text": "Meanwhile, the 10-fold cross-validation method is also applied in finding the hyper-parameters."
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-4-Sentence-1",
              "text": "To evaluate the performance of the newly proposed modified TF-IDF algorithm and the TF-IDF algorithm with different data mining classifiers, the classification accuracy (Acc), F1 score are selected as the evaluation metrics."
            },
            {
              "iri": "Section-5-Paragraph-4-Sentence-2",
              "text": "The hardware platform is MacBook Pro with Intel Core i7 2.9 GHz Quard-Core processor."
            },
            {
              "iri": "Section-5-Paragraph-4-Sentence-3",
              "text": "The memory configuration is 16GB 2133 MHz LPDDR3."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-6",
      "subtitle": "Experimental Result",
      "paragraphs": [
        {
          "iri": "Section-6-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-1-Sentence-1",
              "text": "Table 5 shows the performance of the TF-IDF algorithm with DT and RF classifiers."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-2",
              "text": "It can be found that the RF classifier can consistently achieve better performance than the DT classifier under the different settings of the n-grams and deletion of rare terms."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-2-Sentence-1",
              "text": "Table 6 shows the performance of the newly proposed modified TF-IDF algorithm with DT and RF classifiers."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-2",
              "text": "Based on the comparison of Table 5 and Table 6, the best performance is achieved with 84.17% accuracy by the RF classifier with the newly proposed modified TF-IDF algorithm except the No.14 model combination in Table 6."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-3",
              "text": "The hyper-parameters are max_depth = 22, max_features = 0.9931, min_samples_leaf = 11, min_samples_split = 67 and n_estimation = 102."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-4",
              "text": "To include all the terms from the corpus, we choose the RF classifier based on unigram and the modified TF-IDF algorithm as the final proposed model."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-5",
              "text": "Another reason why we do not choose the bigram and trigram combinations as the proposed model is the bigram and trigram terms are in fact not regarded as essential features by DT and RF classifiers."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-6",
              "text": "Features extracted from the proposed model shows that only 618 features are considered significant, based on tens of thousands of features in the research proposals."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-3-Sentence-1",
              "text": "Based on the comparison of the two tables, it can be found that the proposed modified TF-IDF algorithm is practical and effective despite two or three exceptions exist."
            },
            {
              "iri": "Section-6-Paragraph-3-Sentence-2",
              "text": "At the same time, the experimental results prove that the core idea of defining the modified TF-IDF algorithm is meaningful and show the rare terms associated with innovativeness."
            },
            {
              "iri": "Section-6-Paragraph-3-Sentence-3",
              "text": "It should also be noted that the newly proposed modified TF-IDF algorithm can be understood as a simple encoding technique, such as taking the value 0 or the IDF value of the term depending on whether the term exists in the research proposals."
            },
            {
              "iri": "Section-6-Paragraph-3-Sentence-4",
              "text": "Based on the decision tree plots generated by the best performance model, it can be found that the modified TF-IDF algorithm does not affect the shape of the tree as seen in the tree graph, helping to understand whether the chosen split term is rare or common."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-4-Sentence-1",
              "text": "From the result of finding hyper-parameters, it can be found that the best performing model does not use all the features to apply with the data mining algorithms, such as the RF classifier only uses 99.31% features."
            },
            {
              "iri": "Section-6-Paragraph-4-Sentence-2",
              "text": "In addition, although we consider different n-grams, especially bigram and trigram, with removing scarce words, Table 5 and Table 6 could prove that it might help but not always."
            },
            {
              "iri": "Section-6-Paragraph-4-Sentence-3",
              "text": "Moreover, based on the same feature extraction algorithm, the classification accuracy of the RF classifier is always better than that of the DT classifier."
            },
            {
              "iri": "Section-6-Paragraph-4-Sentence-4",
              "text": "Nevertheless, the results of the DT classifier are still crucial because the plot of DT classifier contains all the decisions."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-5",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-5-Sentence-1",
              "text": "Fig. 2 shows the confusion matrix of the proposed model for the \u201cunseen\u201d test data."
            },
            {
              "iri": "Section-6-Paragraph-5-Sentence-2",
              "text": "It shows 13 high IC-score research proposals are incorrectly predicted as low IC-score proposals."
            },
            {
              "iri": "Section-6-Paragraph-5-Sentence-3",
              "text": "In addition, 6 research proposals with low IC scores are guessed wrongly which they are predicted as high IC-score proposals."
            },
            {
              "iri": "Section-6-Paragraph-5-Sentence-4",
              "text": "The number 59 denotes that the proposed model correctly predicts 59 research proposals with low IC scores and 42 with high IC scores."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-6",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-6-Sentence-1",
              "text": "In addition to analysing the confusion matrix, we also extract the 100 most influential features from the proposed model, which gives an intuitive understanding of how much each feature contributes to reducing the weighted impurities."
            },
            {
              "iri": "Section-6-Paragraph-6-Sentence-2",
              "text": "The top 100 features give us a better understanding of what is going on inside the black box."
            },
            {
              "iri": "Section-6-Paragraph-6-Sentence-3",
              "text": "A measure of the feature importance is valuable for internal model development purposes by showing to what extent features contribute to test data."
            },
            {
              "iri": "Section-6-Paragraph-6-Sentence-4",
              "text": "Although the classifier is only established for the 2019 grant applications and may not predict the high research proposals for future applications, these unique terms are still valuable and meaningful as a reference for evaluators."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-7",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-7-Sentence-1",
              "text": "Table 7 brings the performance of checking research proposals of moderate IC scores based on the proposed model."
            },
            {
              "iri": "Section-6-Paragraph-7-Sentence-2",
              "text": "Based on the test accuracy, it can be concluded that there is a correlation between the moderate IC-score research proposals and high/low IC-score research proposals."
            },
            {
              "iri": "Section-6-Paragraph-7-Sentence-3",
              "text": "Moreover, it is easy to find that the proposed model can better predict the research proposals close to the original training set settings (0~15% for low IC score and 85%~100% for high IC score)."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-8",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-8-Sentence-1",
              "text": "Based on the confusion matrix above and the experimental results of checking moderate IC-score research proposals, it can be found that the model is always more accurate in predicting research proposals with low IC scores than with high IC scores."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-2",
              "text": "Meanwhile, the research proposals with the median IC score of 5.0 are predicted to be about 37.2% with high-IC score research proposals and about 62.8% with low-IC score research proposals."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-3",
              "text": "Therefore, it can be concluded that research proposals with high IC scores use more diverse language than those with low IC-score."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-4",
              "text": "In addition to the experiments analysing all grant applications, we follow the same pipeline and establish a new model to evaluate Ideas Grant applications only, the one with innovation criteria."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-5",
              "text": "Applying the same method but with different hyper-parameters, the best performing model for analysing the Ideas Grants can reach an accuracy of 82.5%."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-6",
              "text": "In every Ideas Grant application, there is a section called \u201cInnovation and Creativity statement.\u201d"
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-7",
              "text": "We also extract this part from each Ideas grant and analyse using the proposed pipeline."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-8",
              "text": "The experimental result shows that the proposed method can achieve 68.33% accuracy on analysing \u201cInnovation and Creativity statement\u201d sections only from Ideas Grants."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-9",
              "text": "Although we guess the IC score is more relevant to the \u201cInnovation and Creativity statement\u201d compared with other sections, as evaluators may describe their innovation in this section, the experimental result does not support our guess."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-7",
      "subtitle": "Conclusion",
      "paragraphs": [
        {
          "iri": "Section-7-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-7-Paragraph-1-Sentence-1",
              "text": "In summary, a pipeline for analysing grant applications has been proposed with several crucial steps."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-2",
              "text": "The proposed data mining model is an RF classifier over documents encoded with features denoting the presence or absence of unigrams."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-3",
              "text": "Specifically, the unigram terms are encoded by a modified Term Frequency - Inverse Document Frequency(TF-IDF) algorithm, which only implements the IDF part of TF-IDF."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-4",
              "text": "As a result, the proposed model achieves an accuracy of 84.17% based on all types of grant applications."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-5",
              "text": "In addition, we also build experiments for Ideas Grants only and \u201cInnovation and Creativity statement\u201d single section."
            }
          ]
        },
        {
          "iri": "Section-7-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-7-Paragraph-2-Sentence-1",
              "text": "The future work can be carried out from different perspectives."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-2",
              "text": "Firstly, innovation should not be the only evaluation criterion."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-3",
              "text": "In order to better evaluate the entire grant application, we should consider other evaluation scores and establish a more comprehensive system that can predict a grant application based on multiple criteria."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-4",
              "text": "Secondly, in the future, this project can also apply some other effective data mining models, such as SVM, AdaBoost, and Xgboost."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-5",
              "text": "In addition, the pre-trained language models in the Natural Language Processing (NLP) field perform well in understanding text semantics, which can also be our next research focus."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-6",
              "text": "Thirdly, our proposed method cannot predict future grant applications because the current data set contains only key terms for 2019 and does not represent future grant applications."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-7",
              "text": "Therefore, it is an important research topic to consider building a long-term data mining model to predict future grant applications."
            }
          ]
        }
      ]
    }
  ],
  "summary": "A data mining model was applied to analyze Australian Government research grant applications from 2019, aiming to identify innovative project proposals using a Random Forest classifier and unigram features.\n\nGovernments use data mining models with feature extraction techniques like Decision Tree or Random Forest classifiers to review research proposals, improving evaluation quality and achieving an accuracy of 84.17%.\n\nComputer science methods for evaluating grant applications include multi-criteria approaches using interval-valued intuitionistic fuzzy sets and Preference Selection Index (PSI), as well as text representation techniques like TF-IDF to adjust term weights.\n\nThis section details the workflow of our proposed pipeline and the data mining model. Fig. 1 shows the pipeline of analysing grant applications. 3.1 Data set. The data set used to analyse the grant applications is the 2019 grant applications submitted to an Australian Government research funding agency. 3,805 research proposals are given in this data set with peer-reviewed IC scores (1 - 7). In addition, the entire data set contains different types of grant applications, such as Synergy Grants, Standard Project Grants, and Ideas Grants. Besides the IC score, reviewers also score several other assessment scores, such as \u201cFeasibility Score\u201d or \u201cSignificance Score.\u201d Since all research proposals are saved in PDF format, extracting the text from PDF files is necessary. A Metadata Extractor & Loader (MEL) [20] tool is applied to extract text from PDF research proposals and save it in a JSON file with metadata sets and content. By default, all JSON files are stored in CouchDB database [21] based on the proposal index. Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals. At the same time, some fundamental values are also the basis of designing the entire pipeline, such as the median IC score and mode IC score. Table 1 shows a statistic of IC scores, showing that 3,693 research proposals have valid IC scores. In addition, 99 research proposals do not contain an IC score, 13 of which have an IC score below 1.0, and these research proposals therefore not be used in this project. Table 1 also shows the median IC score, 5.0, the most frequent IC score.\n\n3.2 Text pre-processing for grant applications. HaCohen-Kerner et al. [22] proved that text pre-processing techniques could make the model achieve better performance than without the text pre-processing step. After all the text is extracted, all characters, whether uppercase or lowercase, are converted to lowercase. Then, the numbers are also removed because the numbers in the research proposals are not relevant for future analysis. Thirdly, removing punctuations and tokenizing by whitespace are also adopted, which make the text into small pieces called tokens. In addition, the deletion of stop words is one of the most crucial text pre-processing techniques. Fani et al. [23] have shown that deleting stop words can improve the performance of data mining tasks. Therefore, we create a list of custom stop words according to the IDF formula and delete the IDF value of the term from the text lower than 1.0. The reason for choosing 1.0 is that after implementation some preliminary experiments, we confirm that the feature words considered as important by DT and RF classifiers will less than 1000 words. Meanwhile, the words whose IDF value are less than 1.0 only account for 0.2% of the total words, and they are all common words such as \u201cnext\u201d, \u201cshift\u201d and \u201cother\u201d. We believe that these words appear too frequently and have no influence on the experimental results. Finally, text stemming is the last technique we apply in the text pre-processing step. Text stemming is a technique for reducing each word to its root format [24]. It helps to reduce the vocabulary and surface syntax to get closer to the meaning of each term, and the Porter Stemming algorithm [25] is implemented in this step.\n\nThis section details the workflow of our proposed pipeline and the data mining model. Fig. 1 shows the pipeline of analysing grant applications. 3.1 Data set. The data set used to analyse the grant applications is the 2019 grant applications submitted to an Australian Government research funding agency. 3,805 research proposals are given in this data set with peer-reviewed IC scores (1 - 7). In addition, the entire data set contains different types of grant applications, such as Synergy Grants, Standard Project Grants, and Ideas Grants. Besides the IC score, reviewers also score several other assessment scores, such as \u201cFeasibility Score\u201d or \u201cSignificance Score.\u201d Since all research proposals are saved in PDF format, extracting the text from PDF files is necessary. A Metadata Extractor & Loader (MEL) [20] tool is applied to extract text from PDF research proposals and save it in a JSON file with metadata sets and content. By default, all JSON files are stored in CouchDB database [21] based on the proposal index. Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals. At the same time, some fundamental values are also the basis of designing the entire pipeline, such as the median IC score and mode IC score. Table 1 shows a statistic of IC scores, showing that 3,693 research proposals have valid IC scores. In addition, 99 research proposals do not contain an IC score, 13 of which have an IC score below 1.0, and these research proposals therefore not be used in this project. Table 1 also shows the median IC score, 5.0, the most frequent IC score.\n\n3.4 Design and apply the feature extraction technique. We propose a modified TF-IDF algorithm, which only implements the IDF part of TF-IDF as the feature extraction technique. In specific, if the term exists at least once in the documents, specify the IDF value for this term directly. In addition, if a term does not exist in the documents, then the term is assigned a value of 0. The design of this modified feature extraction algorithm follows the idea that rare terms can define innovativeness. The experiment also considers the n-grams [26]. Unigram is the most common choice for text classification tasks, but bigram and trigram may better represent scientific terms, where bigram is two consecutive words in a sentence, and trigram is three consecutive words in a sentence. At the same time, when collecting proposals, we also consider deleting the words that only exist once or twice, because very rare terms tend not to be predictive. In addition, the bigram mentioned in this paper denotes a combination of the unigrams and bigrams. The trigram denotes a combination of the unigrams, bigrams, and trigrams.\n\n3.5 Apply data mining models with grant applications. This paper uses DT and RF classifiers for text classification because we would like to find out the most influential terms and understood how the data mining model predicts high and low IC-score research proposals. The DT and RF classifiers are convenient to present this valuable information. Based on the experimental result of the high and low IC-score research proposals selection, all experiments are conducted with the low IC-score research proposals (IC score 0~15%) and the high IC-score research proposals (IC score 85%~100%). In the comparison study of feature extraction techniques, 400 research proposals for each low and high IC score are randomly selected for model training, and the training data is 85%, and the test data is 15%. In order to analyse the proposed model in the end, the 100 most influential terms from the collections of research proposals are extracted by the function from scikit-learn library [27], which bring us an intuitive understanding of how much each term contributes to reducing the weighted impurities.\n\n3.6 Analyse moderate IC-score grant applications. We also conduct several experiments to analyse moderate IC-score research proposals based on the proposed model. The purpose of this series of experiments is to determine whether there is a relation between proposals with moderate IC scores and that of high and low IC scores. Since the proposed model is trained based on the low IC-score proposals of 0~15% and high IC-score proposals of 85~100%, the range of research proposals with moderate IC score is 15%~85%. Based on the median IC score, the selection range of testing moderate IC score by testing several cut-off options, such as 20, 25, 30, 35, 40, 45, and 50. Table 4 shows a list of experiments used to analyse the research proposals of moderate IC score. Considering the symmetric distribution of the IC scores, new research proposals with low and high IC scores are selected in each experiment, and performance analysis is conducted based on the proposed training model. In addition to the experiments in Table 4, another experiment is designed to check the median IC-score research proposals (IC score = 5.0) to predict the proportion of high or low IC-score research proposals rather than calculate the test accuracy.\n\nThis paper uses Python-based methods to extract metadata from various file types using MEL, with statistical analysis involving Numpy and scikit-learn.\n\nThe TF-IDF algorithm with a Random Forest (RF) classifier outperforms Decision Tree (DT) under different settings, especially for rare terms related to innovativeness. The best-performing model uses only 99.31% of features and omits bigrams and trigrams.\n\nIn summary, a pipeline for analysing grant applications has been proposed with several crucial steps. The proposed data mining model is an RF classifier over documents encoded with features denoting the presence or absence of unigrams. Specifically, the unigram terms are encoded by a modified Term Frequency - Inverse Document Frequency(TF-IDF) algorithm, which only implements the IDF part of TF-IDF. As a result, the proposed model achieves an accuracy of 84.17% based on all types of grant applications. In addition, we also build experiments for Ideas Grants only and \u201cInnovation and Creativity statement\u201d single section.\n\nThe future work can be carried out from different perspectives. Firstly, innovation should not be the only evaluation criterion. In order to better evaluate the entire grant application, we should consider other evaluation scores and establish a more comprehensive system that can predict a grant application based on multiple criteria. Secondly, in the future, this project can also apply some other effective data mining models, such as SVM, AdaBoost, and Xgboost. In addition, the pre-trained language models in the Natural Language Processing (NLP) field perform well in understanding text semantics, which can also be our next research focus. Thirdly, our proposed method cannot predict future grant applications because the current data set contains only key terms for 2019 and does not represent future grant applications. Therefore, it is an important research topic to consider building a long-term data mining model to predict future grant applications.",
  "kg2text": [
    "This paper proposes an experimental pipeline for analysing grant applications, which uses the data set of 3,805 peer-reviewed research proposals with IC scores (1-7) submitted to an Australian Government research funding agency in 2019. The proposed pipeline includes a data mining model that predicts high and low IC-score research proposals. This paper also describes how this data mining model is used for training and testing new research proposals. Furthermore, the paper presents our proposed pipeline and the data mining model as a framework to assist human evaluators in reviewing grant applications.",
    "The dataset used to analyze grant applications consists of peer-reviewed research proposals submitted to an Australian Government research funding agency in 2019. This project uses a strict experimental pipeline for analyzing grant applications, which includes data mining models such as Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms. The proposed pipeline is used to analyze and evaluate grant applications, including selecting high, low, and moderate IC-score research proposals. Additionally, this paper proposes a data mining model that uses a Random Forest classifier to predict innovation and creativity scores for grant applications. Furthermore, it discusses how data mining models can assist in the manual review of research proposals.",
    "The data set used for analyzing grant applications consists of the 2019 grant applications submitted to an Australian Government research funding agency. Our proposed pipeline and a model, specifically a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms, are applied to analyze these proposals. The dataset contains 3,805 peer-reviewed research proposals with IC scores ranging from 1 to 7. Research proposals with moderate IC scores account for 15%~85%. Our proposed pipeline and model assist in manual review by predicting high and low IC-score research proposals using a data mining approach. This paper presents an experimental pipeline that utilizes the dataset, applies a modified Term Frequency - Inverse Document Frequency algorithm, and predicts high IC-score research proposals.",
    "This paper proposes a data mining model with moderate IC score research proposals, which uses Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms. The proposed pipeline and data mining model assist in reviewing grant applications by predicting high and low IC-score research proposals. A strict experimental pipeline is used to analyze new research proposals, including a dataset of 3,805 peer-reviewed research proposals submitted in 2019 to an Australian Government research funding agency. This paper discusses the process of selecting high, low, and moderate IC-score research proposals using our proposed pipeline and data mining model.",
    "The proposed methodology, or A strict experimental pipeline, uses a data set of 3,805 research proposals with peer-reviewed IC scores ranging from 1 to 7. This data set includes moderate IC-score research proposals that are used for training and testing a data mining model. The data mining models assist in the manual review of research proposals by predicting high and low IC-score research proposals. Our proposed pipeline and the data mining model analyze new research proposals, which have been extracted from each Ideas grant application. This paper discusses how the data mining model predicts high and low IC-score research proposals using a Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams.",
    "This paper proposes a pipeline for analyzing grant applications, which includes applying data mining models to assist human evaluators. The proposed methodology uses Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms and applies modified Term Frequency - Inverse Document Frequency algorithm to predict high IC-score research proposals. The experiments used 3,805 peer-reviewed research proposals submitted in 2019 to an Australian Government research funding agency, including IC scores ranging from 1 to 7. Our proposed pipeline uses a data mining model that predicts whether grant applications have high or low innovation and creativity (IC) scores.",
    "This paper proposes a pipeline for analyzing grant applications, which involves extracting text from PDF files and applying various preprocessing techniques. The data mining models utilize our proposed pipeline to assist in manual review of research proposals. Research proposals with moderate IC scores ranging from 15% to 85% are used to train and test the model. The project's motivation and problem statement introduce the importance of predicting high and low IC-score research proposals, which is achieved by applying a data mining model that predicts whether an application has a high or low innovation and creativity score using features denoting the presence or absence of unigram terms. A strict experimental pipeline uses this process to select high, low, and moderate IC-score research proposals for analysis.",
    "This paper proposes a data mining pipeline that uses a Random Forest classifier to analyze grant applications, encoding documents with features denoting the presence or absence of unigrams. The proposed methodology includes selecting high, low, and moderate IC-score research proposals using a model that applies data mining models with experiments. This project is described by introducing the motivation and problem statement briefly, which are used as input for the pipeline. The data set contains 3,805 peer-reviewed research proposals submitted in 2019 to an Australian Government research funding agency, including IC scores and various types of grant applications. The proposed model uses this paper's approach to predict high and low IC-score research proposals.",
    "The proposed pipeline extracts a specific section from each Ideas grant and analyses it to predict high IC-score research proposals. The process involves using data mining models, including Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams, and Decision Tree classifier for analyzing grant applications. These models are applied to analyze 3,805 research proposals given in this dataset with peer-reviewed IC scores ranging from 1 to 7. The project's motivation is to assist government funding agencies in reviewing and assessing grant applications by predicting high IC-score proposals using data mining models.",
    "The data mining models were applied to analyze the grant applications, including those with peer-reviewed IC scores ranging from 1-7. The proposed pipeline and data mining model used Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams, as well as a modified Term Frequency - Inverse Document Frequency algorithm. This project aimed to predict high IC-score research proposals by analyzing grant applications using various preprocessing techniques such as tokenization, stopword removal, and stemming. The data set used for analysis consisted of 3,805 peer-reviewed research proposals submitted in 2019 to an Australian Government research funding agency. Additionally, the model was applied to select high, low, and moderate IC-score research proposals, with a broader term being 'research proposals' that include new grant applications.",
    "The proposed model correctly predicts 59 research proposals with low IC scores and 42 with high IC scores. These research proposals have a broader term, which covers the range of research proposals with moderate IC score that correlates with proposals having both high and low IC scores. The feasibility of this approach is proven by its accuracy of 84.17%. This paper presents a pipeline for analysing grant applications using data mining models across all the research proposals. A predictive vocabulary for contemporaneous proposals was developed as part of this project, which demonstrates the potential to identify innovative grant proposals and understand the vocabulary of high-IC-score research projects.",
    "Research proposals with moderate IC scores, ranging from 15% to 85%, are characterized by innovation and creativity. A data mining model was proposed based on all types of grant applications, including research proposals submitted for funding or support. The dataset used to analyze these grant applications is the 2019 grant applications submitted to an Australian Government research funding agency, containing 3,805 peer-reviewed research proposals with IC scores ranging from 1 to 7. A Random Forest classifier was implemented as part of a data mining model to predict future grant applications and understand the vocabulary of innovative proposals.",
    "The dataset consists of 3,805 research proposals with peer-reviewed innovation and creativity (IC) scores ranging from 1 to 7. These moderate IC-score grant applications are characterized by a set of innovative project proposals with high IC scores, which may require different linguistic patterns or features to accurately predict. The proposed model uses Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams using a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, specifically applied to analyze and investigate grant applications. This data mining framework is used for building a long-term predictive model that can forecast potential high-IC score research proposals.",
    "The research proposals, categorized by their innovation and creativity (IC) scores as either low or high, were submitted to an Australian Government research funding agency. The proposed pipeline and data mining model used Decision Tree (DT) and RF classifiers for text classification. A total of 3,805 research proposals with peer-reviewed IC scores ranging from 1 to 7 were analyzed using various data mining models in text classification. Building a long-term data mining model to predict future grant applications was also proposed. The range of research proposals with moderate IC score spanned from 15% to 85%, and the high IC-score research proposals had innovation and creativity scores above 5.",
    "The grant applications submitted to an Australian Government research funding agency are a set of requests for financial support or funding. These research proposals, which include specific 'innovation and creativity' scores assigned by reviewers, aim to present their research plans and explain the significance of the project to the funding agencies. Building a long-term data mining model to predict future grant applications involves various data mining models and feature encoding algorithms. The DT classifier is used in this paper's experimental pipeline for analysing grant applications. A more comprehensive system can predict a grant application based on multiple criteria, including features extracted from research proposals with moderate IC scores ranging from 15% to 85%. Predicting high IC-score research proposals involves training data mining models using these research proposals and their corresponding innovation and creativity scores. The proposed model is used for text classification, which incorrectly predicts some low IC-score proposals as grant applications.",
    "The collection of peer-reviewed grant applications submitted to an Australian Government research funding agency in 2019, including Synergy Grants, Standard Project Grants, and Ideas Grants. The proposed model uses a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms using a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm to predict high IC-score research proposals based on innovation and creativity scores assigned by expert reviewers. This approach has been applied across all 3,693 research proposals submitted in 2019, with an effective data mining model that uses ensemble methods such as Bagging to combine multiple models for improved performance.",
    "The data mining models have been used to analyze grant applications and predict high IC-score research proposals. The process of automatically discovering patterns or relationships in large datasets, known as Data Mining, has a broader term that includes building long-term data mining models to predict future grant applications. A set of machine learning algorithms, including Random Forest classifier and Decision Tree classifier, were used for analyzing 3,693 research proposals with assigned IC scores from the 2019 grant applications submitted to an Australian Government research funding agency. The proposed model can better predict the research proposals close to the original training set settings (0~15% for low IC score and 85%~100% for high IC score). Additionally, a predictive vocabulary was developed for contemporaneous proposals and understanding how the model inferred research proposals with high IC scores from data features.",
    "The proposed data mining model, which combines Random Forest with unigram features and modified TF-IDF algorithm, can reach an accuracy of 82.5% when analyzing high IC- score research proposals. This model applies to grant applications submitted in 2019, including Synergy Grants, Standard Project Grants, and Ideas Grants. The proposed method also achieves a higher accuracy of 68.33% for predicting 'Innovation and Creativity' statements in Idea Grant applications. Furthermore, the Random Forest classifier based on unigram features can be used to identify high IC- score research proposals among all grant applications submitted.",
    "The proposed model, based on Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams using a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, has been applied to analyze grant applications. The methodology used in this paper includes a strict experimental pipeline for analyzing grant applications and four different data mining models. These models are designed to predict innovation and creativity scores of research proposals, including those with high IC scores. Experiments have shown that the proposed model can accurately classify moderate IC-score grant applications. Furthermore, building a long-term data mining model to predict future grant applications is also possible using this approach.",
    "This paper proposes a data mining model with a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms, and presents an experimental pipeline for analysing grant applications. The contributions are listed as follows: this paper outlines its methodology and results. Another popular data mining model is the proposed data mining model, which uses ensemble learning to combine multiple decision trees. This study also examines 13 high IC- score research proposals, with a median IC-score of 5.0, indicating their quality or relevance. The data mining models across all the research proposals were used for training and testing purposes. Building on this foundation, it builds a long-term data mining model to predict future grant applications. Furthermore, scientists and researchers always write research proposals to present their research plans and explain the significance of the project to funding agencies, resulting in 3,693 research proposals submitted with assigned IC scores. The study also presents valuable information extracted from these proposals that can be used for predicting high or low IC-score grant applications.",
    "The proposed model, which uses Random Forest classifiers over documents encoded with features denoting the presence or absence of unigrams, achieved an accuracy of 84.17% in predicting high IC-score research proposals from a dataset comprising peer-reviewed grant applications. The best performance was obtained using this approach, outperforming other effective data mining models such as SVM, AdaBoost, and Xgboost. This paper presents the results of our analysis on moderate IC-score grant applications, which showed that the LDA with 30 keywords using TF-IDF is a suitable feature extraction technique for identifying high-scoring research proposals.",
    "The Australian Government research funding agency received numerous grant proposals from scientists and researchers, each outlining their innovative project plans. To predict high IC-score research proposals based on expert reviewers' scores, a data mining model was proposed to extract essential features of these proposals. The model can briefly introduce the key aspects of research proposals to assist human evaluators in screening excellent submissions. By training this model using 13 high IC-score research proposals with innovation and creativity (IC) scores ranging from 85% to 100%, we aimed to develop a predictive vocabulary for contemporaneous proposals. Future work includes exploring alternative evaluation criteria, applying other machine learning models, integrating pre-trained language models from NLP, and developing a long-term predictive model.",
    "The range of research proposals with moderate IC scores, spanning from 15% to 85%, is a subset of grant applications characterized by innovation and creativity scores between low (0-15%) and high (85-100%) levels. To predict the high IC-score research proposals, scientists and researchers always write research proposals to present their research plans and explain the significance of the project to the funding agencies. The proposed method involves applying data mining models, such as Random Forest classifiers based on unigram features encoded with a modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithm. This approach has been shown to be effective in predicting high IC-score research proposals, which are not included in the training data and may require different linguistic patterns or features to accurately predict.",
    "The data mining model, which includes decision trees and random forests, was used to analyze grant proposals. The experiments involved applying a modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithm with DT and RF classifiers to predict high IC-score research proposals. A pipeline for analyzing grant applications included the TF-IDF algorithm with DT and RF classifiers, which uses TF-IDF and decision trees to classify texts. This project aimed at developing a system for predicting high IC-score research proposals by testing several cut-off options. The results showed that moderate IC-score grant applications were crucial in understanding the significance of the project. Low IC-score research proposals had lower innovation and creativity scores compared to median IC-score research proposals, which had an equal score of 5.0.",
    "The study focuses on high-IC score research proposals, which are innovative project proposals that have been evaluated to be highly impactful. These proposals can be classified using data mining models such as Decision Tree (DT) and RF classifiers. The DT classifier uses a tree-like model to classify data by splitting it into subsets based on the values of input features. On the other hand, RF classifiers use an ensemble learning method that combines multiple decision trees and votes on each tree in specific classification problems. In this study, we also explore another popular data mining model, Random Forest (RF), which can consistently achieve better performance than DT classifier. The project aims to develop a predictive vocabulary for contemporaneous proposals and understand how the model inferred research proposals with high IC scores from data features.",
    "Data mining models, such as Decision Tree (DT) and RF classifiers, are used for extracting valuable patterns or relationships from large datasets. The data mining model has a broader term of 'data mining algorithms', which includes various techniques like DT classifier, SVM, AdaBoost, and Xgboost. When collecting proposals, research ideas or plans that have been evaluated to be highly innovative and impactful, such as high IC-score proposals of 85~100%, are considered. The proposed model is a Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams using a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm. Another popular data mining model is RF classifiers, which is an ensemble learning method that combines multiple decision trees and votes on each tree in specific classification problems.",
    "The project aims to predict high IC-score research proposals based on expert reviewers' scores. To achieve this, we employed various data mining models such as RF classifiers and Decision Tree (DT) algorithms. The overall design of the project involves extracting features from grant applications using a modified TF-IDF algorithm. Thousands of research proposals are submitted each year, with moderate IC- score grant applications falling between 15% to 85%. Our methodology predicts high and low IC-score research proposals by analyzing the data mining models' performance on these proposals. The RF classifier based on unigram and the modified TF-IDF algorithm proved effective in predicting high IC-score research proposals. Additionally, we explored other effective data mining models such as SVM, AdaBoost, and Xgboost to predict innovative project ideas.",
    "The design, which only implements the IDF part of TF-IDF as a feature extraction technique to identify rare terms that can define innovativeness. The range of research proposals with moderate IC scores, spanning from 15% to 85%, is a subset of grant applications characterized by innovation and creativity scores between low (0-15%) and high (85-100%) levels. We choose the very common Decision Tree (DT) and RF classifiers for experimental comparison. These models are used for predicting high IC-score research proposals, which have been assigned a peer-reviewed innovation and creativity score of 5 or higher, indicating high levels of innovativeness.",
    "The study proposes to analyze grant applications using data mining models, specifically Random Forest (RF) classifiers and K-means clustering algorithm. The range of research proposals with moderate IC scores, spanning from 15% to 85%, are characterized by innovation and creativity scores between low (0-15%) and high (85-100%) levels. To establish a more comprehensive system that can predict grant applications based on multiple criteria, we apply data mining models across all the research proposals. The study also explores other evaluation scores and proposes a framework for evaluating grant applications considering various evaluation scores to make predictions. Furthermore, it highlights the importance of scientists and researchers writing research proposals to present their plans and explain the significance of projects to funding agencies.",
    "The task of predicting high IC-score research proposals involves analyzing grant applications submitted to an Australian Government research funding agency. To achieve this, we employ various data mining models and classifiers, including Decision Trees (DT) and Random Forests (RF). Our experiment uses a modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithm to encode unigram terms in the documents. The results show that our model can accurately predict IC scores for research proposals, with 13 of them having an IC score below 1.0. Furthermore, we demonstrate the effectiveness of data mining techniques and models in extracting valuable patterns from large datasets.",
    "In this study, we employed Decision Tree (DT) and RF classifiers to analyze grant applications. Specifically, we used scikit-learn library [27] to implement these algorithms. Our proposed pipeline involves extracting a specific section ('Innovation and Creativity statement') from each Ideas grant application and analyzing it using the DT classifier. We also extracted this part from each Ideas grant and analyzed using the proposed model. The median IC-score research proposals were found to have an innovation and creativity score equal to 5.0, which is the median IC score of all grant applications. Our methodology involves presenting a written plan outlining the objectives, methodology, and expected outcomes of a scientific research project, typically submitted for funding or peer review. We chose Decision Tree (DT) and RF classifiers as our baseline models for experimental comparison. The proposed method uses an efficient feature extraction technique to extract relevant features from data that can be used to predict high IC-score research proposals.",
    "The RF classifier with Bagging ensemble method has been used to analyze grant applications. A multi-criteria approach was employed to evaluate research proposals, which included a range of moderate IC scores and high/low IC-score research proposals. The proposed model combined unigram presence or absence features encoded using modified TF-IDF algorithm, achieving an accuracy of 84.17%. The choice of classifiers, including Decision Trees and Random Forest, played a crucial role in predicting high IC-score research proposals. Excellent research proposals were identified as those that met specific innovation and creativity scores assigned by reviewers.",
    "Research proposals with high IC scores are challenging to predict, but models like Random Forest classifiers can achieve better accuracy. The proposed pipeline involves building a long-term data mining model using features from unigram terms and applying it to grant applications. Statistical analysis of IC scores is required before designing the whole pipeline. Various data mining algorithms such as SVM, AdaBoost, and Xgboost can be applied to this project. This paper proposes an experimental comparison between Decision Tree (DT) and RF classifiers for predicting high IC-score research proposals based on expert reviewers' assigned IC scores.",
    "In this research project, we applied various data sets to extract tens of thousands of features from research proposals. We used an intra-class dispersion algorithm based on TF-IDF to adjust term weights and increase the importance of rare but significant words. The IC scores assigned by reviewers were moderate for some research proposals, while others had invalid or low scores below 1.0. To predict high IC-score research proposals, we employed a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms. Our proposed method used feature extraction techniques and data mining models like SVM, AdaBoost, and Xgboost to classify texts into predefined categories. We chose Decision Tree (DT) and RF classifiers for experimental comparison, considering up to 99.31% of features at each split. The pipeline we applied was a rigorous methodology that analyzed grant applications using peer-reviewed research proposals as input.",
    "The proposed modified TF-IDF algorithm evaluates the performance of a variant of traditional Term Frequency - Inverse Document Frequency (TF-IDF) technique. This new approach only incorporates inverse document frequency, used for encoding unigram terms in text analysis and feature extraction tasks. The range of research proposals with moderate IC scores is characterized by innovation and creativity scores between 15% to 85%. A study on the significance of these proposals reveals that scientists and researchers always write research plans to present their projects to funding agencies. To predict IC scores, a data mining model was trained using K-means clustering algorithm and five data mining classifiers, including Decision Trees (DT) and Random Forests (RF). The proposed model uses TF-IDF as the feature extraction technique and combines it with DT and RF classifiers for text classification tasks.",
    "The Preference Selection Index (PSI) evaluates research grant applications. Decision Tree and RF classifiers have a broader term, classifier. Proposals are often presented as PDF research proposals submitted by scientists and researchers to funding agencies. High IC-score proposals are typically innovative project ideas with high Innovation and Creativity scores. Data mining models apply feature extraction techniques using modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithms. A pipeline for analyzing grant applications can be applied across all types of grant applications, including research proposals submitted by scientists and researchers to funding agencies. The related work of this project involves predicting high IC-score research proposals using data mining models like Random Forest classifier and Decision Tree classifier. Finding the hyper-parameters requires applying a 10-fold cross-validation method. TF-IDF is used in information retrieval, while TF-IGM performed better than traditional Term Frequency-Inverse Document Frequency (TF-IDF) algorithm. A modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithm can be understood as a simple encoding technique that takes the value 0 or the IDF value of the term depending on whether it exists in research proposals. Finally, six research proposals with low IC scores were guessed wrongly as high IC-score proposals.",
    "The proposed method uses various data sets to analyze grant applications submitted to an Australian Government research funding agency. The TF-IDF algorithm with different data mining classifiers evaluates the performance of a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, achieving an accuracy of 84.17% based on all types of grant applications. Experimental results show that the proposed model can predict high IC-score research proposals effectively. This paper proposes a pipeline for analyzing grant applications using data mining techniques, including Decision Tree and RF classifiers. The original training set settings used in this study are moderate IC-score research proposals.",
    "The study proposes the use of data mining models, specifically Random Forest classifiers, to evaluate research proposals. The PSI method was used to assess grant applications, and experimental results showed that high-quality data mining models can accurately predict low IC-score research proposals. Future work includes exploring alternative evaluation criteria and integrating pre-trained language models from NLP. Additionally, the study highlights the importance of information retrieval techniques in identifying relevant features for classification tasks.",
    "Research proposals are based on interval-valued intuitionistic fuzzy sets, which provide a mathematical framework for modeling uncertain or imprecise information. The proposed model combines bigram and trigram combinations to analyze grant applications. Our method cannot predict future grant applications due to the limitations of current data sets. A strict experimental pipeline is given, and the results prove its feasibility. Decision Trees (DT) and Random Forests (RF) classifiers are chosen as a baseline for experimental comparison. The proposed modified TF-IDF algorithm with RF classifier shows promising results in predicting IC scores. Future grant applications will require innovative approaches to address emerging challenges.",
    "Researchers often submit innovative project proposals to present their research plans and explain the significance of the project to funding agencies. These proposals are peer-reviewed, with expert reviewers assigning 'innovation and creativity' (IC) scores based on the proposal's novelty and originality. To predict high IC-score research proposals, scientists use machine learning algorithms like SVM, AdaBoost, and Xgboost for classification or regression tasks in data mining. The task involves selecting grant applications based on their innovation and creativity scores, distinguishing between high and low IC-score research proposals. A combination of unigrams, bigrams, and trigrams is used to analyze linguistic patterns and features in these proposals.",
    "The K-means clustering algorithm, a popular unsupervised machine learning technique, was used to partition data into clusters. This method was applied to group similar objects or patterns. The modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, which only incorporates the inverse document frequency component, was employed for encoding unigram terms. Additionally, peer-reviewed research proposals were submitted and evaluated by peers for innovation and creativity scores. Furthermore, RF classifier with Bagging ensemble method was used to classify data into predefined categories. The experiments conducted using this approach aimed at analyzing grant applications and predicting their 'innovation and creativity' scores.",
    "The proposed method, which combines term frequency with inverse document frequency (TF-IDF), has been shown to improve the performance of data mining tasks. This approach was used to analyze grant applications and predict high IC-score research proposals, achieving an accuracy of 84.17%. The TF-IDCRF algorithm, a variant of traditional TF-IDF, also demonstrated improved results. In addition, deleting stop words can further enhance the effectiveness of this method. A pipeline for analyzing grant applications has been proposed, which involves feature extraction techniques and Random Forest classification. This approach was used to analyze research proposals with moderate IC scores, providing valuable insights into innovative project ideas.",
    "A pipeline for analysing grant applications has been developed, which includes a modified TF-IDF algorithm with Decision Tree (DT) and RF classifiers. This proposed method can be used to predict research proposals with high IC scores from data features. The innovation and creativity (IC) scores are relevant to the significance of the project, as government research funding agencies use Data mining models to evaluate grant applications. In this context, a high-quality data mining model was developed using unigram terms encoded by the modified TF-IDF algorithm, which can be applied to develop procedures and guidelines for human assessors to evaluate future research proposals.",
    "Research proposals with high Information Content (IC) scores have been evaluated to be highly innovative and impactful. The experimental results show that the Random Forest classifier achieves the best performance, achieving an accuracy of 84.17%. This highlights the importance of using suitable machine learning models for evaluating grant applications. Furthermore, peer-reviewed research proposals are a crucial step in assessing innovation and creativity. In this study, we used various data sets to analyze grant applications and predict IC scores. The proposed method involves removing punctuations and tokenizing by whitespace, which makes text into small pieces called tokens. Additionally, hyper-parameter tuning is an essential step in applying machine learning models for data mining tasks.",
    "The experimental result refers to the outcome of applying a data mining model, specifically a Random Forest classifier with modified TF-IDF algorithm, to analyze grant applications and predict innovation scores. The proposed method uses a Latent Dirichlet allocation scheme to extract representative keywords from abstracts of each paper. In addition, we focus on proposing an efficient feature extraction technique rather than the choice of classifiers. This system used a Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams, using a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm. The design only implements the IDF part of TF-IDF as a feature extraction technique to identify rare terms that can define innovativeness. Several experiments were conducted to analyze grant applications with moderate innovation and creativity scores, aiming to determine whether there is a relation between these proposals and those with high or low IC scores.",
    "The project aims to apply data mining models to analyze grant applications and predict high IC- score proposals. The first step defines the data mining model, such as the Random Forest classifier with its adjustable hyperparameters. The proposed method cannot predict future grant applications because the current dataset contains only key terms for 2019 and does not represent future grant applications. An effective data mining model uses a pipeline to analyze peer-reviewed research proposals, which are written by scientists and researchers to present their research plans and explain the significance of the project to funding agencies. The proposed method is based on an improved TF-IDF algorithm that focuses on the relationship between classes in a classification model.",
    "The study proposes an improved TF-IDF algorithm, TF-IDCRF, which combines unigrams, bigrams, and trigrams to analyze grant applications. The proposed method uses a Random Forest classifier based on unigram terms encoded with the modified TF-IDF algorithm. This approach is shown to be more accurate in predicting research proposals with low IC scores than those with high IC scores across all types of grant applications. Furthermore, deleting stop words can improve the performance of data mining tasks as demonstrated by Fani et al. [23]. The study also highlights the importance of feature extraction techniques such as TF-IDF and proposes a modified version that only incorporates the inverse document frequency component.",
    "The concept of Random Forest (RF) classifier, specifically highlighting its composition as an ensemble of Decision Trees (DTs), where each DT serves as a classifier within an ensemble. This can be interpreted to mean that each classifier in the ensemble is a DT classifier. The Bagging ensemble method has a broader term, five different ensemble methods. Each decision tree depends independently on a random sample. Our proposed pipeline and the data mining model are used for classification tasks. RF classifiers have a broader term, news classification method. This modified feature extraction algorithm uses Term Frequency - Inverse Document Frequency (TF-IGM) to extract relevant characteristics from data. The best performing model is based on moderate IC scores. We follow the same pipeline and establish a new model to evaluate Ideas Grant applications only, considering innovation criteria. Experiments select proposals with moderate IC scores and those of high and low IC scores. Innovative project proposals have a broader term, research proposal. MEL extracts metadata from various file formats.",
    "In this study, we propose an effective data mining model that uses Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms. This approach can help human evaluators understand research proposals' strengths and weaknesses during manual review. Our proposed method achieved an accuracy of 82.5% when analyzing Ideas Grant applications. Future work can be carried out from different perspectives, such as considering multiple evaluation criteria, exploring alternative data mining models, or predicting future grant applications.",
    "The proposed method, which combines experiments with moderate IC scores and uses the DT classifier to achieve performance, has been shown to be effective. The experimental results of checking these proposals reveal that the top 100 features extracted from grant applications are crucial in determining whether a scientific research project is worthy of funding. Furthermore, applying the same method but with different hyper-parameters yields each accuracy, highlighting the importance of custom stop words and rare terms associated with innovativeness. Moreover, designing a modified TF-IDF algorithm that only implements the IDF part has led to significant improvements in feature extraction techniques, such as combining unigrams, bigrams, and trigrams. Ultimately, this project aims to provide insight into what is going on inside the black box of machine learning models like Random Forest classifiers.",
    "The proposed method, LDA, has been used to analyze large datasets. Innovative project proposals are written by scientists and researchers always presenting their research plans and explaining the significance of the projects to funding agencies. A combination of unigrams, bigrams, and trigrams was used to represent grant applications. The number of estimated features for predicting IC scores is 11. Table 1 shows a statistic of IC scores, with thousands of research proposals having valid IC scores each year. The TF-IDCRF algorithm uses the modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm and hyper-parameters to classify texts. Random Forest classifiers are used in combination with Bagging ensemble methods for predicting IC scores. Data mining techniques transform quantitative data into meaningful patterns, while K-means clustering algorithms group similar objects or patterns.",
    "A novel algorithm, research approach, technique or approach for solving a problem or achieving a specific goal has been proposed. This methodology incorporates Latent Dirichlet allocation and TF-IGM to encode unigram terms. The model uses Multivariate Bernoulli Naive Bayes to classify grant applications based on their features. A predictive vocabulary is developed to understand how the model infers research proposals with high IC scores from data features. Experimental results show that moderate IC-score research proposals can be accurately predicted using a modified feature extraction algorithm and five data mining classifiers, including Decision Tree (DT) and Random Forest (RF). The bigram and trigram terms are not regarded as essential features by DT and RF classifiers. Support Vector Machine (SVM) is also used for classification purposes.",
    "According to Table 1, IC scores are used as an evaluation metric. The confusion matrix shows a broader term of statistical measures. N_estimation has a broader term parameter and is used by Random Forest classifiers for predicting IC scores. So we choose common Decision Tree (DT) and RF classifiers for experimental comparison. TF-IDF algorithm combines term frequency with inverse document frequency to measure the importance of words in documents, which are part of Natural Language Processing. The research paper classification system uses techniques such as Term Frequency-Inverse Document Frequency (TF-IDF) and Latent Dirichlet Allocation (LDA). Government funding agencies use data mining models like five data mining classifiers compared [5] for evaluating grant applications. To include all the terms from the corpus, we choose a Random Forest classifier with modified TF-IDF algorithm. Scientists and researchers write research proposals to present their plans and explain project significance to funding agencies.",
    "The Preference Selection Index (PSI) methodology has been widely used for evaluating and selecting preferences, often applied to assess research proposals or grant applications. The scoring method involves a technique that assigns scores to research proposals based on their innovation and creativity. In this study, we propose a modified TF-IDF algorithm using gensim to analyze n-grams and various data sets from different datasets. Our pipeline for analysing grant applications shows the process of assigning predefined categories or labels to text data based on its content. We also use DT and RF classifiers for text classification tasks to identify the most influential terms in research proposals. The proposed model correctly classified a number of predicted research proposals by their Innovation and Creativity (IC) scores, demonstrating its effectiveness in evaluating grant applications.",
    "In addition to studying grant applications, researchers have proposed an improved TF-IDF algorithm for natural language processing and information retrieval tasks. This modified algorithm was used as a basis for developing news classification methods that can achieve high accuracy in analyzing 'Innovation and Creativity' statements from Ideas Grants. The results show that the best performance is achieved with 84.17% accuracy by using an RF classifier, which demonstrates the feasibility of this approach. Furthermore, the overall design of the project involves evaluating grant applications to determine their worthiness for funding, a significant and rigorous step for government research funding agencies. Experimental results demonstrate the effectiveness of this pipeline in analyzing 'Innovation and Creativity' statements from Ideas Grants.",
    "The proposed method, which combines feature extraction techniques with Latent Dirichlet allocation (LDA) scheme and TF-IDF algorithm, has been applied to analyze grant applications. The Australian Government research funding agency provides various types of grants, including Synergy Grants, Standard Project Grants, and Ideas Grants. Fani et al.'s paper on data mining highlights the importance of understanding text semantics using pre-trained language models. The current dataset contains key terms related to 2019 grant applications, which are analyzed using a combination of unigrams, bigrams, and trigrams. Bayesian Optimization is used for efficient search in high-dimensional spaces. Another similar work uses TF-IDF and LDA schemes to classify papers.",
    "A comparison study was conducted to evaluate different feature extraction techniques, including bigram and trigram combinations. The proposed method used a Random Forest classifier with unigrams encoded using a modified Term Frequency - Inverse Document Frequency algorithm instead of choosing between DT and RF classifiers for text classification because we would like to find out the most influential terms. This approach was applied to scientific research funding grants such as Synergy Grants, Standard Project Grants, and Ideas Grants. The methodology section described the experimental pipeline used to analyze grant applications in this research project. Additionally, data mining techniques were employed to identify papers with similar topics and clustering algorithms like K-means based on their TF-IDF vector encoding.",
    "The methodology, MEL, has been used to extract metadata from various file formats. The scikit-learn library was employed for implementing decision tree and random forest classifiers in data mining experiments. A fuzzy preference relation matrix was proposed as a novel algorithm for solving problems or achieving specific goals. In the text pre-processing step, Porter Stemming algorithm was applied to convert all characters into lowercase, remove numbers and punctuations, tokenize by whitespace, delete stop words with an IDF value less than 1.0, and apply Porter Stemming algorithm. Data mining algorithms were used to transform massive amounts of unstructured data into structured information. RF classifiers selected the most popular category as the final result from a set of categories classified using random forest classifier. Grant applications have been categorized under topics. Confusion matrices were generated for evaluating the performance of machine learning models or statistical classification algorithms. The LDA with 30 keywords using TF-IDF was used to extract representative keywords from text data. To find the hyper-parameters of RF classifiers, scientific research methods were employed. Research paper classification systems have been developed based on news classification method. All experiments were conducted under a multi-criteria approach for evaluating and selecting the best-performing models or algorithms. Features extracted from proposed models showed that only 618 features are considered significant among tens of thousands of features in research proposals. The Multivariate Bernoulli Naive Bayes algorithm was compared with SVM, another machine learning algorithm.",
    "Innovative proposals often rely on features extracted from research studies, which can be evaluated using methods like cross-validation. The vocabulary of these proposals can be understood by analyzing bigrams and predicting IC scores with a data mining model that incorporates techniques such as TF-IDF. This approach has been applied to various datasets, including those related to Ideas Grants, where the Innovation and Creativity statement is crucial for evaluating proposals. By selecting top features from tens of thousands of attributes, we can better understand how human evaluators assess research studies. Furthermore, methods like 10-fold cross-validation have been used to evaluate data mining models that predict IC scores based on various criteria.",
    "Pre-trained language models excel at understanding text semantics, which features contribute to test data. The importance of terms can be calculated using IDF technique. In grant applications, criteria such as innovation and creativity scores are crucial for evaluation. A combination of unigrams, bigrams, and trigrams is used in the analysis of scientific research proposals. Different funding projects like Synergy Grants, Standard Project Grants, and Ideas Grants aim to improve the quality and diversity of research. Wongso et al.'s proposed method uses TF-IDF and SVD algorithms for feature selection. Our pipeline involves a sequence of processes designed to achieve specific goals. The purpose of this series of experiments is to investigate whether there is a relation between proposals with moderate innovation and creativity scores, high IC scores, and low IC scores. Scientific research often employs data mining models in text classification to categorize texts into predefined categories. This system uses LDA scheme to extract representative keywords from the abstracts of each paper.",
    "Research funding agencies, such as Synergy Grants and Standard Project Grants, provide financial support for scientific research projects. These grants are categorized into different types of funding initiatives aimed at improving the quality and diversity of scientific research. The process of preparing and transforming text data into a suitable form for analysis or processing is crucial in understanding the essential features of research proposals. A systematic approach called TF-IDF algorithm is used to analyze grant applications, which involves encoding unigram terms using inverse document frequency component only. Furthermore, statistical analysis techniques are applied to quantify the importance of words in documents. The results show that research proposals with high IC scores use more diverse language than those with low IC-scores.",
    "Researchers have proposed an efficient feature extraction technique, using Term vectors and statistical measures to analyze data. This approach has been shown to improve test accuracy by deleting stop words, as demonstrated by Fani et al. [23]. The method combines a simple encoding technique with Decision Tree (DT) and Random Forest (RF) classifiers, which have been used in specific classification problems. Additionally, the TF-IDF algorithm was modified to focus on class relationships, resulting in an improved text classification model called TF-IDCRF. Furthermore, scientists and researchers write research proposals using a methodology that involves extracting representative keywords from abstracts of papers [5]. The proposed method has also been shown to be effective for optimizing hyperparameters [32] and can be used with various techniques such as bigrams [26], which are sequences of two adjacent words or tokens.",
    "The proposed model, which combines the Term Frequency-Inverse Document Frequency (TF-IDF) algorithm with decision trees and random forests for text classification tasks. The design follows the idea that rare terms can define innovativeness. Experimental results prove this concept meaningful by showing how the modified TF-IDF algorithm identifies rare terms associated with innovativeness. Additionally, the study aims to develop a predictive vocabulary for contemporaneous proposals and understand how the model infers research proposals with high IC scores from data features. The proposed method achieves an accuracy of 84.17%. Furthermore, Bayesian Optimization is used as an optimization function in this pipeline project.",
    "The proposed method for evaluating grant applications involves using a set of hyper-parameters, including max_depth and min_samples_split. This approach utilizes Preference Selection Index (PSI) as a methodology to assess research proposals or grant applications. The only evaluation criterion used in this study is the performance of RF classifiers, which are part of five different ensemble methods. Hyper-parameter tuning was also applied using modified TF-IDF algorithm. In addition, removing punctuations and tokenizing by whitespace were adopted to make text into small pieces called tokens. Furthermore, Attribute Selection Measures (ASM) were used as a measure for selecting attributes from datasets. The best performance achieved in this study is 84.17%, except for one model combination in Table 6. As evaluators may describe their innovation in this section, the experimental result does not support our guess.",
    "The most influential terms have been identified as key contributors to predicting innovative project proposals. Attribute Selection Measures and measures are used to evaluate attributes or features in a dataset, while motivation drives research projects like this one on developing data mining models for high IC-score research proposals. The Tesseract-OCR method is employed to extract text from images, with unigrams representing single words and n-grams being sequences of contiguous words. PSI methods are applied to select attributes based on their importance. We need to implement the scoring method to evaluate grant applications without requiring weight criteria determination. Latent Dirichlet allocation (LDA) schemes are used to extract representative keywords from abstracts, while Chen et al.'s research proves that text pre-processing techniques improve model performance. HaCohen-Kerner et al.'s study shows that feature extraction techniques can be applied to reduce weighted impurities. The top 100 features have been extracted and contribute to reducing weighted impurities.",
    "A comparison study has a broader term of 'study', which systematically investigates or analyzes different methods, approaches, or techniques. The number of decision trees used in ensemble learning or random forests, n_estimators, also has a broader term of 'parameter'. Similarly, the size of the data set and features have a broader term of 'features' and 'Natural Language Processing', respectively. Preference Selection Index is another method that evaluates research grant applications without determining the weight of criteria. It's worth noting that our proposed method cannot predict future grant applications because the current data set contains only key terms for 2019 and does not represent future grant applications, which highlights a limitation or constraint on predicting future outcomes. Furthermore, researchers like Wongso et al. submit grant applications to government research funding agencies, presenting their research plans and explaining the significance of the projects.",
    "The feasibility score of a project can be scored as its significance score. A news classification method has a broader term, text classification, which involves the process of automatically assigning predefined categories or labels to written content. This modified feature extraction algorithm defines innovativeness and plays a crucial role in evaluating grant applications. The fifth section is part of six sections that provide further analysis on experimental results. TF-IDF and LDA schemes are techniques used for information retrieval, including term frequency-inverse document frequency (TF-IDF) and latent Dirichlet allocation (LDA) methods. Maximize method is a Bayesian Optimization tool used to tune hyperparameters in data mining models. Feature extraction technique is an approach used to identify relevant characteristics from data. Table 5 provides evaluation scores for the performance of machine learning models, while [25] offers additional information on this topic. Term Frequency - Inverse Document Frequency (TF-IDF) algorithm and LDA schemes are techniques that can be applied in various contexts. Fani et al.'s research team has made significant contributions to data mining. A significant step for funding agencies is the evaluation of grant applications, which requires careful consideration by government research funding agencies. The accuracy of a model's performance can be measured using evaluation scores. Human evaluators play a crucial role in screening excellent research proposals.",
    "The proposed method, which utilizes Python-based methods and incorporates RF classifier with the Bagging ensemble method, has been shown to be effective. The init_points parameters used for Bayesian Optimization were found to have a broader term of parameter. Additionally, Data mining techniques and TF-IGM are both considered as important techniques in this field. Furthermore, scientific research funding agencies provide essential support each year. We confirm that the feature words considered as important by DT and RF classifiers will less than 1000 words. The text sentiment classification technique is a proposed method for evaluating data. A multi-criteria approach was used to evaluate research proposals. Different perspectives were explored in this study, including considering multiple evaluation criteria. Finally, we conclude that MEL is an effective methodology for extracting metadata from various file formats.",
    "A proposed method for text stemming has been developed, which can be used to simplify words into their most basic form. This approach was inspired by Chen et al., a group of researchers who have collaborated on research and published papers together. The evaluation criterion should not only focus on innovation but also consider other factors. N-grams are sequences of contiguous words that can be analyzed or represented in text. Each country's government provides financial support for scientific research projects, which is crucial for developing cutting-edge scientific research. Statistical analysis involves the process of using mathematical and logical techniques to summarize and describe data. Data mining algorithms use computational procedures to automatically discover patterns or relationships from large datasets. Research grant applications are formal requests submitted by individuals or organizations to pursue specific projects or research endeavors. The Random Forest classifier is a technique used for classification tasks, with adjustable hyperparameters such as maximum depth, minimum samples for splitting, and number of estimators. Expert panels review research proposals to evaluate their quality and feasibility. This paper is divided into six sections: introduction, methodology, results, discussion, conclusion, and future work.",
    "The TF-IDF algorithm, also known as the IDF, plays a crucial role in adjusting term weights in documents by increasing the importance of rare words and decreasing that of frequent but less important ones. This technique has been widely used for feature extraction from text data. In fact, bigram and trigram terms are not considered essential features by Decision Tree (DT) and Random Forest (RF) classifiers. The relationship between classes in a classification model is another key aspect to consider. Scientists and researchers always write research proposals to present their plans and explain the significance of projects to funding agencies. This paper's methodology section outlines the experimental pipeline used for analyzing grant applications, which involves selecting features using Attribute Selection Measures (ASM). Furthermore, this study employs LDA as a topic modeling technique to analyze large datasets. The background context highlights the importance of developing cutting-edge scientific research and government funding agencies' roles in supporting essential projects.",
    "The study of attribute selection measures (ASM) and techniques, such as LDA, highlights the importance of statistical measures like 59. Pre-trained language models excel at understanding text semantics, which can be applied to various projects funded by government or funding agencies through initiatives like Ideas Grants. Modified TF-IDF algorithms are a method for feature extraction that has been implemented in different ways, including only computing IDF part. Random Forest (RF) is another technique used for classification and clustering. The n-grams [26] provide additional information on the topic of text analysis. In addition to these techniques, we focus on proposing an efficient feature extraction technique rather than the choice of classifiers.",
    "Researchers have proposed various methods for analyzing grant applications, including the use of K-means clustering algorithm and modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm. A recent study focused on proposing an efficient feature extraction technique rather than the choice of classifiers. The overall design of a project involves considering deleting words that only exist once or twice. This paper mentions bigram is two consecutive words in a sentence, which is used to analyze grant applications. Experimental results show insights, trends, and patterns behind the original data.",
    "The study of unigrams, which are single words in natural language, has led to advancements in methodology. Researchers have evaluated future research proposals using human assessors and found that A measure is valuable for internal model development purposes. The news classification method used by Oztaysi et al., a group of researchers, relies on the technique of TF-IDCRF, an improved Term Frequency - Inverse Document Frequency algorithm. Data mining has revealed insights, trends, and patterns in massive amounts of unstructured data. This section provides details on the workflow of the proposed pipeline and the data mining model.",
    "The proposed pipeline and data mining model are designed to support essential and cutting-edge scientific research each year. The core idea of defining the modified TF-IDF algorithm is meaningful, highlighting rare terms associated with innovativeness. To improve performance, stop words are deleted from text data during pre-processing. A significant step for funding agencies involves evaluating grant applications rigorously. In this section, we explore all combinations of classifiers as a forest and discuss methodology. We also examine statistical measures to evaluate the importance of features. Furthermore, we introduce Term Frequency & Inverse Gravity Moment, an improved TF-IDF algorithm that focuses on class discrimination. Additionally, we present random exploration in parameter space and plot DT classifier results.",
    "The study employed various techniques, including Term Frequency & Inverse Gravity Moment and TF-IDF and SVD algorithms to analyze grant applications. The methodology section outlined the experimental pipeline used to classify news articles using TF-IDF and Multivariate Bernoulli Naive Bayes. Insights, trends, and patterns were drawn from massive amounts of unstructured data in various datasets. Statistical measures such as 42 represented a combination of unigrams, bigrams, and trigrams. The results showed that the best combination of parameter and target value was achieved through experimental results. Furthermore, natural language processing (NLP) techniques like n-grams were used to analyze text, while funding projects received support from an Australian Government research funding agency.",
    "Scientific research funding has a broader term, which is funding projects. Fan and Qin proposed TF-IDCRF as an improved Term Frequency - Inverse Document Frequency algorithm that focuses on the relationship between classes in a classification model. Table 4 has a broader term [25], which provides additional information or support to an argument, idea, or statement. Text pre-processing techniques have a broader term method, and experiments also follow methodology. A combination of unigrams, bigrams, and trigrams is represented by the trigram, which is three consecutive words in a sentence. Custom stop words are a subset of stop words that appear too frequently and have little influence on experimental results. The n_iter parameter controls the number of iterations or steps in Bayesian Optimization process used for hyperparameter tuning. Term weights represent the relative importance or significance of terms in a given context, often used to rank or prioritize them. Scientific research projects are systematic investigations aimed at advancing knowledge, understanding, or solving problems in a specific field or domain. Innovation is not the only evaluation criterion; instead, it should be considered along with other relevant criteria.",
    "The proposed method, which involves feature extraction techniques and random exploration on the parameter space using Bayesian Optimization, has been applied to various domains such as government research proposals. The results show that this approach can effectively identify important features in datasets like Table 7, a data visualization presenting information and statistics. Furthermore, the technique used for calculating term frequency (TF) is based on treating each word with equal importance, which provides an intuitive understanding of how individual characteristics contribute to overall outcomes. In addition, the black box process has been explored by examining the top features extracted from the proposed model, giving insight into its internal workings.",
    "Previous studies or research that have a bearing on the current topic, such as related work and study, are crucial for advancing scientific inquiry. Novel approaches like proposed method and technique can be used to solve complex problems. The importance of developing cutting-edge scientific research cannot be overstated. In fact, government research funding agencies provide financial support for various projects, including those that utilize innovative methods like a fuzzy preference relation matrix. Experimental results often lead to conclusions about the effectiveness of certain approaches. Furthermore, techniques such as TF-IDF and Multivariate Bernoulli Naive Bayes can be used to classify text data. The Porter Stemming algorithm is another technique used for simplifying words into their most basic form.",
    "The multi-criteria approach considers multiple criteria for evaluation, assessment, or decision-making. This methodology involves a series of steps, including text pre-processing and applying techniques such as TF-IDF and Multivariate Bernoulli Naive Bayes. Experimental pipelines are also part of this process, which can involve using methods like Tesseract-OCR to extract text from images. Hyper-parameters play an important role in controlling the algorithm's performance. The proposed method involves a combination of Porter Stemming algorithm and LDA schemes. Additionally, predictive vocabulary is used for understanding research proposals. Funding projects are also part of this process, which can involve using tables like Table 1 to present data. Researchers such as Guo and Yang have contributed significantly to the field by proposing new methods. Next Word Negation (NWN) technique has been applied in natural language processing.",
    "Researchers have proposed various techniques for text sentiment analysis, including modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithms. Das and Chakraborty [9] suggested a technique based on this algorithm to classify texts as positive or negative. Other researchers like Fan and Qin [10], Chen et al. [8], have also contributed to the development of text sentiment analysis methods, including ensemble techniques such as Bagging. These approaches can be applied in various domains, including news classification, where the goal is to categorize articles into predefined categories based on their content. The most popular category may not always be the correct one, and experimental results [59] have shown that different algorithms can produce varying outcomes.",
    "According to the graph, max depth has a broader term parameter. TF-IDF and Multivariate Bernoulli Naive Bayes were used on news articles in the Indonesian Language corpus. Trigram has a broader term technique, which was also applied to news classification method. The government is a sovereign entity responsible for governing Australia, while Innovation and Creativity statement is divided into six sections with Text pre-processing being one of them. Performance is measured by experimental results, where Wongso et al. conducted research on methodology. Experimental settings were used in the study, which was explained by scientists and researchers as having significance. Applying the same method but with different hyper-parameters led to better accuracy values, making it easier to find the best value. The more steps taken in Bayesian Optimization improve the likelihood of finding this optimal value.",
    "The NWN method identifies negated words in sequence, which can be applied to various techniques. Research proposals are reviewed by expert panels from government research funding agencies, who receive thousands of submissions each year. Experimental settings and implementations with hardware platforms involve methodology, while Hyper-parameter tuning is a technique used for optimizing model performance. The Indonesian Language corpus contains news articles that provide insights into the benefits and motivations mentioned above. Punctuations can be extracted using Tesseract-OCR method, which has been applied by researchers like Chen et al.. Implementations on various hardware platforms require careful consideration of these necessary qualities. Human evaluators respond to these criteria when assessing research proposals. The importance of maximizing model performance is highlighted in Fig. 2, which illustrates the concept further.",
    "The maximize technique aims to find the maximum value of a given function, which can be achieved through iterative processes with parameters such as n_iter. This process can be abstracted into sections or steps that require text pre-processing and sentiment classification techniques. The Australian Government research funding agency provides grants for researchers like Das and Chakraborty [9] to develop innovative proposals using Python-based methods on hardware platforms, including memory configurations like 16GB 2133 MHz LPDDR3. Furthermore, the researcher can utilize bigrams or text sentiment classification techniques to analyze language patterns.",
    "The process of simplifying words into their most basic form, text stemming, is a technique that has been used to develop cutting-edge scientific research. In practice, this methodology involves using various techniques such as Next Word Negation (NWN) and TF-IDF algorithm proposed by Das and Chakraborty [9]. The idea that rare terms can define innovativeness suggests that uncommon words in a text can be indicative of innovative ideas. However, because very rare terms tend not to be predictive, researchers rely on human assessors or evaluators to evaluate the quality of research proposals. Government funding agencies provide financial support for scientific research initiatives, which are crucial for every country in the 21st century. This paper is divided into six sections: section 1 introduces the concept of text sentiment classification; section 2 discusses the methodology used by Das and Chakraborty [9]; section 3 presents an experimental pipeline using Next Word Negation (NWN); section 4 explores the idea that rare terms can define innovativeness; section 5 describes the process of developing cutting-edge scientific research, including hardware platforms such as MacBook Pro with Intel Core i7 2.9 GHz Quard-Core processor; and finally, section 6 discusses deletion as a technique used in natural language processing.",
    "This section describes experimental settings. The MacBook Pro with Intel Core i7 2.9 GHz Quad-Core processor has an Intel Core i7 2.9 GHz Quad-Core processor, which is a high-performance laptop computer model from Apple featuring advanced hardware capabilities. This paper is divided into six sections, each of which contains organized content. Every country requires the importance of developing cutting-edge scientific research to be introduced in section 6. The background and related work of this project are also introduced in section 4. Furthermore, bigram combinations play a crucial role in analyzing language structures.",
    "This paper is divided into six sections, with each section containing organized content. The concept of 'other' refers to something that does not fit into a specific category or classification. A method can be seen as a systematic approach for achieving a goal or solving a problem. Human assessors and evaluators are responsible for evaluating proposals, projects, or performances from different perspectives. Section 4 is part of this paper's organization structure. The black box represents complex algorithms or decision-making processes whose internal workings are not publicly disclosed. A trigram is three consecutive words in a sentence used to represent scientific terms. This section describes experimental settings and configurations. Das and Chakraborty [9] are researchers who have contributed to the field of research. Shifts can occur in position, direction, or status. The Australian Government is responsible for governing Australia.",
    "Every country has a broader term, which is simply referred to as 'country'. Additionally, every country's government also falls under this broader category. Furthermore, it is self-evident that developing cutting-edge scientific research is essential for the 21st century."
  ],
  "times": [
    834.2700214385986
  ]
}