{
  "iri": "Paper-53",
  "title": "ICML_1995_38_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-53-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-53-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-1",
              "text": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems ."
            },
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-2",
              "text": "In this paper , we present methods by which an agent learns action models from its own experience and from its observation of a domain expert ."
            },
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-3",
              "text": "These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms ."
            },
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-4",
              "text": "Training instances are generated from experience and observation , and a variant of GOLEM is used to learn action models from these instances ."
            },
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-5",
              "text": "The integrated learning system has been experimentally validated in simulated construction and ooce domains ."
            }
          ]
        }
      ]
    }
  ],
  "summary": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems . In this paper , we present methods by which an agent learns action models from its own experience and from its observation of a domain expert . These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms . Training instances are generated from experience and observation , and a variant of GOLEM is used to learn action models from these instances . The integrated learning system has been experimentally validated in simulated construction and ooce domains .",
  "kg2text": [
    "This paper presents methods for learning action models, which are domain-specific representations that autonomous agents utilize for planning. These methods enable agents to learn action models from their own experiences and observations of domain experts. Specifically, a variant of GOLEM is employed to facilitate this learning process. The methods introduced in this paper differ from previous work by incorporating a suitable action model formalism designed for reactive agents, which enhances their ability to learn effectively. The action model formalism encompasses broader concepts, including actions, which represent the various activities that agents learn to execute. Furthermore, the agent learns from both its own experience and the observation of a domain expert, with these experiences and observations forming the basis for generating training instances used to refine the action models. Overall, the relationship between these elements illustrates a comprehensive approach to improving the learning capabilities of autonomous agents.",
    "The needs of a re-active agent encompass the specific requirements for developing action model formalisms that enable autonomous agents to learn and adapt their behavior. Instances are generated from experience and observation, which are crucial for the learning process. The integrated learning system has been experimentally validated in simulated construction and ooce domains, demonstrating its effectiveness in these controlled environments. The action model formalism is particularly suited to meet the needs of a re-active agent, facilitating the learning of action models by autonomous agents. Furthermore, noise-handling mechanisms play a vital role in the successful implementation of methods within the area of autonomous agent learning, ensuring that the learning process remains accurate despite potential data noise. Training instances, which are also generated from experience and observation, serve as essential examples for training models, reinforcing the connection between these concepts."
  ],
  "times": [
    9.222768545150757
  ]
}