{
  "iri": "Paper-82",
  "title": "ICML_2016_18_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-82-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-82-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-82-Section-1-Paragraph-1-Sentence-1",
              "text": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects ."
            },
            {
              "iri": "Paper-82-Section-1-Paragraph-1-Sentence-2",
              "text": "With the rise of deep archi-tectures , the prime focus has been on object category recognition ."
            },
            {
              "iri": "Paper-82-Section-1-Paragraph-1-Sentence-3",
              "text": "Deep learning methods have achieved wide success in this task ."
            },
            {
              "iri": "Paper-82-Section-1-Paragraph-1-Sentence-4",
              "text": "In contrast , object pose estimation using these approaches has received relatively less attention ."
            },
            {
              "iri": "Paper-82-Section-1-Paragraph-1-Sentence-5",
              "text": "In this work , we study how Convolutional Neural Networks -LRB- CNN -RRB- architectures can be adapted to the task of simultaneous object recognition and pose estimation ."
            },
            {
              "iri": "Paper-82-Section-1-Paragraph-1-Sentence-6",
              "text": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations ."
            },
            {
              "iri": "Paper-82-Section-1-Paragraph-1-Sentence-7",
              "text": "We extensively experiment on two recent large and challenging multi-view datasets and we achieve better than the state-of-the-art ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.0005462169647216797,
    80.82701992988586,
    77.80436086654663,
    80.52369999885559,
    0.05964803695678711,
    0.00019621849060058594,
    0.00015091896057128906,
    296.3400011062622,
    306.0834810733795,
    3.6613352298736572,
    0.07945871353149414,
    0.013164997100830078,
    0.0016529560089111328,
    72.73786783218384,
    0.007306098937988281,
    0.0487520694732666,
    0.002980947494506836,
    5.518970012664795,
    11.149045944213867,
    31.11697793006897,
    590.0325911045074,
    8.681985855102539,
    303.3673610687256,
    3.979578971862793,
    0.002138853073120117,
    0.014002799987792969
  ],
  "nodes": {
    "Entity-this_work": {
      "node_id": "this_work",
      "disambiguation_index": 0,
      "label": "this work",
      "aliases": [
        "this work"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This work refers to the research study that investigates the adaptation of Convolutional Neural Networks (CNNs) for the simultaneous tasks of object recognition and pose estimation, analyzing the representation of object pose information in comparison to object category representations.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-5",
          "local_name": "this work",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_work-Mention-1"
        }
      ],
      "relevance": 0.74755859375
    },
    "Entity-distributed_representation_within_cnns": {
      "node_id": "distributed_representation_within_cnns",
      "disambiguation_index": 0,
      "label": "distributed representations within CNNs",
      "aliases": [
        "distributed representations within CNNs"
      ],
      "types": [
        "representation",
        "CNN"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Distributed representations within CNNs refer to the internal feature representations learned by Convolutional Neural Networks that capture different aspects of input data, such as object pose information, which can be analyzed to understand the network's ability to differentiate between object categories and their poses.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-6",
          "local_name": "distributed representations within CNNs",
          "local_types": [
            "representation",
            "CNN"
          ],
          "iri": "Entity-distributed_representation_within_cnns-Mention-1"
        }
      ],
      "relevance": 0.7216796875
    },
    "Entity-approach": {
      "node_id": "approach",
      "disambiguation_index": 0,
      "label": "approaches",
      "aliases": [
        "approaches"
      ],
      "types": [
        "methodology",
        "technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'approaches' refers to the methodologies and techniques employed in deep learning for object pose estimation, particularly in the context of Convolutional Neural Networks (CNNs) that are adapted for simultaneous object recognition and pose estimation.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-4",
          "local_name": "approaches",
          "local_types": [
            "methodology",
            "technique"
          ],
          "iri": "Entity-approach-Mention-1"
        }
      ],
      "relevance": 0.71044921875
    },
    "Entity-di-chotomy": {
      "node_id": "di-chotomy",
      "disambiguation_index": 0,
      "label": "di-chotomy",
      "aliases": [
        "di-chotomy"
      ],
      "types": [
        "concept",
        "classification",
        "theoretical framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'di-chotomy' refers to the conceptual distinction in the Object Recognition task between object categorization, which requires a view-invariant representation, and object pose estimation, which necessitates a representation that captures pose information across different object categories.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "di-chotomy",
          "local_types": [
            "concept",
            "classification",
            "theoretical framework"
          ],
          "iri": "Entity-di-chotomy-Mention-1"
        }
      ],
      "relevance": 0.68896484375
    },
    "Entity-layer": {
      "node_id": "layer",
      "disambiguation_index": 0,
      "label": "layers",
      "aliases": [
        "layers"
      ],
      "types": [
        "component",
        "structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'layers' refers to the individual components of Convolutional Neural Networks (CNNs) that process and represent information, specifically focusing on how these layers contribute to the understanding of object pose and category recognition.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-6",
          "local_name": "layers",
          "local_types": [
            "component",
            "structure"
          ],
          "iri": "Entity-layer-Mention-1"
        }
      ],
      "relevance": 0.67724609375
    },
    "Entity-simultaneous_object_recognition_and_pose_estimation": {
      "node_id": "simultaneous_object_recognition_and_pose_estimation",
      "disambiguation_index": 0,
      "label": "simultaneous object recognition and pose estimation",
      "aliases": [
        "simultaneous object recognition and pose estimation"
      ],
      "types": [
        "pose estimation",
        "computer vision",
        "combined task",
        "task",
        "object recognition"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Simultaneous object recognition and pose estimation is a combined task in computer vision that involves identifying objects within an image and determining their spatial orientation or position at the same time.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-5",
          "local_name": "simultaneous object recognition and pose estimation",
          "local_types": [
            "pose estimation",
            "computer vision",
            "combined task",
            "task",
            "object recognition"
          ],
          "iri": "Entity-simultaneous_object_recognition_and_pose_estimation-Mention-1"
        }
      ],
      "relevance": 0.6767578125
    },
    "Entity-cnn_model": {
      "node_id": "cnn_model",
      "disambiguation_index": 0,
      "label": "CNN models",
      "aliases": [
        "CNN models"
      ],
      "types": [
        "neural network",
        "machine learning model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "CNN models are a class of deep learning architectures specifically designed for processing structured grid data, such as images, by utilizing convolutional layers to automatically learn spatial hierarchies of features.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-6",
          "local_name": "CNN models",
          "local_types": [
            "neural network",
            "machine learning model"
          ],
          "iri": "Entity-cnn_model-Mention-1"
        }
      ],
      "relevance": 0.6728515625
    },
    "Entity-these_approach": {
      "node_id": "these_approach",
      "disambiguation_index": 0,
      "label": "these approaches",
      "aliases": [
        "these approaches"
      ],
      "types": [
        "approach"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "These approaches refer to deep learning methods, specifically Convolutional Neural Networks (CNNs), that have been primarily focused on object category recognition in the context of object recognition tasks.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-4",
          "local_name": "these approaches",
          "local_types": [
            "approach"
          ],
          "iri": "Entity-these_approach-Mention-1"
        }
      ],
      "relevance": 0.66162109375
    },
    "Entity-layer_of_various_cnn_model": {
      "node_id": "layer_of_various_cnn_model",
      "disambiguation_index": 0,
      "label": "layers of various CNN models",
      "aliases": [
        "layers of various CNN models",
        "the layers of various CNN models"
      ],
      "types": [
        "CNN",
        "component",
        "layer",
        "model architecture",
        "neural network architecture",
        "CNN model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Layers of various CNN models refer to the individual processing units and structures within convolutional neural networks that are responsible for feature extraction and transformation of input data in the context of deep learning.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-6",
          "local_name": "layers of various CNN models",
          "local_types": [
            "CNN",
            "component",
            "model architecture",
            "neural network architecture",
            "CNN model"
          ],
          "iri": "Entity-layer_of_various_cnn_model-Mention-1"
        },
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-6",
          "local_name": "the layers of various CNN models",
          "local_types": [
            "CNN model",
            "layer"
          ],
          "iri": "Entity-layer_of_various_cnn_model-Mention-2"
        }
      ],
      "relevance": 0.65869140625
    },
    "Entity-two_recent_large_and_challenging_multi-view_datasets": {
      "node_id": "two_recent_large_and_challenging_multi-view_datasets",
      "disambiguation_index": 0,
      "label": "two recent large and challenging multi-view datasets",
      "aliases": [
        "two recent large and challenging multi-view datasets"
      ],
      "types": [
        "dataset"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'two recent large and challenging multi-view datasets' refers to specific datasets used in the study of object recognition and pose estimation, which facilitate the evaluation of Convolutional Neural Networks in capturing both object categories and pose information from multiple viewpoints.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-7",
          "local_name": "two recent large and challenging multi-view datasets",
          "local_types": [
            "dataset"
          ],
          "iri": "Entity-two_recent_large_and_challenging_multi-view_datasets-Mention-1"
        }
      ],
      "relevance": 0.65576171875
    },
    "Entity-cnn": {
      "node_id": "cnn",
      "disambiguation_index": 0,
      "label": "CNN",
      "aliases": [
        "CNN"
      ],
      "types": [
        "machine learning",
        "artificial intelligence",
        "architecture",
        "neural network",
        "model",
        "abbreviation",
        "deep learning",
        "machine learning model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "CNN refers to Convolutional Neural Networks, which are a class of deep learning models primarily used for processing structured grid data such as images.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-5",
          "local_name": "CNN",
          "local_types": [
            "machine learning",
            "artificial intelligence",
            "architecture",
            "neural network",
            "model",
            "abbreviation",
            "deep learning",
            "machine learning model"
          ],
          "iri": "Entity-cnn-Mention-1"
        },
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-6",
          "local_name": "CNN",
          "local_types": [
            "model",
            "neural network"
          ],
          "iri": "Entity-cnn-Mention-2"
        }
      ],
      "relevance": 0.64794921875
    },
    "Entity-object_recognition_task": {
      "node_id": "object_recognition_task",
      "disambiguation_index": 0,
      "label": "Object Recognition task",
      "aliases": [
        "Object Recognition task"
      ],
      "types": [
        "computer vision",
        "task"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The Object Recognition task is a computer vision challenge that involves identifying and categorizing objects within images, often requiring the analysis of their spatial orientation and pose.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "Object Recognition task",
          "local_types": [
            "computer vision",
            "task"
          ],
          "iri": "Entity-object_recognition_task-Mention-1"
        }
      ],
      "relevance": 0.64794921875
    },
    "Entity-task": {
      "node_id": "task",
      "disambiguation_index": 0,
      "label": "task",
      "aliases": [
        "task"
      ],
      "types": [
        "activity",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'task' refers to the challenge of object recognition within the context of deep learning, specifically focusing on the simultaneous recognition of object categories and estimation of their poses.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-3",
          "local_name": "task",
          "local_types": [
            "activity",
            "process"
          ],
          "iri": "Entity-task-Mention-1"
        }
      ],
      "relevance": 0.63427734375
    },
    "Entity-object_recognition": {
      "node_id": "object_recognition",
      "disambiguation_index": 0,
      "label": "Object Recognition",
      "aliases": [
        "object recognition",
        "Object Recognition"
      ],
      "types": [
        "image processing",
        "computer vision",
        "field",
        "task",
        "computer vision task"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Object Recognition is a computer vision task that involves identifying and classifying objects within images or video streams.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "Object Recognition",
          "local_types": [
            "field",
            "computer vision",
            "task"
          ],
          "iri": "Entity-object_recognition-Mention-1"
        },
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-5",
          "local_name": "object recognition",
          "local_types": [
            "computer vision task",
            "image processing"
          ],
          "iri": "Entity-object_recognition-Mention-2"
        }
      ],
      "relevance": 0.6328125
    },
    "Entity-convolutional_neural_network": {
      "node_id": "convolutional_neural_network",
      "disambiguation_index": 0,
      "label": "Convolutional Neural Networks",
      "aliases": [
        "Convolutional Neural Networks"
      ],
      "types": [
        "machine learning",
        "artificial intelligence",
        "CNN",
        "architecture",
        "neural network",
        "model",
        "deep learning",
        "machine learning model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Convolutional Neural Networks are a class of deep learning models designed to process and analyze visual data by mimicking the way the human brain processes images, utilizing layers of convolutional filters to extract features.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-5",
          "local_name": "Convolutional Neural Networks",
          "local_types": [
            "machine learning",
            "artificial intelligence",
            "CNN",
            "architecture",
            "neural network",
            "model",
            "deep learning",
            "machine learning model"
          ],
          "iri": "Entity-convolutional_neural_network-Mention-1"
        }
      ],
      "relevance": 0.63134765625
    },
    "Entity-object_category_recognition": {
      "node_id": "object_category_recognition",
      "disambiguation_index": 0,
      "label": "object category recognition",
      "aliases": [
        "object category recognition"
      ],
      "types": [
        "computer vision",
        "recognition",
        "classification",
        "task",
        "recognition task"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Object category recognition is a task in computer vision that involves identifying and classifying objects into predefined categories based on their visual features.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-2",
          "local_name": "object category recognition",
          "local_types": [
            "computer vision",
            "recognition",
            "classification",
            "task",
            "recognition task"
          ],
          "iri": "Entity-object_category_recognition-Mention-1"
        }
      ],
      "relevance": 0.630859375
    },
    "Entity-representation_capable_of_capturing_pose_information": {
      "node_id": "representation_capable_of_capturing_pose_information",
      "disambiguation_index": 0,
      "label": "representation capable of capturing pose information",
      "aliases": [
        "representation capable of capturing pose information"
      ],
      "types": [
        "representation"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'representation capable of capturing pose information' refers to a specific type of representation used in object recognition that enables the estimation of the orientation and position of objects across various categories, contrasting with view-invariant representations used for object categorization.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "representation capable of capturing pose information",
          "local_types": [
            "representation"
          ],
          "iri": "Entity-representation_capable_of_capturing_pose_information-Mention-1"
        }
      ],
      "relevance": 0.6240234375
    },
    "Entity-this_task": {
      "node_id": "this_task",
      "disambiguation_index": 0,
      "label": "this task",
      "aliases": [
        "this task"
      ],
      "types": [
        "task"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "this task refers to the object category recognition within the broader context of the Object Recognition task, which involves distinguishing between different categories of objects using deep learning methods.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-3",
          "local_name": "this task",
          "local_types": [
            "task"
          ],
          "iri": "Entity-this_task-Mention-1"
        }
      ],
      "relevance": 0.6171875
    },
    "Entity-estimating_object_pose": {
      "node_id": "estimating_object_pose",
      "disambiguation_index": 0,
      "label": "estimating object pose",
      "aliases": [
        "object pose estimation",
        "estimating object pose"
      ],
      "types": [
        "regression",
        "computer vision",
        "pose estimation",
        "estimation",
        "object pose estimation",
        "task",
        "technique",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Estimating object pose refers to the process of determining the position and orientation of an object in a given space, often in relation to a camera or observer.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "estimating object pose",
          "local_types": [
            "estimation",
            "process",
            "object pose estimation"
          ],
          "iri": "Entity-estimating_object_pose-Mention-1"
        },
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-4",
          "local_name": "object pose estimation",
          "local_types": [
            "regression",
            "computer vision",
            "pose estimation",
            "estimation",
            "task",
            "technique"
          ],
          "iri": "Entity-estimating_object_pose-Mention-2"
        }
      ],
      "relevance": 0.6162109375
    },
    "Entity-different_category_of_object": {
      "node_id": "different_category_of_object",
      "disambiguation_index": 0,
      "label": "different categories of objects",
      "aliases": [
        "different categories of objects"
      ],
      "types": [
        "objects",
        "group",
        "classification",
        "category"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'different categories of objects' refers to the various classifications of objects that are recognized in the context of object recognition tasks, particularly in relation to their pose estimation and view-invariant representation.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "different categories of objects",
          "local_types": [
            "objects",
            "group",
            "classification",
            "category"
          ],
          "iri": "Entity-different_category_of_object-Mention-1"
        }
      ],
      "relevance": 0.60986328125
    },
    "Entity-pose_estimation": {
      "node_id": "pose_estimation",
      "disambiguation_index": 0,
      "label": "pose estimation",
      "aliases": [
        "pose estimation"
      ],
      "types": [
        "computer vision task",
        "image processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pose estimation is a computer vision task that involves determining the position and orientation of a person or object in an image or video.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-5",
          "local_name": "pose estimation",
          "local_types": [
            "computer vision task",
            "image processing"
          ],
          "iri": "Entity-pose_estimation-Mention-1"
        }
      ],
      "relevance": 0.59912109375
    },
    "Entity-object": {
      "node_id": "object",
      "disambiguation_index": 0,
      "label": "objects",
      "aliases": [
        "objects"
      ],
      "types": [
        "entity",
        "physical object"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the Object Recognition task, 'objects' refers to physical entities that are categorized and whose poses are estimated, requiring distinct representations for categorization and pose information.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "objects",
          "local_types": [
            "entity",
            "physical object"
          ],
          "iri": "Entity-object-Mention-1"
        }
      ],
      "relevance": 0.59521484375
    },
    "Entity-categorization_of_object": {
      "node_id": "categorization_of_object",
      "disambiguation_index": 0,
      "label": "categorization of objects",
      "aliases": [
        "categorization of objects"
      ],
      "types": [
        "process",
        "object categorization",
        "classification"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The categorization of objects refers to the process of classifying objects into distinct categories based on their features, which is essential for achieving a view-invariant representation in object recognition tasks.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "categorization of objects",
          "local_types": [
            "process",
            "object categorization",
            "classification"
          ],
          "iri": "Entity-categorization_of_object-Mention-1"
        }
      ],
      "relevance": 0.58447265625
    },
    "Entity-object_category_representation": {
      "node_id": "object_category_representation",
      "disambiguation_index": 0,
      "label": "object category representations",
      "aliases": [
        "object category representations"
      ],
      "types": [
        "object category",
        "object classification",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Object category representations refer to the cognitive or computational models that encode and categorize visual objects based on their shared characteristics and classifications.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-6",
          "local_name": "object category representations",
          "local_types": [
            "object category",
            "object classification",
            "representation"
          ],
          "iri": "Entity-object_category_representation-Mention-1"
        }
      ],
      "relevance": 0.57568359375
    },
    "Entity-less_attention": {
      "node_id": "less_attention",
      "disambiguation_index": 0,
      "label": "less attention",
      "aliases": [
        "less attention"
      ],
      "types": [
        "attention"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'less attention' refers to the comparatively lower focus and research efforts dedicated to the task of object pose estimation in deep learning methods, particularly in contrast to the more extensively studied area of object category recognition.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-4",
          "local_name": "less attention",
          "local_types": [
            "attention"
          ],
          "iri": "Entity-less_attention-Mention-1"
        }
      ],
      "relevance": 0.5712890625
    },
    "Entity-deep_learning_method": {
      "node_id": "deep_learning_method",
      "disambiguation_index": 0,
      "label": "Deep learning methods",
      "aliases": [
        "Deep learning methods"
      ],
      "types": [
        "machine learning technique",
        "machine learning",
        "artificial intelligence",
        "technique",
        "method",
        "deep learning"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Deep learning methods are a subset of machine learning techniques that utilize neural networks with multiple layers to model complex patterns in data.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-3",
          "local_name": "Deep learning methods",
          "local_types": [
            "machine learning technique",
            "machine learning",
            "artificial intelligence",
            "technique",
            "method",
            "deep learning"
          ],
          "iri": "Entity-deep_learning_method-Mention-1"
        }
      ],
      "relevance": 0.5673828125
    },
    "Entity-distributed_representation": {
      "node_id": "distributed_representation",
      "disambiguation_index": 0,
      "label": "distributed representations",
      "aliases": [
        "distributed representations"
      ],
      "types": [
        "data structure",
        "concept",
        "data representation",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Distributed representations are a type of data representation that encodes information in a way that captures relationships and similarities between data points, often used in machine learning and neural networks to represent complex features in a lower-dimensional space.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-6",
          "local_name": "distributed representations",
          "local_types": [
            "data structure",
            "concept",
            "data representation",
            "representation"
          ],
          "iri": "Entity-distributed_representation-Mention-1"
        }
      ],
      "relevance": 0.5634765625
    },
    "Entity-object_pose_information": {
      "node_id": "object_pose_information",
      "disambiguation_index": 0,
      "label": "object pose information",
      "aliases": [
        "object pose information"
      ],
      "types": [
        "object pose",
        "object representation",
        "information",
        "information type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Object pose information refers to the data that describes the orientation and position of an object in a given space, often used in computer vision and robotics to understand how objects are situated relative to a reference frame.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-6",
          "local_name": "object pose information",
          "local_types": [
            "object pose",
            "object representation",
            "information",
            "information type"
          ],
          "iri": "Entity-object_pose_information-Mention-1"
        }
      ],
      "relevance": 0.56201171875
    },
    "Entity-the_state-of-the-art": {
      "node_id": "the_state-of-the-art",
      "disambiguation_index": 0,
      "label": "the state-of-the-art",
      "aliases": [
        "the state-of-the-art"
      ],
      "types": [
        "benchmark"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The state-of-the-art refers to the highest level of development or performance achieved in a particular field, specifically in the context of object recognition and pose estimation using deep learning methods, as indicated by the benchmark results against which the authors' findings are compared.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-7",
          "local_name": "the state-of-the-art",
          "local_types": [
            "benchmark"
          ],
          "iri": "Entity-the_state-of-the-art-Mention-1"
        }
      ],
      "relevance": 0.5615234375
    },
    "Entity-pose_information": {
      "node_id": "pose_information",
      "disambiguation_index": 0,
      "label": "pose information",
      "aliases": [
        "pose information"
      ],
      "types": [
        "spatial information",
        "data type",
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Pose information refers to the data representation that captures the orientation and position of objects in space, which is essential for accurately estimating object pose in the context of object recognition tasks.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "pose information",
          "local_types": [
            "spatial information",
            "data type",
            "data",
            "information"
          ],
          "iri": "Entity-pose_information-Mention-1"
        }
      ],
      "relevance": 0.54345703125
    },
    "Entity-view-invariant_representation": {
      "node_id": "view-invariant_representation",
      "disambiguation_index": 0,
      "label": "view-invariant representation",
      "aliases": [
        "view-invariant representation"
      ],
      "types": [
        "data structure",
        "model",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A view-invariant representation is a type of data structure or model that encodes information about objects in a way that remains consistent regardless of the viewpoint from which the objects are observed.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-1",
          "local_name": "view-invariant representation",
          "local_types": [
            "data structure",
            "model",
            "representation"
          ],
          "iri": "Entity-view-invariant_representation-Mention-1"
        }
      ],
      "relevance": 0.53564453125
    },
    "Entity-multi-view_datasets": {
      "node_id": "multi-view_datasets",
      "disambiguation_index": 0,
      "label": "multi-view datasets",
      "aliases": [
        "multi-view datasets"
      ],
      "types": [
        "dataset",
        "data collection",
        "data set",
        "data structure",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Multi-view datasets are collections of data that capture information from multiple perspectives or modalities, allowing for comprehensive analysis and improved performance in various machine learning tasks.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-7",
          "local_name": "multi-view datasets",
          "local_types": [
            "dataset",
            "data collection",
            "data set",
            "data structure",
            "data"
          ],
          "iri": "Entity-multi-view_datasets-Mention-1"
        }
      ],
      "relevance": 0.47705078125
    },
    "Entity-state-of-the-art": {
      "node_id": "state-of-the-art",
      "disambiguation_index": 0,
      "label": "state-of-the-art",
      "aliases": [
        "state-of-the-art"
      ],
      "types": [
        "benchmark",
        "performance metric",
        "performance",
        "term",
        "performance benchmark",
        "performance standard",
        "standard"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The term 'state-of-the-art' refers to the highest level of development or performance achieved in a particular field or area at a given time, often used as a benchmark for comparison.",
      "mentions": [
        {
          "reference": "Paper-82-Section-1-Paragraph-1-Sentence-7",
          "local_name": "state-of-the-art",
          "local_types": [
            "benchmark",
            "performance metric",
            "performance",
            "term",
            "performance benchmark",
            "performance standard",
            "standard"
          ],
          "iri": "Entity-state-of-the-art-Mention-1"
        }
      ],
      "relevance": 0.43359375
    }
  },
  "summary": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects . With the rise of deep archi-tectures , the prime focus has been on object category recognition . Deep learning methods have achieved wide success in this task . In contrast , object pose estimation using these approaches has received relatively less attention . In this work , we study how Convolutional Neural Networks -LRB- CNN -RRB- architectures can be adapted to the task of simultaneous object recognition and pose estimation . We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations . We extensively experiment on two recent large and challenging multi-view datasets and we achieve better than the state-of-the-art .",
  "triples": [
    [
      "Entity-object_recognition_task",
      "Predicate-exists_a_di-chotomy_between",
      "Entity-categorization_of_object"
    ],
    [
      "Entity-object_recognition_task",
      "Predicate-exists_a_di-chotomy_between",
      "Entity-estimating_object_pose"
    ],
    [
      "Entity-categorization_of_object",
      "Predicate-necessitates",
      "Entity-view-invariant_representation"
    ],
    [
      "Entity-estimating_object_pose",
      "Predicate-requires",
      "Entity-representation_capable_of_capturing_pose_information"
    ],
    [
      "Entity-representation_capable_of_capturing_pose_information",
      "Predicate-captures",
      "Entity-pose_information"
    ],
    [
      "Entity-representation_capable_of_capturing_pose_information",
      "Predicate-captures_over",
      "Entity-different_category_of_object"
    ],
    [
      "Entity-deep_learning_method",
      "Predicate-achieved_success_in",
      "Entity-this_task"
    ],
    [
      "Entity-deep_learning_method",
      "Predicate-achieved_success_in",
      "Entity-task"
    ],
    [
      "Entity-estimating_object_pose",
      "Predicate-has_received",
      "Entity-less_attention"
    ],
    [
      "Entity-approach",
      "Predicate-are_used_for",
      "Entity-estimating_object_pose"
    ],
    [
      "Entity-these_approach",
      "Predicate-are_used_for",
      "Entity-estimating_object_pose"
    ],
    [
      "Entity-convolutional_neural_network",
      "Predicate-are_adapted_to",
      "Entity-simultaneous_object_recognition_and_pose_estimation"
    ],
    [
      "Entity-cnn_model",
      "Predicate-have_layers",
      "Entity-layer_of_various_cnn_model"
    ],
    [
      "Entity-layer_of_various_cnn_model",
      "Predicate-represent",
      "Entity-object_pose_information"
    ],
    [
      "Entity-layer_of_various_cnn_model",
      "Predicate-contradict_with",
      "Entity-object_category_representation"
    ],
    [
      "Entity-distributed_representation_within_cnns",
      "Predicate-represent",
      "Entity-object_pose_information"
    ],
    [
      "Entity-distributed_representation_within_cnns",
      "Predicate-contradict_with",
      "Entity-object_category_representation"
    ],
    [
      "Entity-cnn_model",
      "Predicate-represent",
      "Entity-object_pose_information"
    ],
    [
      "Entity-cnn_model",
      "Predicate-contradict_with",
      "Entity-object_category_representation"
    ],
    [
      "Entity-two_recent_large_and_challenging_multi-view_datasets",
      "Predicate-experiment_on",
      "Entity-multi-view_datasets"
    ],
    [
      "Entity-two_recent_large_and_challenging_multi-view_datasets",
      "Predicate-achieve_better_than",
      "Entity-the_state-of-the-art"
    ],
    [
      "Entity-multi-view_datasets",
      "Predicate-are",
      "Entity-two_recent_large_and_challenging_multi-view_datasets"
    ],
    [
      "Entity-this_work",
      "Predicate-investigates_and_analyzes",
      "Entity-layer_of_various_cnn_model"
    ],
    [
      "Entity-this_work",
      "Predicate-investigates_how",
      "Entity-distributed_representation_within_cnns"
    ],
    [
      "Entity-this_work",
      "Predicate-investigates",
      "Entity-approach"
    ],
    [
      "Entity-approach",
      "Predicate-utilize",
      "Entity-distributed_representation_within_cnns"
    ]
  ],
  "triples_typing": [
    [
      "Entity-layer_of_various_cnn_model",
      "skos:broader",
      "Entity-cnn_model"
    ],
    [
      "Entity-convolutional_neural_network",
      "skos:broader",
      "Entity-cnn_model"
    ],
    [
      "Entity-object_pose_information",
      "skos:broader",
      "Entity-object_category_representation"
    ],
    [
      "Entity-estimating_object_pose",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-simultaneous_object_recognition_and_pose_estimation",
      "skos:broader",
      "Entity-estimating_object_pose"
    ],
    [
      "Entity-different_category_of_object",
      "skos:broader",
      "Entity-object"
    ],
    [
      "Entity-cnn",
      "skos:broader",
      "Entity-deep_learning_method"
    ],
    [
      "Entity-object_category_recognition",
      "skos:broader",
      "Entity-object_recognition_task"
    ],
    [
      "Entity-this_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-estimating_object_pose",
      "skos:broader",
      "Entity-pose_estimation"
    ],
    [
      "Entity-these_approach",
      "skos:broader",
      "Entity-approach"
    ],
    [
      "Entity-categorization_of_object",
      "skos:broader",
      "Entity-object_category_recognition"
    ],
    [
      "Entity-distributed_representation_within_cnns",
      "skos:broader",
      "Entity-cnn"
    ],
    [
      "Entity-layer_of_various_cnn_model",
      "skos:broader",
      "Entity-cnn"
    ],
    [
      "Entity-simultaneous_object_recognition_and_pose_estimation",
      "skos:broader",
      "Entity-object_category_recognition"
    ],
    [
      "Entity-convolutional_neural_network",
      "skos:broader",
      "Entity-cnn"
    ],
    [
      "Entity-simultaneous_object_recognition_and_pose_estimation",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-convolutional_neural_network",
      "skos:broader",
      "Entity-deep_learning_method"
    ],
    [
      "Entity-simultaneous_object_recognition_and_pose_estimation",
      "skos:broader",
      "Entity-pose_estimation"
    ],
    [
      "Entity-layer_of_various_cnn_model",
      "skos:broader",
      "Entity-layer"
    ],
    [
      "Entity-simultaneous_object_recognition_and_pose_estimation",
      "skos:broader",
      "Entity-object_recognition"
    ],
    [
      "Entity-object_recognition",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-simultaneous_object_recognition_and_pose_estimation",
      "skos:broader",
      "Entity-object_recognition_task"
    ],
    [
      "Entity-object_recognition_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-distributed_representation_within_cnns",
      "skos:broader",
      "Entity-cnn_model"
    ],
    [
      "Entity-object_category_recognition",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-object_category_representation",
      "skos:broader",
      "Entity-categorization_of_object"
    ]
  ],
  "predicates": {
    "Predicate-exists_a_di-chotomy_between": {
      "label": "exists a di-chotomy between",
      "description": "The predicate 'exists a di-chotomy between' indicates that there is a fundamental division or contrast between the subject and the object, suggesting that they represent two distinct categories, concepts, or approaches that are often viewed in opposition to each other. This relationship highlights the differences and separations that can be observed in the context of the subject, emphasizing the complexity and multifaceted nature of the topic at hand.",
      "disambiguation_index": 0
    },
    "Predicate-necessitates": {
      "label": "necessitates",
      "description": "The predicate 'necessitates' indicates a relationship where the subject is a condition or requirement that must be fulfilled in order for the object to be achieved or realized. It implies that the existence or occurrence of the object is dependent on the subject, suggesting a causal or essential link between the two.",
      "disambiguation_index": 0
    },
    "Predicate-requires": {
      "label": "requires",
      "description": "The predicate 'requires' establishes a necessary relationship between the subject and the object, indicating that the subject cannot be effectively or successfully executed without the presence or fulfillment of the object. It implies that the object provides essential resources, conditions, or capabilities that are indispensable for the subject's operation or realization.",
      "disambiguation_index": 0
    },
    "Predicate-captures": {
      "label": "captures",
      "description": "The predicate 'captures' indicates that the subject has the ability or function to effectively represent, record, or convey the essence of the object. In this context, it suggests a relationship where the subject actively engages with the object to preserve or express its characteristics, qualities, or details.",
      "disambiguation_index": 0
    },
    "Predicate-captures_over": {
      "label": "captures over",
      "description": "The predicate 'captures over' indicates a relationship where the subject possesses the ability or function to encompass, represent, or convey information regarding the object across various instances or types. It suggests that the subject can effectively gather or interpret data related to the object in a broad or inclusive manner.",
      "disambiguation_index": 0
    },
    "Predicate-achieved_success_in": {
      "label": "achieved success in",
      "description": "The predicate 'achieved success in' indicates that the subject has reached a favorable or desired outcome in relation to the object. It implies that the subject has effectively accomplished or excelled in a particular area, task, or goal represented by the object, demonstrating competence or effectiveness.",
      "disambiguation_index": 0
    },
    "Predicate-has_received": {
      "label": "has received",
      "description": "The predicate 'has received' indicates that the subject has been the recipient of something, which is represented by the object. It implies a transfer or allocation of attention, resources, or recognition from a broader context to the subject, suggesting that the subject is now associated with or impacted by the object in some way.",
      "disambiguation_index": 0
    },
    "Predicate-are_used_for": {
      "label": "are used for",
      "description": "The predicate 'are used for' indicates the purpose or function of the subject in relation to the object. It connects the subject to the object by specifying that the subject serves a particular role or is applied in a specific context to achieve the outcome represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_adapted_to": {
      "label": "are adapted to",
      "description": "The predicate 'are adapted to' indicates a relationship where the subject has been modified, designed, or evolved in a way that makes it suitable or effective for achieving the objectives or functions described by the object. This implies a purposeful alignment between the characteristics of the subject and the requirements or challenges posed by the object, suggesting that the subject possesses specific features or capabilities that enhance its performance in the context of the object.",
      "disambiguation_index": 0
    },
    "Predicate-have_layers": {
      "label": "have layers",
      "description": "The predicate 'have layers' indicates that the subject possesses multiple distinct levels or components, which are organized in a hierarchical or structured manner. In the context of the example, it signifies that the subject, such as CNN models, is characterized by the presence of various layers that contribute to its functionality and complexity, with each layer serving a specific role in processing or transforming input data.",
      "disambiguation_index": 0
    },
    "Predicate-represent": {
      "label": "represent",
      "description": "The predicate 'represent' establishes a relationship where the subject serves as a means of conveying, depicting, or symbolizing the object. In this context, the subject encapsulates or embodies the characteristics, features, or information of the object, thereby allowing for interpretation or understanding of the object's nature or state through the subject.",
      "disambiguation_index": 0
    },
    "Predicate-contradict_with": {
      "label": "contradict with",
      "description": "The predicate 'contradict with' indicates a relationship where the subject presents information, ideas, or characteristics that are in opposition to or conflict with those represented by the object. This suggests that the two entities cannot coexist in harmony, as they hold mutually exclusive positions or interpretations regarding a particular concept or phenomenon.",
      "disambiguation_index": 0
    },
    "Predicate-experiment_on": {
      "label": "experiment on",
      "description": "The predicate 'experiment on' indicates a process in which the subject conducts a systematic investigation or trial involving the object, typically to test hypotheses, gather data, or explore the characteristics and behaviors of the object in a controlled or structured manner.",
      "disambiguation_index": 0
    },
    "Predicate-achieve_better_than": {
      "label": "achieve better than",
      "description": "The predicate 'achieve better than' indicates a comparative relationship where the subject is evaluated against a benchmark or standard represented by the object. It signifies that the subject has attained a level of performance, quality, or effectiveness that surpasses that of the object, which is often a recognized or established reference point in a particular field or context.",
      "disambiguation_index": 0
    },
    "Predicate-are": {
      "label": "are",
      "description": "The predicate 'are' serves as a linking verb that connects the subject to the object, indicating that the subject is being identified or described by the object. It establishes a relationship of equivalence or classification, suggesting that the subject possesses the characteristics or identity represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-investigates_and_analyzes": {
      "label": "investigates and analyzes",
      "description": "The predicate 'investigates and analyzes' denotes an action where the subject engages in a systematic examination and evaluation of the object. This involves exploring the characteristics, structures, or functions of the object in order to gain insights, draw conclusions, or enhance understanding. The relationship established by this predicate indicates a thorough and methodical approach to studying the object, often with the aim of uncovering patterns, relationships, or underlying principles.",
      "disambiguation_index": 0
    },
    "Predicate-investigates_how": {
      "label": "investigates how",
      "description": "The predicate 'investigates how' indicates an inquiry or examination conducted by the subject to understand the mechanisms, processes, or methodologies related to the object. It implies a systematic exploration aimed at uncovering the underlying principles or functioning of the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-investigates": {
      "label": "investigates",
      "description": "The predicate 'investigates' denotes an action where the subject actively examines, explores, or studies the object in order to gain deeper understanding, insights, or knowledge about it. This relationship implies a systematic inquiry or analysis conducted by the subject towards the object.",
      "disambiguation_index": 0
    },
    "Predicate-utilize": {
      "label": "utilize",
      "description": "The predicate 'utilize' indicates that the subject employs or makes use of the object in a practical or effective manner. It suggests an active engagement where the subject applies the object to achieve a specific purpose or outcome.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' indicates a hierarchical relationship where the subject represents a specific instance or subset of a category, while the object denotes a more general category or concept that encompasses the subject. This relationship implies that the subject is a part of the broader category represented by the object, highlighting the inclusion of the subject within the wider context of the object.",
      "disambiguation_index": 0
    }
  }
}