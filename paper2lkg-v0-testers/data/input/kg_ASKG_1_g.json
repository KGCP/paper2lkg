{
  "iri": "Paper-MEL_Metadata_Extractor__Loader",
  "title": "MEL: Metadata Extractor & Loader",
  "authors": [
    "Sergio J. Rodr\u00edguez M\u00e9ndez",
    "Pouya G. Omran",
    "Armin Haller",
    "KerryTaylor"
  ],
  "keywords": [
    "Metadata Extraction",
    "Information Extraction",
    "Data Preprocessing",
    "Knowledge Graph Construction",
    "Data Analysis Pipeline"
  ],
  "sections": [
    {
      "iri": "Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-1-Paragraph-1-Sentence-1",
              "text": "The metadata and content-based information extraction tasks from heterogeneous file sets are pre-processing steps of many Knowledge Graph Construction Pipelines (KGCP)."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-2",
              "text": "These tasks often take longer than necessary due to the lack of proper tools that integrate several complementary extraction methods and properties to get a rich output set."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-3",
              "text": "This paper presents MEL, a Python-based tool that implements a set of methods to extract metadata and content-based information from unstructured information encoded in different source document formats."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-4",
              "text": "The results are generated as JSON files, which can: (a) optionally be stored in a document store, and (b) easily be mapped to RDF using a variety of tools such as J2RM."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-5",
              "text": "MEL supports more than 20 different file types, making it a versatile tool that aids pre-processing tasks as part of a KGCP based on comprehensive configurable settings."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-2",
      "subtitle": "Introduction",
      "paragraphs": [
        {
          "iri": "Section-2-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-1-Sentence-1",
              "text": "This paper introduces MEL, a tool that implements a set of methods to extract metadata and content-based information from various file formats as JSON objects."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-2",
              "text": "For each supported file type, MEL extracts the textual content from the source document and performs specific pre-processing and data cleaning tasks."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-3",
              "text": "Also, it performs basic text analysis tasks (pattern matching and keyword extraction) and generates the results in a machine-readable format (JSON), preparing the ground for content-based analysis."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-4",
              "text": "MEL is integrated with \u201cThe NLP -NER Toolkit\u201d (TNNT), which automates the extraction task of categorised named entities from the MEL results by using diverse state-of-the-art NLP tools and NER models [5]."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-5",
              "text": "MEL implements primitives for metadata and content extraction from unstructured data sets of heterogeneous formats, and along with the TNNT results, it provides the groundwork for content-based analysis."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-6",
              "text": "MEL and TNNT were developed in conjunction with J2RM [4], to easily map the JSON results to RDF as part of an automated KGCP."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-3",
      "subtitle": "Core Features",
      "paragraphs": [
        {
          "iri": "Section-3-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-1-Sentence-1",
              "text": "MEL has comprehensive metadata extraction support of various file types and formats."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-2",
              "text": "In a nutshell: (1) it takes as input a document (file) set; (2) then, for each document, it extracts its related metadata and content-based information, while performing basic text analysis (such as applying a configurable set of regular expressions and keyword extraction task); and, (3) as output, it generates a JSON file with the extracted metadata and text content with a structure based on the supported formats' document object model."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-3",
              "text": "It can store the results in a document store."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-4",
              "text": "MEL's general output structure is presented in Table 1."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-5",
              "text": "MEL has a detailed configuration JSON file that defines how the processing will be performed through a set of parameters and flags that establish the initial settings related to the document store, input document sets, TNNT general configuration, file extension mappings, the \u201cAssociated-Metadata\u201d processing (Table 1), and regular expressions to apply in the text analysis task, among other settings."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-6",
              "text": "The supported file types are presented in Table 2."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-7",
              "text": "The third column shows the theoretical number of attributes that the tool is able to extract per document type, whilst the fourth column shows the average of the extracted attributes from four use case document sets."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-8",
              "text": "OLE 2 file types and .docm can only be processed on Windows operating systems."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-9",
              "text": "Specifically for OLE 2 file types, MEL uses the olemeta tool."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-4",
      "subtitle": "Architecture",
      "paragraphs": [
        {
          "iri": "Section-4-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-1-Sentence-1",
              "text": "MEL is fully integrated with TNNT as depicted in Figure 1."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-2",
              "text": "The set of Python-based methods implemented in MEL are generic and can be applied to extract the content and metadata of all supported file types."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-3",
              "text": "MEL uses various opensource packages and tools with complementary capabilities to form a \u201cSwiss army knife\u201d of metadata and content-based information extraction from heterogeneous document sets."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-4",
              "text": "As part of the \u201cGeneral-Metadata\u201d extraction task, MEL optionally uses the XML output from the NLNZ Metadata Extractor tool, a Java standalone tool that extracts a comprehensive attribute and property list from dozens of file formats."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-5",
              "text": "The MEL general processing model is presented in Figure 2."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-6",
              "text": "It is important to note that each file type has its own specific processing model as well as the text analysis task, which is the last step that is performed for any output."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-5",
      "subtitle": "Related Work",
      "paragraphs": [
        {
          "iri": "Section-5-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-1-Sentence-1",
              "text": "The most comprehensive and current state-of-the-art tool for content extraction and analysis is Apache Tika, which is a complete and complex Java-based general-purpose system."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-2",
              "text": "While MEL's core goals resemble the ones of Apache Tika, the main difference and benefit of MEL as compared to Apache Tika is that it is a lightweight Python-based package for the metadata extraction of common file formats aimed to be used in a KGCP."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-3",
              "text": "Although there is a wide range of Python-based tools and libraries for metadata extraction, to the best of our knowledge, there is no package available that fully integrates in one system a comprehensive set of methods for metadata and content extraction of common file formats that generate the results in JSON structures based on the document object model of each format type."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-4",
              "text": "Last, MEL can assist in the information extraction stage of several KGCPs, such as the ones described in [6], [2], and [3]."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-6",
      "subtitle": "Conclusions and Future Work",
      "paragraphs": [
        {
          "iri": "Section-6-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-1-Sentence-1",
              "text": "MEL provides a versatile mechanism to extract metadata and content-based information from unstructured data sets of heterogeneous file formats, agnostic of the data sets' domain (general purpose)."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-2",
              "text": "It has been tested over thousands of documents using different formats and datasets as part of the AGRIF project."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-3",
              "text": "Based on the structure of the MEL's JSON results, it is possible to easily add a vocabulary or light-weight ontology using JSON-LD annotations, in order to make the extracted metadata \u201cRDF ready\u201d."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-4",
              "text": "This will be explored in the near future leveraging on the integration with JSON-LD ontologies."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-5",
              "text": "More file formats will be added in a per use-case requirements basis, in order to support KGCP tasks."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-6",
              "text": "Additionally, a project to \u201ccontainerise\u201d the MEL+TNNT tools is planned in the near future."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-7",
              "text": "The major contributions of this tool are: (1) the ability to extract metadata sets and content-based information from different source document formats; (2) the comprehensive support of over 20 different file types/formats integrated into one easy-to-use Python-based system; (3) integration with TNNT which automates the extraction of categorised named entities from the results by using diverse state-of-the-art NLP tools and NER models; and (4) the JSON result files can be easily mapped to RDF using J2RM."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    6.937980651855469e-05,
    150.54796290397644,
    256.126900434494,
    223.9802963733673,
    1.6026957035064697,
    0.0005109310150146484,
    0.0011298656463623047,
    230.54593777656555,
    336.1672306060791,
    15.67893362045288,
    3.689149856567383,
    0.20249557495117188,
    0.0012483596801757812,
    161.85711193084717,
    0.0021142959594726562,
    1.9205341339111328,
    0.008209466934204102,
    63.39877963066101,
    141.33051133155823,
    226.53708362579346,
    288.40484142303467,
    11.55124306678772,
    722.7179980278015,
    18.075104236602783,
    0.020561695098876953,
    0.16205549240112305
  ],
  "nodes": {
    "Entity-this_paper": {
      "node_id": "this_paper",
      "disambiguation_index": 0,
      "label": "This paper",
      "aliases": [
        "This paper"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "This paper refers to the introduction of MEL, a Python-based tool designed for extracting metadata and content-based information from various file formats and outputting the results as JSON objects.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "This paper",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_paper-Mention-1"
        }
      ],
      "relevance": 0.83349609375
    },
    "Entity-mel": {
      "node_id": "mel",
      "disambiguation_index": 0,
      "label": "MEL",
      "aliases": [
        "MEL"
      ],
      "types": [
        "entity",
        "system",
        "package",
        "metadata",
        "model",
        "software",
        "Python-based tool",
        "method",
        "acronym",
        "tool",
        "metadata extraction",
        "organization",
        "metadata extraction tool"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "MEL is a Python-based tool designed for extracting metadata and content-based information from unstructured data in various document formats, facilitating pre-processing tasks in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software",
            "Python-based tool"
          ],
          "iri": "Entity-mel-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software",
            "system"
          ],
          "iri": "Entity-mel-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "system"
          ],
          "iri": "Entity-mel-Mention-5"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software",
            "system"
          ],
          "iri": "Entity-mel-Mention-6"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "MEL",
          "local_types": [
            "system",
            "entity",
            "software",
            "tool",
            "acronym"
          ],
          "iri": "Entity-mel-Mention-7"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "MEL",
          "local_types": [
            "metadata extraction",
            "software",
            "tool",
            "metadata extraction tool"
          ],
          "iri": "Entity-mel-Mention-8"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "MEL",
          "local_types": [
            "model",
            "system"
          ],
          "iri": "Entity-mel-Mention-9"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "MEL",
          "local_types": [
            "software",
            "system"
          ],
          "iri": "Entity-mel-Mention-10"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-11"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "MEL",
          "local_types": [
            "system",
            "metadata extraction tool",
            "metadata extraction",
            "software",
            "tool"
          ],
          "iri": "Entity-mel-Mention-12"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "MEL",
          "local_types": [
            "software",
            "method",
            "tool",
            "system"
          ],
          "iri": "Entity-mel-Mention-13"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-14"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "organization",
            "software"
          ],
          "iri": "Entity-mel-Mention-15"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "MEL",
          "local_types": [
            "metadata extraction tool",
            "metadata extraction",
            "software",
            "tool",
            "package"
          ],
          "iri": "Entity-mel-Mention-16"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "system"
          ],
          "iri": "Entity-mel-Mention-17"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-18"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "MEL",
          "local_types": [
            "metadata extraction tool",
            "metadata",
            "system"
          ],
          "iri": "Entity-mel-Mention-19"
        }
      ],
      "relevance": 0.83251953125
    },
    "Entity-a_python-based_tool": {
      "node_id": "a_python-based_tool",
      "disambiguation_index": 0,
      "label": "a Python-based tool",
      "aliases": [
        "a Python-based tool"
      ],
      "types": [
        "tool",
        "programming language"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "MEL is a Python-based tool designed to extract metadata and content-based information from unstructured data in various document formats, facilitating pre-processing for Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "a Python-based tool",
          "local_types": [
            "tool",
            "programming language"
          ],
          "iri": "Entity-a_python-based_tool-Mention-1"
        }
      ],
      "relevance": 0.8115234375
    },
    "Entity-the_tool": {
      "node_id": "the_tool",
      "disambiguation_index": 0,
      "label": "the tool",
      "aliases": [
        "the tool",
        "this tool"
      ],
      "types": [
        "tool"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The tool refers to MEL, a Python-based metadata extraction and content analysis tool designed to process various document formats and generate structured JSON outputs for knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "the tool",
          "local_types": [
            "tool"
          ],
          "iri": "Entity-the_tool-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "this tool",
          "local_types": [
            "tool"
          ],
          "iri": "Entity-the_tool-Mention-2"
        }
      ],
      "relevance": 0.7998046875
    },
    "Entity-method_to_extract_metadata_and_content-based_information": {
      "node_id": "method_to_extract_metadata_and_content-based_information",
      "disambiguation_index": 0,
      "label": "methods to extract metadata and content-based information",
      "aliases": [
        "a versatile mechanism to extract metadata and content-based information",
        "methods to extract metadata and content-based information"
      ],
      "types": [
        "mechanism",
        "method",
        "information extraction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The entity 'methods to extract metadata and content-based information' refers to the techniques implemented in the MEL tool, which is designed to process unstructured data from various document formats to extract relevant metadata and content information for knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "methods to extract metadata and content-based information",
          "local_types": [
            "method",
            "information extraction"
          ],
          "iri": "Entity-method_to_extract_metadata_and_content-based_information-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "a versatile mechanism to extract metadata and content-based information",
          "local_types": [
            "mechanism",
            "information extraction"
          ],
          "iri": "Entity-method_to_extract_metadata_and_content-based_information-Mention-2"
        }
      ],
      "relevance": 0.76513671875
    },
    "Entity-extracted_metadata_and_text_content": {
      "node_id": "extracted_metadata_and_text_content",
      "disambiguation_index": 0,
      "label": "extracted metadata and text content",
      "aliases": [
        "extracted metadata and text content"
      ],
      "types": [
        "metadata",
        "text content"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'extracted metadata and text content' refers to the information derived from various document types, including structured metadata and textual data, which is processed and outputted in a JSON format by the MEL tool during the pre-processing phase of knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "extracted metadata and text content",
          "local_types": [
            "metadata",
            "text content"
          ],
          "iri": "Entity-extracted_metadata_and_text_content-Mention-1"
        }
      ],
      "relevance": 0.763671875
    },
    "Entity-package": {
      "node_id": "package",
      "disambiguation_index": 0,
      "label": "package",
      "aliases": [
        "package"
      ],
      "types": [
        "library",
        "software",
        "package",
        "software package"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'package' refers to MEL, a lightweight Python-based software package designed for the metadata extraction of common file formats, which integrates various methods to produce results in JSON format for use in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "package",
          "local_types": [
            "library",
            "software",
            "package",
            "software package"
          ],
          "iri": "Entity-package-Mention-1"
        }
      ],
      "relevance": 0.7607421875
    },
    "Entity-content": {
      "node_id": "content",
      "disambiguation_index": 0,
      "label": "content",
      "aliases": [
        "content"
      ],
      "types": [
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the paper, 'content' refers to the information extracted from various supported file types by the MEL tool, which is used for metadata and content-based information extraction from unstructured documents.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "content",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-Mention-1"
        }
      ],
      "relevance": 0.75439453125
    },
    "Entity-meltnnt": {
      "node_id": "meltnnt",
      "disambiguation_index": 0,
      "label": "MEL+TNNT",
      "aliases": [
        "MEL+TNNT",
        "MEL+TNNT tools"
      ],
      "types": [
        "tool",
        "software"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "MEL+TNNT refers to a combined toolset that integrates the MEL (Metadata Extractor & Loader) software with TNNT, which automates the extraction of categorized named entities from metadata and content-based information extracted from various document formats.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "MEL+TNNT",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-meltnnt-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "MEL+TNNT tools",
          "local_types": [
            "software",
            "tool"
          ],
          "iri": "Entity-meltnnt-Mention-2"
        }
      ],
      "relevance": 0.751953125
    },
    "Entity-mel_general_processing_model": {
      "node_id": "mel_general_processing_model",
      "disambiguation_index": 0,
      "label": "MEL general processing model",
      "aliases": [
        "MEL general processing model",
        "The MEL general processing model"
      ],
      "types": [
        "theoretical framework",
        "processing model",
        "model",
        "concept",
        "processing"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The MEL general processing model refers to a conceptual framework within the MEL tool that outlines the systematic approach for extracting metadata and content from various file types, integrating multiple extraction methods to enhance the efficiency of information processing in knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "MEL general processing model",
          "local_types": [
            "model",
            "concept",
            "theoretical framework",
            "processing model",
            "processing"
          ],
          "iri": "Entity-mel_general_processing_model-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "The MEL general processing model",
          "local_types": [
            "model"
          ],
          "iri": "Entity-mel_general_processing_model-Mention-2"
        }
      ],
      "relevance": 0.7509765625
    },
    "Entity-metadata_and_content-based_information": {
      "node_id": "metadata_and_content-based_information",
      "disambiguation_index": 0,
      "label": "metadata and content-based information",
      "aliases": [
        "metadata and content-based information"
      ],
      "types": [
        "information",
        "metadata"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'metadata and content-based information' refers to the structured and unstructured data extracted by the MEL tool from various file formats, which includes descriptive data about the files (metadata) and the actual content within those files, facilitating knowledge graph construction and data analysis.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "metadata and content-based information",
          "local_types": [
            "metadata",
            "information"
          ],
          "iri": "Entity-metadata_and_content-based_information-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "metadata and content-based information",
          "local_types": [
            "information",
            "metadata"
          ],
          "iri": "Entity-metadata_and_content-based_information-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "metadata and content-based information",
          "local_types": [
            "information"
          ],
          "iri": "Entity-metadata_and_content-based_information-Mention-3"
        }
      ],
      "relevance": 0.74755859375
    },
    "Entity-output_set": {
      "node_id": "output_set",
      "disambiguation_index": 0,
      "label": "output set",
      "aliases": [
        "output set"
      ],
      "types": [
        "data",
        "results"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'output set' refers to the rich results generated by the MEL tool, which includes extracted metadata and content-based information from various unstructured document formats, formatted as JSON files for further processing in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "output set",
          "local_types": [
            "data",
            "results"
          ],
          "iri": "Entity-output_set-Mention-1"
        }
      ],
      "relevance": 0.7412109375
    },
    "Entity-comprehensive_metadata_extraction_support": {
      "node_id": "comprehensive_metadata_extraction_support",
      "disambiguation_index": 0,
      "label": "comprehensive metadata extraction support",
      "aliases": [
        "comprehensive metadata extraction support"
      ],
      "types": [
        "feature"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Comprehensive metadata extraction support refers to MEL's capability to efficiently extract metadata and content-based information from a wide range of file types and formats, facilitating the preprocessing of documents for knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "comprehensive metadata extraction support",
          "local_types": [
            "feature"
          ],
          "iri": "Entity-comprehensive_metadata_extraction_support-Mention-1"
        }
      ],
      "relevance": 0.74072265625
    },
    "Entity-a_set_of_method": {
      "node_id": "a_set_of_method",
      "disambiguation_index": 0,
      "label": "a set of methods",
      "aliases": [
        "a set of methods"
      ],
      "types": [
        "method"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A set of methods refers to the various techniques and processes implemented by the MEL tool to extract metadata and content-based information from diverse file formats, enabling the generation of structured JSON outputs for further analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "a set of methods",
          "local_types": [
            "method"
          ],
          "iri": "Entity-a_set_of_method-Mention-1"
        }
      ],
      "relevance": 0.7294921875
    },
    "Entity-related_metadata_and_content-based_information": {
      "node_id": "related_metadata_and_content-based_information",
      "disambiguation_index": 0,
      "label": "related metadata and content-based information",
      "aliases": [
        "related metadata and content-based information"
      ],
      "types": [
        "metadata",
        "content"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'related metadata and content-based information' refers to the specific data extracted by the MEL tool from various document types, which includes both descriptive metadata about the documents and the actual textual content, processed through text analysis techniques.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "related metadata and content-based information",
          "local_types": [
            "metadata",
            "content"
          ],
          "iri": "Entity-related_metadata_and_content-based_information-Mention-1"
        }
      ],
      "relevance": 0.72705078125
    },
    "Entity-result": {
      "node_id": "result",
      "disambiguation_index": 0,
      "label": "results",
      "aliases": [
        "The results",
        "results",
        "MEL results"
      ],
      "types": [
        "data",
        "output",
        "results",
        "outcome"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The results refer to the output generated by the MEL tool, which are JSON files containing extracted metadata and content-based information from various document formats.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "results",
          "local_types": [
            "data",
            "outcome"
          ],
          "iri": "Entity-result-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "results",
          "local_types": [
            "output",
            "data"
          ],
          "iri": "Entity-result-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "The results",
          "local_types": [
            "results"
          ],
          "iri": "Entity-result-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "MEL results",
          "local_types": [
            "results"
          ],
          "iri": "Entity-result-Mention-4"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "results",
          "local_types": [
            "data"
          ],
          "iri": "Entity-result-Mention-5"
        }
      ],
      "relevance": 0.7197265625
    },
    "Entity-json_result_(1)": {
      "node_id": "json_result_(1)",
      "disambiguation_index": 1,
      "label": "JSON results",
      "aliases": [
        "MEL's JSON results",
        "JSON results"
      ],
      "types": [
        "metadata",
        "results",
        "data format"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "JSON results refer to the structured output generated by the MEL tool, which encapsulates extracted metadata and content-based information from various file formats in a machine-readable JSON format, facilitating further processing and integration into Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "JSON results",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json_result_(1)-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "MEL's JSON results",
          "local_types": [
            "results",
            "metadata"
          ],
          "iri": "Entity-json_result_(1)-Mention-2"
        }
      ],
      "relevance": 0.716796875
    },
    "Entity-document__file__set": {
      "node_id": "document__file__set",
      "disambiguation_index": 0,
      "label": "document (file) set",
      "aliases": [
        "a document (file) set",
        "document (file) set"
      ],
      "types": [
        "file set",
        "document"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'document (file) set' refers to a collection of various file types and formats that are input into the MEL tool for the purpose of extracting metadata and content-based information.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "document (file) set",
          "local_types": [
            "document",
            "file set"
          ],
          "iri": "Entity-document__file__set-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "a document (file) set",
          "local_types": [
            "document",
            "file set"
          ],
          "iri": "Entity-document__file__set-Mention-2"
        }
      ],
      "relevance": 0.71533203125
    },
    "Entity-table_1": {
      "node_id": "table_1",
      "disambiguation_index": 0,
      "label": "Table 1",
      "aliases": [
        "Table 1"
      ],
      "types": [
        "data representation",
        "table",
        "reference"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Table 1 presents the general output structure of the MEL tool, detailing how extracted metadata and content-based information are organized in the generated JSON files.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "Table 1",
          "local_types": [
            "data representation",
            "table",
            "reference"
          ],
          "iri": "Entity-table_1-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "Table 1",
          "local_types": [
            "table"
          ],
          "iri": "Entity-table_1-Mention-2"
        }
      ],
      "relevance": 0.71240234375
    },
    "Entity-comprehensive_set_of_method": {
      "node_id": "comprehensive_set_of_method",
      "disambiguation_index": 0,
      "label": "comprehensive set of methods",
      "aliases": [
        "comprehensive set of methods"
      ],
      "types": [
        "methods"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'comprehensive set of methods' refers to an integrated collection of techniques within the MEL tool that enables the extraction of metadata and content from various common file formats, producing structured JSON outputs based on the document object model.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "comprehensive set of methods",
          "local_types": [
            "methods"
          ],
          "iri": "Entity-comprehensive_set_of_method-Mention-1"
        }
      ],
      "relevance": 0.71240234375
    },
    "Entity-content_and_metadata": {
      "node_id": "content_and_metadata",
      "disambiguation_index": 0,
      "label": "content and metadata",
      "aliases": [
        "content and metadata"
      ],
      "types": [
        "data"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'content and metadata' refers to the information extracted from various file types, encompassing both the actual data contained within the files and the descriptive information that provides context about that data, as utilized by the MEL tool for knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "content and metadata",
          "local_types": [
            "data"
          ],
          "iri": "Entity-content_and_metadata-Mention-1"
        }
      ],
      "relevance": 0.71044921875
    },
    "Entity-output_structure": {
      "node_id": "output_structure",
      "disambiguation_index": 0,
      "label": "output structure",
      "aliases": [
        "MEL's general output structure",
        "output structure"
      ],
      "types": [
        "output structure",
        "structure",
        "data format",
        "information structure",
        "output"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'output structure' refers to the organized format in which MEL generates and presents the extracted metadata and content-based information from documents, specifically formatted as JSON files based on the document object model of the supported file types.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "output structure",
          "local_types": [
            "information structure",
            "structure",
            "output",
            "data format"
          ],
          "iri": "Entity-output_structure-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "MEL's general output structure",
          "local_types": [
            "output structure"
          ],
          "iri": "Entity-output_structure-Mention-2"
        }
      ],
      "relevance": 0.703125
    },
    "Entity-primitive_for_metadata_and_content_extraction": {
      "node_id": "primitive_for_metadata_and_content_extraction",
      "disambiguation_index": 0,
      "label": "primitives for metadata and content extraction",
      "aliases": [
        "primitives for metadata and content extraction"
      ],
      "types": [
        "methodology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Primitives for metadata and content extraction refer to the foundational methods and techniques implemented in the MEL tool that facilitate the extraction of structured metadata and content from unstructured data sets across various file formats, enabling further content-based analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "primitives for metadata and content extraction",
          "local_types": [
            "methodology"
          ],
          "iri": "Entity-primitive_for_metadata_and_content_extraction-Mention-1"
        }
      ],
      "relevance": 0.70263671875
    },
    "Entity-document": {
      "node_id": "document",
      "disambiguation_index": 0,
      "label": "document",
      "aliases": [
        "documents",
        "document"
      ],
      "types": [
        "information",
        "data structure",
        "data object",
        "document",
        "file",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'document' refers to a file or set of files from which the MEL tool extracts metadata and content-based information for processing in knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "document",
          "local_types": [
            "data structure",
            "data object",
            "document",
            "file"
          ],
          "iri": "Entity-document-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "documents",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-document-Mention-2"
        }
      ],
      "relevance": 0.701171875
    },
    "Entity-input_document_set": {
      "node_id": "input_document_set",
      "disambiguation_index": 0,
      "label": "input document sets",
      "aliases": [
        "input document sets"
      ],
      "types": [
        "data collection",
        "document",
        "document set",
        "input set",
        "input data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Input document sets refer to collections of documents that are provided as input to the MEL tool for the purpose of extracting metadata and content-based information during the pre-processing phase of Knowledge Graph Construction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "input document sets",
          "local_types": [
            "data collection",
            "document",
            "document set",
            "input set",
            "input data"
          ],
          "iri": "Entity-input_document_set-Mention-1"
        }
      ],
      "relevance": 0.69970703125
    },
    "Entity-several_kgcps": {
      "node_id": "several_kgcps",
      "disambiguation_index": 0,
      "label": "several KGCPs",
      "aliases": [
        "several KGCPs"
      ],
      "types": [
        "project"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Several KGCPs refer to various Knowledge Graph Construction Pipelines that utilize the MEL tool for information extraction from heterogeneous file sets.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "several KGCPs",
          "local_types": [
            "project"
          ],
          "iri": "Entity-several_kgcps-Mention-1"
        }
      ],
      "relevance": 0.69970703125
    },
    "Entity-the_nlp_-ner_toolkit": {
      "node_id": "the_nlp_-ner_toolkit",
      "disambiguation_index": 0,
      "label": "The NLP -NER Toolkit",
      "aliases": [
        "The NLP -NER Toolkit",
        "TNNT"
      ],
      "types": [
        "system",
        "entity",
        "toolkit",
        "software",
        "tool",
        "acronym"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The NLP -NER Toolkit (TNNT) is a software tool that automates the extraction of categorized named entities from metadata and content extracted by the MEL tool, utilizing various advanced natural language processing (NLP) tools and named entity recognition (NER) models.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "The NLP -NER Toolkit",
          "local_types": [
            "tool",
            "software",
            "toolkit"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "TNNT",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "TNNT",
          "local_types": [
            "system",
            "entity",
            "software",
            "tool",
            "acronym"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "TNNT",
          "local_types": [
            "software",
            "tool",
            "system"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-4"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "TNNT",
          "local_types": [
            "tool",
            "software",
            "system"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-5"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "TNNT",
          "local_types": [
            "tool",
            "software",
            "toolkit"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-6"
        }
      ],
      "relevance": 0.69921875
    },
    "Entity-document_set": {
      "node_id": "document_set",
      "disambiguation_index": 0,
      "label": "document sets",
      "aliases": [
        "document sets"
      ],
      "types": [
        "collection",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Document sets refer to collections of heterogeneous files that MEL processes to extract metadata and content-based information for knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "document sets",
          "local_types": [
            "collection",
            "data"
          ],
          "iri": "Entity-document_set-Mention-1"
        }
      ],
      "relevance": 0.69677734375
    },
    "Entity-heterogeneous_document_set": {
      "node_id": "heterogeneous_document_set",
      "disambiguation_index": 0,
      "label": "heterogeneous document sets",
      "aliases": [
        "heterogeneous document sets"
      ],
      "types": [
        "data",
        "document",
        "set",
        "document collection"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Heterogeneous document sets refer to collections of documents that vary in format, structure, and content, which are processed for metadata and information extraction using tools like MEL.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "heterogeneous document sets",
          "local_types": [
            "data",
            "document",
            "set",
            "document collection"
          ],
          "iri": "Entity-heterogeneous_document_set-Mention-1"
        }
      ],
      "relevance": 0.6953125
    },
    "Entity-each_file_type": {
      "node_id": "each_file_type",
      "disambiguation_index": 0,
      "label": "each file type",
      "aliases": [
        "each file type"
      ],
      "types": [
        "file type"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Each file type refers to the distinct formats of documents that MEL can process, each requiring a tailored processing model and text analysis approach for effective metadata and content extraction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "each file type",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-each_file_type-Mention-1"
        }
      ],
      "relevance": 0.69482421875
    },
    "Entity-20_different_file_type": {
      "node_id": "20_different_file_type",
      "disambiguation_index": 0,
      "label": "20 different file types",
      "aliases": [
        "more than 20 different file types",
        "over 20 different file types/formats",
        "20 different file types"
      ],
      "types": [
        "format",
        "file type",
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention '20 different file types' refers to the various formats of documents that the MEL tool can process for metadata and content extraction in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "20 different file types",
          "local_types": [
            "data format",
            "file type"
          ],
          "iri": "Entity-20_different_file_type-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "more than 20 different file types",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-20_different_file_type-Mention-2"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "over 20 different file types/formats",
          "local_types": [
            "file type",
            "format"
          ],
          "iri": "Entity-20_different_file_type-Mention-3"
        }
      ],
      "relevance": 0.6923828125
    },
    "Entity-format": {
      "node_id": "format",
      "disambiguation_index": 0,
      "label": "formats",
      "aliases": [
        "formats"
      ],
      "types": [
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'formats' refers to the various types of source document formats that the MEL tool can process for metadata and content-based information extraction.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "formats",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-format-Mention-1"
        }
      ],
      "relevance": 0.6923828125
    },
    "Entity-various_file_format": {
      "node_id": "various_file_format",
      "disambiguation_index": 0,
      "label": "various file formats",
      "aliases": [
        "various file formats",
        "various file types and formats"
      ],
      "types": [
        "format",
        "file type",
        "file format"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Various file formats refer to the diverse types of document formats supported by the MEL tool for extracting metadata and content-based information, enabling the processing of unstructured data from multiple sources.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "various file formats",
          "local_types": [
            "file format"
          ],
          "iri": "Entity-various_file_format-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "various file types and formats",
          "local_types": [
            "format",
            "file type"
          ],
          "iri": "Entity-various_file_format-Mention-2"
        }
      ],
      "relevance": 0.689453125
    },
    "Entity-specific_pre-processing_and_data_cleaning_task": {
      "node_id": "specific_pre-processing_and_data_cleaning_task",
      "disambiguation_index": 0,
      "label": "specific pre-processing and data cleaning tasks",
      "aliases": [
        "specific pre-processing and data cleaning tasks"
      ],
      "types": [
        "process",
        "data cleaning"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Specific pre-processing and data cleaning tasks refer to the operations performed by the MEL tool to prepare and refine the extracted textual content from various file formats, ensuring the data is clean and suitable for subsequent analysis and integration into knowledge graph construction pipelines.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "specific pre-processing and data cleaning tasks",
          "local_types": [
            "process",
            "data cleaning"
          ],
          "iri": "Entity-specific_pre-processing_and_data_cleaning_task-Mention-1"
        }
      ],
      "relevance": 0.68896484375
    },
    "Entity-metadata_and_content-based_information_extraction": {
      "node_id": "metadata_and_content-based_information_extraction",
      "disambiguation_index": 0,
      "label": "metadata and content-based information extraction",
      "aliases": [
        "metadata and content-based information extraction",
        "metadata and content-based information extraction tasks"
      ],
      "types": [
        "process",
        "task",
        "data processing task",
        "information extraction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Metadata and content-based information extraction refers to the pre-processing tasks that involve extracting structured information from unstructured data across various file formats, which are essential for building Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "metadata and content-based information extraction",
          "local_types": [
            "information extraction",
            "data processing task"
          ],
          "iri": "Entity-metadata_and_content-based_information_extraction-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "metadata and content-based information extraction tasks",
          "local_types": [
            "task",
            "information extraction"
          ],
          "iri": "Entity-metadata_and_content-based_information_extraction-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "metadata and content-based information extraction",
          "local_types": [
            "process",
            "information extraction"
          ],
          "iri": "Entity-metadata_and_content-based_information_extraction-Mention-3"
        }
      ],
      "relevance": 0.68603515625
    },
    "Entity-the_supported_file_type": {
      "node_id": "the_supported_file_type",
      "disambiguation_index": 0,
      "label": "The supported file types",
      "aliases": [
        "The supported file types",
        "all supported file types"
      ],
      "types": [
        "file type"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The supported file types refer to the various document formats that the MEL tool can process to extract metadata and content-based information, as detailed in Table 2 of the paper.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-6",
          "local_name": "The supported file types",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-the_supported_file_type-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "all supported file types",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-the_supported_file_type-Mention-2"
        }
      ],
      "relevance": 0.6845703125
    },
    "Entity-any_output": {
      "node_id": "any_output",
      "disambiguation_index": 0,
      "label": "any output",
      "aliases": [
        "any output"
      ],
      "types": [
        "output"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'any output' refers to the final results generated after processing various file types and performing text analysis, which can be stored as JSON files for further use in knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "any output",
          "local_types": [
            "output"
          ],
          "iri": "Entity-any_output-Mention-1"
        }
      ],
      "relevance": 0.6845703125
    },
    "Entity-general-metadata": {
      "node_id": "general-metadata",
      "disambiguation_index": 0,
      "label": "General-Metadata",
      "aliases": [
        "General-Metadata"
      ],
      "types": [
        "task"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "General-Metadata refers to the extraction task within the MEL tool that utilizes XML output from the NLNZ Metadata Extractor to obtain a comprehensive list of attributes and properties from various file formats.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "General-Metadata",
          "local_types": [
            "task"
          ],
          "iri": "Entity-general-metadata-Mention-1"
        }
      ],
      "relevance": 0.68408203125
    },
    "Entity-processing_model": {
      "node_id": "processing_model",
      "disambiguation_index": 0,
      "label": "processing model",
      "aliases": [
        "processing model"
      ],
      "types": [
        "algorithm",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The processing model refers to the specific methodology and framework used by the MEL tool to handle and analyze different file types during the metadata and content extraction process.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "processing model",
          "local_types": [
            "algorithm",
            "system"
          ],
          "iri": "Entity-processing_model-Mention-1"
        }
      ],
      "relevance": 0.68359375
    },
    "Entity-it": {
      "node_id": "it",
      "disambiguation_index": 0,
      "label": "It",
      "aliases": [
        "It"
      ],
      "types": [
        "entity"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'It' refers to the MEL tool, which is capable of storing the results of its metadata and content extraction processes in a document store.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "It",
          "local_types": [
            "entity"
          ],
          "iri": "Entity-it-Mention-1"
        }
      ],
      "relevance": 0.68310546875
    },
    "Entity-different_source_document_format": {
      "node_id": "different_source_document_format",
      "disambiguation_index": 0,
      "label": "different source document formats",
      "aliases": [
        "different source document formats",
        "different formats"
      ],
      "types": [
        "format",
        "document format"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Different source document formats refer to the various types of file formats that contain unstructured information, which can be processed by the MEL tool for metadata and content extraction.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "different source document formats",
          "local_types": [
            "format",
            "document format"
          ],
          "iri": "Entity-different_source_document_format-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "different formats",
          "local_types": [
            "format"
          ],
          "iri": "Entity-different_source_document_format-Mention-2"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "different source document formats",
          "local_types": [
            "document format"
          ],
          "iri": "Entity-different_source_document_format-Mention-3"
        }
      ],
      "relevance": 0.6826171875
    },
    "Entity-a_project_to__containerise__the_meltnnt_tool": {
      "node_id": "a_project_to__containerise__the_meltnnt_tool",
      "disambiguation_index": 0,
      "label": "a project to \u201ccontainerise\u201d the MEL+TNNT tools",
      "aliases": [
        "a project to \u201ccontainerise\u201d the MEL+TNNT tools"
      ],
      "types": [
        "project",
        "tools"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A project aimed at packaging the MEL and TNNT tools into containerized environments to enhance their deployment and usability in metadata extraction and named entity recognition tasks.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "a project to \u201ccontainerise\u201d the MEL+TNNT tools",
          "local_types": [
            "project",
            "tools"
          ],
          "iri": "Entity-a_project_to__containerise__the_meltnnt_tool-Mention-1"
        }
      ],
      "relevance": 0.68212890625
    },
    "Entity-a_json_file": {
      "node_id": "a_json_file",
      "disambiguation_index": 0,
      "label": "a JSON file",
      "aliases": [
        "a JSON file"
      ],
      "types": [
        "file",
        "JSON"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A JSON file is a structured text file that stores extracted metadata and content-based information in a format compliant with the document object model, generated as output by the MEL tool during the metadata extraction process from various document types.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "a JSON file",
          "local_types": [
            "file",
            "JSON"
          ],
          "iri": "Entity-a_json_file-Mention-1"
        }
      ],
      "relevance": 0.681640625
    },
    "Entity-processing": {
      "node_id": "processing",
      "disambiguation_index": 0,
      "label": "processing",
      "aliases": [
        "processing"
      ],
      "types": [
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'processing' refers to the execution of a defined set of operations and configurations applied to document sets for extracting metadata and content-based information using the MEL tool.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "processing",
          "local_types": [
            "process"
          ],
          "iri": "Entity-processing-Mention-1"
        }
      ],
      "relevance": 0.6787109375
    },
    "Entity-automated_kgcp": {
      "node_id": "automated_kgcp",
      "disambiguation_index": 0,
      "label": "automated KGCP",
      "aliases": [
        "automated KGCP"
      ],
      "types": [
        "process"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Automated KGCP refers to a Knowledge Graph Construction Pipeline that utilizes automated tools and methods, such as MEL and TNNT, to streamline the extraction and processing of metadata and content from various unstructured data sources, ultimately facilitating the mapping of results to RDF format.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "automated KGCP",
          "local_types": [
            "process"
          ],
          "iri": "Entity-automated_kgcp-Mention-1"
        }
      ],
      "relevance": 0.677734375
    },
    "Entity-various_opensource_package_and_tool": {
      "node_id": "various_opensource_package_and_tool",
      "disambiguation_index": 0,
      "label": "various opensource packages and tools",
      "aliases": [
        "various opensource packages and tools"
      ],
      "types": [
        "software",
        "tool"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Various opensource packages and tools refer to a collection of freely available software components that provide complementary functionalities, enabling the MEL tool to efficiently perform metadata and content-based information extraction from diverse document formats.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "various opensource packages and tools",
          "local_types": [
            "software",
            "tool"
          ],
          "iri": "Entity-various_opensource_package_and_tool-Mention-1"
        }
      ],
      "relevance": 0.677734375
    },
    "Entity-keyword_extraction_task": {
      "node_id": "keyword_extraction_task",
      "disambiguation_index": 0,
      "label": "keyword extraction task",
      "aliases": [
        "keyword extraction task"
      ],
      "types": [
        "task",
        "keyword extraction"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The keyword extraction task refers to the process of identifying and extracting significant words or phrases from a document set, which is part of the broader metadata and content-based information extraction performed by the MEL tool.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "keyword extraction task",
          "local_types": [
            "task",
            "keyword extraction"
          ],
          "iri": "Entity-keyword_extraction_task-Mention-1"
        }
      ],
      "relevance": 0.6767578125
    },
    "Entity-extracted_metadata": {
      "node_id": "extracted_metadata",
      "disambiguation_index": 0,
      "label": "extracted metadata",
      "aliases": [
        "extracted metadata"
      ],
      "types": [
        "metadata"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Extracted metadata refers to the structured information derived from unstructured data sets of various file formats, which can be formatted as JSON and made compatible with RDF through JSON-LD annotations, facilitating its use in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "extracted metadata",
          "local_types": [
            "metadata"
          ],
          "iri": "Entity-extracted_metadata-Mention-1"
        }
      ],
      "relevance": 0.6767578125
    },
    "Entity-figure_2": {
      "node_id": "figure_2",
      "disambiguation_index": 0,
      "label": "Figure 2",
      "aliases": [
        "Figure 2"
      ],
      "types": [
        "figure",
        "illustration"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Figure 2 illustrates the general processing model of the MEL tool, which outlines the methodology for extracting metadata and content from various supported file types.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "Figure 2",
          "local_types": [
            "figure",
            "illustration"
          ],
          "iri": "Entity-figure_2-Mention-1"
        }
      ],
      "relevance": 0.6748046875
    },
    "Entity-associated-metadata": {
      "node_id": "associated-metadata",
      "disambiguation_index": 0,
      "label": "Associated-Metadata",
      "aliases": [
        "Associated-Metadata"
      ],
      "types": [
        "metadata",
        "data descriptor"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Associated-Metadata refers to the specific processing settings and parameters defined in MEL's configuration JSON file that dictate how metadata related to input documents is extracted and structured.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "Associated-Metadata",
          "local_types": [
            "metadata",
            "data descriptor"
          ],
          "iri": "Entity-associated-metadata-Mention-1"
        }
      ],
      "relevance": 0.6708984375
    },
    "Entity-parameter": {
      "node_id": "parameter",
      "disambiguation_index": 0,
      "label": "parameters",
      "aliases": [
        "parameters"
      ],
      "types": [
        "settings",
        "configuration element"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'parameters' refer to the configurable settings defined in a JSON file that dictate how metadata extraction and processing tasks are performed, including aspects such as document store configurations, input document sets, and text analysis methods.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "parameters",
          "local_types": [
            "settings",
            "configuration element"
          ],
          "iri": "Entity-parameter-Mention-1"
        }
      ],
      "relevance": 0.669921875
    },
    "Entity-supported_format__document_object_model": {
      "node_id": "supported_format__document_object_model",
      "disambiguation_index": 0,
      "label": "supported formats' document object model",
      "aliases": [
        "supported formats' document object model"
      ],
      "types": [
        "document object model",
        "format"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The 'supported formats' document object model' refers to the structured representation of metadata and content extracted from various document types by the MEL tool, which organizes this information in a JSON format tailored to the specific characteristics of each supported file format.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "supported formats' document object model",
          "local_types": [
            "document object model",
            "format"
          ],
          "iri": "Entity-supported_format__document_object_model-Mention-1"
        }
      ],
      "relevance": 0.669921875
    },
    "Entity-heterogeneous_format": {
      "node_id": "heterogeneous_format",
      "disambiguation_index": 0,
      "label": "heterogeneous formats",
      "aliases": [
        "heterogeneous formats"
      ],
      "types": [
        "format",
        "data type",
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Heterogeneous formats refer to the various unstructured data types and file formats that MEL can process for metadata and content extraction, enabling integration and analysis across diverse sources.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "heterogeneous formats",
          "local_types": [
            "format",
            "data type",
            "data format"
          ],
          "iri": "Entity-heterogeneous_format-Mention-1"
        }
      ],
      "relevance": 0.66845703125
    },
    "Entity-general_purpose": {
      "node_id": "general_purpose",
      "disambiguation_index": 0,
      "label": "general purpose",
      "aliases": [
        "general purpose"
      ],
      "types": [
        "application type",
        "purpose"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'general purpose' refers to the capability of the MEL tool to extract metadata and content-based information from unstructured data sets across various domains without being limited to a specific area or application.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "general purpose",
          "local_types": [
            "application type",
            "purpose"
          ],
          "iri": "Entity-general_purpose-Mention-1"
        }
      ],
      "relevance": 0.66796875
    },
    "Entity-pre-processing_step": {
      "node_id": "pre-processing_step",
      "disambiguation_index": 0,
      "label": "pre-processing steps",
      "aliases": [
        "pre-processing steps"
      ],
      "types": [
        "process",
        "step"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Pre-processing steps refer to the initial tasks of extracting metadata and content-based information from diverse file sets, which are essential for the effective functioning of Knowledge Graph Construction Pipelines (KGCP).",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "pre-processing steps",
          "local_types": [
            "process",
            "step"
          ],
          "iri": "Entity-pre-processing_step-Mention-1"
        }
      ],
      "relevance": 0.6591796875
    },
    "Entity-tnnt_result": {
      "node_id": "tnnt_result",
      "disambiguation_index": 0,
      "label": "TNNT results",
      "aliases": [
        "TNNT results"
      ],
      "types": [
        "results",
        "output"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "TNNT results refer to the output generated by 'The NLP -NER Toolkit', which automates the extraction of categorized named entities from the metadata and content extracted by the MEL tool.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "TNNT results",
          "local_types": [
            "results",
            "output"
          ],
          "iri": "Entity-tnnt_result-Mention-1"
        }
      ],
      "relevance": 0.65869140625
    },
    "Entity-specific_processing_model": {
      "node_id": "specific_processing_model",
      "disambiguation_index": 0,
      "label": "specific processing model",
      "aliases": [
        "specific processing model"
      ],
      "types": [
        "processing model"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'specific processing model' refers to the tailored methodologies employed by the MEL tool to handle and extract metadata and content from various file types, ensuring that each type is processed according to its unique characteristics and requirements.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "specific processing model",
          "local_types": [
            "processing model"
          ],
          "iri": "Entity-specific_processing_model-Mention-1"
        }
      ],
      "relevance": 0.6572265625
    },
    "Entity-output": {
      "node_id": "output",
      "disambiguation_index": 0,
      "label": "output",
      "aliases": [
        "output"
      ],
      "types": [
        "result",
        "data output"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the paper, 'output' refers to the final results generated by the MEL tool after processing various file types and performing text analysis, which are produced in a structured format suitable for further use.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "output",
          "local_types": [
            "result",
            "data output"
          ],
          "iri": "Entity-output-Mention-1"
        }
      ],
      "relevance": 0.65673828125
    },
    "Entity-attribute": {
      "node_id": "attribute",
      "disambiguation_index": 0,
      "label": "attributes",
      "aliases": [
        "attributes"
      ],
      "types": [
        "characteristics",
        "features"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'attributes' refers to the specific characteristics or features of metadata that the tool is capable of extracting from various document types during the information extraction process.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "attributes",
          "local_types": [
            "characteristics",
            "features"
          ],
          "iri": "Entity-attribute-Mention-1"
        }
      ],
      "relevance": 0.65478515625
    },
    "Entity-common_file_format_(1)": {
      "node_id": "common_file_format_(1)",
      "disambiguation_index": 1,
      "label": "common file formats",
      "aliases": [
        "common file formats"
      ],
      "types": [
        "file format"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Common file formats refer to widely used digital document types that can be processed and analyzed for metadata extraction, such as PDF, DOCX, and TXT, which are supported by tools like MEL for integration into Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "common file formats",
          "local_types": [
            "file format"
          ],
          "iri": "Entity-common_file_format_(1)-Mention-1"
        }
      ],
      "relevance": 0.654296875
    },
    "Entity-thousand_of_document": {
      "node_id": "thousand_of_document",
      "disambiguation_index": 0,
      "label": "thousands of documents",
      "aliases": [
        "thousands of documents"
      ],
      "types": [
        "documents"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'thousands of documents' refers to a large collection of heterogeneous file formats that were utilized in the AGRIF project to evaluate the MEL tool's capabilities in extracting metadata and content-based information.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "thousands of documents",
          "local_types": [
            "documents"
          ],
          "iri": "Entity-thousand_of_document-Mention-1"
        }
      ],
      "relevance": 0.65234375
    },
    "Entity-extracted_attribute": {
      "node_id": "extracted_attribute",
      "disambiguation_index": 0,
      "label": "extracted attributes",
      "aliases": [
        "extracted attributes"
      ],
      "types": [
        "attribute"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'extracted attributes' refers to the specific pieces of metadata and content-based information that the MEL tool is capable of retrieving from various document types during its processing tasks.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "extracted attributes",
          "local_types": [
            "attribute"
          ],
          "iri": "Entity-extracted_attribute-Mention-1"
        }
      ],
      "relevance": 0.65185546875
    },
    "Entity-document_type": {
      "node_id": "document_type",
      "disambiguation_index": 0,
      "label": "document type",
      "aliases": [
        "document type"
      ],
      "types": [
        "classification",
        "category",
        "document",
        "type"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'document type' refers to the specific category or format of a document that the MEL tool is capable of processing and extracting metadata from, which influences the attributes that can be extracted.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "document type",
          "local_types": [
            "classification",
            "category",
            "document",
            "type"
          ],
          "iri": "Entity-document_type-Mention-1"
        }
      ],
      "relevance": 0.64794921875
    },
    "Entity-the_text_analysis_task": {
      "node_id": "the_text_analysis_task",
      "disambiguation_index": 0,
      "label": "the text analysis task",
      "aliases": [
        "the text analysis task"
      ],
      "types": [
        "task",
        "text analysis"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The text analysis task refers to the final step in the processing model of the MEL tool, where specific analytical methods are applied to extract and analyze content from various file types.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "the text analysis task",
          "local_types": [
            "task",
            "text analysis"
          ],
          "iri": "Entity-the_text_analysis_task-Mention-1"
        }
      ],
      "relevance": 0.64404296875
    },
    "Entity-tool": {
      "node_id": "tool",
      "disambiguation_index": 0,
      "label": "tools",
      "aliases": [
        "tool",
        "tools"
      ],
      "types": [
        "software",
        "utility",
        "application",
        "instruments"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'tools' refers to software utilities that facilitate the integration of various extraction methods for metadata and content-based information from heterogeneous file sets, specifically within the context of Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "tools",
          "local_types": [
            "software",
            "instruments"
          ],
          "iri": "Entity-tool-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "tool",
          "local_types": [
            "software",
            "application"
          ],
          "iri": "Entity-tool-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "tools",
          "local_types": [
            "software",
            "utility"
          ],
          "iri": "Entity-tool-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "tool",
          "local_types": [
            "software",
            "application"
          ],
          "iri": "Entity-tool-Mention-4"
        }
      ],
      "relevance": 0.642578125
    },
    "Entity-heterogeneous_file_set": {
      "node_id": "heterogeneous_file_set",
      "disambiguation_index": 0,
      "label": "heterogeneous file sets",
      "aliases": [
        "heterogeneous file sets"
      ],
      "types": [
        "data collection",
        "data source",
        "file collection",
        "file set",
        "data",
        "file type"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Heterogeneous file sets refer to collections of files that vary in format, structure, and content, which are utilized in metadata and content-based information extraction processes for Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "heterogeneous file sets",
          "local_types": [
            "data collection",
            "data source",
            "file collection",
            "file set",
            "data",
            "file type"
          ],
          "iri": "Entity-heterogeneous_file_set-Mention-1"
        }
      ],
      "relevance": 0.64013671875
    },
    "Entity-rich_output_set": {
      "node_id": "rich_output_set",
      "disambiguation_index": 0,
      "label": "rich output set",
      "aliases": [
        "rich output set"
      ],
      "types": [
        "output",
        "set"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'rich output set' refers to a comprehensive collection of extracted metadata and content-based information generated from heterogeneous file sets, which is essential for efficient pre-processing in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "rich output set",
          "local_types": [
            "output",
            "set"
          ],
          "iri": "Entity-rich_output_set-Mention-1"
        }
      ],
      "relevance": 0.64013671875
    },
    "Entity-table_2": {
      "node_id": "table_2",
      "disambiguation_index": 0,
      "label": "Table 2",
      "aliases": [
        "Table 2"
      ],
      "types": [
        "data representation",
        "table",
        "reference"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Table 2 presents the supported file types for the MEL tool, including the theoretical number of attributes that can be extracted per document type and the average number of extracted attributes from four use case document sets.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-6",
          "local_name": "Table 2",
          "local_types": [
            "data representation",
            "table",
            "reference"
          ],
          "iri": "Entity-table_2-Mention-1"
        }
      ],
      "relevance": 0.6376953125
    },
    "Entity-kgcp_task": {
      "node_id": "kgcp_task",
      "disambiguation_index": 0,
      "label": "KGCP tasks",
      "aliases": [
        "KGCP tasks"
      ],
      "types": [
        "task",
        "project"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "KGCP tasks refer to the various metadata and content-based information extraction tasks that are part of Knowledge Graph Construction Pipelines, aimed at processing heterogeneous file formats to facilitate the creation of knowledge graphs.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "KGCP tasks",
          "local_types": [
            "task",
            "project"
          ],
          "iri": "Entity-kgcp_task-Mention-1"
        }
      ],
      "relevance": 0.6376953125
    },
    "Entity-several_complementary_extraction_method": {
      "node_id": "several_complementary_extraction_method",
      "disambiguation_index": 0,
      "label": "several complementary extraction methods",
      "aliases": [
        "several complementary extraction methods"
      ],
      "types": [
        "extraction method"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Several complementary extraction methods refer to a variety of techniques used in metadata and content-based information extraction that, when integrated, enhance the efficiency and richness of the output generated from heterogeneous file sets in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "several complementary extraction methods",
          "local_types": [
            "extraction method"
          ],
          "iri": "Entity-several_complementary_extraction_method-Mention-1"
        }
      ],
      "relevance": 0.63720703125
    },
    "Entity-use_case_document_set": {
      "node_id": "use_case_document_set",
      "disambiguation_index": 0,
      "label": "use case document sets",
      "aliases": [
        "four use case document sets",
        "use case document sets"
      ],
      "types": [
        "use case",
        "document set",
        "case study",
        "document collection"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'use case document sets' refers to collections of documents utilized in practical scenarios to demonstrate the capabilities and performance of the MEL tool in extracting metadata and content-based information.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "use case document sets",
          "local_types": [
            "case study",
            "document collection"
          ],
          "iri": "Entity-use_case_document_set-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "four use case document sets",
          "local_types": [
            "use case",
            "document set"
          ],
          "iri": "Entity-use_case_document_set-Mention-2"
        }
      ],
      "relevance": 0.63623046875
    },
    "Entity-attribute_and_property_list": {
      "node_id": "attribute_and_property_list",
      "disambiguation_index": 0,
      "label": "attribute and property list",
      "aliases": [
        "attribute and property list"
      ],
      "types": [
        "data structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'attribute and property list' refers to a comprehensive collection of metadata attributes and properties extracted from various file formats by the NLNZ Metadata Extractor tool, which is utilized in the MEL tool for metadata extraction tasks.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "attribute and property list",
          "local_types": [
            "data structure"
          ],
          "iri": "Entity-attribute_and_property_list-Mention-1"
        }
      ],
      "relevance": 0.63330078125
    },
    "Entity-proper_tool": {
      "node_id": "proper_tool",
      "disambiguation_index": 0,
      "label": "proper tools",
      "aliases": [
        "proper tools"
      ],
      "types": [
        "tool"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Proper tools refer to integrated software solutions that combine various complementary methods for metadata and content-based information extraction, facilitating efficient processing in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "proper tools",
          "local_types": [
            "tool"
          ],
          "iri": "Entity-proper_tool-Mention-1"
        }
      ],
      "relevance": 0.6298828125
    },
    "Entity-metadata_extraction": {
      "node_id": "metadata_extraction",
      "disambiguation_index": 0,
      "label": "metadata extraction",
      "aliases": [
        "metadata extraction",
        "metadata and content extraction"
      ],
      "types": [
        "metadata",
        "data processing",
        "process",
        "information retrieval",
        "data handling",
        "content extraction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Metadata extraction is the process of retrieving and organizing metadata from various data sources to enhance data management and information retrieval.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "metadata extraction",
          "local_types": [
            "data handling",
            "metadata",
            "data processing",
            "process"
          ],
          "iri": "Entity-metadata_extraction-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "metadata extraction",
          "local_types": [
            "data processing",
            "process"
          ],
          "iri": "Entity-metadata_extraction-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "metadata extraction",
          "local_types": [
            "metadata",
            "information retrieval",
            "data processing",
            "process"
          ],
          "iri": "Entity-metadata_extraction-Mention-3"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "metadata and content extraction",
          "local_types": [
            "information retrieval",
            "process",
            "data processing",
            "content extraction",
            "metadata"
          ],
          "iri": "Entity-metadata_extraction-Mention-4"
        }
      ],
      "relevance": 0.62939453125
    },
    "Entity-the_integration_with_json-ld_ontology": {
      "node_id": "the_integration_with_json-ld_ontology",
      "disambiguation_index": 0,
      "label": "the integration with JSON-LD ontologies",
      "aliases": [
        "the integration with JSON-LD ontologies"
      ],
      "types": [
        "integration",
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The integration with JSON-LD ontologies refers to the process of incorporating lightweight ontological structures into the metadata extracted by the MEL tool, enabling the resulting JSON data to be compatible with RDF standards for enhanced semantic interoperability.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "the integration with JSON-LD ontologies",
          "local_types": [
            "integration",
            "ontology"
          ],
          "iri": "Entity-the_integration_with_json-ld_ontology-Mention-1"
        }
      ],
      "relevance": 0.62939453125
    },
    "Entity-nlp_-ner_toolkit": {
      "node_id": "nlp_-ner_toolkit",
      "disambiguation_index": 0,
      "label": "NLP -NER Toolkit",
      "aliases": [
        "NLP -NER Toolkit"
      ],
      "types": [
        "tool",
        "software"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The NLP -NER Toolkit is a software tool designed for automating the extraction of categorized named entities from text using advanced natural language processing and named entity recognition techniques.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "NLP -NER Toolkit",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-nlp_-ner_toolkit-Mention-1"
        }
      ],
      "relevance": 0.62451171875
    },
    "Entity-comprehensive_configurable_setting": {
      "node_id": "comprehensive_configurable_setting",
      "disambiguation_index": 0,
      "label": "comprehensive configurable settings",
      "aliases": [
        "comprehensive configurable settings"
      ],
      "types": [
        "settings"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Comprehensive configurable settings refer to the flexible and extensive options available within the MEL tool that allow users to customize the metadata extraction and content-based information processing for various file types in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "comprehensive configurable settings",
          "local_types": [
            "settings"
          ],
          "iri": "Entity-comprehensive_configurable_setting-Mention-1"
        }
      ],
      "relevance": 0.62451171875
    },
    "Entity-olemeta": {
      "node_id": "olemeta",
      "disambiguation_index": 0,
      "label": "olemeta",
      "aliases": [
        "olemeta",
        "olemeta tool"
      ],
      "types": [
        "tool",
        "metadata extraction",
        "metadata extraction tool",
        "software"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "olemeta is a software tool utilized by MEL for extracting metadata from OLE 2 file types.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "olemeta",
          "local_types": [
            "metadata extraction",
            "tool",
            "software"
          ],
          "iri": "Entity-olemeta-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "olemeta tool",
          "local_types": [
            "metadata extraction tool",
            "software",
            "tool"
          ],
          "iri": "Entity-olemeta-Mention-2"
        }
      ],
      "relevance": 0.6201171875
    },
    "Entity-nlnz_metadata_extractor": {
      "node_id": "nlnz_metadata_extractor",
      "disambiguation_index": 0,
      "label": "NLNZ Metadata Extractor",
      "aliases": [
        "NLNZ Metadata Extractor tool",
        "NLNZ Metadata Extractor"
      ],
      "types": [
        "tool",
        "metadata extraction tool",
        "Java application",
        "software"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The NLNZ Metadata Extractor is a Java standalone tool designed to extract a comprehensive list of attributes and properties from a wide range of file formats.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "NLNZ Metadata Extractor",
          "local_types": [
            "metadata extraction tool",
            "tool",
            "software",
            "Java application"
          ],
          "iri": "Entity-nlnz_metadata_extractor-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "NLNZ Metadata Extractor tool",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-nlnz_metadata_extractor-Mention-2"
        }
      ],
      "relevance": 0.61962890625
    },
    "Entity-setting": {
      "node_id": "setting",
      "disambiguation_index": 0,
      "label": "settings",
      "aliases": [
        "settings"
      ],
      "types": [
        "settings"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'settings' refers to the configurable parameters and flags defined in a JSON configuration file that dictate the processing of document sets, including aspects such as document storage, file type mappings, and text analysis methods.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "settings",
          "local_types": [
            "settings"
          ],
          "iri": "Entity-setting-Mention-1"
        }
      ],
      "relevance": 0.619140625
    },
    "Entity-format_type": {
      "node_id": "format_type",
      "disambiguation_index": 0,
      "label": "format type",
      "aliases": [
        "format type"
      ],
      "types": [
        "format"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'format type' refers to the specific category or structure of a document format that defines how metadata and content are extracted and represented, particularly in the context of generating JSON structures based on the document object model in the MEL tool.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "format type",
          "local_types": [
            "format"
          ],
          "iri": "Entity-format_type-Mention-1"
        }
      ],
      "relevance": 0.61767578125
    },
    "Entity-tnnt_general_configuration": {
      "node_id": "tnnt_general_configuration",
      "disambiguation_index": 0,
      "label": "TNNT general configuration",
      "aliases": [
        "TNNT general configuration"
      ],
      "types": [
        "system setting",
        "configuration"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The TNNT general configuration refers to a specific set of parameters and flags defined in a detailed JSON configuration file that dictates the initial settings for processing document sets within the MEL tool.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "TNNT general configuration",
          "local_types": [
            "system setting",
            "configuration"
          ],
          "iri": "Entity-tnnt_general_configuration-Mention-1"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-complementary_capability": {
      "node_id": "complementary_capability",
      "disambiguation_index": 0,
      "label": "complementary capabilities",
      "aliases": [
        "complementary capabilities"
      ],
      "types": [
        "capability"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Complementary capabilities refer to the diverse and synergistic functionalities of various open-source packages and tools that, when integrated, enhance the effectiveness of metadata and content-based information extraction processes in the MEL tool.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "complementary capabilities",
          "local_types": [
            "capability"
          ],
          "iri": "Entity-complementary_capability-Mention-1"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-information_extraction_stage": {
      "node_id": "information_extraction_stage",
      "disambiguation_index": 0,
      "label": "information extraction stage",
      "aliases": [
        "information extraction stage"
      ],
      "types": [
        "process"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The information extraction stage refers to the process within Knowledge Graph Construction Pipelines (KGCPs) where metadata and content-based information is extracted from unstructured data sources to facilitate further data analysis and integration.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "information extraction stage",
          "local_types": [
            "process"
          ],
          "iri": "Entity-information_extraction_stage-Mention-1"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis": {
      "node_id": "the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis",
      "disambiguation_index": 0,
      "label": "The most comprehensive and current state-of-the-art tool for content extraction and analysis",
      "aliases": [
        "The most comprehensive and current state-of-the-art tool for content extraction and analysis"
      ],
      "types": [
        "tool",
        "content extraction",
        "analysis"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The most comprehensive and current state-of-the-art tool for content extraction and analysis refers to Apache Tika, a Java-based system designed for extracting metadata and content from various file formats.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "The most comprehensive and current state-of-the-art tool for content extraction and analysis",
          "local_types": [
            "tool",
            "content extraction",
            "analysis"
          ],
          "iri": "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis-Mention-1"
        }
      ],
      "relevance": 0.615234375
    },
    "Entity-flag": {
      "node_id": "flag",
      "disambiguation_index": 0,
      "label": "flags",
      "aliases": [
        "flags"
      ],
      "types": [
        "settings",
        "configuration element"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'flags' refer to specific parameters within a configuration JSON file that dictate the initial settings for processing document sets, including aspects like document storage and metadata extraction methods.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "flags",
          "local_types": [
            "settings",
            "configuration element"
          ],
          "iri": "Entity-flag-Mention-1"
        }
      ],
      "relevance": 0.6142578125
    },
    "Entity-content-based_information_extraction": {
      "node_id": "content-based_information_extraction",
      "disambiguation_index": 0,
      "label": "content-based information extraction",
      "aliases": [
        "content-based information extraction"
      ],
      "types": [
        "process",
        "methodology",
        "data processing",
        "information extraction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Content-based information extraction is a process that involves extracting relevant information from data sources based on the content they contain, often used in data processing and information retrieval applications.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "content-based information extraction",
          "local_types": [
            "data processing",
            "information extraction"
          ],
          "iri": "Entity-content-based_information_extraction-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "content-based information extraction",
          "local_types": [
            "process",
            "methodology"
          ],
          "iri": "Entity-content-based_information_extraction-Mention-2"
        }
      ],
      "relevance": 0.61181640625
    },
    "Entity-configurable_set_of_regular_expression": {
      "node_id": "configurable_set_of_regular_expression",
      "disambiguation_index": 0,
      "label": "configurable set of regular expressions",
      "aliases": [
        "configurable set of regular expressions"
      ],
      "types": [
        "regular expression",
        "regular expressions"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A configurable set of regular expressions refers to a customizable collection of regex patterns used in the MEL tool to perform text analysis and extract relevant metadata and content-based information from various document types.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "configurable set of regular expressions",
          "local_types": [
            "regular expression",
            "regular expressions"
          ],
          "iri": "Entity-configurable_set_of_regular_expression-Mention-1"
        }
      ],
      "relevance": 0.611328125
    },
    "Entity-content-based_information": {
      "node_id": "content-based_information",
      "disambiguation_index": 0,
      "label": "content-based information",
      "aliases": [
        "content-based information"
      ],
      "types": [
        "information",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Content-based information refers to the data extracted from unstructured information in various document formats, which is essential for pre-processing in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-3"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-4"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-5"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-6"
        }
      ],
      "relevance": 0.60986328125
    },
    "Entity-dozen_of_file_format": {
      "node_id": "dozen_of_file_format",
      "disambiguation_index": 0,
      "label": "dozens of file formats",
      "aliases": [
        "dozens of file formats"
      ],
      "types": [
        "file format"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'dozens of file formats' refers to the various document types that the NLNZ Metadata Extractor tool can process to extract metadata and content-based information.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "dozens of file formats",
          "local_types": [
            "file format"
          ],
          "iri": "Entity-dozen_of_file_format-Mention-1"
        }
      ],
      "relevance": 0.60986328125
    },
    "Entity-content_extraction": {
      "node_id": "content_extraction",
      "disambiguation_index": 0,
      "label": "content extraction",
      "aliases": [
        "content extraction"
      ],
      "types": [
        "process",
        "methodology",
        "data processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Content extraction is a process or methodology used to retrieve and organize relevant information from unstructured data sources, enabling further analysis and understanding of the content.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "content extraction",
          "local_types": [
            "process",
            "methodology"
          ],
          "iri": "Entity-content_extraction-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "content extraction",
          "local_types": [
            "process",
            "data processing"
          ],
          "iri": "Entity-content_extraction-Mention-2"
        }
      ],
      "relevance": 0.60791015625
    },
    "Entity-_6_": {
      "node_id": "_6_",
      "disambiguation_index": 0,
      "label": "[6]",
      "aliases": [
        "[3]",
        "[6]",
        "[2]"
      ],
      "types": [
        "reference"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term '[6]' refers to a specific Knowledge Graph Construction Pipeline (KGCP) that is discussed in the paper, highlighting its relevance to the information extraction capabilities of the MEL tool.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "[6]",
          "local_types": [
            "reference"
          ],
          "iri": "Entity-_6_-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "[2]",
          "local_types": [
            "reference"
          ],
          "iri": "Entity-_6_-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "[3]",
          "local_types": [
            "reference"
          ],
          "iri": "Entity-_6_-Mention-3"
        }
      ],
      "relevance": 0.607421875
    },
    "Entity-project": {
      "node_id": "project",
      "disambiguation_index": 0,
      "label": "project",
      "aliases": [
        "project"
      ],
      "types": [
        "research program",
        "initiative"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'project' refers to an initiative aimed at 'containerising' the MEL and TNNT tools to enhance their deployment and usability.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "project",
          "local_types": [
            "research program",
            "initiative"
          ],
          "iri": "Entity-project-Mention-1"
        }
      ],
      "relevance": 0.60693359375
    },
    "Entity-metadata_set": {
      "node_id": "metadata_set",
      "disambiguation_index": 0,
      "label": "metadata sets",
      "aliases": [
        "metadata sets"
      ],
      "types": [
        "data",
        "metadata",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Metadata sets are collections of data that provide information about other data, facilitating the organization, discovery, and management of information across various formats and systems.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "metadata sets",
          "local_types": [
            "data",
            "metadata",
            "information"
          ],
          "iri": "Entity-metadata_set-Mention-1"
        }
      ],
      "relevance": 0.60302734375
    },
    "Entity-per_use-case_requirement_basis": {
      "node_id": "per_use-case_requirement_basis",
      "disambiguation_index": 0,
      "label": "per use-case requirements basis",
      "aliases": [
        "per use-case requirements basis"
      ],
      "types": [
        "requirements"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'per use-case requirements basis' refers to the approach of adding file formats to the MEL tool based on the specific needs and requirements of different use cases in order to enhance its functionality for Knowledge Graph Construction Pipeline tasks.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "per use-case requirements basis",
          "local_types": [
            "requirements"
          ],
          "iri": "Entity-per_use-case_requirement_basis-Mention-1"
        }
      ],
      "relevance": 0.6025390625
    },
    "Entity-the_average_of_the_extracted_attribute": {
      "node_id": "the_average_of_the_extracted_attribute",
      "disambiguation_index": 0,
      "label": "the average of the extracted attributes",
      "aliases": [
        "the average of the extracted attributes"
      ],
      "types": [
        "average",
        "attribute"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The average of the extracted attributes refers to the mean value calculated from the number of metadata attributes that the MEL tool is able to extract from various document types across four specific use case document sets.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "the average of the extracted attributes",
          "local_types": [
            "average",
            "attribute"
          ],
          "iri": "Entity-the_average_of_the_extracted_attribute-Mention-1"
        }
      ],
      "relevance": 0.60205078125
    },
    "Entity-kgcps": {
      "node_id": "kgcps",
      "disambiguation_index": 0,
      "label": "KGCPs",
      "aliases": [
        "KGCPs"
      ],
      "types": [
        "methodology",
        "concept",
        "knowledge graph construction process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "KGCPs refers to Knowledge Graph Construction Pipelines, which are processes that involve the extraction and integration of metadata and content from various data sources to build knowledge graphs.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "KGCPs",
          "local_types": [
            "methodology",
            "concept",
            "knowledge graph construction process"
          ],
          "iri": "Entity-kgcps-Mention-1"
        }
      ],
      "relevance": 0.60107421875
    },
    "Entity-swiss_army_knife": {
      "node_id": "swiss_army_knife",
      "disambiguation_index": 0,
      "label": "Swiss army knife",
      "aliases": [
        "Swiss army knife"
      ],
      "types": [
        "metaphor",
        "tool"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'Swiss army knife' metaphorically refers to MEL's versatile integration of various open-source packages and tools that collectively provide a comprehensive solution for metadata and content-based information extraction from diverse document formats.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "Swiss army knife",
          "local_types": [
            "metaphor",
            "tool"
          ],
          "iri": "Entity-swiss_army_knife-Mention-1"
        }
      ],
      "relevance": 0.60107421875
    },
    "Entity-task": {
      "node_id": "task",
      "disambiguation_index": 0,
      "label": "tasks",
      "aliases": [
        "tasks",
        "These tasks"
      ],
      "types": [
        "activities",
        "operations",
        "task"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'tasks' refers to the metadata and content-based information extraction activities that serve as pre-processing steps in Knowledge Graph Construction Pipelines (KGCP).",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "tasks",
          "local_types": [
            "activities",
            "operations"
          ],
          "iri": "Entity-task-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "These tasks",
          "local_types": [
            "task"
          ],
          "iri": "Entity-task-Mention-2"
        }
      ],
      "relevance": 0.6005859375
    },
    "Entity-nlp_tool": {
      "node_id": "nlp_tool",
      "disambiguation_index": 0,
      "label": "NLP tools",
      "aliases": [
        "NLP tools"
      ],
      "types": [
        "software",
        "tool",
        "technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "NLP tools are software applications or technologies designed to process and analyze natural language data, enabling tasks such as text analysis, language understanding, and information extraction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "NLP tools",
          "local_types": [
            "software",
            "technology",
            "tool"
          ],
          "iri": "Entity-nlp_tool-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "NLP tools",
          "local_types": [
            "software",
            "technology",
            "tool"
          ],
          "iri": "Entity-nlp_tool-Mention-2"
        }
      ],
      "relevance": 0.5947265625
    },
    "Entity-j2rm": {
      "node_id": "j2rm",
      "disambiguation_index": 0,
      "label": "J2RM",
      "aliases": [
        "J2RM"
      ],
      "types": [
        "system",
        "entity",
        "software",
        "project",
        "acronym",
        "tool",
        "organization"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "J2RM is a software tool developed to facilitate the mapping of JSON results to RDF within automated Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "J2RM",
          "local_types": [
            "organization",
            "system",
            "project",
            "entity",
            "software",
            "tool",
            "acronym"
          ],
          "iri": "Entity-j2rm-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "J2RM",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-j2rm-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "J2RM",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-j2rm-Mention-3"
        }
      ],
      "relevance": 0.59375
    },
    "Entity-ole_2": {
      "node_id": "ole_2",
      "disambiguation_index": 0,
      "label": "OLE 2",
      "aliases": [
        "OLE 2"
      ],
      "types": [
        "format",
        "file type"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "OLE 2 refers to a specific file type format that is compatible with the MEL tool for metadata extraction, which can only be processed on Windows operating systems.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": "OLE 2",
          "local_types": [
            "format",
            "file type"
          ],
          "iri": "Entity-ole_2-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "OLE 2",
          "local_types": [
            "file type",
            "format"
          ],
          "iri": "Entity-ole_2-Mention-2"
        }
      ],
      "relevance": 0.5927734375
    },
    "Entity-apache_tika": {
      "node_id": "apache_tika",
      "disambiguation_index": 0,
      "label": "Apache Tika",
      "aliases": [
        "Apache Tika"
      ],
      "types": [
        "system",
        "package",
        "tool",
        "content extraction system",
        "software",
        "content extraction"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Apache Tika is an open-source content extraction and analysis tool written in Java, designed to detect and extract metadata and text from various file formats.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "Apache Tika",
          "local_types": [
            "system",
            "content extraction system",
            "software",
            "content extraction",
            "tool"
          ],
          "iri": "Entity-apache_tika-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "Apache Tika",
          "local_types": [
            "software",
            "tool",
            "package"
          ],
          "iri": "Entity-apache_tika-Mention-2"
        }
      ],
      "relevance": 0.59228515625
    },
    "Entity-content-based_analysis": {
      "node_id": "content-based_analysis",
      "disambiguation_index": 0,
      "label": "content-based analysis",
      "aliases": [
        "content-based analysis"
      ],
      "types": [
        "research methodology",
        "analysis method",
        "research approach",
        "analysis"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Content-based analysis is a research methodology that focuses on examining and interpreting the content of various forms of data, such as text, images, or audio, to extract meaningful insights and patterns.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "content-based analysis",
          "local_types": [
            "analysis",
            "analysis method",
            "research approach"
          ],
          "iri": "Entity-content-based_analysis-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "content-based analysis",
          "local_types": [
            "analysis",
            "analysis method",
            "research methodology"
          ],
          "iri": "Entity-content-based_analysis-Mention-2"
        }
      ],
      "relevance": 0.5908203125
    },
    "Entity-keyword_extraction": {
      "node_id": "keyword_extraction",
      "disambiguation_index": 0,
      "label": "keyword extraction",
      "aliases": [
        "keyword extraction"
      ],
      "types": [
        "data analysis",
        "information retrieval",
        "method",
        "technique",
        "algorithm",
        "text analysis technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Keyword extraction is a text analysis technique that identifies and extracts significant words or phrases from a body of text, facilitating information retrieval and data analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "keyword extraction",
          "local_types": [
            "algorithm",
            "method",
            "data analysis",
            "text analysis technique",
            "technique"
          ],
          "iri": "Entity-keyword_extraction-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "keyword extraction",
          "local_types": [
            "text analysis technique",
            "information retrieval"
          ],
          "iri": "Entity-keyword_extraction-Mention-2"
        }
      ],
      "relevance": 0.58740234375
    },
    "Entity-parameter_and_flag": {
      "node_id": "parameter_and_flag",
      "disambiguation_index": 0,
      "label": "parameters and flags",
      "aliases": [
        "parameters and flags"
      ],
      "types": [
        "parameter",
        "settings",
        "flag",
        "configuration",
        "parameters"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'parameters and flags' refers to the configurable settings defined in a JSON file that dictate the processing behavior of the MEL tool, including aspects such as document store configuration, input document sets, and text analysis methods.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "parameters and flags",
          "local_types": [
            "parameter",
            "settings",
            "flag",
            "configuration",
            "parameters"
          ],
          "iri": "Entity-parameter_and_flag-Mention-1"
        }
      ],
      "relevance": 0.5849609375
    },
    "Entity-java_standalone_tool": {
      "node_id": "java_standalone_tool",
      "disambiguation_index": 0,
      "label": "Java standalone tool",
      "aliases": [
        "Java standalone tool"
      ],
      "types": [
        "tool",
        "software",
        "programming language"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A Java standalone tool that extracts a comprehensive attribute and property list from various file formats, facilitating metadata extraction tasks.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "Java standalone tool",
          "local_types": [
            "tool",
            "software",
            "programming language"
          ],
          "iri": "Entity-java_standalone_tool-Mention-1"
        }
      ],
      "relevance": 0.58447265625
    },
    "Entity-text_analysis": {
      "node_id": "text_analysis",
      "disambiguation_index": 0,
      "label": "text analysis",
      "aliases": [
        "text analysis"
      ],
      "types": [
        "process",
        "methodology",
        "method",
        "data analysis"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Text analysis is a process of examining and interpreting textual data to extract meaningful information, patterns, and insights using various methodologies and techniques.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "text analysis",
          "local_types": [
            "methodology",
            "method",
            "data analysis",
            "process"
          ],
          "iri": "Entity-text_analysis-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "text analysis",
          "local_types": [
            "process",
            "methodology"
          ],
          "iri": "Entity-text_analysis-Mention-2"
        }
      ],
      "relevance": 0.583984375
    },
    "Entity-the_last_step": {
      "node_id": "the_last_step",
      "disambiguation_index": 0,
      "label": "the last step",
      "aliases": [
        "the last step"
      ],
      "types": [
        "step"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The last step refers to the final text analysis task performed on the output generated from the specific processing model of each file type in the MEL tool.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "the last step",
          "local_types": [
            "step"
          ],
          "iri": "Entity-the_last_step-Mention-1"
        }
      ],
      "relevance": 0.58349609375
    },
    "Entity-knowledge_graph_construction_pipeline__kgcp_": {
      "node_id": "knowledge_graph_construction_pipeline__kgcp_",
      "disambiguation_index": 0,
      "label": "Knowledge Graph Construction Pipelines (KGCP)",
      "aliases": [
        "Knowledge Graph Construction Pipelines (KGCP)"
      ],
      "types": [
        "knowledge graph",
        "pipeline",
        "Knowledge Graph"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Knowledge Graph Construction Pipelines (KGCP) are structured processes designed to extract, integrate, and organize information from various data sources to create and enhance knowledge graphs.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "Knowledge Graph Construction Pipelines (KGCP)",
          "local_types": [
            "knowledge graph",
            "pipeline",
            "Knowledge Graph"
          ],
          "iri": "Entity-knowledge_graph_construction_pipeline__kgcp_-Mention-1"
        }
      ],
      "relevance": 0.58251953125
    },
    "Entity-theoretical_number_of_attribute": {
      "node_id": "theoretical_number_of_attribute",
      "disambiguation_index": 0,
      "label": "theoretical number of attributes",
      "aliases": [
        "theoretical number of attributes"
      ],
      "types": [
        "attribute"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Theoretical number of attributes refers to the estimated count of distinct metadata attributes that the MEL tool is capable of extracting from each specific document type during the metadata extraction process.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "theoretical number of attributes",
          "local_types": [
            "attribute"
          ],
          "iri": "Entity-theoretical_number_of_attribute-Mention-1"
        }
      ],
      "relevance": 0.58251953125
    },
    "Entity-knowledge_graph_construction_pipeline": {
      "node_id": "knowledge_graph_construction_pipeline",
      "disambiguation_index": 0,
      "label": "Knowledge Graph Construction Pipelines",
      "aliases": [
        "Knowledge Graph Construction Pipelines"
      ],
      "types": [
        "knowledge graph",
        "process",
        "data processing framework",
        "concept",
        "pipeline"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Knowledge Graph Construction Pipelines are systematic frameworks designed to automate the process of extracting, integrating, and organizing data from various sources to create structured knowledge graphs.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "Knowledge Graph Construction Pipelines",
          "local_types": [
            "knowledge graph",
            "process",
            "data processing framework",
            "concept",
            "pipeline"
          ],
          "iri": "Entity-knowledge_graph_construction_pipeline-Mention-1"
        }
      ],
      "relevance": 0.5810546875
    },
    "Entity-ner_model": {
      "node_id": "ner_model",
      "disambiguation_index": 0,
      "label": "NER models",
      "aliases": [
        "NER models"
      ],
      "types": [
        "model",
        "technology",
        "machine learning"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "NER models are machine learning algorithms designed to identify and classify named entities in text into predefined categories such as names of people, organizations, locations, and other specific terms.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "NER models",
          "local_types": [
            "model",
            "technology"
          ],
          "iri": "Entity-ner_model-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "NER models",
          "local_types": [
            "model",
            "technology",
            "machine learning"
          ],
          "iri": "Entity-ner_model-Mention-2"
        }
      ],
      "relevance": 0.5791015625
    },
    "Entity-python-based_tool": {
      "node_id": "python-based_tool",
      "disambiguation_index": 0,
      "label": "Python-based tool",
      "aliases": [
        "Python-based tool"
      ],
      "types": [
        "tool",
        "software"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A Python-based tool is a software application developed using the Python programming language, designed to perform specific tasks or functions, often related to data processing or analysis.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "Python-based tool",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-python-based_tool-Mention-1"
        }
      ],
      "relevance": 0.57568359375
    },
    "Entity-the_data_set__domain": {
      "node_id": "the_data_set__domain",
      "disambiguation_index": 0,
      "label": "the data sets' domain",
      "aliases": [
        "the data sets' domain"
      ],
      "types": [
        "domain"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The data sets' domain refers to the specific area or field of application from which the unstructured data sets are derived, indicating that MEL is designed to work with various types of data regardless of their specific context or subject matter.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "the data sets' domain",
          "local_types": [
            "domain"
          ],
          "iri": "Entity-the_data_set__domain-Mention-1"
        }
      ],
      "relevance": 0.5751953125
    },
    "Entity-json_result_file": {
      "node_id": "json_result_file",
      "disambiguation_index": 0,
      "label": "JSON result files",
      "aliases": [
        "JSON result files"
      ],
      "types": [
        "file",
        "file format",
        "data",
        "format",
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON result files are structured text files that store data in a format that is easy for both humans and machines to read and write, using JavaScript Object Notation (JSON) to represent the data in key-value pairs.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "JSON result files",
          "local_types": [
            "file",
            "file format",
            "data",
            "format",
            "data format"
          ],
          "iri": "Entity-json_result_file-Mention-1"
        }
      ],
      "relevance": 0.57421875
    },
    "Entity-kgcp": {
      "node_id": "kgcp",
      "disambiguation_index": 0,
      "label": "KGCP",
      "aliases": [
        "KGCP"
      ],
      "types": [
        "system",
        "abbreviation",
        "data processing framework",
        "concept",
        "process",
        "knowledge graph construction",
        "task",
        "framework",
        "project",
        "knowledge graph",
        "knowledge graph construction process",
        "acronym"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "KGCP refers to Knowledge Graph Construction Pipelines, which are frameworks that facilitate the process of constructing knowledge graphs through various data processing and extraction methods.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "KGCP",
          "local_types": [
            "framework",
            "system"
          ],
          "iri": "Entity-kgcp-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "KGCP",
          "local_types": [
            "framework",
            "project",
            "process",
            "concept",
            "knowledge graph construction",
            "acronym"
          ],
          "iri": "Entity-kgcp-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "KGCP",
          "local_types": [
            "system",
            "framework",
            "project",
            "knowledge graph construction process",
            "concept",
            "acronym"
          ],
          "iri": "Entity-kgcp-Mention-3"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "KGCP",
          "local_types": [
            "abbreviation",
            "knowledge graph",
            "data processing framework"
          ],
          "iri": "Entity-kgcp-Mention-4"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "KGCP",
          "local_types": [
            "task",
            "project"
          ],
          "iri": "Entity-kgcp-Mention-5"
        }
      ],
      "relevance": 0.5732421875
    },
    "Entity-agrif_project": {
      "node_id": "agrif_project",
      "disambiguation_index": 0,
      "label": "AGRIF project",
      "aliases": [
        "AGRIF project"
      ],
      "types": [
        "research project",
        "initiative",
        "project"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The AGRIF project is a research initiative focused on testing and validating tools for metadata and content-based information extraction from diverse document formats.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "AGRIF project",
          "local_types": [
            "research project",
            "initiative",
            "project"
          ],
          "iri": "Entity-agrif_project-Mention-1"
        }
      ],
      "relevance": 0.5732421875
    },
    "Entity-agrif": {
      "node_id": "agrif",
      "disambiguation_index": 0,
      "label": "AGRIF",
      "aliases": [
        "AGRIF"
      ],
      "types": [
        "project"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "AGRIF refers to a project that involves testing the MEL tool over thousands of documents in various formats and datasets.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "AGRIF",
          "local_types": [
            "project"
          ],
          "iri": "Entity-agrif-Mention-1"
        }
      ],
      "relevance": 0.572265625
    },
    "Entity-metadata": {
      "node_id": "metadata",
      "disambiguation_index": 0,
      "label": "metadata",
      "aliases": [
        "metadata"
      ],
      "types": [
        "metadata",
        "data description",
        "information",
        "data type",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Metadata refers to structured information that describes, explains, or gives context to other data, facilitating its organization, discovery, and understanding.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "metadata",
          "local_types": [
            "data",
            "data type",
            "information"
          ],
          "iri": "Entity-metadata-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-4"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "metadata",
          "local_types": [
            "data",
            "metadata",
            "information"
          ],
          "iri": "Entity-metadata-Mention-5"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-6"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-7"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-8"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "metadata",
          "local_types": [
            "data description"
          ],
          "iri": "Entity-metadata-Mention-9"
        }
      ],
      "relevance": 0.5703125
    },
    "Entity-json_file": {
      "node_id": "json_file",
      "disambiguation_index": 0,
      "label": "JSON files",
      "aliases": [
        "JSON file",
        "JSON files"
      ],
      "types": [
        "format",
        "JSON",
        "file type",
        "data format",
        "file format",
        "file"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON files are text files that store data in a structured format using JavaScript Object Notation (JSON), which is easy for humans to read and write, and easy for machines to parse and generate.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "JSON files",
          "local_types": [
            "file",
            "file format",
            "format",
            "file type",
            "data format"
          ],
          "iri": "Entity-json_file-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "JSON file",
          "local_types": [
            "file",
            "JSON",
            "format",
            "file type",
            "data format"
          ],
          "iri": "Entity-json_file-Mention-2"
        }
      ],
      "relevance": 0.5703125
    },
    "Entity-vocabulary_or_light-weight_ontology": {
      "node_id": "vocabulary_or_light-weight_ontology",
      "disambiguation_index": 0,
      "label": "vocabulary or light-weight ontology",
      "aliases": [
        "light-weight ontology",
        "vocabulary or light-weight ontology"
      ],
      "types": [
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The term 'vocabulary or light-weight ontology' refers to a structured set of terms and relationships that can be incorporated into the JSON results of the MEL tool using JSON-LD annotations to enhance the metadata's compatibility with RDF standards.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "vocabulary or light-weight ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-vocabulary_or_light-weight_ontology-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "light-weight ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-vocabulary_or_light-weight_ontology-Mention-2"
        }
      ],
      "relevance": 0.56982421875
    },
    "Entity-comprehensive_attribute_and_property_list": {
      "node_id": "comprehensive_attribute_and_property_list",
      "disambiguation_index": 0,
      "label": "comprehensive attribute and property list",
      "aliases": [
        "comprehensive attribute and property list"
      ],
      "types": [
        "data"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'comprehensive attribute and property list' refers to a structured output generated by the NLNZ Metadata Extractor tool, which encapsulates detailed metadata attributes and properties extracted from various file formats, facilitating enhanced data processing and integration in knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "comprehensive attribute and property list",
          "local_types": [
            "data"
          ],
          "iri": "Entity-comprehensive_attribute_and_property_list-Mention-1"
        }
      ],
      "relevance": 0.56982421875
    },
    "Entity-information_extraction": {
      "node_id": "information_extraction",
      "disambiguation_index": 0,
      "label": "information extraction",
      "aliases": [
        "information extraction"
      ],
      "types": [
        "process",
        "technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Information extraction is a process or technique used to automatically extract structured information from unstructured or semi-structured data sources.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "information extraction",
          "local_types": [
            "process",
            "technique"
          ],
          "iri": "Entity-information_extraction-Mention-1"
        }
      ],
      "relevance": 0.56787109375
    },
    "Entity-state-of-the-art_nlp_tool_and_ner_model": {
      "node_id": "state-of-the-art_nlp_tool_and_ner_model",
      "disambiguation_index": 0,
      "label": "state-of-the-art NLP tools and NER models",
      "aliases": [
        "state-of-the-art NLP tools",
        "state-of-the-art NLP tools and NER models"
      ],
      "types": [
        "tool",
        "NLP tool",
        "model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "state-of-the-art NLP tools and NER models refer to advanced software and algorithms designed for natural language processing tasks, including the identification and classification of named entities within text.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "state-of-the-art NLP tools and NER models",
          "local_types": [
            "tool",
            "model"
          ],
          "iri": "Entity-state-of-the-art_nlp_tool_and_ner_model-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "state-of-the-art NLP tools",
          "local_types": [
            "NLP tool"
          ],
          "iri": "Entity-state-of-the-art_nlp_tool_and_ner_model-Mention-2"
        }
      ],
      "relevance": 0.5673828125
    },
    "Entity-python-based_tool_and_library": {
      "node_id": "python-based_tool_and_library",
      "disambiguation_index": 0,
      "label": "Python-based tools and libraries",
      "aliases": [
        "Python-based tools and libraries"
      ],
      "types": [
        "library",
        "software",
        "tools",
        "tool",
        "libraries"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Python-based tools and libraries refer to software packages and frameworks developed in the Python programming language that provide functionalities for various tasks, including data manipulation, analysis, and extraction.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "Python-based tools and libraries",
          "local_types": [
            "library",
            "software",
            "tools",
            "tool",
            "libraries"
          ],
          "iri": "Entity-python-based_tool_and_library-Mention-1"
        }
      ],
      "relevance": 0.5634765625
    },
    "Entity-text_analysis_task": {
      "node_id": "text_analysis_task",
      "disambiguation_index": 0,
      "label": "text analysis task",
      "aliases": [
        "text analysis task"
      ],
      "types": [
        "analysis process",
        "data processing",
        "text analysis",
        "process",
        "task",
        "analysis"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A text analysis task refers to a systematic process of examining and interpreting textual data to extract meaningful information, identify patterns, or derive insights.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "text analysis task",
          "local_types": [
            "analysis",
            "task",
            "process"
          ],
          "iri": "Entity-text_analysis_task-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "text analysis task",
          "local_types": [
            "task",
            "process",
            "analysis process",
            "text analysis",
            "data processing",
            "analysis"
          ],
          "iri": "Entity-text_analysis_task-Mention-2"
        }
      ],
      "relevance": 0.5625
    },
    "Entity-rdf": {
      "node_id": "rdf",
      "disambiguation_index": 0,
      "label": "RDF",
      "aliases": [
        "RDF"
      ],
      "types": [
        "format",
        "semantic web technology",
        "data representation",
        "linked data",
        "semantic web",
        "standard",
        "data structure",
        "data model",
        "data format",
        "technology",
        "semantic web standard"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "RDF, or Resource Description Framework, is a standard model for data interchange on the web that facilitates the representation of information about resources in a structured way, enabling linked data and semantic web applications.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "RDF",
          "local_types": [
            "data structure",
            "semantic web",
            "format",
            "data format"
          ],
          "iri": "Entity-rdf-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "RDF",
          "local_types": [
            "semantic web standard",
            "format",
            "standard",
            "semantic web",
            "data model",
            "data format"
          ],
          "iri": "Entity-rdf-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "RDF",
          "local_types": [
            "semantic web technology",
            "semantic web standard",
            "format",
            "semantic web",
            "data representation",
            "data format"
          ],
          "iri": "Entity-rdf-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "RDF",
          "local_types": [
            "technology",
            "semantic web standard",
            "format",
            "linked data",
            "semantic web",
            "data model",
            "data format"
          ],
          "iri": "Entity-rdf-Mention-4"
        }
      ],
      "relevance": 0.56201171875
    },
    "Entity-ner": {
      "node_id": "ner",
      "disambiguation_index": 0,
      "label": "NER",
      "aliases": [
        "NER"
      ],
      "types": [
        "field",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "NER refers to Named Entity Recognition, a subtask of natural language processing that involves identifying and classifying key entities in text into predefined categories such as names, organizations, locations, and more.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "NER",
          "local_types": [
            "field",
            "technology"
          ],
          "iri": "Entity-ner-Mention-1"
        }
      ],
      "relevance": 0.5615234375
    },
    "Entity-basic_text_analysis": {
      "node_id": "basic_text_analysis",
      "disambiguation_index": 0,
      "label": "basic text analysis",
      "aliases": [
        "basic text analysis"
      ],
      "types": [
        "analysis",
        "text analysis"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Basic text analysis refers to the preliminary processing of text data that includes tasks such as applying regular expressions and extracting keywords to derive meaningful information from documents.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "basic text analysis",
          "local_types": [
            "analysis",
            "text analysis"
          ],
          "iri": "Entity-basic_text_analysis-Mention-1"
        }
      ],
      "relevance": 0.5595703125
    },
    "Entity-xml_output": {
      "node_id": "xml_output",
      "disambiguation_index": 0,
      "label": "XML output",
      "aliases": [
        "XML output"
      ],
      "types": [
        "data",
        "markup language",
        "data format",
        "format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "XML output refers to data formatted in Extensible Markup Language (XML), which is used to encode structured information in a machine-readable format.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "XML output",
          "local_types": [
            "data",
            "markup language",
            "data format",
            "format"
          ],
          "iri": "Entity-xml_output-Mention-1"
        }
      ],
      "relevance": 0.55908203125
    },
    "Entity-pattern_matching": {
      "node_id": "pattern_matching",
      "disambiguation_index": 0,
      "label": "pattern matching",
      "aliases": [
        "pattern matching"
      ],
      "types": [
        "algorithm",
        "method",
        "data analysis",
        "text analysis technique",
        "technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pattern matching is a technique used in data analysis and text analysis that involves identifying and locating specific sequences or patterns within data sets or text.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "pattern matching",
          "local_types": [
            "algorithm",
            "method",
            "data analysis",
            "text analysis technique",
            "technique"
          ],
          "iri": "Entity-pattern_matching-Mention-1"
        }
      ],
      "relevance": 0.55859375
    },
    "Entity-json-ld": {
      "node_id": "json-ld",
      "disambiguation_index": 0,
      "label": "JSON-LD",
      "aliases": [
        "JSON-LD ontologies",
        "JSON-LD"
      ],
      "types": [
        "format",
        "semantic web technology",
        "linked data",
        "ontology",
        "annotation format",
        "serialization format",
        "data format",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "JSON-LD is a lightweight Linked Data format that allows the representation of structured data using JSON, enabling interoperability and integration of data across different systems.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "JSON-LD",
          "local_types": [
            "technology",
            "ontology"
          ],
          "iri": "Entity-json-ld-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "JSON-LD",
          "local_types": [
            "technology",
            "format",
            "annotation format",
            "linked data",
            "serialization format",
            "data format"
          ],
          "iri": "Entity-json-ld-Mention-2"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "JSON-LD ontologies",
          "local_types": [
            "data format",
            "ontology",
            "semantic web technology"
          ],
          "iri": "Entity-json-ld-Mention-3"
        }
      ],
      "relevance": 0.5576171875
    },
    "Entity-basic_text_analysis_task": {
      "node_id": "basic_text_analysis_task",
      "disambiguation_index": 0,
      "label": "basic text analysis tasks",
      "aliases": [
        "basic text analysis tasks"
      ],
      "types": [
        "task",
        "text analysis"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Basic text analysis tasks refer to fundamental operations such as pattern matching and keyword extraction performed on textual content to facilitate further content-based analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "basic text analysis tasks",
          "local_types": [
            "task",
            "text analysis"
          ],
          "iri": "Entity-basic_text_analysis_task-Mention-1"
        }
      ],
      "relevance": 0.556640625
    },
    "Entity-textual_content": {
      "node_id": "textual_content",
      "disambiguation_index": 0,
      "label": "textual content",
      "aliases": [
        "textual content"
      ],
      "types": [
        "data",
        "content",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Textual content refers to the written or printed material that conveys information or data within a document or file.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "textual content",
          "local_types": [
            "data",
            "content",
            "information"
          ],
          "iri": "Entity-textual_content-Mention-1"
        }
      ],
      "relevance": 0.5556640625
    },
    "Entity-document_store": {
      "node_id": "document_store",
      "disambiguation_index": 0,
      "label": "document store",
      "aliases": [
        "document store"
      ],
      "types": [
        "system component",
        "document store",
        "data storage",
        "document",
        "database",
        "repository",
        "storage system",
        "storage"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A document store is a type of database designed to store, retrieve, and manage document-oriented information, typically in formats like JSON or XML.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "document store",
          "local_types": [
            "data storage",
            "database",
            "storage",
            "storage system"
          ],
          "iri": "Entity-document_store-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "document store",
          "local_types": [
            "document",
            "storage",
            "database",
            "data storage",
            "document store",
            "repository"
          ],
          "iri": "Entity-document_store-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "document store",
          "local_types": [
            "system component",
            "storage",
            "data storage"
          ],
          "iri": "Entity-document_store-Mention-3"
        }
      ],
      "relevance": 0.55419921875
    },
    "Entity-rdf_ready": {
      "node_id": "rdf_ready",
      "disambiguation_index": 0,
      "label": "RDF ready",
      "aliases": [
        "RDF ready"
      ],
      "types": [
        "RDF"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "RDF ready refers to the state of extracted metadata that has been enhanced with a vocabulary or lightweight ontology using JSON-LD annotations, making it suitable for conversion to RDF format.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "RDF ready",
          "local_types": [
            "RDF"
          ],
          "iri": "Entity-rdf_ready-Mention-1"
        }
      ],
      "relevance": 0.552734375
    },
    "Entity-datasets": {
      "node_id": "datasets",
      "disambiguation_index": 0,
      "label": "datasets",
      "aliases": [
        "datasets"
      ],
      "types": [
        "data collection",
        "dataset"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Datasets are structured collections of data, typically organized in a way that facilitates analysis and processing for various applications.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "datasets",
          "local_types": [
            "data collection",
            "dataset"
          ],
          "iri": "Entity-datasets-Mention-1"
        }
      ],
      "relevance": 0.5517578125
    },
    "Entity-pattern_matching_and_keyword_extraction": {
      "node_id": "pattern_matching_and_keyword_extraction",
      "disambiguation_index": 0,
      "label": "pattern matching and keyword extraction",
      "aliases": [
        "pattern matching and keyword extraction"
      ],
      "types": [
        "task"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pattern matching and keyword extraction are techniques used in text analysis to identify specific patterns and extract significant words or phrases from a body of text.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "pattern matching and keyword extraction",
          "local_types": [
            "task"
          ],
          "iri": "Entity-pattern_matching_and_keyword_extraction-Mention-1"
        }
      ],
      "relevance": 0.55126953125
    },
    "Entity-json-ld_annotation": {
      "node_id": "json-ld_annotation",
      "disambiguation_index": 0,
      "label": "JSON-LD annotations",
      "aliases": [
        "JSON-LD annotations"
      ],
      "types": [
        "JSON-LD",
        "annotation"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "JSON-LD annotations are a method for adding structured metadata to JSON data, enabling the integration of vocabularies or lightweight ontologies to enhance the interoperability of extracted metadata with RDF standards.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "JSON-LD annotations",
          "local_types": [
            "JSON-LD",
            "annotation"
          ],
          "iri": "Entity-json-ld_annotation-Mention-1"
        }
      ],
      "relevance": 0.54931640625
    },
    "Entity-extraction_method": {
      "node_id": "extraction_method",
      "disambiguation_index": 0,
      "label": "extraction methods",
      "aliases": [
        "extraction methods"
      ],
      "types": [
        "techniques",
        "processes"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Extraction methods are techniques or processes used to obtain specific information or data from various sources.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "extraction methods",
          "local_types": [
            "techniques",
            "processes"
          ],
          "iri": "Entity-extraction_method-Mention-1"
        }
      ],
      "relevance": 0.54638671875
    },
    "Entity-heterogeneous_file_format": {
      "node_id": "heterogeneous_file_format",
      "disambiguation_index": 0,
      "label": "heterogeneous file formats",
      "aliases": [
        "heterogeneous file formats"
      ],
      "types": [
        "file format",
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Heterogeneous file formats refer to a variety of data storage formats that differ in structure, encoding, and organization, allowing for the representation of diverse types of information across different systems and applications.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "heterogeneous file formats",
          "local_types": [
            "file format",
            "data format"
          ],
          "iri": "Entity-heterogeneous_file_format-Mention-1"
        }
      ],
      "relevance": 0.54638671875
    },
    "Entity-xml": {
      "node_id": "xml",
      "disambiguation_index": 0,
      "label": "XML",
      "aliases": [
        "XML"
      ],
      "types": [
        "markup language",
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "XML is a markup language used for encoding documents in a format that is both human-readable and machine-readable, often utilized for data representation and storage.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "XML",
          "local_types": [
            "markup language",
            "data format"
          ],
          "iri": "Entity-xml-Mention-1"
        }
      ],
      "relevance": 0.544921875
    },
    "Entity-java-based_general-purpose_system": {
      "node_id": "java-based_general-purpose_system",
      "disambiguation_index": 0,
      "label": "Java-based general-purpose system",
      "aliases": [
        "Java-based general-purpose system"
      ],
      "types": [
        "system",
        "Java"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A Java-based general-purpose system refers to a versatile software framework, exemplified by Apache Tika, designed to facilitate content extraction and analysis from various file formats, providing comprehensive tools for metadata and information processing.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "Java-based general-purpose system",
          "local_types": [
            "system",
            "Java"
          ],
          "iri": "Entity-java-based_general-purpose_system-Mention-1"
        }
      ],
      "relevance": 0.54296875
    },
    "Entity-data_cleaning": {
      "node_id": "data_cleaning",
      "disambiguation_index": 0,
      "label": "data cleaning",
      "aliases": [
        "data cleaning"
      ],
      "types": [
        "method",
        "data processing",
        "data preparation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Data cleaning is the process of identifying and correcting errors or inconsistencies in data to improve its quality and usability for analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "data cleaning",
          "local_types": [
            "method",
            "data processing",
            "data preparation"
          ],
          "iri": "Entity-data_cleaning-Mention-1"
        }
      ],
      "relevance": 0.54248046875
    },
    "Entity-data_set": {
      "node_id": "data_set",
      "disambiguation_index": 0,
      "label": "data sets",
      "aliases": [
        "data sets"
      ],
      "types": [
        "data",
        "collection"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Data sets are collections of related data points or information organized for analysis, processing, or reference, often used in various fields such as research, statistics, and machine learning.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "data sets",
          "local_types": [
            "data",
            "collection"
          ],
          "iri": "Entity-data_set-Mention-1"
        }
      ],
      "relevance": 0.54052734375
    },
    "Entity-property": {
      "node_id": "property",
      "disambiguation_index": 0,
      "label": "properties",
      "aliases": [
        "properties"
      ],
      "types": [
        "characteristics",
        "attributes"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'properties' refers to the various characteristics and attributes of extraction methods that are integrated to enhance the output quality in metadata and content-based information extraction tasks.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "properties",
          "local_types": [
            "characteristics",
            "attributes"
          ],
          "iri": "Entity-property-Mention-1"
        }
      ],
      "relevance": 0.53662109375
    },
    "Entity-pre-processing_and_data_cleaning_task": {
      "node_id": "pre-processing_and_data_cleaning_task",
      "disambiguation_index": 0,
      "label": "pre-processing and data cleaning tasks",
      "aliases": [
        "pre-processing and data cleaning tasks"
      ],
      "types": [
        "task"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pre-processing and data cleaning tasks refer to the systematic procedures applied to raw data to prepare it for analysis by removing inaccuracies, inconsistencies, and irrelevant information.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "pre-processing and data cleaning tasks",
          "local_types": [
            "task"
          ],
          "iri": "Entity-pre-processing_and_data_cleaning_task-Mention-1"
        }
      ],
      "relevance": 0.53369140625
    },
    "Entity-unstructured_data_set": {
      "node_id": "unstructured_data_set",
      "disambiguation_index": 0,
      "label": "unstructured data sets",
      "aliases": [
        "unstructured data sets"
      ],
      "types": [
        "information",
        "data set",
        "data format",
        "unstructured data",
        "data type",
        "data",
        "dataset"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Unstructured data sets refer to collections of information that do not have a predefined data model or structure, making them difficult to organize and analyze using traditional data processing methods.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "unstructured data sets",
          "local_types": [
            "data type",
            "information",
            "data",
            "data set",
            "data format"
          ],
          "iri": "Entity-unstructured_data_set-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "unstructured data sets",
          "local_types": [
            "unstructured data",
            "data type",
            "dataset",
            "data",
            "data set"
          ],
          "iri": "Entity-unstructured_data_set-Mention-2"
        }
      ],
      "relevance": 0.53369140625
    },
    "Entity-json": {
      "node_id": "json",
      "disambiguation_index": 0,
      "label": "JSON",
      "aliases": [
        "JSON"
      ],
      "types": [
        "format",
        "data representation",
        "serialization format",
        "data structure",
        "data format",
        "file format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "JSON is a lightweight data interchange format that is easy for humans to read and write, and easy for machines to parse and generate, often used for representing structured data.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "JSON",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "JSON",
          "local_types": [
            "format",
            "data structure"
          ],
          "iri": "Entity-json-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "JSON",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "JSON",
          "local_types": [
            "format",
            "data representation",
            "file format",
            "data format"
          ],
          "iri": "Entity-json-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "JSON",
          "local_types": [
            "data format",
            "serialization format"
          ],
          "iri": "Entity-json-Mention-5"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "JSON",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json-Mention-6"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "JSON",
          "local_types": [
            "file format",
            "data format"
          ],
          "iri": "Entity-json-Mention-7"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "JSON",
          "local_types": [
            "serialization format",
            "data format"
          ],
          "iri": "Entity-json-Mention-8"
        }
      ],
      "relevance": 0.533203125
    },
    "Entity-json_object": {
      "node_id": "json_object",
      "disambiguation_index": 0,
      "label": "JSON objects",
      "aliases": [
        "JSON objects"
      ],
      "types": [
        "data structure",
        "format",
        "data format",
        "JSON"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON objects are structured data representations in the JavaScript Object Notation (JSON) format, which use key-value pairs to organize and transmit data in a lightweight and easily readable manner.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "JSON objects",
          "local_types": [
            "data structure",
            "format",
            "data format",
            "JSON"
          ],
          "iri": "Entity-json_object-Mention-1"
        }
      ],
      "relevance": 0.533203125
    },
    "Entity-pre-processing": {
      "node_id": "pre-processing",
      "disambiguation_index": 0,
      "label": "pre-processing",
      "aliases": [
        "pre-processing"
      ],
      "types": [
        "method",
        "data processing",
        "data cleaning"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pre-processing refers to the methods and techniques applied to prepare and clean data before it is analyzed or processed further.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "pre-processing",
          "local_types": [
            "method",
            "data processing",
            "data cleaning"
          ],
          "iri": "Entity-pre-processing-Mention-1"
        }
      ],
      "relevance": 0.53271484375
    },
    "Entity-file_format": {
      "node_id": "file_format",
      "disambiguation_index": 0,
      "label": "file formats",
      "aliases": [
        "file types/formats",
        "file formats",
        "file types and formats"
      ],
      "types": [
        "format",
        "information format",
        "data structure",
        "data format",
        "file format",
        "information structure",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "File formats are standardized structures for encoding and storing digital data, enabling the organization and interpretation of information across different software and systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "file formats",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-file_format-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "file formats",
          "local_types": [
            "data",
            "format",
            "data format"
          ],
          "iri": "Entity-file_format-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "file formats",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-file_format-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "file formats",
          "local_types": [
            "information structure",
            "format",
            "data format"
          ],
          "iri": "Entity-file_format-Mention-4"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "file types and formats",
          "local_types": [
            "data structure",
            "information format"
          ],
          "iri": "Entity-file_format-Mention-5"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "file types/formats",
          "local_types": [
            "data format",
            "file format"
          ],
          "iri": "Entity-file_format-Mention-6"
        }
      ],
      "relevance": 0.53173828125
    },
    "Entity-named_entity": {
      "node_id": "named_entity",
      "disambiguation_index": 0,
      "label": "named entities",
      "aliases": [
        "named entities"
      ],
      "types": [
        "information",
        "entity",
        "data type",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Named entities are specific items or concepts that are recognized and categorized in text, such as names of people, organizations, locations, and other distinct entities, often used in natural language processing and information extraction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "named entities",
          "local_types": [
            "data",
            "entity",
            "data type",
            "information"
          ],
          "iri": "Entity-named_entity-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "named entities",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-named_entity-Mention-2"
        }
      ],
      "relevance": 0.53125
    },
    "Entity-python-based_system": {
      "node_id": "python-based_system",
      "disambiguation_index": 0,
      "label": "Python-based system",
      "aliases": [
        "Python-based system"
      ],
      "types": [
        "software",
        "programming language",
        "programming environment",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A Python-based system is a software application or framework developed using the Python programming language, designed to perform specific tasks or functions, often incorporating various tools and libraries for enhanced capabilities.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "Python-based system",
          "local_types": [
            "software",
            "programming language",
            "programming environment",
            "system"
          ],
          "iri": "Entity-python-based_system-Mention-1"
        }
      ],
      "relevance": 0.53076171875
    },
    "Entity-source_document": {
      "node_id": "source_document",
      "disambiguation_index": 0,
      "label": "source document",
      "aliases": [
        "source document"
      ],
      "types": [
        "document",
        "reference material"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A source document is a primary text or reference material from which information is derived or extracted for analysis or processing.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "source document",
          "local_types": [
            "document",
            "reference material"
          ],
          "iri": "Entity-source_document-Mention-1"
        }
      ],
      "relevance": 0.52978515625
    },
    "Entity-python-based_method": {
      "node_id": "python-based_method",
      "disambiguation_index": 0,
      "label": "Python-based methods",
      "aliases": [
        "Python-based methods"
      ],
      "types": [
        "programming language",
        "method",
        "software technique",
        "programming method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Python-based methods refer to techniques or approaches that utilize the Python programming language to perform tasks or solve problems, often in the context of software development or data processing.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "Python-based methods",
          "local_types": [
            "programming language",
            "method",
            "software technique",
            "programming method"
          ],
          "iri": "Entity-python-based_method-Mention-1"
        }
      ],
      "relevance": 0.5283203125
    },
    "Entity-machine-readable_format": {
      "node_id": "machine-readable_format",
      "disambiguation_index": 0,
      "label": "machine-readable format",
      "aliases": [
        "machine-readable format"
      ],
      "types": [
        "format",
        "data format",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A machine-readable format is a structured data representation that can be easily processed and understood by computers, enabling automated data manipulation and analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "machine-readable format",
          "local_types": [
            "format",
            "data format",
            "representation"
          ],
          "iri": "Entity-machine-readable_format-Mention-1"
        }
      ],
      "relevance": 0.52490234375
    },
    "Entity-window": {
      "node_id": "window",
      "disambiguation_index": 0,
      "label": "Windows",
      "aliases": [
        "Windows"
      ],
      "types": [
        "operating system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Windows refers to the family of operating systems developed by Microsoft, which is required for processing OLE 2 file types and .docm documents using the MEL tool.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": "Windows",
          "local_types": [
            "operating system"
          ],
          "iri": "Entity-window-Mention-1"
        }
      ],
      "relevance": 0.52392578125
    },
    "Entity-python-based_package": {
      "node_id": "python-based_package",
      "disambiguation_index": 0,
      "label": "Python-based package",
      "aliases": [
        "Python-based package"
      ],
      "types": [
        "package",
        "programming language",
        "tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A Python-based package is a software library or tool developed using the Python programming language, designed to provide specific functionalities or services for various applications.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "Python-based package",
          "local_types": [
            "package",
            "programming language",
            "tool"
          ],
          "iri": "Entity-python-based_package-Mention-1"
        }
      ],
      "relevance": 0.52392578125
    },
    "Entity-source_document_format": {
      "node_id": "source_document_format",
      "disambiguation_index": 0,
      "label": "source document formats",
      "aliases": [
        "source document formats"
      ],
      "types": [
        "document format",
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Source document formats refer to the various types of file formats used to store and represent documents, which can include text, images, and other data types.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "source document formats",
          "local_types": [
            "document format",
            "data format"
          ],
          "iri": "Entity-source_document_format-Mention-1"
        }
      ],
      "relevance": 0.5205078125
    },
    "Entity-configuration_json_file": {
      "node_id": "configuration_json_file",
      "disambiguation_index": 0,
      "label": "configuration JSON file",
      "aliases": [
        "configuration JSON file"
      ],
      "types": [
        "configuration document",
        "file",
        "configuration"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A configuration JSON file is a structured text file formatted in JSON that contains settings and parameters used to configure software applications or systems.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "configuration JSON file",
          "local_types": [
            "configuration document",
            "file",
            "configuration"
          ],
          "iri": "Entity-configuration_json_file-Mention-1"
        }
      ],
      "relevance": 0.52001953125
    },
    "Entity-json_structure": {
      "node_id": "json_structure",
      "disambiguation_index": 0,
      "label": "JSON structures",
      "aliases": [
        "JSON structures"
      ],
      "types": [
        "data format",
        "JSON"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON structures refer to data representations that utilize the JavaScript Object Notation (JSON) format, which is a lightweight and easy-to-read format for structuring data in a key-value pair format.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "JSON structures",
          "local_types": [
            "data format",
            "JSON"
          ],
          "iri": "Entity-json_structure-Mention-1"
        }
      ],
      "relevance": 0.5146484375
    },
    "Entity-pre-processing_task": {
      "node_id": "pre-processing_task",
      "disambiguation_index": 0,
      "label": "pre-processing tasks",
      "aliases": [
        "pre-processing tasks"
      ],
      "types": [
        "task",
        "data processing task",
        "data processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pre-processing tasks refer to a set of operations or activities performed on data to prepare it for further analysis or processing, often involving cleaning, transforming, and organizing the data.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "pre-processing tasks",
          "local_types": [
            "task",
            "data processing task",
            "data processing"
          ],
          "iri": "Entity-pre-processing_task-Mention-1"
        }
      ],
      "relevance": 0.51171875
    },
    "Entity-supported_file_type": {
      "node_id": "supported_file_type",
      "disambiguation_index": 0,
      "label": "supported file types",
      "aliases": [
        "supported file types"
      ],
      "types": [
        "file type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Supported file types refer to the various formats of files that a system, application, or service can recognize, process, or utilize.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-6",
          "local_name": "supported file types",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-supported_file_type-Mention-1"
        }
      ],
      "relevance": 0.51171875
    },
    "Entity-ole_2_file_type": {
      "node_id": "ole_2_file_type",
      "disambiguation_index": 0,
      "label": "OLE 2 file types",
      "aliases": [
        "OLE 2 file types"
      ],
      "types": [
        "data structure",
        "document format",
        "data format",
        "file format",
        "file type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "OLE 2 file types refer to a set of file formats and data structures used for storing and managing compound documents that can contain various types of data, such as text, images, and other media, typically associated with Microsoft applications.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": "OLE 2 file types",
          "local_types": [
            "document format",
            "file type",
            "file format",
            "data format"
          ],
          "iri": "Entity-ole_2_file_type-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "OLE 2 file types",
          "local_types": [
            "data structure",
            "file type",
            "file format"
          ],
          "iri": "Entity-ole_2_file_type-Mention-2"
        }
      ],
      "relevance": 0.50927734375
    },
    "Entity-file_type": {
      "node_id": "file_type",
      "disambiguation_index": 0,
      "label": "file types",
      "aliases": [
        "file types",
        "file type"
      ],
      "types": [
        "information type",
        "data format",
        "file format",
        "file category",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "File types refer to the various formats or categories of data files that define how information is stored and organized within a computer system.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "file types",
          "local_types": [
            "file format",
            "data type",
            "data format"
          ],
          "iri": "Entity-file_type-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "file type",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-file_type-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-6",
          "local_name": "file types",
          "local_types": [
            "data format",
            "information type"
          ],
          "iri": "Entity-file_type-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "file types",
          "local_types": [
            "file category",
            "data format"
          ],
          "iri": "Entity-file_type-Mention-4"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "file type",
          "local_types": [
            "data format",
            "information type"
          ],
          "iri": "Entity-file_type-Mention-5"
        }
      ],
      "relevance": 0.5078125
    },
    "Entity-document_object_model": {
      "node_id": "document_object_model",
      "disambiguation_index": 0,
      "label": "document object model",
      "aliases": [
        "document object model"
      ],
      "types": [
        "model",
        "programming concept",
        "data structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The document object model is a programming concept and data structure that represents the structure of a document, typically in web development, allowing for the manipulation of its elements and content through a programming interface.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "document object model",
          "local_types": [
            "data structure",
            "programming concept"
          ],
          "iri": "Entity-document_object_model-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "document object model",
          "local_types": [
            "data structure",
            "model"
          ],
          "iri": "Entity-document_object_model-Mention-2"
        }
      ],
      "relevance": 0.5068359375
    },
    "Entity-json_result": {
      "node_id": "json_result",
      "disambiguation_index": 0,
      "label": "JSON results",
      "aliases": [
        "JSON results"
      ],
      "types": [
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON results refer to data formatted in JavaScript Object Notation (JSON), which is a lightweight data interchange format that is easy for humans to read and write, and easy for machines to parse and generate.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "JSON results",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json_result-Mention-1"
        }
      ],
      "relevance": 0.50634765625
    },
    "Entity-regular_expression": {
      "node_id": "regular_expression",
      "disambiguation_index": 0,
      "label": "regular expressions",
      "aliases": [
        "regular expressions"
      ],
      "types": [
        "pattern matching",
        "regex",
        "text analysis tool",
        "text processing",
        "programming tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Regular expressions are sequences of characters that form a search pattern, primarily used for string matching and manipulation in text processing and programming.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "regular expressions",
          "local_types": [
            "text analysis tool",
            "text processing",
            "programming tool",
            "pattern matching"
          ],
          "iri": "Entity-regular_expression-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "regular expressions",
          "local_types": [
            "text analysis tool",
            "regex",
            "pattern matching"
          ],
          "iri": "Entity-regular_expression-Mention-2"
        }
      ],
      "relevance": 0.50048828125
    },
    "Entity-unstructured_information": {
      "node_id": "unstructured_information",
      "disambiguation_index": 0,
      "label": "unstructured information",
      "aliases": [
        "unstructured information"
      ],
      "types": [
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Unstructured information refers to data that does not have a predefined data model or is not organized in a predefined manner, making it difficult to analyze and process using traditional data processing techniques.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "unstructured information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-unstructured_information-Mention-1"
        }
      ],
      "relevance": 0.49853515625
    },
    "Entity-file_extension_mapping": {
      "node_id": "file_extension_mapping",
      "disambiguation_index": 0,
      "label": "file extension mappings",
      "aliases": [
        "file extension mappings"
      ],
      "types": [
        "mapping",
        "file handling",
        "configuration"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "File extension mappings refer to the associations between file types and their corresponding extensions, which dictate how files are recognized and processed by software applications.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "file extension mappings",
          "local_types": [
            "mapping",
            "file handling",
            "configuration"
          ],
          "iri": "Entity-file_extension_mapping-Mention-1"
        }
      ],
      "relevance": 0.4951171875
    },
    "Entity-categorised_named_entity": {
      "node_id": "categorised_named_entity",
      "disambiguation_index": 0,
      "label": "categorised named entities",
      "aliases": [
        "categorised named entities"
      ],
      "types": [
        "entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Categorised named entities are specific entities that have been classified into predefined categories based on their characteristics or roles, often used in natural language processing and information extraction tasks.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "categorised named entities",
          "local_types": [
            "entity"
          ],
          "iri": "Entity-categorised_named_entity-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "categorised named entities",
          "local_types": [
            "entity"
          ],
          "iri": "Entity-categorised_named_entity-Mention-2"
        }
      ],
      "relevance": 0.491943359375
    },
    "Entity-.docm": {
      "node_id": ".docm",
      "disambiguation_index": 0,
      "label": ".docm",
      "aliases": [
        ".docm"
      ],
      "types": [
        "document",
        "file format",
        "format",
        "file type",
        "document format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": ".docm is a file format used for Microsoft Word documents that support macros.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": ".docm",
          "local_types": [
            "document",
            "file format",
            "format",
            "file type",
            "document format"
          ],
          "iri": "Entity-.docm-Mention-1"
        }
      ],
      "relevance": 0.4833984375
    },
    "Entity-common_file_format": {
      "node_id": "common_file_format",
      "disambiguation_index": 0,
      "label": "common file formats",
      "aliases": [
        "common file formats"
      ],
      "types": [
        "file format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Common file formats refer to widely used digital file types that are standardized for storing and exchanging data across different software applications.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "common file formats",
          "local_types": [
            "file format"
          ],
          "iri": "Entity-common_file_format-Mention-1"
        }
      ],
      "relevance": 0.48193359375
    },
    "Entity-nlp": {
      "node_id": "nlp",
      "disambiguation_index": 0,
      "label": "NLP",
      "aliases": [
        "NLP"
      ],
      "types": [
        "field",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "NLP refers to Natural Language Processing, a field of artificial intelligence that focuses on the interaction between computers and human language, enabling machines to understand, interpret, and generate human language in a meaningful way.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "NLP",
          "local_types": [
            "field",
            "technology"
          ],
          "iri": "Entity-nlp-Mention-1"
        }
      ],
      "relevance": 0.478271484375
    },
    "Entity-opensource_package": {
      "node_id": "opensource_package",
      "disambiguation_index": 0,
      "label": "opensource packages",
      "aliases": [
        "opensource packages and tools",
        "opensource packages"
      ],
      "types": [
        "software",
        "library",
        "tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Opensource packages are software components or libraries that are made available to the public for use, modification, and distribution under an open-source license.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "opensource packages",
          "local_types": [
            "software",
            "library"
          ],
          "iri": "Entity-opensource_package-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "opensource packages and tools",
          "local_types": [
            "software",
            "tool"
          ],
          "iri": "Entity-opensource_package-Mention-2"
        }
      ],
      "relevance": 0.437744140625
    },
    "Entity-java": {
      "node_id": "java",
      "disambiguation_index": 0,
      "label": "Java",
      "aliases": [
        "Java"
      ],
      "types": [
        "programming language"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "Java",
          "local_types": [
            "programming language"
          ],
          "iri": "Entity-java-Mention-1"
        }
      ],
      "relevance": 0.430419921875
    },
    "Entity-window_operating_system": {
      "node_id": "window_operating_system",
      "disambiguation_index": 0,
      "label": "Windows operating systems",
      "aliases": [
        "Windows operating systems"
      ],
      "types": [
        "software",
        "operating system",
        "software platform"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Windows operating systems are a family of operating systems developed by Microsoft, designed to run on personal computers and provide a graphical user interface for users.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": "Windows operating systems",
          "local_types": [
            "software",
            "operating system",
            "software platform"
          ],
          "iri": "Entity-window_operating_system-Mention-1"
        }
      ],
      "relevance": 0.414306640625
    },
    "Entity-vocabulary": {
      "node_id": "vocabulary",
      "disambiguation_index": 0,
      "label": "vocabulary",
      "aliases": [
        "vocabulary"
      ],
      "types": [
        "terminology",
        "vocabulary",
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A vocabulary is a set of terms and their meanings used within a specific domain or context, often employed to facilitate communication and understanding in that area.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "vocabulary",
          "local_types": [
            "terminology",
            "vocabulary",
            "ontology"
          ],
          "iri": "Entity-vocabulary-Mention-1"
        }
      ],
      "relevance": 0.4091796875
    },
    "Entity-configurable_setting": {
      "node_id": "configurable_setting",
      "disambiguation_index": 0,
      "label": "configurable settings",
      "aliases": [
        "configurable settings"
      ],
      "types": [
        "parameter",
        "configuration",
        "settings"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Configurable settings refer to adjustable parameters or options within a system or application that allow users to customize its behavior or functionality according to their preferences.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "configurable settings",
          "local_types": [
            "parameter",
            "configuration",
            "settings"
          ],
          "iri": "Entity-configurable_setting-Mention-1"
        }
      ],
      "relevance": 0.4033203125
    },
    "Entity-figure_1": {
      "node_id": "figure_1",
      "disambiguation_index": 0,
      "label": "Figure 1",
      "aliases": [
        "Figure 1"
      ],
      "types": [
        "figure",
        "illustration"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Figure 1 is a visual representation or illustration that conveys information or data related to the subject matter discussed in the document.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "Figure 1",
          "local_types": [
            "figure",
            "illustration"
          ],
          "iri": "Entity-figure_1-Mention-1"
        }
      ],
      "relevance": 0.398193359375
    }
  },
  "summary": "The metadata and content-based information extraction tasks from heterogeneous file sets are pre-processing steps of many Knowledge Graph Construction Pipelines (KGCP). These tasks often take longer than necessary due to the lack of proper tools that integrate several complementary extraction methods and properties to get a rich output set. This paper presents MEL, a Python-based tool that implements a set of methods to extract metadata and content-based information from unstructured information encoded in different source document formats. The results are generated as JSON files, which can: (a) optionally be stored in a document store, and (b) easily be mapped to RDF using a variety of tools such as J2RM. MEL supports more than 20 different file types, making it a versatile tool that aids pre-processing tasks as part of a KGCP based on comprehensive configurable settings.\n\nThis paper introduces MEL, a tool that implements a set of methods to extract metadata and content-based information from various file formats as JSON objects. For each supported file type, MEL extracts the textual content from the source document and performs specific pre-processing and data cleaning tasks. Also, it performs basic text analysis tasks (pattern matching and keyword extraction) and generates the results in a machine-readable format (JSON), preparing the ground for content-based analysis. MEL is integrated with \u201cThe NLP -NER Toolkit\u201d (TNNT), which automates the extraction task of categorised named entities from the MEL results by using diverse state-of-the-art NLP tools and NER models [5]. MEL implements primitives for metadata and content extraction from unstructured data sets of heterogeneous formats, and along with the TNNT results, it provides the groundwork for content-based analysis. MEL and TNNT were developed in conjunction with J2RM [4], to easily map the JSON results to RDF as part of an automated KGCP.\n\nMEL has comprehensive metadata extraction support of various file types and formats. In a nutshell: (1) it takes as input a document (file) set; (2) then, for each document, it extracts its related metadata and content-based information, while performing basic text analysis (such as applying a configurable set of regular expressions and keyword extraction task); and, (3) as output, it generates a JSON file with the extracted metadata and text content with a structure based on the supported formats' document object model. It can store the results in a document store. MEL's general output structure is presented in Table 1. MEL has a detailed configuration JSON file that defines how the processing will be performed through a set of parameters and flags that establish the initial settings related to the document store, input document sets, TNNT general configuration, file extension mappings, the \u201cAssociated-Metadata\u201d processing (Table 1), and regular expressions to apply in the text analysis task, among other settings. The supported file types are presented in Table 2. The third column shows the theoretical number of attributes that the tool is able to extract per document type, whilst the fourth column shows the average of the extracted attributes from four use case document sets. OLE 2 file types and .docm can only be processed on Windows operating systems. Specifically for OLE 2 file types, MEL uses the olemeta tool.\n\nMEL is fully integrated with TNNT as depicted in Figure 1. The set of Python-based methods implemented in MEL are generic and can be applied to extract the content and metadata of all supported file types. MEL uses various opensource packages and tools with complementary capabilities to form a \u201cSwiss army knife\u201d of metadata and content-based information extraction from heterogeneous document sets. As part of the \u201cGeneral-Metadata\u201d extraction task, MEL optionally uses the XML output from the NLNZ Metadata Extractor tool, a Java standalone tool that extracts a comprehensive attribute and property list from dozens of file formats. The MEL general processing model is presented in Figure 2. It is important to note that each file type has its own specific processing model as well as the text analysis task, which is the last step that is performed for any output.\n\nThe most comprehensive and current state-of-the-art tool for content extraction and analysis is Apache Tika, which is a complete and complex Java-based general-purpose system. While MEL's core goals resemble the ones of Apache Tika, the main difference and benefit of MEL as compared to Apache Tika is that it is a lightweight Python-based package for the metadata extraction of common file formats aimed to be used in a KGCP. Although there is a wide range of Python-based tools and libraries for metadata extraction, to the best of our knowledge, there is no package available that fully integrates in one system a comprehensive set of methods for metadata and content extraction of common file formats that generate the results in JSON structures based on the document object model of each format type. Last, MEL can assist in the information extraction stage of several KGCPs, such as the ones described in [6], [2], and [3].\n\nMEL provides a versatile mechanism to extract metadata and content-based information from unstructured data sets of heterogeneous file formats, agnostic of the data sets' domain (general purpose). It has been tested over thousands of documents using different formats and datasets as part of the AGRIF project. Based on the structure of the MEL's JSON results, it is possible to easily add a vocabulary or light-weight ontology using JSON-LD annotations, in order to make the extracted metadata \u201cRDF ready\u201d. This will be explored in the near future leveraging on the integration with JSON-LD ontologies. More file formats will be added in a per use-case requirements basis, in order to support KGCP tasks. Additionally, a project to \u201ccontainerise\u201d the MEL+TNNT tools is planned in the near future. The major contributions of this tool are: (1) the ability to extract metadata sets and content-based information from different source document formats; (2) the comprehensive support of over 20 different file types/formats integrated into one easy-to-use Python-based system; (3) integration with TNNT which automates the extraction of categorised named entities from the results by using diverse state-of-the-art NLP tools and NER models; and (4) the JSON result files can be easily mapped to RDF using J2RM.",
  "triples": [
    [
      "Entity-metadata_and_content-based_information_extraction",
      "Predicate-are_pre-processing_steps_of",
      "Entity-knowledge_graph_construction_pipeline"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "Predicate-are_pre-processing_steps_of",
      "Entity-kgcp"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "Predicate-are",
      "Entity-pre-processing_step"
    ],
    [
      "Entity-knowledge_graph_construction_pipeline",
      "Predicate-are",
      "Entity-kgcp"
    ],
    [
      "Entity-proper_tool",
      "Predicate-integrate",
      "Entity-several_complementary_extraction_method"
    ],
    [
      "Entity-proper_tool",
      "Predicate-integrate",
      "Entity-property"
    ],
    [
      "Entity-several_complementary_extraction_method",
      "Predicate-get",
      "Entity-rich_output_set"
    ],
    [
      "Entity-mel",
      "Predicate-is_a",
      "Entity-python-based_tool"
    ],
    [
      "Entity-python-based_tool",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-metadata"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-content-based_information"
    ],
    [
      "Entity-python-based_tool",
      "Predicate-extracts_from",
      "Entity-unstructured_information"
    ],
    [
      "Entity-unstructured_information",
      "Predicate-encoded_in",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-mel",
      "Predicate-is",
      "Entity-a_python-based_tool"
    ],
    [
      "Entity-mel",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-result",
      "Predicate-generated_as",
      "Entity-json_file"
    ],
    [
      "Entity-json_file",
      "Predicate-mapped_to",
      "Entity-rdf"
    ],
    [
      "Entity-json_file",
      "Predicate-stored_in",
      "Entity-document_store"
    ],
    [
      "Entity-json_file",
      "Predicate-can_be_mapped_to",
      "Entity-rdf"
    ],
    [
      "Entity-mel",
      "Predicate-supports",
      "Entity-20_different_file_type"
    ],
    [
      "Entity-mel",
      "Predicate-aids",
      "Entity-pre-processing_task"
    ],
    [
      "Entity-mel",
      "Predicate-is_based_on",
      "Entity-comprehensive_configurable_setting"
    ],
    [
      "Entity-pre-processing_task",
      "Predicate-are_part_of",
      "Entity-knowledge_graph_construction_pipeline"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-mel"
    ],
    [
      "Entity-mel",
      "Predicate-implements",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-json_object"
    ],
    [
      "Entity-metadata_and_content-based_information",
      "Predicate-from",
      "Entity-various_file_format"
    ],
    [
      "Entity-various_file_format",
      "Predicate-as",
      "Entity-json_object"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-textual_content"
    ],
    [
      "Entity-mel",
      "Predicate-performs",
      "Entity-specific_pre-processing_and_data_cleaning_task"
    ],
    [
      "Entity-basic_text_analysis_task",
      "Predicate-performs",
      "Entity-pattern_matching_and_keyword_extraction"
    ],
    [
      "Entity-basic_text_analysis_task",
      "Predicate-generates",
      "Entity-result"
    ],
    [
      "Entity-result",
      "Predicate-in",
      "Entity-machine-readable_format"
    ],
    [
      "Entity-result",
      "Predicate-prepares_the_ground_for",
      "Entity-content-based_analysis"
    ],
    [
      "Entity-result",
      "Predicate-are_in",
      "Entity-machine-readable_format"
    ],
    [
      "Entity-mel",
      "Predicate-is_integrated_with",
      "Entity-the_nlp_-ner_toolkit"
    ],
    [
      "Entity-result",
      "Predicate-extracts",
      "Entity-categorised_named_entity"
    ],
    [
      "Entity-mel",
      "Predicate-generates",
      "Entity-result"
    ],
    [
      "Entity-mel",
      "Predicate-implements",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-metadata"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-content_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-extracts_from",
      "Entity-unstructured_data_set"
    ],
    [
      "Entity-mel",
      "Predicate-extracts_from",
      "Entity-heterogeneous_format"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "Predicate-results_in",
      "Entity-content-based_analysis"
    ],
    [
      "Entity-mel",
      "Predicate-developed_in_conjunction_with",
      "Entity-j2rm"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "Predicate-developed_in_conjunction_with",
      "Entity-j2rm"
    ],
    [
      "Entity-json_result_(1)",
      "Predicate-mapped_to",
      "Entity-rdf"
    ],
    [
      "Entity-automated_kgcp",
      "Predicate-part_of",
      "Entity-kgcp"
    ],
    [
      "Entity-json_result_(1)",
      "Predicate-map_to",
      "Entity-rdf"
    ],
    [
      "Entity-mel",
      "Predicate-performs",
      "Entity-basic_text_analysis_task"
    ],
    [
      "Entity-mel",
      "Predicate-has",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-mel",
      "Predicate-has",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-has",
      "Entity-various_file_format"
    ],
    [
      "Entity-mel",
      "Predicate-has",
      "Entity-file_format"
    ],
    [
      "Entity-document__file__set",
      "Predicate-takes_as_input",
      "Entity-document"
    ],
    [
      "Entity-document",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-document",
      "Predicate-extracts",
      "Entity-content-based_information"
    ],
    [
      "Entity-document",
      "Predicate-performs",
      "Entity-basic_text_analysis"
    ],
    [
      "Entity-basic_text_analysis",
      "Predicate-applies",
      "Entity-configurable_set_of_regular_expression"
    ],
    [
      "Entity-basic_text_analysis",
      "Predicate-involves",
      "Entity-keyword_extraction_task"
    ],
    [
      "Entity-document",
      "Predicate-generates",
      "Entity-json_file"
    ],
    [
      "Entity-json_file",
      "Predicate-contains",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-json_file",
      "Predicate-has_a_structure_based_on",
      "Entity-supported_format__document_object_model"
    ],
    [
      "Entity-it",
      "Predicate-can_store",
      "Entity-result"
    ],
    [
      "Entity-result",
      "Predicate-in",
      "Entity-document_store"
    ],
    [
      "Entity-output_structure",
      "Predicate-is_presented_in",
      "Entity-table_1"
    ],
    [
      "Entity-processing",
      "Predicate-is_related_to",
      "Entity-document_store"
    ],
    [
      "Entity-processing",
      "Predicate-is_related_to",
      "Entity-input_document_set"
    ],
    [
      "Entity-processing",
      "Predicate-is_related_to",
      "Entity-tnnt_general_configuration"
    ],
    [
      "Entity-processing",
      "Predicate-is_related_to",
      "Entity-file_extension_mapping"
    ],
    [
      "Entity-processing",
      "Predicate-is_related_to",
      "Entity-associated-metadata"
    ],
    [
      "Entity-processing",
      "Predicate-is_related_to",
      "Entity-regular_expression"
    ],
    [
      "Entity-processing",
      "Predicate-is_related_to",
      "Entity-text_analysis_task"
    ],
    [
      "Entity-setting",
      "Predicate-is_related_to",
      "Entity-document_store"
    ],
    [
      "Entity-the_supported_file_type",
      "Predicate-is_presented_in",
      "Entity-table_2"
    ],
    [
      "Entity-supported_file_type",
      "Predicate-is_presented_in",
      "Entity-table_2"
    ],
    [
      "Entity-file_type",
      "Predicate-is_presented_in",
      "Entity-table_2"
    ],
    [
      "Entity-the_tool",
      "Predicate-is_able_to_extract",
      "Entity-attribute"
    ],
    [
      "Entity-theoretical_number_of_attribute",
      "Predicate-shows",
      "Entity-the_tool"
    ],
    [
      "Entity-the_average_of_the_extracted_attribute",
      "Predicate-shows",
      "Entity-extracted_attribute"
    ],
    [
      "Entity-extracted_attribute",
      "Predicate-comes_from",
      "Entity-use_case_document_set"
    ],
    [
      "Entity-ole_2_file_type",
      "Predicate-can_be_processed_on",
      "Entity-window_operating_system"
    ],
    [
      "Entity-.docm",
      "Predicate-can_be_processed_on",
      "Entity-window_operating_system"
    ],
    [
      "Entity-ole_2_file_type",
      "Predicate-can_only_be_processed_on",
      "Entity-window_operating_system"
    ],
    [
      "Entity-mel",
      "Predicate-uses",
      "Entity-olemeta"
    ],
    [
      "Entity-olemeta",
      "Predicate-is_for",
      "Entity-ole_2_file_type"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-mel",
      "Predicate-generates",
      "Entity-a_json_file"
    ],
    [
      "Entity-mel",
      "Predicate-performs",
      "Entity-basic_text_analysis"
    ],
    [
      "Entity-mel",
      "Predicate-is_depicted_in",
      "Entity-figure_1"
    ],
    [
      "Entity-python-based_method",
      "Predicate-implemented_in",
      "Entity-mel"
    ],
    [
      "Entity-python-based_method",
      "Predicate-applied_to_extract",
      "Entity-content_and_metadata"
    ],
    [
      "Entity-content_and_metadata",
      "Predicate-of",
      "Entity-the_supported_file_type"
    ],
    [
      "Entity-mel",
      "Predicate-is_applied_to",
      "Entity-the_supported_file_type"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-content_and_metadata"
    ],
    [
      "Entity-mel",
      "Predicate-applies_to",
      "Entity-the_supported_file_type"
    ],
    [
      "Entity-mel",
      "Predicate-uses",
      "Entity-various_opensource_package_and_tool"
    ],
    [
      "Entity-various_opensource_package_and_tool",
      "Predicate-have",
      "Entity-complementary_capability"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "Predicate-from",
      "Entity-heterogeneous_document_set"
    ],
    [
      "Entity-mel",
      "Predicate-is_a",
      "Entity-swiss_army_knife"
    ],
    [
      "Entity-mel",
      "Predicate-uses",
      "Entity-xml_output"
    ],
    [
      "Entity-nlnz_metadata_extractor",
      "Predicate-extracts",
      "Entity-dozen_of_file_format"
    ],
    [
      "Entity-java_standalone_tool",
      "Predicate-extracts",
      "Entity-dozen_of_file_format"
    ],
    [
      "Entity-mel",
      "Predicate-uses",
      "Entity-nlnz_metadata_extractor"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-is_presented_in_(1)",
      "Entity-figure_2"
    ],
    [
      "Entity-mel",
      "Predicate-is_presented_in_(1)",
      "Entity-figure_2"
    ],
    [
      "Entity-the_text_analysis_task",
      "Predicate-is",
      "Entity-the_last_step"
    ],
    [
      "Entity-the_text_analysis_task",
      "Predicate-is_performed_for",
      "Entity-any_output"
    ],
    [
      "Entity-mel",
      "Predicate-performs",
      "Entity-the_text_analysis_task"
    ],
    [
      "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis",
      "Predicate-is",
      "Entity-apache_tika"
    ],
    [
      "Entity-apache_tika",
      "Predicate-is_a",
      "Entity-java-based_general-purpose_system"
    ],
    [
      "Entity-mel",
      "Predicate-is_aimed_to_be_used_in",
      "Entity-kgcp"
    ],
    [
      "Entity-mel",
      "Predicate-is_for",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-is_for",
      "Entity-common_file_format_(1)"
    ],
    [
      "Entity-python-based_tool_and_library",
      "Predicate-are_available_for",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-package",
      "Predicate-integrate",
      "Entity-comprehensive_set_of_method"
    ],
    [
      "Entity-package",
      "Predicate-extracts",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-common_file_format",
      "Predicate-generates",
      "Entity-json_structure"
    ],
    [
      "Entity-json_structure",
      "Predicate-are_based_on",
      "Entity-document_object_model"
    ],
    [
      "Entity-format_type",
      "Predicate-is_associated_with",
      "Entity-common_file_format"
    ],
    [
      "Entity-metadata_extraction",
      "Predicate-is_a_comprehensive_set_of_methods_for",
      "Entity-common_file_format"
    ],
    [
      "Entity-mel",
      "Predicate-provides",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-unstructured_data_set"
    ],
    [
      "Entity-unstructured_data_set",
      "Predicate-of",
      "Entity-heterogeneous_file_format"
    ],
    [
      "Entity-unstructured_data_set",
      "Predicate-of",
      "Entity-data_set"
    ],
    [
      "Entity-data_set",
      "Predicate-of",
      "Entity-general_purpose"
    ],
    [
      "Entity-agrif_project",
      "Predicate-tested_over",
      "Entity-thousand_of_document"
    ],
    [
      "Entity-agrif_project",
      "Predicate-uses",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-agrif_project",
      "Predicate-uses",
      "Entity-datasets"
    ],
    [
      "Entity-mel",
      "Predicate-has",
      "Entity-json_result"
    ],
    [
      "Entity-json-ld_annotation",
      "Predicate-are_used_to_add",
      "Entity-vocabulary_or_light-weight_ontology"
    ],
    [
      "Entity-extracted_metadata",
      "Predicate-is_made",
      "Entity-rdf_ready"
    ],
    [
      "Entity-json_result",
      "Predicate-can_be_mapped_to",
      "Entity-rdf"
    ],
    [
      "Entity-extracted_metadata",
      "Predicate-is",
      "Entity-rdf_ready"
    ],
    [
      "Entity-the_integration_with_json-ld_ontology",
      "Predicate-leverages",
      "Entity-json-ld"
    ],
    [
      "Entity-file_format",
      "Predicate-will_be_added_in",
      "Entity-per_use-case_requirement_basis"
    ],
    [
      "Entity-file_format",
      "Predicate-support",
      "Entity-kgcp_task"
    ],
    [
      "Entity-project",
      "Predicate-is_planned_to",
      "Entity-a_project_to__containerise__the_meltnnt_tool"
    ],
    [
      "Entity-a_project_to__containerise__the_meltnnt_tool",
      "Predicate-involves",
      "Entity-meltnnt"
    ],
    [
      "Entity-the_tool",
      "Predicate-extracts",
      "Entity-metadata_set"
    ],
    [
      "Entity-the_tool",
      "Predicate-extracts",
      "Entity-content-based_information"
    ],
    [
      "Entity-the_tool",
      "Predicate-support",
      "Entity-20_different_file_type"
    ],
    [
      "Entity-the_tool",
      "Predicate-integrates_with",
      "Entity-the_nlp_-ner_toolkit"
    ],
    [
      "Entity-mel",
      "Predicate-has_been_tested_over",
      "Entity-thousand_of_document"
    ],
    [
      "Entity-mel",
      "Predicate-integrates_with",
      "Entity-the_nlp_-ner_toolkit"
    ],
    [
      "Entity-the_tool",
      "Predicate-is",
      "Entity-mel"
    ],
    [
      "Entity-mel",
      "Predicate-is_a",
      "Entity-package"
    ],
    [
      "Entity-meltnnt",
      "Predicate-integrates",
      "Entity-mel"
    ],
    [
      "Entity-mel",
      "Predicate-defines",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-mel",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-a_python-based_tool"
    ],
    [
      "Entity-the_tool",
      "Predicate-is",
      "Entity-a_python-based_tool"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-designed_to_extract",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-is_a",
      "Entity-package"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-integrate",
      "Entity-meltnnt"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-implements",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-provides",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-implements",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-generates",
      "Entity-result"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-generates",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-a_python-based_tool",
      "Predicate-extracts_metadata_and_content-based_information_from",
      "Entity-document__file__set"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-the_tool"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-the_tool",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-package",
      "Predicate-integrate",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-generate",
      "Entity-result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-the_tool",
      "Predicate-generates",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-implement",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-package",
      "Predicate-produces",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-meltnnt",
      "Predicate-automates_the_extraction_of",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-describes_the_systematic_approach_for_extracting",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-metadata_and_content-based_information",
      "Predicate-is_derived_from",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "Predicate-generate",
      "Entity-result"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "Predicate-is_outputted_as",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-package"
    ],
    [
      "Entity-the_tool",
      "Predicate-is_a",
      "Entity-package"
    ],
    [
      "Entity-package",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-package",
      "Predicate-produces",
      "Entity-result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-content"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-the_tool",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-are_extracted_using",
      "Entity-content"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "Predicate-is_extracted_from",
      "Entity-content"
    ],
    [
      "Entity-package",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-meltnnt",
      "Predicate-automates_the_extraction_of_categorized_named_entities_from_content",
      "Entity-content"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-is_extracted_by",
      "Entity-content"
    ],
    [
      "Entity-metadata_and_content-based_information",
      "Predicate-is_extracted_from",
      "Entity-content"
    ],
    [
      "Entity-content",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-content",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-content",
      "Predicate-generates",
      "Entity-result"
    ],
    [
      "Entity-content",
      "Predicate-is_extracted_as",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-document__file__set",
      "Predicate-is_extracted_from",
      "Entity-content"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-meltnnt"
    ],
    [
      "Entity-meltnnt",
      "Predicate-integrate",
      "Entity-the_tool"
    ],
    [
      "Entity-meltnnt",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-meltnnt",
      "Predicate-integrate",
      "Entity-package"
    ],
    [
      "Entity-meltnnt",
      "Predicate-automates_the_extraction_of_categorized_named_entities_from_content",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-meltnnt",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-meltnnt",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-meltnnt",
      "Predicate-generates",
      "Entity-result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-the_tool",
      "Predicate-is_implemented_by",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-package",
      "Predicate-is_implemented_by",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-integrate",
      "Entity-meltnnt"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-generates",
      "Entity-result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-the_tool",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-is_implemented_by",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-package",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-metadata_and_content-based_information",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-metadata_and_content-based_information",
      "Predicate-generate",
      "Entity-result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-output_set"
    ],
    [
      "Entity-the_tool",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-package",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-output_set",
      "Predicate-includes",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-output_set",
      "Predicate-generate",
      "Entity-result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-mel",
      "Predicate-provides",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-the_tool",
      "Predicate-provides",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-facilitates_the_extraction_of",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-package",
      "Predicate-provides",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-facilitates_the_extraction_of",
      "Entity-content"
    ],
    [
      "Entity-meltnnt",
      "Predicate-provides",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-provides",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-facilitates_the_extraction_of",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-generates",
      "Entity-result"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-generates",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-document__file__set",
      "Predicate-support",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-the_tool",
      "Predicate-implements",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-package",
      "Predicate-integrate",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-meltnnt",
      "Predicate-implements",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-implements",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-enables",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-generate",
      "Entity-result"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-generate",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts_information_from",
      "Entity-document__file__set"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-the_tool",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "Predicate-generate",
      "Entity-result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-result"
    ],
    [
      "Entity-the_tool",
      "Predicate-generates",
      "Entity-result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-mel",
      "Predicate-generates",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-the_tool",
      "Predicate-generates",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-generate",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-package",
      "Predicate-produces",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-meltnnt",
      "Predicate-generates",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-generates",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-json_result_(1)",
      "Predicate-encapsulates",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-json_result_(1)",
      "Predicate-is_formatted_as",
      "Entity-output_set"
    ],
    [
      "Entity-json_result_(1)",
      "Predicate-encapsulates",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-result",
      "Predicate-are_represented_as",
      "Entity-json_result_(1)"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-document__file__set"
    ],
    [
      "Entity-mel",
      "Predicate-processes",
      "Entity-document__file__set"
    ],
    [
      "Entity-the_tool",
      "Predicate-is_input_to",
      "Entity-document__file__set"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-input_into",
      "Entity-document__file__set"
    ],
    [
      "Entity-document__file__set",
      "Predicate-extracts",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-package",
      "Predicate-processes",
      "Entity-document__file__set"
    ],
    [
      "Entity-meltnnt",
      "Predicate-processes",
      "Entity-document__file__set"
    ],
    [
      "Entity-document__file__set",
      "Predicate-is_input_to",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-document__file__set",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-document__file__set",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-document__file__set",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-document__file__set",
      "Predicate-generates",
      "Entity-result"
    ],
    [
      "Entity-document__file__set",
      "Predicate-generates",
      "Entity-json_result_(1)"
    ]
  ],
  "triples_typing": [
    [
      "Entity-mel",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-regular_expression",
      "skos:broader",
      "Entity-pattern_matching"
    ],
    [
      "Entity-parameter",
      "skos:broader",
      "Entity-setting"
    ],
    [
      "Entity-use_case_document_set",
      "skos:broader",
      "Entity-document_set"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-ole_2",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-python-based_package",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-olemeta",
      "skos:broader",
      "Entity-extracted_metadata"
    ],
    [
      "Entity-pattern_matching_and_keyword_extraction",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-file_type",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-metadata",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-input_document_set",
      "skos:broader",
      "Entity-document__file__set"
    ],
    [
      "Entity-nlp_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "skos:broader",
      "Entity-textual_content"
    ],
    [
      "Entity-metadata_extraction",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-.docm",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-agrif",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-pre-processing",
      "skos:broader",
      "Entity-data_cleaning"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-textual_content",
      "skos:broader",
      "Entity-content"
    ],
    [
      "Entity-thousand_of_document",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-theoretical_number_of_attribute",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-kgcps",
      "skos:broader",
      "Entity-knowledge_graph_construction_pipeline"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "skos:broader",
      "Entity-information_extraction"
    ],
    [
      "Entity-output_structure",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-keyword_extraction_task",
      "skos:broader",
      "Entity-keyword_extraction"
    ],
    [
      "Entity-json_object",
      "skos:broader",
      "Entity-json_result"
    ],
    [
      "Entity-metadata_and_content-based_information",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-meltnnt",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-metadata_extraction",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-proper_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-agrif_project",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-file_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-output_structure",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-json_structure",
      "skos:broader",
      "Entity-json_object"
    ],
    [
      "Entity-opensource_package",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-unstructured_data_set",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-document_type",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-a_json_file",
      "skos:broader",
      "Entity-json_result"
    ],
    [
      "Entity-keyword_extraction",
      "skos:broader",
      "Entity-text_analysis_task"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-python-based_tool"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "skos:broader",
      "Entity-content-based_information_extraction"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-result",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-nlp_-ner_toolkit",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-text_analysis_task",
      "skos:broader",
      "Entity-basic_text_analysis"
    ],
    [
      "Entity-heterogeneous_document_set",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-unstructured_data_set",
      "skos:broader",
      "Entity-datasets"
    ],
    [
      "Entity-ole_2_file_type",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-a_json_file",
      "skos:broader",
      "Entity-json_structure"
    ],
    [
      "Entity-j2rm",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-ole_2_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-json_result_(1)",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-metadata_and_content-based_information_extraction"
    ],
    [
      "Entity-use_case_document_set",
      "skos:broader",
      "Entity-document__file__set"
    ],
    [
      "Entity-python-based_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-keyword_extraction",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-python-based_tool_and_library"
    ],
    [
      "Entity-metadata_extraction",
      "skos:broader",
      "Entity-content-based_information_extraction"
    ],
    [
      "Entity-json_result_(1)",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-basic_text_analysis",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-comprehensive_configurable_setting",
      "skos:broader",
      "Entity-setting"
    ],
    [
      "Entity-json_structure",
      "skos:broader",
      "Entity-json_result"
    ],
    [
      "Entity-unstructured_data_set",
      "skos:broader",
      "Entity-unstructured_information"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-python-based_system"
    ],
    [
      "Entity-a_python-based_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-extracted_attribute",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-flag",
      "skos:broader",
      "Entity-setting"
    ],
    [
      "Entity-content-based_information_extraction",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-json_result"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-extracted_metadata"
    ],
    [
      "Entity-a_json_file",
      "skos:broader",
      "Entity-json_object"
    ],
    [
      "Entity-machine-readable_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-common_file_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-json-ld_annotation",
      "skos:broader",
      "Entity-json-ld"
    ],
    [
      "Entity-json_result_(1)",
      "skos:broader",
      "Entity-result"
    ],
    [
      "Entity-various_opensource_package_and_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-metadata_extraction",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-json_structure"
    ],
    [
      "Entity-state-of-the-art_nlp_tool_and_ner_model",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-machine-readable_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-any_output",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-configurable_setting",
      "skos:broader",
      "Entity-parameter"
    ],
    [
      "Entity-format_type",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-parameter_and_flag",
      "skos:broader",
      "Entity-parameter"
    ],
    [
      "Entity-json_object",
      "skos:broader",
      "Entity-json"
    ],
    [
      "Entity-heterogeneous_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-source_document_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-basic_text_analysis_task",
      "skos:broader",
      "Entity-basic_text_analysis"
    ],
    [
      "Entity-the_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-dozen_of_file_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-heterogeneous_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-extracted_metadata",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-tnnt_result",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-a_json_file",
      "skos:broader",
      "Entity-json"
    ],
    [
      "Entity-configurable_set_of_regular_expression",
      "skos:broader",
      "Entity-regular_expression"
    ],
    [
      "Entity-pattern_matching",
      "skos:broader",
      "Entity-text_analysis_task"
    ],
    [
      "Entity-json_result_(1)",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-pre-processing_and_data_cleaning_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-supported_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-json_object"
    ],
    [
      "Entity-java_standalone_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "skos:broader",
      "Entity-content"
    ],
    [
      "Entity-specific_processing_model",
      "skos:broader",
      "Entity-processing_model"
    ],
    [
      "Entity-various_file_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-json_structure",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-xml",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-several_kgcps",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-json_result",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-various_file_format",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-supported_format__document_object_model",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-common_file_format_(1)",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-general-metadata",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-various_file_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-a_project_to__containerise__the_meltnnt_tool",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-text_analysis_task",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-pattern_matching",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-window",
      "skos:broader",
      "Entity-window_operating_system"
    ],
    [
      "Entity-json_result_file",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-json_structure",
      "skos:broader",
      "Entity-json"
    ],
    [
      "Entity-each_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-document_store",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-json",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-json-ld",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-apache_tika",
      "skos:broader",
      "Entity-package"
    ],
    [
      "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-json_result_file",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-json",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-json-ld",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-json"
    ],
    [
      "Entity-associated-metadata",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-swiss_army_knife",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-regular_expression",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-20_different_file_type",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-json_object",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-configurable_setting",
      "skos:broader",
      "Entity-setting"
    ],
    [
      "Entity-parameter_and_flag",
      "skos:broader",
      "Entity-setting"
    ],
    [
      "Entity-kgcp",
      "skos:broader",
      "Entity-knowledge_graph_construction_pipeline"
    ],
    [
      "Entity-20_different_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-extracted_metadata",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-rich_output_set",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-datasets",
      "skos:broader",
      "Entity-data_set"
    ],
    [
      "Entity-20_different_file_type",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-json_object",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-basic_text_analysis_task",
      "skos:broader",
      "Entity-text_analysis_task"
    ],
    [
      "Entity-several_complementary_extraction_method",
      "skos:broader",
      "Entity-extraction_method"
    ],
    [
      "Entity-python-based_package",
      "skos:broader",
      "Entity-package"
    ],
    [
      "Entity-basic_text_analysis_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-the_text_analysis_task",
      "skos:broader",
      "Entity-basic_text_analysis"
    ],
    [
      "Entity-rdf",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-the_average_of_the_extracted_attribute",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-apache_tika",
      "skos:broader",
      "Entity-content-based_information_extraction"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-heterogeneous_file_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "skos:broader",
      "Entity-information_extraction"
    ],
    [
      "Entity-rdf",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-pre-processing_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-basic_text_analysis_task",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-text_analysis_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-content-based_information_extraction",
      "skos:broader",
      "Entity-information_extraction"
    ],
    [
      "Entity-apache_tika",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-rdf_ready",
      "skos:broader",
      "Entity-rdf"
    ],
    [
      "Entity-document__file__set",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis",
      "skos:broader",
      "Entity-content-based_information_extraction"
    ],
    [
      "Entity-property",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-ole_2",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-tnnt_result",
      "skos:broader",
      "Entity-result"
    ],
    [
      "Entity-state-of-the-art_nlp_tool_and_ner_model",
      "skos:broader",
      "Entity-nlp_tool"
    ],
    [
      "Entity-mel_general_processing_model",
      "skos:broader",
      "Entity-processing_model"
    ],
    [
      "Entity-associated-metadata",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-xml_output",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-supported_format__document_object_model",
      "skos:broader",
      "Entity-document_object_model"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-package"
    ],
    [
      "Entity-nlnz_metadata_extractor",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-source_document",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-input_document_set",
      "skos:broader",
      "Entity-document_set"
    ],
    [
      "Entity-keyword_extraction_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-.docm",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-parameter_and_flag",
      "skos:broader",
      "Entity-flag"
    ],
    [
      "Entity-xml_output",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-a_project_to__containerise__the_meltnnt_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-.docm",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-output_set",
      "skos:broader",
      "Entity-result"
    ],
    [
      "Entity-different_source_document_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-nlnz_metadata_extractor",
      "skos:broader",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-.docm",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-the_supported_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-olemeta",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-mel_general_processing_model",
      "skos:broader",
      "Entity-processing"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "skos:broader",
      "Entity-content-based_information_extraction"
    ],
    [
      "Entity-olemeta",
      "skos:broader",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-unstructured_data_set",
      "skos:broader",
      "Entity-data_set"
    ],
    [
      "Entity-the_text_analysis_task",
      "skos:broader",
      "Entity-text_analysis_task"
    ],
    [
      "Entity-heterogeneous_file_set",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-j2rm",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-apache_tika",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-the_text_analysis_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-java-based_general-purpose_system",
      "skos:broader",
      "Entity-java"
    ],
    [
      "Entity-specific_pre-processing_and_data_cleaning_task",
      "skos:broader",
      "Entity-data_cleaning"
    ],
    [
      "Entity-kgcp_task",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-keyword_extraction_task",
      "skos:broader",
      "Entity-pattern_matching_and_keyword_extraction"
    ],
    [
      "Entity-kgcp_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-olemeta",
      "skos:broader",
      "Entity-metadata_and_content-based_information_extraction"
    ],
    [
      "Entity-python-based_tool_and_library",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-metadata_and_content-based_information",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-input_document_set",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-nlnz_metadata_extractor",
      "skos:broader",
      "Entity-extracted_metadata"
    ],
    [
      "Entity-kgcp",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-kgcp",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-the_text_analysis_task",
      "skos:broader",
      "Entity-text_analysis"
    ]
  ],
  "predicates": {
    "Predicate-are_pre-processing_steps_of": {
      "label": "are pre-processing steps of",
      "description": "The predicate 'are pre-processing steps of' establishes a relationship where the subject represents specific techniques, methods, or processes that serve as preliminary actions or operations necessary for the successful execution or development of the object, which is typically a larger system, framework, or methodology. This indicates that the subject contributes foundational work that enhances, prepares, or optimizes the object for its intended purpose.",
      "disambiguation_index": 0
    },
    "Predicate-are": {
      "label": "are",
      "description": "The predicate 'are' serves as a linking verb that establishes an identity or classification relationship between the subject and the object. It indicates that the subject is being defined or described in terms of the object, suggesting that the subject falls under the category or possesses the characteristics represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-integrate": {
      "label": "integrate",
      "description": "The predicate 'integrate' denotes the action of combining or unifying the subject with the object in a way that creates a cohesive and functional whole. It implies that the subject is bringing together various elements represented by the object, often enhancing their effectiveness or efficiency when used in conjunction. This process typically involves the alignment of different components to work synergistically, thereby achieving a more comprehensive or improved outcome.",
      "disambiguation_index": 0
    },
    "Predicate-get": {
      "label": "get",
      "description": "The predicate 'get' indicates a relationship where the subject acquires, obtains, or receives the object, often implying a transformation or a process that results in the subject achieving or accessing the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_a": {
      "label": "is a",
      "description": "The predicate 'is a' establishes a classification or categorization relationship between the subject and the object, indicating that the subject belongs to or is an instance of the type or category defined by the object. It serves to define the nature or identity of the subject in relation to the object, suggesting that the subject possesses the characteristics or qualities associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-implements": {
      "label": "implements",
      "description": "The predicate 'implements' denotes a relationship where the subject provides a practical realization or execution of the concepts, techniques, or procedures described in the object. It indicates that the subject actively incorporates or applies the methods, functionalities, or systems outlined in the object to achieve specific goals or outcomes.",
      "disambiguation_index": 0
    },
    "Predicate-extracts": {
      "label": "extracts",
      "description": "The predicate 'extracts' indicates an action where the subject is performing a process or operation to obtain or derive specific information, data, or elements represented by the object. This action typically involves identifying, isolating, and retrieving relevant components from a larger set of data or context, thereby transforming or distilling the original material into a more focused or usable form.",
      "disambiguation_index": 0
    },
    "Predicate-extracts_from": {
      "label": "extracts from",
      "description": "The predicate 'extracts from' indicates a relationship where the subject is capable of obtaining or deriving specific data, insights, or elements from the object. This implies a process of retrieval or processing, where the subject utilizes the object as a source to gather relevant information or components, often transforming or organizing the extracted content for further use or analysis.",
      "disambiguation_index": 0
    },
    "Predicate-encoded_in": {
      "label": "encoded in",
      "description": "The predicate 'encoded in' signifies a relationship where the subject is represented or transformed into a specific format or structure defined by the object. It implies that the subject's original form is altered or organized in a way that allows it to be stored, transmitted, or processed according to the characteristics of the object. This relationship highlights the process of encoding, which is essential for data management and communication.",
      "disambiguation_index": 0
    },
    "Predicate-is": {
      "label": "is",
      "description": "The predicate 'is' serves as a linking verb that establishes an identity or equivalence between the subject and the object. It indicates that the subject possesses the characteristics or qualities described by the object, effectively defining or categorizing the subject within a certain context.",
      "disambiguation_index": 0
    },
    "Predicate-generated_as": {
      "label": "generated as",
      "description": "The predicate 'generated as' indicates the process or method by which the subject is produced or created in a specific form or format represented by the object. It establishes a relationship where the subject is the outcome or result of a generation process that yields the object as its manifestation.",
      "disambiguation_index": 0
    },
    "Predicate-mapped_to": {
      "label": "mapped to",
      "description": "The predicate 'mapped to' indicates a relationship where the subject is associated with or transformed into the object, often implying a conversion or representation of data from one format or structure to another. This connection suggests that the subject can be understood, interpreted, or utilized in the context of the object, highlighting a correspondence or equivalence between the two.",
      "disambiguation_index": 0
    },
    "Predicate-stored_in": {
      "label": "stored in",
      "description": "The predicate 'stored in' indicates a relationship where the subject is kept or maintained within the confines or structure of the object. It implies that the subject is located or preserved in the object, which serves as a container, repository, or storage medium for the subject.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_mapped_to": {
      "label": "can be mapped to",
      "description": "The predicate 'can be mapped to' indicates a relationship where the subject can be transformed, represented, or correlated with the object in a meaningful way. This suggests that there exists a method or process that allows for the conversion or alignment of the subject's structure, data, or semantics to that of the object, facilitating interoperability or integration between different formats, systems, or representations.",
      "disambiguation_index": 0
    },
    "Predicate-supports": {
      "label": "supports",
      "description": "The predicate 'supports' indicates that the subject has the capability or provision to accommodate, enable, or facilitate the object. In this context, it signifies that the subject can effectively work with or provide functionality for the specified object, which may include various types, formats, or categories.",
      "disambiguation_index": 0
    },
    "Predicate-aids": {
      "label": "aids",
      "description": "The predicate 'aids' indicates a supportive or facilitative relationship between the subject and the object, where the subject provides assistance, help, or enhancement to the processes, activities, or entities represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_based_on": {
      "label": "is based on",
      "description": "The predicate 'is based on' establishes a foundational relationship between the subject and the object, indicating that the subject derives its principles, structure, or functionality from the object. It suggests that the object serves as a fundamental reference or source upon which the subject is constructed or developed.",
      "disambiguation_index": 0
    },
    "Predicate-are_part_of": {
      "label": "are part of",
      "description": "The predicate 'are part of' indicates a relationship of inclusion or membership, where the subject is a component, element, or subset that contributes to the whole represented by the object. This relationship signifies that the subject plays a role within the broader context or framework defined by the object, highlighting the interconnectedness and hierarchical structure between the two.",
      "disambiguation_index": 0
    },
    "Predicate-introduces": {
      "label": "introduces",
      "description": "The predicate 'introduces' signifies an action where the subject presents or brings forth the object to an audience or context, often for the first time. It implies a transfer of information or knowledge, highlighting the relationship where the subject serves as a source or medium for the object, which is typically a concept, idea, or entity that is being made known or explained.",
      "disambiguation_index": 0
    },
    "Predicate-from": {
      "label": "from",
      "description": "The predicate 'from' indicates a source or origin relationship between the subject and the object, suggesting that the subject is derived, obtained, or extracted from the object. It establishes a connection where the subject is influenced or shaped by the characteristics or properties of the object.",
      "disambiguation_index": 0
    },
    "Predicate-as": {
      "label": "as",
      "description": "The predicate 'as' is used to indicate a relationship of equivalence or representation between the subject and the object, suggesting that the subject can be understood, categorized, or defined in the same manner as the object. It often implies that the subject takes on the characteristics or role of the object in a specific context.",
      "disambiguation_index": 0
    },
    "Predicate-performs": {
      "label": "performs",
      "description": "The predicate 'performs' indicates an action or activity carried out by the subject, which involves executing or engaging in a specific task or set of tasks represented by the object. It establishes a relationship where the subject is the agent that actively undertakes the responsibilities or functions described in the object.",
      "disambiguation_index": 0
    },
    "Predicate-generates": {
      "label": "generates",
      "description": "The predicate 'generates' indicates a causal or productive relationship where the subject produces or creates the object as a result of its actions or processes. It implies that the subject is an active agent that leads to the formation, emergence, or occurrence of the object, which can be tangible or intangible outcomes.",
      "disambiguation_index": 0
    },
    "Predicate-in": {
      "label": "in",
      "description": "The predicate 'in' indicates a relationship where the subject is contained within or expressed in the form of the object. It signifies that the subject exists or is represented in the context or medium specified by the object.",
      "disambiguation_index": 0
    },
    "Predicate-prepares_the_ground_for": {
      "label": "prepares the ground for",
      "description": "The predicate 'prepares the ground for' indicates that the subject creates the necessary conditions, context, or foundation that enables or facilitates the realization or implementation of the object. It suggests a preparatory action that leads to the eventual occurrence or success of the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_in": {
      "label": "are in",
      "description": "The predicate 'are in' indicates a state of being or existence, connecting the subject to the object by expressing that the subject is contained within, characterized by, or represented in the form specified by the object. It suggests a relationship where the subject is associated with the qualities or attributes defined by the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_integrated_with": {
      "label": "is integrated with",
      "description": "The predicate 'is integrated with' indicates a relationship where the subject is combined or connected with the object in a way that allows them to function together as a cohesive unit. This integration often implies that the subject and object share data, resources, or functionalities, enhancing their overall capabilities and effectiveness in a specific context.",
      "disambiguation_index": 0
    },
    "Predicate-results_in": {
      "label": "results in",
      "description": "The predicate 'results in' indicates a causal relationship where the subject leads to or produces the object as an outcome or consequence. It implies that the action or process represented by the subject directly influences or contributes to the occurrence of the object.",
      "disambiguation_index": 0
    },
    "Predicate-developed_in_conjunction_with": {
      "label": "developed in conjunction with",
      "description": "The predicate 'developed in conjunction with' indicates a collaborative process where the subject has been created, designed, or enhanced through a partnership or cooperative effort with the object. This suggests that both entities contributed to the development, implying a shared goal or mutual benefit in the creation or improvement of a product, project, or concept.",
      "disambiguation_index": 0
    },
    "Predicate-part_of": {
      "label": "part of",
      "description": "The predicate 'part of' indicates a relationship where the subject is a component, element, or constituent of the object. This implies that the subject is included within the larger structure or system represented by the object, suggesting a hierarchical or organizational connection between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-map_to": {
      "label": "map to",
      "description": "The predicate 'map to' indicates a relationship where the subject is transformed, represented, or correlated to the object, suggesting a systematic or structured connection between the two entities. It implies that the subject can be aligned or converted into the format or structure of the object, facilitating interoperability or understanding between different data representations.",
      "disambiguation_index": 0
    },
    "Predicate-has": {
      "label": "has",
      "description": "The predicate 'has' establishes a possessive relationship between the subject and the object, indicating that the subject possesses, contains, or is characterized by the qualities or features represented by the object. In this context, it signifies that the subject is associated with or includes the attributes described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-takes_as_input": {
      "label": "takes as input",
      "description": "The predicate 'takes as input' establishes a relationship where the subject is an entity or process that requires or utilizes the object as a necessary component or resource for its operation or function. In this context, the subject is designed to process, analyze, or manipulate the object, which serves as the input that influences the outcome or behavior of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-applies": {
      "label": "applies",
      "description": "The predicate 'applies' indicates a relationship where the subject utilizes or implements the object in a relevant context or process. It suggests that the subject is actively engaging with the object to achieve a specific function or outcome, often implying that the object serves as a tool, method, or framework that enhances or facilitates the operations of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-involves": {
      "label": "involves",
      "description": "The predicate 'involves' indicates a relationship where the subject encompasses or requires the object as a necessary component or activity. It suggests that the subject cannot be fully realized or understood without the inclusion of the object, highlighting a connection where the object plays a significant role in the functioning or execution of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-contains": {
      "label": "contains",
      "description": "The predicate 'contains' establishes a relationship between the subject and the object, indicating that the subject is composed of or includes the elements represented by the object. It signifies that the subject holds or encompasses the object within its scope, suggesting a part-whole relationship or a subset inclusion.",
      "disambiguation_index": 0
    },
    "Predicate-has_a_structure_based_on": {
      "label": "has a structure based on",
      "description": "The predicate 'has a structure based on' indicates that the subject is organized or arranged according to the principles, rules, or framework provided by the object. It establishes a foundational relationship where the subject's configuration or format is derived from or influenced by the characteristics and specifications outlined in the object.",
      "disambiguation_index": 0
    },
    "Predicate-can_store": {
      "label": "can store",
      "description": "The predicate 'can store' indicates the ability or capacity of the subject to retain or keep the object in a particular state or location for future use or reference. It implies that the subject has the functionality or resources necessary to hold the object, which can be data, information, or physical items, thereby allowing for retrieval or access at a later time.",
      "disambiguation_index": 0
    },
    "Predicate-is_presented_in": {
      "label": "is presented in",
      "description": "The predicate 'is presented in' indicates that the subject is displayed, illustrated, or detailed within the context of the object. It establishes a relationship where the subject is the content or information that can be found or referenced in the specified object, which typically serves as a medium or format for the presentation.",
      "disambiguation_index": 0
    },
    "Predicate-is_related_to": {
      "label": "is related to",
      "description": "The predicate 'is related to' establishes a connection or association between the subject and the object, indicating that there is a relevant link, correlation, or interaction between the two entities. This relationship can encompass various forms of relevance, such as functional, conceptual, or contextual ties, suggesting that understanding one may provide insights into the other.",
      "disambiguation_index": 0
    },
    "Predicate-is_able_to_extract": {
      "label": "is able to extract",
      "description": "The predicate 'is able to extract' indicates the capability or functionality of the subject to retrieve or obtain specific information, data, or elements represented by the object. It suggests that the subject possesses the necessary means, skills, or mechanisms to perform the action of extraction, thereby establishing a relationship where the subject can effectively access and separate the object from a larger context or dataset.",
      "disambiguation_index": 0
    },
    "Predicate-shows": {
      "label": "shows",
      "description": "The predicate 'shows' serves to establish a relationship where the subject provides evidence, representation, or demonstration of the object. It indicates that the subject reveals, illustrates, or makes apparent certain characteristics, qualities, or functionalities of the object, thereby facilitating understanding or insight into the object being referenced.",
      "disambiguation_index": 0
    },
    "Predicate-comes_from": {
      "label": "comes from",
      "description": "The predicate 'comes from' establishes a relationship of origin or source between the subject and the object. It indicates that the subject is derived, obtained, or generated from the object, suggesting a directional flow of information, attributes, or characteristics from the object to the subject.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_processed_on": {
      "label": "can be processed on",
      "description": "The predicate 'can be processed on' indicates the compatibility or suitability of a subject for operation or manipulation within a specified environment or system, represented by the object. It establishes a relationship where the subject is capable of being handled, utilized, or executed in the context of the object, suggesting that the object provides the necessary conditions or resources for the subject's processing.",
      "disambiguation_index": 0
    },
    "Predicate-can_only_be_processed_on": {
      "label": "can only be processed on",
      "description": "The predicate 'can only be processed on' indicates a restriction or limitation regarding the processing capabilities of the subject. It establishes that the subject is compatible with, or can function within, the context of the object, while also implying that processing cannot occur outside of this specified environment. This highlights a dependency relationship where the subject requires the object for its processing needs.",
      "disambiguation_index": 0
    },
    "Predicate-uses": {
      "label": "uses",
      "description": "The predicate 'uses' indicates a relationship in which the subject actively employs or utilizes the object for a specific purpose or function. It signifies that the subject has a practical engagement with the object, often implying that the object serves as a tool, resource, or method that facilitates the subject's actions or goals.",
      "disambiguation_index": 0
    },
    "Predicate-is_for": {
      "label": "is for",
      "description": "The predicate 'is for' establishes a relationship of purpose or association between the subject and the object, indicating that the subject serves, supports, or is intended for the use or benefit of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_depicted_in": {
      "label": "is depicted in",
      "description": "The predicate 'is depicted in' establishes a relationship where the subject is represented or illustrated within the context of the object. This indicates that the subject is visually or conceptually included in the object, which often refers to a specific image, diagram, or representation.",
      "disambiguation_index": 0
    },
    "Predicate-implemented_in": {
      "label": "implemented in",
      "description": "The predicate 'implemented in' establishes a relationship where the subject represents a method, technique, or system that is realized or executed within the framework, environment, or language specified by the object. It indicates that the subject is operationally integrated or constructed using the resources or capabilities provided by the object.",
      "disambiguation_index": 0
    },
    "Predicate-applied_to_extract": {
      "label": "applied to extract",
      "description": "The predicate 'applied to extract' indicates a functional relationship where the subject is utilized or implemented in order to obtain or retrieve specific information or elements represented by the object. This suggests that the subject serves as a tool or technique that facilitates the process of extraction, targeting the particular aspects or data types denoted by the object.",
      "disambiguation_index": 0
    },
    "Predicate-of": {
      "label": "of",
      "description": "The predicate 'of' indicates a relationship of belonging or association between the subject and the object. It signifies that the subject is related to, characterized by, or derived from the object, often implying that the object provides context, classification, or specification for the subject.",
      "disambiguation_index": 0
    },
    "Predicate-is_applied_to": {
      "label": "is applied to",
      "description": "The predicate 'is applied to' indicates a relationship where the subject utilizes or implements the object in a specific context or function. It suggests that the subject has a direct association with the object, often indicating that the object serves as a relevant category, framework, or set of criteria that the subject engages with or operates upon.",
      "disambiguation_index": 0
    },
    "Predicate-applies_to": {
      "label": "applies to",
      "description": "The predicate 'applies to' establishes a relationship where the subject is associated with or relevant to the object, indicating that the subject has a direct connection or applicability concerning the characteristics, functionalities, or conditions represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-have": {
      "label": "have",
      "description": "The predicate 'have' indicates a possession or ownership relationship between the subject and the object. It signifies that the subject possesses certain attributes, qualities, or items represented by the object, establishing a connection where the subject is characterized or defined by what it has.",
      "disambiguation_index": 0
    },
    "Predicate-is_presented_in_(1)": {
      "label": "is presented in",
      "description": "The predicate 'is presented in' establishes a relationship where the subject is the entity or concept being described or illustrated, and the object is the medium or context in which this description or illustration occurs. This indicates that the subject can be found or is depicted within the specified object, suggesting a visual, textual, or conceptual representation.",
      "disambiguation_index": 1
    },
    "Predicate-is_performed_for": {
      "label": "is performed for",
      "description": "The predicate 'is performed for' indicates a purpose or intention behind the action represented by the subject. It connects the subject, which is an action or task, to the object, which represents the intended outcome, result, or beneficiary of that action. This relationship highlights that the action is undertaken with the goal of achieving or providing something specific, thus establishing a functional link between the task and its expected output.",
      "disambiguation_index": 0
    },
    "Predicate-is_aimed_to_be_used_in": {
      "label": "is aimed to be used in",
      "description": "The predicate 'is aimed to be used in' indicates a purpose or intended application of the subject in relation to the object. It suggests that the subject is designed, developed, or intended for utilization within the context or framework represented by the object. This connection implies a functional relationship where the subject serves a specific role or fulfills a particular need within the domain of the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_available_for": {
      "label": "are available for",
      "description": "The predicate 'are available for' indicates that the subject provides access, support, or resources that can be utilized for the purpose or activity specified by the object. It establishes a relationship where the subject is capable of fulfilling the needs or requirements associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_based_on": {
      "label": "are based on",
      "description": "The predicate 'are based on' indicates a foundational relationship where the subject derives its principles, structure, or functionality from the object. It suggests that the subject is built upon, influenced by, or fundamentally connected to the object, establishing a dependency or origin that informs the characteristics or behavior of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-is_associated_with": {
      "label": "is associated with",
      "description": "The predicate 'is associated with' indicates a relationship between the subject and the object, suggesting that they share a connection or relevance to each other. This connection can imply various forms of association, such as categorization, correlation, or contextual relevance, where the subject may belong to, influence, or be commonly linked with the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_comprehensive_set_of_methods_for": {
      "label": "is a comprehensive set of methods for",
      "description": "The predicate 'is a comprehensive set of methods for' establishes a relationship where the subject represents a specific domain or area of expertise, while the object denotes the particular applications, tasks, or categories that the methods are designed to address. This indicates that the subject encompasses a variety of techniques or strategies that collectively provide a thorough approach to handling the needs or challenges associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-provides": {
      "label": "provides",
      "description": "The predicate 'provides' indicates a relationship in which the subject offers, supplies, or makes available a certain resource, service, or information to the object. This connection implies that the subject is the source or provider of the object, which can be a tool, method, or any form of assistance that fulfills a need or requirement.",
      "disambiguation_index": 0
    },
    "Predicate-tested_over": {
      "label": "tested over",
      "description": "The predicate 'tested over' indicates that the subject has undergone a process of evaluation or examination in relation to the object, which typically represents a set of items, data, or conditions. This connection implies that the subject's effectiveness, performance, or validity has been assessed using the specified object as a basis for testing.",
      "disambiguation_index": 0
    },
    "Predicate-are_used_to_add": {
      "label": "are used to add",
      "description": "The predicate 'are used to add' indicates a functional relationship where the subject serves a purpose or function of incorporating or introducing the object into a particular context or system. It implies that the subject facilitates the inclusion or enhancement of the object, which can be a concept, element, or component, thereby contributing to the overall structure or meaning of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-is_made": {
      "label": "is made",
      "description": "The predicate 'is made' indicates a process or action through which the subject undergoes transformation or creation to achieve the state or condition represented by the object. It signifies that the subject is the source or origin of the resulting object, implying a relationship where the subject contributes to or facilitates the formation of the object.",
      "disambiguation_index": 0
    },
    "Predicate-leverages": {
      "label": "leverages",
      "description": "The predicate 'leverages' indicates that the subject utilizes or takes advantage of the object in order to enhance its functionality, effectiveness, or performance. It implies a relationship where the subject benefits from the properties or capabilities of the object, suggesting a strategic use of resources or concepts to achieve a desired outcome.",
      "disambiguation_index": 0
    },
    "Predicate-will_be_added_in": {
      "label": "will be added in",
      "description": "The predicate 'will be added in' indicates a future action or event where the subject is expected to incorporate or include the object within a specified context or framework. It suggests that the addition is contingent upon certain conditions or requirements, which may vary based on the situation or criteria outlined in the object.",
      "disambiguation_index": 0
    },
    "Predicate-support": {
      "label": "support",
      "description": "The predicate 'support' indicates a relationship where the subject provides assistance, resources, or functionality to enable or enhance the capabilities of the object. It signifies that the subject plays a role in facilitating the successful execution or realization of the object, thereby contributing to its effectiveness or performance.",
      "disambiguation_index": 0
    },
    "Predicate-is_planned_to": {
      "label": "is planned to",
      "description": "The predicate 'is planned to' indicates a future intention or arrangement regarding the subject, suggesting that the subject is associated with a specific objective or action represented by the object. It conveys that there is a deliberate plan or proposal in place for the subject to undertake the action or achieve the goal described in the object.",
      "disambiguation_index": 0
    },
    "Predicate-integrates_with": {
      "label": "integrates with",
      "description": "The predicate 'integrates with' denotes a relationship where the subject is designed to work in conjunction with the object, facilitating a seamless connection or interaction between the two entities. This integration often implies that the subject can utilize the functionalities or features of the object, enhancing its capabilities or performance.",
      "disambiguation_index": 0
    },
    "Predicate-has_been_tested_over": {
      "label": "has been tested over",
      "description": "The predicate 'has been tested over' indicates that the subject has undergone a process of evaluation or examination in relation to the object, which typically represents a set of items, scenarios, or conditions. This phrase suggests that the subject's effectiveness, reliability, or performance has been assessed by applying it to the specified object, thereby establishing a connection between the subject and the object through the act of testing.",
      "disambiguation_index": 0
    },
    "Predicate-integrates": {
      "label": "integrates",
      "description": "The predicate 'integrates' denotes a relationship in which the subject combines or unifies with the object to form a cohesive whole. This implies that the subject incorporates elements or features of the object, resulting in a synthesis that enhances functionality, coherence, or effectiveness. The integration process often involves the merging of distinct components, leading to a new entity that retains characteristics of both the subject and the object.",
      "disambiguation_index": 0
    },
    "Predicate-defines": {
      "label": "defines",
      "description": "The predicate 'defines' establishes a relationship where the subject provides a clear and specific explanation or characterization of the object. It indicates that the subject is responsible for outlining the essential attributes, principles, or framework of the object, thereby clarifying its meaning or function.",
      "disambiguation_index": 0
    },
    "Predicate-designed_to_extract": {
      "label": "designed to extract",
      "description": "The predicate 'designed to extract' indicates that the subject has been intentionally created or developed with the specific purpose of obtaining or retrieving the object, which typically consists of data or information. This connection implies that the subject possesses features, functionalities, or mechanisms that facilitate the extraction process, thereby enabling the acquisition of the specified content or data type represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-extracts_metadata_and_content-based_information_from": {
      "label": "extracts metadata and content-based information from",
      "description": "The predicate 'extracts metadata and content-based information from' indicates a process in which the subject performs an action to retrieve and identify relevant data and insights from the object, which is typically a collection of documents or files. This action involves analyzing the content and structure of the object to gather both descriptive information (metadata) and substantive details (content-based information) that can be used for further processing, analysis, or organization.",
      "disambiguation_index": 0
    },
    "Predicate-generate": {
      "label": "generate",
      "description": "The predicate 'generate' indicates the action of producing or creating something as a result of a process or set of methods. In the context of a subject and object, it connects the subject, which represents the means or methods employed, to the object, which is the outcome or product that is formed as a consequence of that action.",
      "disambiguation_index": 0
    },
    "Predicate-implement": {
      "label": "implement",
      "description": "The predicate 'implement' signifies the action of putting a plan, method, or system into effect, resulting in the realization or execution of a specific outcome or product. In the context of the subject and object, it indicates that the subject is actively applying or executing a particular approach or technique to achieve the results represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-produces": {
      "label": "produces",
      "description": "The predicate 'produces' indicates a relationship where the subject generates, creates, or yields the object as a result of its processes or functions. It signifies that the subject is responsible for the existence or formation of the object, which can encompass various forms of output, such as data, materials, or results.",
      "disambiguation_index": 0
    },
    "Predicate-automates_the_extraction_of": {
      "label": "automates the extraction of",
      "description": "The predicate 'automates the extraction of' indicates a process in which the subject employs a system or method to facilitate the automatic retrieval and processing of specific information or data, represented as the object. This implies that the subject enhances efficiency and reduces manual effort in obtaining the specified content, which can include various forms of data such as metadata and text.",
      "disambiguation_index": 0
    },
    "Predicate-describes_the_systematic_approach_for_extracting": {
      "label": "describes the systematic approach for extracting",
      "description": "The predicate 'describes the systematic approach for extracting' indicates that the subject provides a detailed explanation or framework regarding the methods and processes involved in obtaining specific information or data, which is represented by the object. This connection highlights how the subject outlines the strategies and techniques necessary to effectively retrieve the specified content or metadata.",
      "disambiguation_index": 0
    },
    "Predicate-is_derived_from": {
      "label": "is derived from",
      "description": "The predicate 'is derived from' indicates a relationship where the subject is formed, developed, or obtained as a result of the object. It suggests that the subject has its origins or basis in the object, implying a process of transformation or extraction that connects the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-is_outputted_as": {
      "label": "is outputted as",
      "description": "The predicate 'is outputted as' indicates a transformation or conversion process where the subject is represented or formatted in a specific manner, resulting in the object. It signifies that the information or data contained in the subject is processed and presented in the form specified by the object, often implying a change in structure or format.",
      "disambiguation_index": 0
    },
    "Predicate-are_extracted_using": {
      "label": "are extracted using",
      "description": "The predicate 'are extracted using' indicates a process or method by which a specific object is obtained or derived from a subject. It establishes a relationship where the subject represents the techniques, tools, or approaches employed to retrieve or isolate the object, which is the information or data being extracted. This phrase emphasizes the action of extraction and the means by which it is accomplished.",
      "disambiguation_index": 0
    },
    "Predicate-is_extracted_from": {
      "label": "is extracted from",
      "description": "The predicate 'is extracted from' indicates a relationship where the subject represents a subset or derived component that has been obtained or derived from the object. This implies a process of retrieval or derivation, where the subject is a result of processing, analyzing, or distilling information from the object.",
      "disambiguation_index": 0
    },
    "Predicate-automates_the_extraction_of_categorized_named_entities_from_content": {
      "label": "automates the extraction of categorized named entities from content",
      "description": "The predicate 'automates the extraction of categorized named entities from content' describes a process in which a subject systematically and efficiently identifies and retrieves specific types of information, known as named entities, from a given body of text or data. This process categorizes the entities into predefined classes, enhancing the organization and usability of the content by transforming unstructured information into structured data.",
      "disambiguation_index": 0
    },
    "Predicate-is_extracted_by": {
      "label": "is extracted by",
      "description": "The predicate 'is extracted by' indicates a relationship where the subject undergoes a process or action that results in the removal or retrieval of specific information, data, or elements, represented by the object. This implies that the subject serves as a source or origin from which the object is derived or obtained, highlighting a directional flow of information or material.",
      "disambiguation_index": 0
    },
    "Predicate-is_extracted_as": {
      "label": "is extracted as",
      "description": "The predicate 'is extracted as' indicates a transformation or conversion process where the subject is processed or analyzed to produce the object, which represents the resulting format or representation of the subject's information.",
      "disambiguation_index": 0
    },
    "Predicate-is_implemented_by": {
      "label": "is implemented by",
      "description": "The predicate 'is implemented by' establishes a relationship where the subject represents a system, tool, or method that is realized or executed through the means or framework provided by the object. It indicates that the functionality or operation of the subject is carried out using the principles, structures, or processes defined by the object.",
      "disambiguation_index": 0
    },
    "Predicate-includes": {
      "label": "includes",
      "description": "The predicate 'includes' establishes a relationship between the subject and the object by indicating that the subject contains or comprises the elements represented by the object. It signifies that the object is a part of, or is encompassed within, the broader context of the subject, thereby highlighting the connection and relevance of the object to the subject.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates_the_extraction_of": {
      "label": "facilitates the extraction of",
      "description": "The predicate 'facilitates the extraction of' indicates a supportive or enabling relationship between the subject and the object, where the subject provides the means, tools, or processes that make it easier to obtain or derive the information represented by the object. In this context, the subject enhances the ability to gather or retrieve specific data or content, thereby streamlining the extraction process.",
      "disambiguation_index": 0
    },
    "Predicate-enables": {
      "label": "enables",
      "description": "The predicate 'enables' indicates a facilitative relationship where the subject provides the means, capability, or opportunity for the object to occur or be realized. It suggests that the subject plays a crucial role in making the object possible, thereby enhancing or supporting its implementation or effectiveness.",
      "disambiguation_index": 0
    },
    "Predicate-extracts_information_from": {
      "label": "extracts information from",
      "description": "The predicate 'extracts information from' indicates a process in which the subject utilizes specific techniques, tools, or methodologies to retrieve, identify, or derive relevant data or insights from the object, which is typically a collection of data, documents, or files. This relationship highlights the action of obtaining meaningful content or knowledge from a source, emphasizing the transformation of raw data into usable information.",
      "disambiguation_index": 0
    },
    "Predicate-encapsulates": {
      "label": "encapsulates",
      "description": "The predicate 'encapsulates' indicates that the subject contains or embodies the object within it, suggesting a relationship where the subject serves as a container or representation of the object, which may include various elements or aspects that are integral to the subject's overall meaning or function.",
      "disambiguation_index": 0
    },
    "Predicate-is_formatted_as": {
      "label": "is formatted as",
      "description": "The predicate 'is formatted as' establishes a relationship between a subject and an object by indicating that the subject is presented or structured in a specific manner that corresponds to the characteristics or requirements of the object. This implies that the subject adheres to a particular format or style that is defined by the object, thereby facilitating understanding, processing, or utilization of the subject in a way that aligns with the expectations set by the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_represented_as": {
      "label": "are represented as",
      "description": "The predicate 'are represented as' indicates a relationship where the subject is depicted, illustrated, or characterized in a specific form or format as denoted by the object. It suggests that the subject can be understood or interpreted through the lens of the object, which serves as a representation or manifestation of the subject's attributes, qualities, or data.",
      "disambiguation_index": 0
    },
    "Predicate-processes": {
      "label": "processes",
      "description": "The predicate 'processes' indicates an action or function performed by the subject on the object, where the subject engages in a systematic series of operations or transformations to manipulate, analyze, or manage the object, which in this case is a collection of documents or files. This relationship implies that the subject is actively involved in handling the object to achieve a specific outcome or result.",
      "disambiguation_index": 0
    },
    "Predicate-is_input_to": {
      "label": "is input to",
      "description": "The predicate 'is input to' establishes a relationship where the subject serves as a source or contributor of data, information, or resources that are directed towards the object, which represents a target or destination for that input. This indicates a flow of input from the subject to the object, suggesting that the object relies on or utilizes the input provided by the subject for its function or purpose.",
      "disambiguation_index": 0
    },
    "Predicate-input_into": {
      "label": "input into",
      "description": "The predicate 'input into' signifies a relationship where the subject contributes or feeds information, data, or processes into the object, which is typically a system, collection, or framework. This implies that the subject plays an active role in providing necessary elements that enhance, modify, or populate the object, thereby establishing a functional or operational connection between the two.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' establishes a hierarchical relationship between the subject and the object, indicating that the subject is a specific instance or concept that falls under a more general category represented by the object. This relationship suggests that the object encompasses a wider scope or range of meanings, of which the subject is a part.",
      "disambiguation_index": 0
    }
  }
}