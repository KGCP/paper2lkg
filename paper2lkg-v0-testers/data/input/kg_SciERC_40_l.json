{
  "iri": "Paper-40",
  "title": "E06-1022",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-40-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-40-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-40-Section-1-Paragraph-1-Sentence-1",
              "text": "We present results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers ."
            },
            {
              "iri": "Paper-40-Section-1-Paragraph-1-Sentence-2",
              "text": "First , we investigate how well the addressee of a dialogue act can be predicted based on gaze , utterance and conversational context features ."
            },
            {
              "iri": "Paper-40-Section-1-Paragraph-1-Sentence-3",
              "text": "Then , we explore whether information about meeting context can aid classifiers ' performances ."
            },
            {
              "iri": "Paper-40-Section-1-Paragraph-1-Sentence-4",
              "text": "Both classifiers perform the best when conversational context and utterance features are combined with speaker 's gaze information ."
            },
            {
              "iri": "Paper-40-Section-1-Paragraph-1-Sentence-5",
              "text": "The classifiers show little gain from information about meeting context ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.00020837783813476562,
    12.641324043273926,
    21.24398159980774,
    19.320136547088623,
    0.013956546783447266,
    9.131431579589844e-05,
    0.0001246929168701172,
    37.59772062301636,
    43.177472829818726,
    1.5592973232269287,
    1.3879482746124268,
    0.009644746780395508,
    0.00020766258239746094,
    25.29597759246826,
    1.0947234630584717,
    0.009461641311645508,
    1.0995757579803467,
    3.849964141845703,
    7.603057146072388,
    9.672343015670776,
    41.44936776161194,
    3.3012077808380127,
    13.794088363647461,
    0.9232761859893799,
    0.0005602836608886719,
    0.011082887649536133
  ],
  "nodes": {
    "Entity-both_classifier_perform_the_best_when_conversational_context_and_utterance_feature_are_combined_with_speaker_s_gaze_information": {
      "node_id": "both_classifier_perform_the_best_when_conversational_context_and_utterance_feature_are_combined_with_speaker_s_gaze_information",
      "disambiguation_index": 0,
      "label": "Both classifiers perform the best when conversational context and utterance features are combined with speaker's gaze information",
      "aliases": [
        "Both classifiers perform the best when conversational context and utterance features are combined with speaker's gaze information"
      ],
      "types": [
        "performance evaluation",
        "result",
        "finding"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The results of using Bayesian Network and Naive Bayes classifiers for addressee identification in face-to-face meetings, showing their performance when combining conversational context, utterance features, and speaker's gaze information.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Both classifiers perform the best when conversational context and utterance features are combined with speaker's gaze information",
          "local_types": [
            "performance evaluation",
            "result",
            "finding"
          ],
          "iri": "Entity-both_classifier_perform_the_best_when_conversational_context_and_utterance_feature_are_combined_with_speaker_s_gaze_information-Mention-1"
        }
      ],
      "relevance": 0.91748046875
    },
    "Entity-result_on_addressee_identification_in_four-participants_face-to-face_meeting_using_bayesian_network_and_naive_bayes_classifier": {
      "node_id": "result_on_addressee_identification_in_four-participants_face-to-face_meeting_using_bayesian_network_and_naive_bayes_classifier",
      "disambiguation_index": 0,
      "label": "results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers",
      "aliases": [
        "results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers"
      ],
      "types": [
        "study",
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The outcomes of experiments that used Bayesian Networks and Naive Bayes classifiers to identify the intended recipient (addressee) in face-to-face conversations with four participants.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers",
          "local_types": [
            "study",
            "research"
          ],
          "iri": "Entity-result_on_addressee_identification_in_four-participants_face-to-face_meeting_using_bayesian_network_and_naive_bayes_classifier-Mention-1"
        }
      ],
      "relevance": 0.81396484375
    },
    "Entity-the_classifier": {
      "node_id": "the_classifier",
      "disambiguation_index": 0,
      "label": "The classifiers",
      "aliases": [
        "The classifiers"
      ],
      "types": [
        "classifier"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Bayesian Network and Naive Bayes machine learning models used for addressee identification in face-to-face meetings",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-5",
          "local_name": "The classifiers",
          "local_types": [
            "classifier"
          ],
          "iri": "Entity-the_classifier-Mention-1"
        }
      ],
      "relevance": 0.78515625
    },
    "Entity-the_classifier_show_little_gain_from_information_about_meeting_context": {
      "node_id": "the_classifier_show_little_gain_from_information_about_meeting_context",
      "disambiguation_index": 0,
      "label": "The classifiers show little gain from information about meeting context",
      "aliases": [
        "The classifiers show little gain from information about meeting context"
      ],
      "types": [
        "conclusion",
        "insight",
        "evaluation metric"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Bayesian Network and Naive Bayes classifiers used for addressee identification",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-5",
          "local_name": "The classifiers show little gain from information about meeting context",
          "local_types": [
            "conclusion",
            "insight",
            "evaluation metric"
          ],
          "iri": "Entity-the_classifier_show_little_gain_from_information_about_meeting_context-Mention-1"
        }
      ],
      "relevance": 0.78369140625
    },
    "Entity-then__we_explore_whether_information_about_meeting_context_can_aid_classifier__performance": {
      "node_id": "then__we_explore_whether_information_about_meeting_context_can_aid_classifier__performance",
      "disambiguation_index": 0,
      "label": "Then, we explore whether information about meeting context can aid classifiers' performances",
      "aliases": [
        "Then, we explore whether information about meeting context can aid classifiers' performances"
      ],
      "types": [
        "hypothesis",
        "evaluation metric"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The exploration of whether additional information about a meeting's context can improve the performance of classifiers used for addressee identification.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-3",
          "local_name": "Then, we explore whether information about meeting context can aid classifiers' performances",
          "local_types": [
            "hypothesis",
            "evaluation metric"
          ],
          "iri": "Entity-then__we_explore_whether_information_about_meeting_context_can_aid_classifier__performance-Mention-1"
        }
      ],
      "relevance": 0.77099609375
    },
    "Entity-conversational_context": {
      "node_id": "conversational_context",
      "disambiguation_index": 0,
      "label": "conversational context",
      "aliases": [
        "conversational context"
      ],
      "types": [
        "natural language processing",
        "communication process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The set of linguistic and situational features surrounding an utterance in a face-to-face meeting, including speaker's gaze information, which can be used for addressee identification.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-4",
          "local_name": "conversational context",
          "local_types": [
            "natural language processing",
            "communication process"
          ],
          "iri": "Entity-conversational_context-Mention-1"
        }
      ],
      "relevance": 0.748046875
    },
    "Entity-first": {
      "node_id": "first",
      "disambiguation_index": 0,
      "label": "First",
      "aliases": [
        "First"
      ],
      "types": [
        "introductory phrase"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The introduction to an investigation into predicting the addressee of a dialogue act in four-participants face-to-face meetings based on gaze, utterance, and conversational context features.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-2",
          "local_name": "First",
          "local_types": [
            "introductory phrase"
          ],
          "iri": "Entity-first-Mention-1"
        }
      ],
      "relevance": 0.7265625
    },
    "Entity-addressee_identification_in_four-participants_face-to-face_meeting": {
      "node_id": "addressee_identification_in_four-participants_face-to-face_meeting",
      "disambiguation_index": 0,
      "label": "addressee identification in four-participants face-to-face meetings",
      "aliases": [
        "addressee identification in four-participants face-to-face meetings"
      ],
      "types": [
        "identification",
        "meeting",
        "study"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The process of identifying the intended recipient (addressee) in a dialogue act during a meeting involving four participants, where face-to-face interactions take place.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "addressee identification in four-participants face-to-face meetings",
          "local_types": [
            "identification",
            "meeting",
            "study"
          ],
          "iri": "Entity-addressee_identification_in_four-participants_face-to-face_meeting-Mention-1"
        }
      ],
      "relevance": 0.72265625
    },
    "Entity-first__we_investigate_how_well_the_addressee_of_a_dialogue_act_can_be_predicted_based_on_gaze__utterance_and_conversational_context_feature": {
      "node_id": "first__we_investigate_how_well_the_addressee_of_a_dialogue_act_can_be_predicted_based_on_gaze__utterance_and_conversational_context_feature",
      "disambiguation_index": 0,
      "label": "First, we investigate how well the addressee of a dialogue act can be predicted based on gaze, utterance and conversational context features",
      "aliases": [
        "First, we investigate how well the addressee of a dialogue act can be predicted based on gaze, utterance and conversational context features"
      ],
      "types": [
        "prediction task",
        "research question"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A research question or prediction task investigating whether it is possible to accurately predict who will respond to a given dialogue act in a conversation based on various contextual cues.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-2",
          "local_name": "First, we investigate how well the addressee of a dialogue act can be predicted based on gaze, utterance and conversational context features",
          "local_types": [
            "prediction task",
            "research question"
          ],
          "iri": "Entity-first__we_investigate_how_well_the_addressee_of_a_dialogue_act_can_be_predicted_based_on_gaze__utterance_and_conversational_context_feature-Mention-1"
        }
      ],
      "relevance": 0.708984375
    },
    "Entity-conversational_context_and_utterance_feature": {
      "node_id": "conversational_context_and_utterance_feature",
      "disambiguation_index": 0,
      "label": "conversational context and utterance features",
      "aliases": [
        "conversational context and utterance features"
      ],
      "types": [
        "feature set"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A set of characteristics or attributes related to both the conversation itself (context) and individual speech acts within it (utterances), used for addressee identification in face-to-face meetings.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-4",
          "local_name": "conversational context and utterance features",
          "local_types": [
            "feature set"
          ],
          "iri": "Entity-conversational_context_and_utterance_feature-Mention-1"
        }
      ],
      "relevance": 0.69384765625
    },
    "Entity-we": {
      "node_id": "we",
      "disambiguation_index": 0,
      "label": "We",
      "aliases": [
        "We"
      ],
      "types": [
        "author"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The authors of this paper, presenting their research on addressee identification in face-to-face meetings.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "We",
          "local_types": [
            "author"
          ],
          "iri": "Entity-we-Mention-1"
        }
      ],
      "relevance": 0.685546875
    },
    "Entity-we_explore_whether_information_about_meeting_context_can_aid_classifier__performance": {
      "node_id": "we_explore_whether_information_about_meeting_context_can_aid_classifier__performance",
      "disambiguation_index": 0,
      "label": "we explore whether information about meeting context can aid classifiers' performances",
      "aliases": [
        "we explore whether information about meeting context can aid classifiers' performances"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The investigation into whether incorporating contextual information from meetings can improve the performance of classification models.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-3",
          "local_name": "we explore whether information about meeting context can aid classifiers' performances",
          "local_types": [
            "research"
          ],
          "iri": "Entity-we_explore_whether_information_about_meeting_context_can_aid_classifier__performance-Mention-1"
        }
      ],
      "relevance": 0.67333984375
    },
    "Entity-conversational_context_feature": {
      "node_id": "conversational_context_feature",
      "disambiguation_index": 0,
      "label": "conversational context features",
      "aliases": [
        "conversational context features"
      ],
      "types": [
        "contextual information",
        "pragmatic knowledge"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Information about the setting or situation in which dialogue takes place, including factors such as speaker gaze and utterance content.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-2",
          "local_name": "conversational context features",
          "local_types": [
            "contextual information",
            "pragmatic knowledge"
          ],
          "iri": "Entity-conversational_context_feature-Mention-1"
        }
      ],
      "relevance": 0.64697265625
    },
    "Entity-gaze__utterance_and_conversational_context_feature": {
      "node_id": "gaze__utterance_and_conversational_context_feature",
      "disambiguation_index": 0,
      "label": "gaze, utterance and conversational context features",
      "aliases": [
        "gaze, utterance and conversational context features"
      ],
      "types": [
        "data type",
        "feature set",
        "input variable",
        "data feature"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A set of characteristics related to visual attention, spoken language, and conversation dynamics",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-2",
          "local_name": "gaze, utterance and conversational context features",
          "local_types": [
            "data type",
            "feature set",
            "input variable",
            "data feature"
          ],
          "iri": "Entity-gaze__utterance_and_conversational_context_feature-Mention-1"
        }
      ],
      "relevance": 0.63671875
    },
    "Entity-speaker_s_gaze_information": {
      "node_id": "speaker_s_gaze_information",
      "disambiguation_index": 0,
      "label": "speaker's gaze information",
      "aliases": [
        "speaker's gaze information"
      ],
      "types": [
        "visual perception",
        "human-computer interaction",
        "information source"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The visual cues or data collected from a person's eye movements, typically used to infer their attention, interest, or intentions.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-4",
          "local_name": "speaker's gaze information",
          "local_types": [
            "visual perception",
            "human-computer interaction",
            "information source"
          ],
          "iri": "Entity-speaker_s_gaze_information-Mention-1"
        }
      ],
      "relevance": 0.62158203125
    },
    "Entity-addressee_identification": {
      "node_id": "addressee_identification",
      "disambiguation_index": 0,
      "label": "addressee identification",
      "aliases": [
        "addressee identification"
      ],
      "types": [
        "task",
        "problem solving",
        "research topic",
        "study"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of identifying or determining who a message, information, or request is intended for.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "addressee identification",
          "local_types": [
            "task",
            "problem solving",
            "research topic",
            "study"
          ],
          "iri": "Entity-addressee_identification-Mention-1"
        }
      ],
      "relevance": 0.611328125
    },
    "Entity-the_addressee_of_a_dialogue_act": {
      "node_id": "the_addressee_of_a_dialogue_act",
      "disambiguation_index": 0,
      "label": "the addressee of a dialogue act",
      "aliases": [
        "the addressee of a dialogue act"
      ],
      "types": [
        "entity",
        "dialogue participant"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The entity receiving or being addressed by a spoken utterance in a conversation, such as a person or group involved in a face-to-face meeting.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-2",
          "local_name": "the addressee of a dialogue act",
          "local_types": [
            "entity",
            "dialogue participant"
          ],
          "iri": "Entity-the_addressee_of_a_dialogue_act-Mention-1"
        }
      ],
      "relevance": 0.6083984375
    },
    "Entity-bayesian_network_and_naive_bayes_classifier": {
      "node_id": "bayesian_network_and_naive_bayes_classifier",
      "disambiguation_index": 0,
      "label": "Bayesian Network and Naive Bayes classifiers",
      "aliases": [
        "Bayesian Network and Naive Bayes classifiers"
      ],
      "types": [
        "algorithm",
        "methodology",
        "computational method",
        "machine learning algorithm"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A combination of a probabilistic graphical model (Bayesian Network) and a type of statistical classifier (Naive Bayes), used for machine learning tasks.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "Bayesian Network and Naive Bayes classifiers",
          "local_types": [
            "algorithm",
            "methodology",
            "computational method",
            "machine learning algorithm"
          ],
          "iri": "Entity-bayesian_network_and_naive_bayes_classifier-Mention-1"
        }
      ],
      "relevance": 0.60302734375
    },
    "Entity-addressee": {
      "node_id": "addressee",
      "disambiguation_index": 0,
      "label": "addressee",
      "aliases": [
        "addressee"
      ],
      "types": [
        "party",
        "person"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The recipient or intended listener in a communication exchange",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-2",
          "local_name": "addressee",
          "local_types": [
            "party",
            "person"
          ],
          "iri": "Entity-addressee-Mention-1"
        }
      ],
      "relevance": 0.59716796875
    },
    "Entity-four-participants_face-to-face_meeting": {
      "node_id": "four-participants_face-to-face_meeting",
      "disambiguation_index": 0,
      "label": "four-participants face-to-face meetings",
      "aliases": [
        "four-participants face-to-face meetings"
      ],
      "types": [
        "social interaction",
        "event",
        "communication"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A gathering of four individuals engaging in direct, interpersonal communication.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "four-participants face-to-face meetings",
          "local_types": [
            "social interaction",
            "event",
            "communication"
          ],
          "iri": "Entity-four-participants_face-to-face_meeting-Mention-1"
        }
      ],
      "relevance": 0.57568359375
    },
    "Entity-naive_bayes_classifier": {
      "node_id": "naive_bayes_classifier",
      "disambiguation_index": 0,
      "label": "Naive Bayes classifiers",
      "aliases": [
        "Naive Bayes classifiers"
      ],
      "types": [
        "algorithm",
        "classifier",
        "machine learning model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A type of statistical classifier that uses Bayes' theorem to calculate probabilities",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "Naive Bayes classifiers",
          "local_types": [
            "algorithm",
            "classifier",
            "machine learning model"
          ],
          "iri": "Entity-naive_bayes_classifier-Mention-1"
        }
      ],
      "relevance": 0.57373046875
    },
    "Entity-information_about_meeting_context": {
      "node_id": "information_about_meeting_context",
      "disambiguation_index": 0,
      "label": "information about meeting context",
      "aliases": [
        "information about meeting context"
      ],
      "types": [
        "context"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Contextual details or facts related to a meeting, such as participants' roles, agenda, and location.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-5",
          "local_name": "information about meeting context",
          "local_types": [
            "context"
          ],
          "iri": "Entity-information_about_meeting_context-Mention-1"
        }
      ],
      "relevance": 0.5673828125
    },
    "Entity-meeting_context": {
      "node_id": "meeting_context",
      "disambiguation_index": 0,
      "label": "meeting context",
      "aliases": [
        "meeting context"
      ],
      "types": [
        "situation",
        "context",
        "environmental factor",
        "contextual information",
        "event"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A gathering or assembly of people for discussion, negotiation, or other purposes",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-3",
          "local_name": "meeting context",
          "local_types": [
            "environmental factor",
            "contextual information",
            "context"
          ],
          "iri": "Entity-meeting_context-Mention-1"
        },
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-5",
          "local_name": "meeting context",
          "local_types": [
            "event",
            "situation"
          ],
          "iri": "Entity-meeting_context-Mention-2"
        }
      ],
      "relevance": 0.5576171875
    },
    "Entity-utterance_feature": {
      "node_id": "utterance_feature",
      "disambiguation_index": 0,
      "label": "utterance features",
      "aliases": [
        "utterance features"
      ],
      "types": [
        "linguistic feature",
        "text analysis"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A set of characteristics or attributes that describe a spoken statement, used in linguistic analysis.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-4",
          "local_name": "utterance features",
          "local_types": [
            "linguistic feature",
            "text analysis"
          ],
          "iri": "Entity-utterance_feature-Mention-1"
        }
      ],
      "relevance": 0.55224609375
    },
    "Entity-bayesian_network": {
      "node_id": "bayesian_network",
      "disambiguation_index": 0,
      "label": "Bayesian Network",
      "aliases": [
        "Bayesian Network"
      ],
      "types": [
        "algorithm",
        "machine learning model",
        "model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A probabilistic graphical model that represents a set of variables and their conditional dependencies, used for reasoning with uncertainty.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "Bayesian Network",
          "local_types": [
            "algorithm",
            "machine learning model",
            "model"
          ],
          "iri": "Entity-bayesian_network-Mention-1"
        }
      ],
      "relevance": 0.544921875
    },
    "Entity-gaze": {
      "node_id": "gaze",
      "disambiguation_index": 0,
      "label": "gaze",
      "aliases": [
        "gaze"
      ],
      "types": [
        "visual behavior",
        "non-verbal cue"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A person's visual attention or direction of their eyes",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-2",
          "local_name": "gaze",
          "local_types": [
            "visual behavior",
            "non-verbal cue"
          ],
          "iri": "Entity-gaze-Mention-1"
        }
      ],
      "relevance": 0.54296875
    },
    "Entity-utterance": {
      "node_id": "utterance",
      "disambiguation_index": 0,
      "label": "utterance",
      "aliases": [
        "utterance"
      ],
      "types": [
        "spoken language",
        "textual output"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A spoken or written statement made by someone in conversation",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-2",
          "local_name": "utterance",
          "local_types": [
            "spoken language",
            "textual output"
          ],
          "iri": "Entity-utterance-Mention-1"
        }
      ],
      "relevance": 0.5126953125
    },
    "Entity-classifier": {
      "node_id": "classifier",
      "disambiguation_index": 0,
      "label": "classifiers",
      "aliases": [
        "classifiers"
      ],
      "types": [
        "algorithm",
        "model",
        "machine learning model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A type of machine learning algorithm or model that categorizes data into predefined categories",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-3",
          "local_name": "classifiers",
          "local_types": [
            "algorithm",
            "model"
          ],
          "iri": "Entity-classifier-Mention-1"
        },
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-4",
          "local_name": "classifiers",
          "local_types": [
            "machine learning model",
            "algorithm"
          ],
          "iri": "Entity-classifier-Mention-2"
        },
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-5",
          "local_name": "classifiers",
          "local_types": [
            "machine learning model"
          ],
          "iri": "Entity-classifier-Mention-3"
        }
      ],
      "relevance": 0.51171875
    },
    "Entity-dialogue_act": {
      "node_id": "dialogue_act",
      "disambiguation_index": 0,
      "label": "dialogue act",
      "aliases": [
        "dialogue act"
      ],
      "types": [
        "communication protocol",
        "verbal interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A unit of verbal interaction that conveys a specific communicative intention or meaning.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-2",
          "local_name": "dialogue act",
          "local_types": [
            "communication protocol",
            "verbal interaction"
          ],
          "iri": "Entity-dialogue_act-Mention-1"
        }
      ],
      "relevance": 0.509765625
    },
    "Entity-we_present_result": {
      "node_id": "we_present_result",
      "disambiguation_index": 0,
      "label": "We present results",
      "aliases": [
        "We present results"
      ],
      "types": [
        "research"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A research presentation",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "We present results",
          "local_types": [
            "research"
          ],
          "iri": "Entity-we_present_result-Mention-1"
        }
      ],
      "relevance": 0.491943359375
    },
    "Entity-both_classifier": {
      "node_id": "both_classifier",
      "disambiguation_index": 0,
      "label": "Both classifiers",
      "aliases": [
        "Both classifiers"
      ],
      "types": [
        "algorithm",
        "classifier",
        "tool"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A type of algorithm or tool that uses multiple classification methods to categorize data.",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Both classifiers",
          "local_types": [
            "algorithm",
            "classifier",
            "tool"
          ],
          "iri": "Entity-both_classifier-Mention-1"
        }
      ],
      "relevance": 0.480712890625
    },
    "Entity-result": {
      "node_id": "result",
      "disambiguation_index": 0,
      "label": "results",
      "aliases": [
        "results"
      ],
      "types": [
        "research finding"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A research finding or outcome",
      "mentions": [
        {
          "reference": "Paper-40-Section-1-Paragraph-1-Sentence-1",
          "local_name": "results",
          "local_types": [
            "research finding"
          ],
          "iri": "Entity-result-Mention-1"
        }
      ],
      "relevance": 0.454345703125
    }
  },
  "summary": "We present results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers . First , we investigate how well the addressee of a dialogue act can be predicted based on gaze , utterance and conversational context features . Then , we explore whether information about meeting context can aid classifiers ' performances . Both classifiers perform the best when conversational context and utterance features are combined with speaker 's gaze information . The classifiers show little gain from information about meeting context .",
  "triples": [
    [
      "Entity-we",
      "Predicate-present",
      "Entity-result"
    ],
    [
      "Entity-we",
      "Predicate-present",
      "Entity-result_on_addressee_identification_in_four-participants_face-to-face_meeting_using_bayesian_network_and_naive_bayes_classifier"
    ],
    [
      "Entity-the_addressee_of_a_dialogue_act",
      "Predicate-can_be_predicted_based_on",
      "Entity-gaze__utterance_and_conversational_context_feature"
    ],
    [
      "Entity-classifier",
      "Predicate-show_little_gain_from_information_about",
      "Entity-meeting_context"
    ],
    [
      "Entity-both_classifier_perform_the_best_when_conversational_context_and_utterance_feature_are_combined_with_speaker_s_gaze_information",
      "Predicate-show",
      "Entity-result_on_addressee_identification_in_four-participants_face-to-face_meeting_using_bayesian_network_and_naive_bayes_classifier"
    ],
    [
      "Entity-the_classifier",
      "Predicate-perform",
      "Entity-both_classifier_perform_the_best_when_conversational_context_and_utterance_feature_are_combined_with_speaker_s_gaze_information"
    ],
    [
      "Entity-the_classifier",
      "Predicate-use",
      "Entity-result_on_addressee_identification_in_four-participants_face-to-face_meeting_using_bayesian_network_and_naive_bayes_classifier"
    ]
  ],
  "triples_typing": [
    [
      "Entity-both_classifier",
      "skos:broader",
      "Entity-classifier"
    ],
    [
      "Entity-naive_bayes_classifier",
      "skos:broader",
      "Entity-classifier"
    ],
    [
      "Entity-the_classifier",
      "skos:broader",
      "Entity-classifier"
    ],
    [
      "Entity-addressee_identification_in_four-participants_face-to-face_meeting",
      "skos:broader",
      "Entity-meeting_context"
    ],
    [
      "Entity-both_classifier_perform_the_best_when_conversational_context_and_utterance_feature_are_combined_with_speaker_s_gaze_information",
      "skos:broader",
      "Entity-result"
    ]
  ],
  "predicates": {
    "Predicate-present": {
      "label": "present",
      "description": "The predicate 'present' indicates a state of being or existence where the subject has something to offer, display, or share with others. It implies that the subject possesses or embodies the object in some way.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_predicted_based_on": {
      "label": "can be predicted based on",
      "description": "This predicate indicates that there exists an underlying relationship or pattern between the subject (e.g., a dialogue act's addressee) and the object (e.g., gaze, utterance, and conversational context features), such that the properties of the subject can be inferred or forecasted based on those characteristics. In other words, it suggests that there is an underlying correlation or dependency between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-show_little_gain_from_information_about": {
      "label": "show little gain from information about",
      "description": "This predicate indicates that there is a lack of insight or understanding gained by considering specific contextual factors (information about), resulting in limited progress or improvement. It suggests that the subject's perspective, knowledge, or approach does not significantly benefit from taking into account the object-related context.",
      "disambiguation_index": 0
    },
    "Predicate-show": {
      "label": "show",
      "description": "To indicate the presentation or demonstration of information, data, or results from a process or analysis. The predicate 'show' connects the subject to the object by highlighting the outcome or consequence of an action, process, or investigation.",
      "disambiguation_index": 0
    },
    "Predicate-perform": {
      "label": "perform",
      "description": "To perform indicates a connection between the subject (agent or entity) and object, suggesting that the subject engages in an action or activity to achieve a specific outcome, accomplish something, or fulfill a particular role. The predicate 'perform' implies a sense of execution, realization, or manifestation, highlighting the subject's involvement in bringing about the described state or result.",
      "disambiguation_index": 0
    },
    "Predicate-use": {
      "label": "use",
      "description": "To employ or apply a resource, method, or approach to achieve a specific purpose or outcome.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' indicates that the subject is a more specific or narrower category than the object. It establishes a hierarchical relationship between the two, where the subject is a subcategory of the object.",
      "disambiguation_index": 0
    }
  }
}