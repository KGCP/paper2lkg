{
  "iri": "Paper-32",
  "title": "P03-1070",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-32-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-32-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-32-Section-1-Paragraph-1-Sentence-1",
              "text": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction ."
            },
            {
              "iri": "Paper-32-Section-1-Paragraph-1-Sentence-2",
              "text": "We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task ."
            },
            {
              "iri": "Paper-32-Section-1-Paragraph-1-Sentence-3",
              "text": "The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded , and the overall pattern reflected a monitoring of lack of negative feedback ."
            },
            {
              "iri": "Paper-32-Section-1-Paragraph-1-Sentence-4",
              "text": "Based on these results , we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.001405477523803711,
    13.42396068572998,
    20.76241707801819,
    19.4282283782959,
    0.020370006561279297,
    7.939338684082031e-05,
    9.655952453613281e-05,
    31.272914171218872,
    35.78217554092407,
    1.4467415809631348,
    1.1518330574035645,
    0.008420467376708984,
    0.00018548965454101562,
    22.02899432182312,
    1.0822727680206299,
    0.01297616958618164,
    1.0860342979431152,
    3.2776377201080322,
    3.0189545154571533,
    3.0756144523620605,
    44.16456151008606,
    3.256974220275879,
    8.700407266616821,
    0.8302934169769287,
    0.0004596710205078125,
    0.012891054153442383
  ],
  "nodes": {
    "Entity-verbal_and_nonverbal_grounding_act": {
      "node_id": "verbal_and_nonverbal_grounding_act",
      "disambiguation_index": 0,
      "label": "verbal and nonverbal grounding acts",
      "aliases": [
        "verbal and nonverbal grounding acts"
      ],
      "types": [
        "technique",
        "approach"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Verbal and nonverbal behaviors used by embodied conversational agents (ECAs) to establish common ground with humans during human-computer interaction, updating dialogue state.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-4",
          "local_name": "verbal and nonverbal grounding acts",
          "local_types": [
            "technique",
            "approach"
          ],
          "iri": "Entity-verbal_and_nonverbal_grounding_act-Mention-1"
        }
      ],
      "relevance": 0.884765625
    },
    "Entity-based_on_these_result": {
      "node_id": "based_on_these_result",
      "disambiguation_index": 0,
      "label": "Based on these results",
      "aliases": [
        "Based on these results"
      ],
      "types": [
        "study"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The presentation of a design for embodied conversational agents (ECA) that updates dialogue state using both verbal and nonverbal grounding acts.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Based on these results",
          "local_types": [
            "study"
          ],
          "iri": "Entity-based_on_these_result-Mention-1"
        }
      ],
      "relevance": 0.82958984375
    },
    "Entity-we_investigate": {
      "node_id": "we_investigate",
      "disambiguation_index": 0,
      "label": "We investigate",
      "aliases": [
        "We investigate"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The research into the verbal and nonverbal means of grounding, specifically exploring how embodied conversational agents can use both kinds of signals to establish common ground in human-computer interaction.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "We investigate",
          "local_types": [
            "research"
          ],
          "iri": "Entity-we_investigate-Mention-1"
        }
      ],
      "relevance": 0.828125
    },
    "Entity-the_verbal_and_nonverbal_mean_for_grounding": {
      "node_id": "the_verbal_and_nonverbal_mean_for_grounding",
      "disambiguation_index": 0,
      "label": "the verbal and nonverbal means for grounding",
      "aliases": [
        "the verbal and nonverbal means for grounding"
      ],
      "types": [
        "method",
        "approach",
        "methodology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The methods or approaches used by embodied conversational agents to establish a shared understanding with humans through verbal and nonverbal cues.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "the verbal and nonverbal means for grounding",
          "local_types": [
            "method",
            "approach",
            "methodology"
          ],
          "iri": "Entity-the_verbal_and_nonverbal_mean_for_grounding-Mention-1"
        }
      ],
      "relevance": 0.76318359375
    },
    "Entity-that_relies_on_both_kind_of_signal_to_establish_common_ground_in_human-computer_interaction": {
      "node_id": "that_relies_on_both_kind_of_signal_to_establish_common_ground_in_human-computer_interaction",
      "disambiguation_index": 0,
      "label": "that relies on both kinds of signals to establish common ground in human-computer interaction",
      "aliases": [
        "that relies on both kinds of signals to establish common ground in human-computer interaction"
      ],
      "types": [
        "approach"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "An approach or method that uses verbal and nonverbal cues, such as eye gaze, head nods, and attentional focus, to establish common ground in human-computer interaction.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "that relies on both kinds of signals to establish common ground in human-computer interaction",
          "local_types": [
            "approach"
          ],
          "iri": "Entity-that_relies_on_both_kind_of_signal_to_establish_common_ground_in_human-computer_interaction-Mention-1"
        }
      ],
      "relevance": 0.74267578125
    },
    "Entity-a_design_for_embodied_conversational_agent_that_relies_on_both_kind_of_signal_to_establish_common_ground_in_human-computer_interaction": {
      "node_id": "a_design_for_embodied_conversational_agent_that_relies_on_both_kind_of_signal_to_establish_common_ground_in_human-computer_interaction",
      "disambiguation_index": 0,
      "label": "a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction",
      "aliases": [
        "a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction",
        "a design for embodied conversational agents"
      ],
      "types": [
        "design",
        "technology",
        "proposal"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A proposal for designing an embodied conversational agent that uses verbal and nonverbal cues to establish common understanding between humans and computers.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction",
          "local_types": [
            "design",
            "proposal"
          ],
          "iri": "Entity-a_design_for_embodied_conversational_agent_that_relies_on_both_kind_of_signal_to_establish_common_ground_in_human-computer_interaction-Mention-1"
        },
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "a design for embodied conversational agents",
          "local_types": [
            "design",
            "technology"
          ],
          "iri": "Entity-a_design_for_embodied_conversational_agent_that_relies_on_both_kind_of_signal_to_establish_common_ground_in_human-computer_interaction-Mention-2"
        }
      ],
      "relevance": 0.72998046875
    },
    "Entity-nonverbal_mean_for_grounding": {
      "node_id": "nonverbal_mean_for_grounding",
      "disambiguation_index": 0,
      "label": "nonverbal means for grounding",
      "aliases": [
        "nonverbal means for grounding"
      ],
      "types": [
        "approach",
        "methodology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Methods or approaches used to establish shared understanding between humans and computers through non-verbal cues.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "nonverbal means for grounding",
          "local_types": [
            "approach",
            "methodology"
          ],
          "iri": "Entity-nonverbal_mean_for_grounding-Mention-1"
        }
      ],
      "relevance": 0.7255859375
    },
    "Entity-eca": {
      "node_id": "eca",
      "disambiguation_index": 0,
      "label": "ECA",
      "aliases": [
        "ECA"
      ],
      "types": [
        "algorithm",
        "concept",
        "model",
        "method"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A computational framework or approach for updating dialogue states using verbal and non-verbal cues.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-4",
          "local_name": "ECA",
          "local_types": [
            "algorithm",
            "concept",
            "model",
            "method"
          ],
          "iri": "Entity-eca-Mention-1"
        }
      ],
      "relevance": 0.71728515625
    },
    "Entity-dialogue_move_being_grounded": {
      "node_id": "dialogue_move_being_grounded",
      "disambiguation_index": 0,
      "label": "dialogue move being grounded",
      "aliases": [
        "dialogue move being grounded",
        "the type of dialogue move being grounded"
      ],
      "types": [
        "move",
        "category",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A type of conversational action or utterance in human-computer interaction, characterized by its grounding and establishment of common understanding.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-3",
          "local_name": "dialogue move being grounded",
          "local_types": [
            "category",
            "concept"
          ],
          "iri": "Entity-dialogue_move_being_grounded-Mention-1"
        },
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-3",
          "local_name": "the type of dialogue move being grounded",
          "local_types": [
            "concept",
            "move"
          ],
          "iri": "Entity-dialogue_move_being_grounded-Mention-2"
        }
      ],
      "relevance": 0.6826171875
    },
    "Entity-embodied_conversational_agent": {
      "node_id": "embodied_conversational_agent",
      "disambiguation_index": 0,
      "label": "embodied conversational agents",
      "aliases": [
        "embodied conversational agents"
      ],
      "types": [
        "system",
        "concept",
        "technology",
        "artificial intelligence",
        "computer science"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Computer-generated entities that combine artificial intelligence with physical embodiment, designed to engage in natural language conversations and nonverbal interactions.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "embodied conversational agents",
          "local_types": [
            "system",
            "concept",
            "technology",
            "artificial intelligence",
            "computer science"
          ],
          "iri": "Entity-embodied_conversational_agent-Mention-1"
        }
      ],
      "relevance": 0.66650390625
    },
    "Entity-the_distribution": {
      "node_id": "the_distribution",
      "disambiguation_index": 0,
      "label": "The distribution",
      "aliases": [
        "The distribution"
      ],
      "types": [
        "study"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A statistical analysis or visualization of the patterns in nonverbal behaviors (e.g., eye gaze, head nods) that differed depending on the type of dialogue move being grounded.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-3",
          "local_name": "The distribution",
          "local_types": [
            "study"
          ],
          "iri": "Entity-the_distribution-Mention-1"
        }
      ],
      "relevance": 0.65966796875
    },
    "Entity-eye_gaze__head_nod_and_attentional_focus": {
      "node_id": "eye_gaze__head_nod_and_attentional_focus",
      "disambiguation_index": 0,
      "label": "eye gaze, head nods and attentional focus",
      "aliases": [
        "eye gaze, head nods and attentional focus"
      ],
      "types": [
        "behavior",
        "phenomenon"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A nonverbal behavior characterized by visual cues, bodily gestures, and cognitive processes that indicate an individual's engagement or disengagement with their environment.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-2",
          "local_name": "eye gaze, head nods and attentional focus",
          "local_types": [
            "behavior",
            "phenomenon"
          ],
          "iri": "Entity-eye_gaze__head_nod_and_attentional_focus-Mention-1"
        }
      ],
      "relevance": 0.6474609375
    },
    "Entity-head_nod": {
      "node_id": "head_nod",
      "disambiguation_index": 0,
      "label": "head nods",
      "aliases": [
        "head nods"
      ],
      "types": [
        "nonverbal cue",
        "behavioral signal",
        "concept",
        "body language",
        "behavioral phenomenon",
        "behavioral measure",
        "behavioral trait",
        "nonverbal behavior",
        "phenomenon"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A subtle movement or gesture involving the human head that conveys meaning without spoken language.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-2",
          "local_name": "head nods",
          "local_types": [
            "nonverbal cue",
            "behavioral signal",
            "concept",
            "body language",
            "behavioral phenomenon",
            "behavioral measure",
            "behavioral trait",
            "nonverbal behavior",
            "phenomenon"
          ],
          "iri": "Entity-head_nod-Mention-1"
        }
      ],
      "relevance": 0.638671875
    },
    "Entity-nonverbal_behavior": {
      "node_id": "nonverbal_behavior",
      "disambiguation_index": 0,
      "label": "nonverbal behaviors",
      "aliases": [
        "nonverbal behaviors"
      ],
      "types": [
        "signals",
        "social behavior",
        "behaviors",
        "communication method",
        "behavior"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A form of communication that conveys meaning without using words",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-3",
          "local_name": "nonverbal behaviors",
          "local_types": [
            "signals",
            "social behavior",
            "behaviors",
            "communication method",
            "behavior"
          ],
          "iri": "Entity-nonverbal_behavior-Mention-1"
        }
      ],
      "relevance": 0.63427734375
    },
    "Entity-dialogue_move": {
      "node_id": "dialogue_move",
      "disambiguation_index": 0,
      "label": "dialogue move",
      "aliases": [
        "dialogue move"
      ],
      "types": [
        "speech act",
        "linguistic phenomenon",
        "communication act"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A deliberate verbal or non-verbal action that conveys meaning in an interaction.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-3",
          "local_name": "dialogue move",
          "local_types": [
            "speech act",
            "linguistic phenomenon",
            "communication act"
          ],
          "iri": "Entity-dialogue_move-Mention-1"
        }
      ],
      "relevance": 0.6025390625
    },
    "Entity-we_(1)": {
      "node_id": "we_(1)",
      "disambiguation_index": 1,
      "label": "We",
      "aliases": [
        "We"
      ],
      "types": [
        "author"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The authors or researchers conducting an analysis on eye gaze, head nods, and attentional focus in the context of a direction-giving task.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-2",
          "local_name": "We",
          "local_types": [
            "author"
          ],
          "iri": "Entity-we_(1)-Mention-1"
        }
      ],
      "relevance": 0.59228515625
    },
    "Entity-eye_gaze": {
      "node_id": "eye_gaze",
      "disambiguation_index": 0,
      "label": "eye gaze",
      "aliases": [
        "eye gaze"
      ],
      "types": [
        "nonverbal cue",
        "biological phenomenon",
        "measure",
        "behavioral signal",
        "concept",
        "biometric",
        "behavioral trait",
        "physiological response",
        "phenomenon"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The act or process by which an individual directs their visual attention towards something.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-2",
          "local_name": "eye gaze",
          "local_types": [
            "nonverbal cue",
            "biological phenomenon",
            "measure",
            "behavioral signal",
            "concept",
            "biometric",
            "behavioral trait",
            "physiological response",
            "phenomenon"
          ],
          "iri": "Entity-eye_gaze-Mention-1"
        }
      ],
      "relevance": 0.56884765625
    },
    "Entity-grounding": {
      "node_id": "grounding",
      "disambiguation_index": 0,
      "label": "grounding",
      "aliases": [
        "grounding"
      ],
      "types": [
        "concept",
        "theory"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process or act of establishing a shared understanding, connection, or basis for communication between two entities.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "grounding",
          "local_types": [
            "concept",
            "theory"
          ],
          "iri": "Entity-grounding-Mention-1"
        }
      ],
      "relevance": 0.568359375
    },
    "Entity-human-computer_interaction": {
      "node_id": "human-computer_interaction",
      "disambiguation_index": 0,
      "label": "human-computer interaction",
      "aliases": [
        "human-computer interaction"
      ],
      "types": [
        "research area",
        "computing discipline",
        "field of study",
        "field",
        "domain"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The study or practice of designing interfaces between humans and computers, enabling effective communication and collaboration.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "human-computer interaction",
          "local_types": [
            "research area",
            "computing discipline",
            "field of study",
            "field",
            "domain"
          ],
          "iri": "Entity-human-computer_interaction-Mention-1"
        }
      ],
      "relevance": 0.54296875
    },
    "Entity-dialogue_state": {
      "node_id": "dialogue_state",
      "disambiguation_index": 0,
      "label": "dialogue state",
      "aliases": [
        "dialogue state"
      ],
      "types": [
        "state",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A current situation or status within a conversation",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-4",
          "local_name": "dialogue state",
          "local_types": [
            "state",
            "information"
          ],
          "iri": "Entity-dialogue_state-Mention-1"
        }
      ],
      "relevance": 0.54296875
    },
    "Entity-the_context_of_a_direction-giving_task": {
      "node_id": "the_context_of_a_direction-giving_task",
      "disambiguation_index": 0,
      "label": "the context of a direction-giving task",
      "aliases": [
        "the context of a direction-giving task"
      ],
      "types": [
        "task",
        "study design",
        "experimental setup",
        "context"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The situation in which someone provides instructions, guidance, or directions to achieve a specific goal or objective.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-2",
          "local_name": "the context of a direction-giving task",
          "local_types": [
            "task",
            "study design",
            "experimental setup",
            "context"
          ],
          "iri": "Entity-the_context_of_a_direction-giving_task-Mention-1"
        }
      ],
      "relevance": 0.537109375
    },
    "Entity-attentional_focus": {
      "node_id": "attentional_focus",
      "disambiguation_index": 0,
      "label": "attentional focus",
      "aliases": [
        "attentional focus"
      ],
      "types": [
        "nonverbal cue",
        "cognitive process",
        "cognitive state",
        "behavioral signal",
        "concept",
        "perceptual process",
        "behavioral trait",
        "mental state",
        "phenomenon"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A mental state or process characterized by concentrated awareness on something.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-2",
          "local_name": "attentional focus",
          "local_types": [
            "nonverbal cue",
            "cognitive process",
            "cognitive state",
            "behavioral signal",
            "concept",
            "perceptual process",
            "behavioral trait",
            "mental state",
            "phenomenon"
          ],
          "iri": "Entity-attentional_focus-Mention-1"
        }
      ],
      "relevance": 0.53369140625
    },
    "Entity-direction-giving_task": {
      "node_id": "direction-giving_task",
      "disambiguation_index": 0,
      "label": "direction-giving task",
      "aliases": [
        "direction-giving task"
      ],
      "types": [
        "task",
        "activity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The activity or process of providing instructions for navigation or movement.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-2",
          "local_name": "direction-giving task",
          "local_types": [
            "task",
            "activity"
          ],
          "iri": "Entity-direction-giving_task-Mention-1"
        }
      ],
      "relevance": 0.49365234375
    },
    "Entity-lack_of_negative_feedback": {
      "node_id": "lack_of_negative_feedback",
      "disambiguation_index": 0,
      "label": "lack of negative feedback",
      "aliases": [
        "lack of negative feedback"
      ],
      "types": [
        "feedback",
        "evaluation process",
        "feedback mechanism",
        "phenomenon"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The absence or scarcity of unfavorable opinions or assessments.",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-3",
          "local_name": "lack of negative feedback",
          "local_types": [
            "feedback",
            "evaluation process",
            "feedback mechanism",
            "phenomenon"
          ],
          "iri": "Entity-lack_of_negative_feedback-Mention-1"
        }
      ],
      "relevance": 0.48486328125
    },
    "Entity-we": {
      "node_id": "we",
      "disambiguation_index": 0,
      "label": "We",
      "aliases": [
        "We"
      ],
      "types": [
        "researcher",
        "author"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A group or collective of researchers or authors",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-1",
          "local_name": "We",
          "local_types": [
            "researcher",
            "author"
          ],
          "iri": "Entity-we-Mention-1"
        }
      ],
      "relevance": 0.429443359375
    },
    "Entity-distribution": {
      "node_id": "distribution",
      "disambiguation_index": 0,
      "label": "distribution",
      "aliases": [
        "distribution"
      ],
      "types": [
        "statistical concept",
        "pattern"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A statistical arrangement or pattern of data",
      "mentions": [
        {
          "reference": "Paper-32-Section-1-Paragraph-1-Sentence-3",
          "local_name": "distribution",
          "local_types": [
            "statistical concept",
            "pattern"
          ],
          "iri": "Entity-distribution-Mention-1"
        }
      ],
      "relevance": 0.39697265625
    }
  },
  "summary": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction . We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task . The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded , and the overall pattern reflected a monitoring of lack of negative feedback . Based on these results , we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state .",
  "triples": [
    [
      "Entity-we",
      "Predicate-investigate",
      "Entity-the_verbal_and_nonverbal_mean_for_grounding"
    ],
    [
      "Entity-nonverbal_behavior",
      "Predicate-differed_depending_on",
      "Entity-dialogue_move_being_grounded"
    ],
    [
      "Entity-the_distribution",
      "Predicate-reflected_a_monitoring_of",
      "Entity-lack_of_negative_feedback"
    ],
    [
      "Entity-eca",
      "Predicate-uses",
      "Entity-verbal_and_nonverbal_grounding_act"
    ],
    [
      "Entity-verbal_and_nonverbal_grounding_act",
      "Predicate-update",
      "Entity-dialogue_state"
    ],
    [
      "Entity-verbal_and_nonverbal_grounding_act",
      "Predicate-present",
      "Entity-based_on_these_result"
    ]
  ],
  "triples_typing": [
    [
      "Entity-head_nod",
      "skos:broader",
      "Entity-nonverbal_behavior"
    ]
  ],
  "predicates": {
    "Predicate-investigate": {
      "label": "investigate",
      "description": "To investigate a predicate is to engage in systematic examination or inquiry into its nature, properties, or underlying mechanisms. This process typically involves gathering information, analyzing data, and drawing conclusions about the object of investigation.",
      "disambiguation_index": 0
    },
    "Predicate-differed_depending_on": {
      "label": "differed depending on",
      "description": "The predicate 'differed depending on' indicates a relationship where the subject's characteristics or properties vary according to some underlying factor or condition specified by the object. In general, it suggests that there exists a correlation between the subject and the object such that the former is influenced or shaped in some way by the latter.",
      "disambiguation_index": 0
    },
    "Predicate-reflected_a_monitoring_of": {
      "label": "reflected a monitoring of",
      "description": "This predicate indicates that the subject's characteristics or properties are mirrored or represented by the object. The object serves as an indicator or proxy for understanding the subject, providing insight into its nature or behavior.",
      "disambiguation_index": 0
    },
    "Predicate-uses": {
      "label": "uses",
      "description": "The predicate 'uses' indicates a relationship of utilization or application between the subject (ECA) and object (verbal and nonverbal grounding acts), suggesting that ECA employs, exploits, or makes use of these acts for some purpose.",
      "disambiguation_index": 0
    },
    "Predicate-update": {
      "label": "update",
      "description": "The predicate 'update' represents an action that modifies or changes the current state of something (the object), typically based on new information or input provided by the subject. This process involves adjusting, refining, or correcting the existing state to reflect a more accurate or up-to-date understanding.",
      "disambiguation_index": 0
    },
    "Predicate-present": {
      "label": "present",
      "description": "The predicate 'present' indicates a state of being or existence that connects the subject to the object. It suggests that the information provided by the object (Based on these results) is currently relevant, applicable, or valid with respect to the verbal and nonverbal grounding acts performed.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' indicates that the subject is related to or encompasses the object as a more general category. It suggests a hierarchical relationship between the two, where the subject represents a higher-level concept and the object represents a lower-level concept within its scope.",
      "disambiguation_index": 0
    }
  }
}