[
  {
  "question": "What is the primary goal of applying a data mining model to the 2019 grant applications as described in the paper?",
  "answer": "The primary goal is to predict high IC-score research proposals based on the IC scores assigned by expert reviewers and to develop a predictive vocabulary for contemporaneous proposals."
  },
  {
  "question": "Which classifiers are used for experimental comparison in the study?",
  "answer": "The Decision Tree (DT) and Random Forest (RF) classifiers are used for experimental comparison."
  },
  {
  "question": "What is the accuracy achieved by the proposed model for predicting high IC-score research proposals?",
  "answer": "The proposed model achieves an accuracy of 84.17% across all types of grant applications."
  },
  {
  "question": "What is the modified TF-IDF algorithm proposed in the paper and how does it differ from the traditional TF-IDF?",
  "answer": "The modified TF-IDF algorithm only implements the IDF part of TF-IDF, assigning the IDF value to a term if it exists in the documents and a value of 0 if it does not. This differs from the traditional TF-IDF, which uses both term frequency (TF) and inverse document frequency (IDF)."
  },
  {
  "question": "What is the median IC score of the research proposals in the dataset?",
  "answer": "The median IC score of the research proposals is 5.0."
  },
  {
  "question": "What text pre-processing techniques are applied to the grant applications?",
  "answer": "The text pre-processing techniques include converting all characters to lowercase, removing numbers, removing punctuations, tokenizing by whitespace, deleting stop words, and applying text stemming using the Porter Stemming algorithm."
  },
  {
  "question": "What is the purpose of the Metadata Extractor & Loader (MEL) tool mentioned in the paper?",
  "answer": "The MEL tool is used to extract text from PDF research proposals and save it in a JSON file with metadata sets and content."
  },
  {
  "question": "What are the evaluation metrics used to assess the performance of the data mining models?",
  "answer": "The evaluation metrics used are classification accuracy (Acc) and F1 score."
  },
  {
  "question": "What is the range of IC scores considered for low IC-score research proposals in the experiments?",
  "answer": "The range of IC scores considered for low IC-score research proposals is 0~15%."
  },
  {
  "question": "What is the accuracy of the proposed model when applied to the 'Innovation and Creativity statement' sections of Ideas Grants?",
  "answer": "The proposed model achieves an accuracy of 68.33% when applied to the 'Innovation and Creativity statement' sections of Ideas Grants."
  }
 ]