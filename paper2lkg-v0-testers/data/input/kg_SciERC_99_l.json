{
  "iri": "Paper-99",
  "title": "CVPR_2003_30_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-99-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-99-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-1",
              "text": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-2",
              "text": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-3",
              "text": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-4",
              "text": "Preliminary modeling and recognition results are presented ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.00022268295288085938,
    17.12142848968506,
    23.3587806224823,
    21.97526264190674,
    0.027019500732421875,
    9.202957153320312e-05,
    0.00011491775512695312,
    47.86089730262756,
    51.53466200828552,
    1.7258427143096924,
    1.1984913349151611,
    0.011288642883300781,
    0.00019788742065429688,
    24.472090005874634,
    3.912186622619629,
    0.01533961296081543,
    1.0892198085784912,
    3.425365686416626,
    7.600800514221191,
    8.832561731338501,
    49.39793920516968,
    3.5454790592193604,
    26.43271827697754,
    1.2577989101409912,
    0.0007631778717041016,
    0.012813568115234375
  ],
  "nodes": {
    "Entity-the_proposed_approach": {
      "node_id": "the_proposed_approach",
      "disambiguation_index": 0,
      "label": "The proposed approach",
      "aliases": [
        "The proposed approach"
      ],
      "types": [
        "approach"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A novel representation for three-dimensional objects that combines affine-invariant image patches, spatial relationships, and multi-view constraints without requiring a separate segmentation stage.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "The proposed approach",
          "local_types": [
            "approach"
          ],
          "iri": "Entity-the_proposed_approach-Mention-1"
        }
      ],
      "relevance": 0.8369140625
    },
    "Entity-a_novel_representation_for_three-dimensional_object": {
      "node_id": "a_novel_representation_for_three-dimensional_object",
      "disambiguation_index": 0,
      "label": "a novel representation for three-dimensional objects",
      "aliases": [
        "a novel representation for three-dimensional objects"
      ],
      "types": [
        "representation",
        "3D object"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A method that represents three-dimensional objects using affine-invariant image patches and their spatial relationships, enabling true 3D model acquisition from multiple images and recognition in a single photograph.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "a novel representation for three-dimensional objects",
          "local_types": [
            "representation",
            "3D object"
          ],
          "iri": "Entity-a_novel_representation_for_three-dimensional_object-Mention-1"
        }
      ],
      "relevance": 0.80810546875
    },
    "Entity-in_term_of_affine-invariant_image_patch_and_their_spatial_relationship": {
      "node_id": "in_term_of_affine-invariant_image_patch_and_their_spatial_relationship",
      "disambiguation_index": 0,
      "label": "in terms of affine-invariant image patches and their spatial relationships",
      "aliases": [
        "in terms of affine-invariant image patches and their spatial relationships"
      ],
      "types": [
        "methodology",
        "image processing"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A methodological approach that represents three-dimensional objects using invariant image patches and their spatial connections.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "in terms of affine-invariant image patches and their spatial relationships",
          "local_types": [
            "methodology",
            "image processing"
          ],
          "iri": "Entity-in_term_of_affine-invariant_image_patch_and_their_spatial_relationship-Mention-1"
        }
      ],
      "relevance": 0.80029296875
    },
    "Entity-affine-invariant_image_patch": {
      "node_id": "affine-invariant_image_patch",
      "disambiguation_index": 0,
      "label": "affine-invariant image patches",
      "aliases": [
        "affine-invariant image patches"
      ],
      "types": [
        "image processing technique",
        "image processing",
        "computer vision",
        "computer vision concept",
        "technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A set of image regions that remain unchanged under different viewpoints, used to represent three-dimensional objects.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "affine-invariant image patches",
          "local_types": [
            "image processing technique",
            "image processing",
            "computer vision",
            "computer vision concept",
            "technique"
          ],
          "iri": "Entity-affine-invariant_image_patch-Mention-1"
        }
      ],
      "relevance": 0.763671875
    },
    "Entity-acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image": {
      "node_id": "acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image",
      "disambiguation_index": 0,
      "label": "acquisition of true three-dimensional affine and Euclidean models from multiple images",
      "aliases": [
        "the acquisition of true three-dimensional affine and Euclidean models from multiple images",
        "acquisition of true three-dimensional affine and Euclidean models from multiple images"
      ],
      "types": [
        "acquisition",
        "image",
        "3D model",
        "model",
        "model acquisition"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A method that reconstructs true three-dimensional affine and Euclidean models of objects from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "acquisition of true three-dimensional affine and Euclidean models from multiple images",
          "local_types": [
            "3D model",
            "model acquisition"
          ],
          "iri": "Entity-acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "the acquisition of true three-dimensional affine and Euclidean models from multiple images",
          "local_types": [
            "acquisition",
            "model",
            "image"
          ],
          "iri": "Entity-acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image-Mention-2"
        }
      ],
      "relevance": 0.74169921875
    },
    "Entity-multi-view_constraint_associated_with_group_of_patch": {
      "node_id": "multi-view_constraint_associated_with_group_of_patch",
      "disambiguation_index": 0,
      "label": "Multi-view constraints associated with groups of patches",
      "aliases": [
        "Multi-view constraints associated with groups of patches"
      ],
      "types": [
        "patch group",
        "constraint"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A set of spatial relationships between image patch clusters that guide matching and reconstruction processes in three-dimensional object recognition.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "Multi-view constraints associated with groups of patches",
          "local_types": [
            "patch group",
            "constraint"
          ],
          "iri": "Entity-multi-view_constraint_associated_with_group_of_patch-Mention-1"
        }
      ],
      "relevance": 0.7412109375
    },
    "Entity-three-dimensional_affine_and_euclidean_model": {
      "node_id": "three-dimensional_affine_and_euclidean_model",
      "disambiguation_index": 0,
      "label": "three-dimensional affine and Euclidean models",
      "aliases": [
        "true three-dimensional affine and Euclidean models",
        "three-dimensional affine and Euclidean models"
      ],
      "types": [
        "models",
        "representation",
        "concept",
        "geometry",
        "model",
        "shape"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Three-dimensional geometric representations that combine both affine transformations (preserving straight lines) and Euclidean transformations (preserving distances and angles).",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "three-dimensional affine and Euclidean models",
          "local_types": [
            "models",
            "representation",
            "concept",
            "geometry",
            "model",
            "shape"
          ],
          "iri": "Entity-three-dimensional_affine_and_euclidean_model-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "true three-dimensional affine and Euclidean models",
          "local_types": [
            "model",
            "geometry"
          ],
          "iri": "Entity-three-dimensional_affine_and_euclidean_model-Mention-2"
        }
      ],
      "relevance": 0.74072265625
    },
    "Entity-normalized_representation_of_their_appearance": {
      "node_id": "normalized_representation_of_their_appearance",
      "disambiguation_index": 0,
      "label": "normalized representation of their appearance",
      "aliases": [
        "normalized representation of their appearance"
      ],
      "types": [
        "representation",
        "computer vision",
        "appearance",
        "image processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A mathematical model that combines multi-view constraints with spatial relationships and image patch appearances to guide object recognition and reconstruction from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "normalized representation of their appearance",
          "local_types": [
            "representation",
            "computer vision",
            "appearance",
            "image processing"
          ],
          "iri": "Entity-normalized_representation_of_their_appearance-Mention-1"
        }
      ],
      "relevance": 0.74072265625
    },
    "Entity-group_of_patch": {
      "node_id": "group_of_patch",
      "disambiguation_index": 0,
      "label": "groups of patches",
      "aliases": [
        "groups of patches"
      ],
      "types": [
        "collection",
        "computer vision",
        "concept",
        "grouping",
        "data set",
        "group",
        "data structure",
        "patch"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Sets of image patches that are used to represent three-dimensional objects and guide matching and reconstruction processes in computer vision applications.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "groups of patches",
          "local_types": [
            "collection",
            "computer vision",
            "concept",
            "grouping",
            "data set",
            "group",
            "data structure",
            "patch"
          ],
          "iri": "Entity-group_of_patch-Mention-1"
        }
      ],
      "relevance": 0.7265625
    },
    "Entity-affine-invariant_image_patch_and_their_spatial_relationship": {
      "node_id": "affine-invariant_image_patch_and_their_spatial_relationship",
      "disambiguation_index": 0,
      "label": "affine-invariant image patches and their spatial relationships",
      "aliases": [
        "affine-invariant image patches and their spatial relationships"
      ],
      "types": [
        "spatial relationship",
        "image patch"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Sets of images with similar features, connected by geometrically meaningful relationships.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "affine-invariant image patches and their spatial relationships",
          "local_types": [
            "spatial relationship",
            "image patch"
          ],
          "iri": "Entity-affine-invariant_image_patch_and_their_spatial_relationship-Mention-1"
        }
      ],
      "relevance": 0.72412109375
    },
    "Entity-appearance": {
      "node_id": "appearance",
      "disambiguation_index": 0,
      "label": "appearance",
      "aliases": [
        "appearance"
      ],
      "types": [
        "attribute",
        "visual feature",
        "image processing",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A normalized representation of image patches' visual features used to guide matching and reconstruction in three-dimensional object recognition.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "appearance",
          "local_types": [
            "attribute",
            "visual feature",
            "image processing",
            "property"
          ],
          "iri": "Entity-appearance-Mention-1"
        }
      ],
      "relevance": 0.72119140625
    },
    "Entity-guide_matching_and_reconstruction": {
      "node_id": "guide_matching_and_reconstruction",
      "disambiguation_index": 0,
      "label": "guide matching and reconstruction",
      "aliases": [
        "guide matching and reconstruction"
      ],
      "types": [
        "process",
        "reconstruction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A process that combines multi-view constraints with normalized patch appearance to facilitate the alignment of image patches across multiple views, enabling the construction of 3D models from images taken from arbitrary viewpoints.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "guide matching and reconstruction",
          "local_types": [
            "process",
            "reconstruction"
          ],
          "iri": "Entity-guide_matching_and_reconstruction-Mention-1"
        }
      ],
      "relevance": 0.71923828125
    },
    "Entity-applicable_to_cluttered_scene": {
      "node_id": "applicable_to_cluttered_scene",
      "disambiguation_index": 0,
      "label": "applicable to cluttered scenes",
      "aliases": [
        "applicable to cluttered scenes"
      ],
      "types": [
        "cluttered scene",
        "scene type"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A representation for three-dimensional objects that can be used without requiring a separate segmentation step, suitable for use with complex or disorganized scenes.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "applicable to cluttered scenes",
          "local_types": [
            "cluttered scene",
            "scene type"
          ],
          "iri": "Entity-applicable_to_cluttered_scene-Mention-1"
        }
      ],
      "relevance": 0.71484375
    },
    "Entity-novel_representation_for_three-dimensional_object": {
      "node_id": "novel_representation_for_three-dimensional_object",
      "disambiguation_index": 0,
      "label": "novel representation for three-dimensional objects",
      "aliases": [
        "novel representation for three-dimensional objects"
      ],
      "types": [
        "representation",
        "3D object"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A method or technique used to depict or describe three-dimensional objects",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "novel representation for three-dimensional objects",
          "local_types": [
            "representation",
            "3D object"
          ],
          "iri": "Entity-novel_representation_for_three-dimensional_object-Mention-1"
        }
      ],
      "relevance": 0.646484375
    },
    "Entity-cluttered_scene": {
      "node_id": "cluttered_scene",
      "disambiguation_index": 0,
      "label": "cluttered scenes",
      "aliases": [
        "cluttered scenes"
      ],
      "types": [
        "scene",
        "scenes",
        "environment"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Three-dimensional environments or settings with disorganized or messy arrangements of objects, people, or other visual elements.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "cluttered scenes",
          "local_types": [
            "scene",
            "scenes",
            "environment"
          ],
          "iri": "Entity-cluttered_scene-Mention-1"
        }
      ],
      "relevance": 0.63623046875
    },
    "Entity-a_normalized_representation_of_their_appearance": {
      "node_id": "a_normalized_representation_of_their_appearance",
      "disambiguation_index": 0,
      "label": "a normalized representation of their appearance",
      "aliases": [
        "a normalized representation of their appearance"
      ],
      "types": [
        "representation",
        "appearance"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A mathematical representation that captures the essential features of an object's visual appearance, normalized to be invariant under certain transformations.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "a normalized representation of their appearance",
          "local_types": [
            "representation",
            "appearance"
          ],
          "iri": "Entity-a_normalized_representation_of_their_appearance-Mention-1"
        }
      ],
      "relevance": 0.62890625
    },
    "Entity-multi-view_constraint": {
      "node_id": "multi-view_constraint",
      "disambiguation_index": 0,
      "label": "Multi-view constraints",
      "aliases": [
        "Multi-view constraints",
        "multi-view constraints"
      ],
      "types": [
        "constraint",
        "image processing",
        "algorithm",
        "computer vision",
        "concept",
        "method"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A set of rules or guidelines that utilize information from multiple views to constrain the processing, reconstruction, or matching of images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "Multi-view constraints",
          "local_types": [
            "constraint",
            "image processing",
            "algorithm",
            "computer vision",
            "concept",
            "method"
          ],
          "iri": "Entity-multi-view_constraint-Mention-1"
        }
      ],
      "relevance": 0.62744140625
    },
    "Entity-multiple_image": {
      "node_id": "multiple_image",
      "disambiguation_index": 0,
      "label": "multiple images",
      "aliases": [
        "multiple images"
      ],
      "types": [
        "collection",
        "image processing",
        "image",
        "computer vision",
        "data set",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A set or collection of two or more visual representations, typically photographs.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "multiple images",
          "local_types": [
            "collection",
            "image processing",
            "image",
            "computer vision",
            "data set",
            "data type"
          ],
          "iri": "Entity-multiple_image-Mention-1"
        }
      ],
      "relevance": 0.61572265625
    },
    "Entity-normalized_representation": {
      "node_id": "normalized_representation",
      "disambiguation_index": 0,
      "label": "normalized representation",
      "aliases": [
        "normalized representation"
      ],
      "types": [
        "technique",
        "representation",
        "image processing",
        "pattern recognition"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A mathematical representation that normalizes data to facilitate pattern recognition, image processing, or other techniques.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "normalized representation",
          "local_types": [
            "technique",
            "representation",
            "image processing",
            "pattern recognition"
          ],
          "iri": "Entity-normalized_representation-Mention-1"
        }
      ],
      "relevance": 0.615234375
    },
    "Entity-recognition_in_a_single_photograph_taken_from_an_arbitrary_viewpoint": {
      "node_id": "recognition_in_a_single_photograph_taken_from_an_arbitrary_viewpoint",
      "disambiguation_index": 0,
      "label": "recognition in a single photograph taken from an arbitrary viewpoint",
      "aliases": [
        "recognition in a single photograph taken from an arbitrary viewpoint",
        "their recognition in a single photograph taken from an arbitrary viewpoint"
      ],
      "types": [
        "photograph",
        "viewpoint",
        "recognition",
        "photograph recognition",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of identifying or verifying something based on its appearance in a single image, regardless of the camera angle.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "recognition in a single photograph taken from an arbitrary viewpoint",
          "local_types": [
            "process",
            "photograph recognition"
          ],
          "iri": "Entity-recognition_in_a_single_photograph_taken_from_an_arbitrary_viewpoint-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "their recognition in a single photograph taken from an arbitrary viewpoint",
          "local_types": [
            "recognition",
            "photograph",
            "viewpoint"
          ],
          "iri": "Entity-recognition_in_a_single_photograph_taken_from_an_arbitrary_viewpoint-Mention-2"
        }
      ],
      "relevance": 0.609375
    },
    "Entity-three-dimensional_object": {
      "node_id": "three-dimensional_object",
      "disambiguation_index": 0,
      "label": "three-dimensional objects",
      "aliases": [
        "three-dimensional objects"
      ],
      "types": [
        "object",
        "geometric shape",
        "3D model",
        "concept",
        "geometry",
        "objects",
        "shape"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Three-dimensional geometric shapes or models that have length, width, and depth.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "three-dimensional objects",
          "local_types": [
            "object",
            "geometric shape",
            "3D model",
            "concept",
            "geometry",
            "objects",
            "shape"
          ],
          "iri": "Entity-three-dimensional_object-Mention-1"
        }
      ],
      "relevance": 0.60693359375
    },
    "Entity-matching_and_reconstruction": {
      "node_id": "matching_and_reconstruction",
      "disambiguation_index": 0,
      "label": "matching and reconstruction",
      "aliases": [
        "matching and reconstruction"
      ],
      "types": [
        "algorithm",
        "computer vision",
        "process",
        "method",
        "procedure"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A process or method that combines matching and reconstruction techniques to achieve a specific goal, often used in computer vision applications.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "matching and reconstruction",
          "local_types": [
            "algorithm",
            "computer vision",
            "process",
            "method",
            "procedure"
          ],
          "iri": "Entity-matching_and_reconstruction-Mention-1"
        }
      ],
      "relevance": 0.60498046875
    },
    "Entity-single_photograph_taken_from_an_arbitrary_viewpoint": {
      "node_id": "single_photograph_taken_from_an_arbitrary_viewpoint",
      "disambiguation_index": 0,
      "label": "single photograph taken from an arbitrary viewpoint",
      "aliases": [
        "single photograph taken from an arbitrary viewpoint"
      ],
      "types": [
        "visual data",
        "image processing",
        "image",
        "photograph",
        "computer vision",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A two-dimensional visual representation captured from any angle.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "single photograph taken from an arbitrary viewpoint",
          "local_types": [
            "visual data",
            "image processing",
            "image",
            "photograph",
            "computer vision",
            "data type"
          ],
          "iri": "Entity-single_photograph_taken_from_an_arbitrary_viewpoint-Mention-1"
        }
      ],
      "relevance": 0.6044921875
    },
    "Entity-preliminary_modeling_and_recognition_result_are_presented": {
      "node_id": "preliminary_modeling_and_recognition_result_are_presented",
      "disambiguation_index": 0,
      "label": "Preliminary modeling and recognition results are presented",
      "aliases": [
        "Preliminary modeling and recognition results are presented",
        "recognition results are presented"
      ],
      "types": [
        "results",
        "result presentation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The preliminary outcomes of object modeling and recognition processes.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Preliminary modeling and recognition results are presented",
          "local_types": [
            "result presentation"
          ],
          "iri": "Entity-preliminary_modeling_and_recognition_result_are_presented-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "recognition results are presented",
          "local_types": [
            "results"
          ],
          "iri": "Entity-preliminary_modeling_and_recognition_result_are_presented-Mention-2"
        }
      ],
      "relevance": 0.5869140625
    },
    "Entity-novel_representation": {
      "node_id": "novel_representation",
      "disambiguation_index": 0,
      "label": "novel representation",
      "aliases": [
        "novel representation"
      ],
      "types": [
        "mathematical concept",
        "algorithm",
        "methodology",
        "method",
        "approach"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A new way to represent or describe something",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "novel representation",
          "local_types": [
            "mathematical concept",
            "algorithm",
            "methodology",
            "method",
            "approach"
          ],
          "iri": "Entity-novel_representation-Mention-1"
        }
      ],
      "relevance": 0.5791015625
    },
    "Entity-spatial_relationship": {
      "node_id": "spatial_relationship",
      "disambiguation_index": 0,
      "label": "spatial relationships",
      "aliases": [
        "spatial relationships"
      ],
      "types": [
        "mathematical concept",
        "relationship",
        "geometry",
        "pattern recognition",
        "geometric relationship",
        "mathematics"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A mathematical concept that describes the connections or patterns between locations, shapes, or positions in space.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "spatial relationships",
          "local_types": [
            "mathematical concept",
            "relationship",
            "geometry",
            "pattern recognition",
            "geometric relationship",
            "mathematics"
          ],
          "iri": "Entity-spatial_relationship-Mention-1"
        }
      ],
      "relevance": 0.55908203125
    },
    "Entity-preliminary_modeling": {
      "node_id": "preliminary_modeling",
      "disambiguation_index": 0,
      "label": "Preliminary modeling",
      "aliases": [
        "Preliminary modeling"
      ],
      "types": [
        "modeling",
        "research method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of creating an initial or early-stage conceptual representation or framework for a system, concept, or phenomenon.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Preliminary modeling",
          "local_types": [
            "modeling",
            "research method"
          ],
          "iri": "Entity-preliminary_modeling-Mention-1"
        }
      ],
      "relevance": 0.55908203125
    },
    "Entity-proposed_approach_doe_not_require_a_separate_segmentation_stage": {
      "node_id": "proposed_approach_doe_not_require_a_separate_segmentation_stage",
      "disambiguation_index": 0,
      "label": "proposed approach does not require a separate segmentation stage",
      "aliases": [
        "proposed approach does not require a separate segmentation stage"
      ],
      "types": [
        "approach",
        "segmentation-free"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A method or technique that eliminates the need for segmenting data into distinct parts.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "proposed approach does not require a separate segmentation stage",
          "local_types": [
            "approach",
            "segmentation-free"
          ],
          "iri": "Entity-proposed_approach_doe_not_require_a_separate_segmentation_stage-Mention-1"
        }
      ],
      "relevance": 0.521484375
    },
    "Entity-segmentation_stage": {
      "node_id": "segmentation_stage",
      "disambiguation_index": 0,
      "label": "segmentation stage",
      "aliases": [
        "a separate segmentation stage",
        "segmentation stage"
      ],
      "types": [
        "stage",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A step in a process that involves dividing or separating something into distinct parts.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "segmentation stage",
          "local_types": [
            "process",
            "stage"
          ],
          "iri": "Entity-segmentation_stage-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "a separate segmentation stage",
          "local_types": [
            "stage"
          ],
          "iri": "Entity-segmentation_stage-Mention-2"
        }
      ],
      "relevance": 0.509765625
    },
    "Entity-proposed_approach": {
      "node_id": "proposed_approach",
      "disambiguation_index": 0,
      "label": "proposed approach",
      "aliases": [
        "proposed approach"
      ],
      "types": [
        "methodology",
        "algorithm"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A methodology or algorithm for solving a problem or achieving an objective.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "proposed approach",
          "local_types": [
            "methodology",
            "algorithm"
          ],
          "iri": "Entity-proposed_approach-Mention-1"
        }
      ],
      "relevance": 0.50634765625
    },
    "Entity-recognition_result": {
      "node_id": "recognition_result",
      "disambiguation_index": 0,
      "label": "recognition results",
      "aliases": [
        "recognition results"
      ],
      "types": [
        "study outcome"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The outcome of a study or experiment, typically involving identification or classification.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "recognition results",
          "local_types": [
            "study outcome"
          ],
          "iri": "Entity-recognition_result-Mention-1"
        }
      ],
      "relevance": 0.489501953125
    },
    "Entity-this_paper": {
      "node_id": "this_paper",
      "disambiguation_index": 0,
      "label": "This paper",
      "aliases": [
        "paper",
        "This paper"
      ],
      "types": [
        "research",
        "research paper",
        "paper",
        "academic publication",
        "publication"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A written work or document that contains original research, ideas, or information on a particular topic.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "This paper",
          "local_types": [
            "publication",
            "paper",
            "research"
          ],
          "iri": "Entity-this_paper-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "paper",
          "local_types": [
            "research paper",
            "academic publication"
          ],
          "iri": "Entity-this_paper-Mention-2"
        }
      ],
      "relevance": 0.451904296875
    }
  },
  "summary": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships . Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint . The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes . Preliminary modeling and recognition results are presented .",
  "triples": [
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-a_novel_representation_for_three-dimensional_object"
    ],
    [
      "Entity-multi-view_constraint",
      "Predicate-associated_with",
      "Entity-group_of_patch"
    ],
    [
      "Entity-multi-view_constraint_associated_with_group_of_patch",
      "Predicate-are_combined_with",
      "Entity-a_normalized_representation_of_their_appearance"
    ],
    [
      "Entity-a_normalized_representation_of_their_appearance",
      "Predicate-guide",
      "Entity-matching_and_reconstruction"
    ],
    [
      "Entity-appearance",
      "Predicate-guide",
      "Entity-matching_and_reconstruction"
    ],
    [
      "Entity-proposed_approach",
      "Predicate-does_not_require",
      "Entity-segmentation_stage"
    ],
    [
      "Entity-the_proposed_approach",
      "Predicate-is_applicable_to",
      "Entity-cluttered_scene"
    ],
    [
      "Entity-proposed_approach",
      "Predicate-is_applicable_to",
      "Entity-cluttered_scene"
    ],
    [
      "Entity-preliminary_modeling",
      "Predicate-are",
      "Entity-recognition_result"
    ],
    [
      "Entity-the_proposed_approach",
      "Predicate-presents",
      "Entity-a_novel_representation_for_three-dimensional_object"
    ],
    [
      "Entity-a_novel_representation_for_three-dimensional_object",
      "Predicate-represents",
      "Entity-in_term_of_affine-invariant_image_patch_and_their_spatial_relationship"
    ],
    [
      "Entity-the_proposed_approach",
      "Predicate-represents",
      "Entity-in_term_of_affine-invariant_image_patch_and_their_spatial_relationship"
    ]
  ],
  "triples_typing": [
    [
      "Entity-novel_representation_for_three-dimensional_object",
      "skos:broader",
      "Entity-three-dimensional_object"
    ],
    [
      "Entity-a_normalized_representation_of_their_appearance",
      "skos:broader",
      "Entity-appearance"
    ],
    [
      "Entity-a_novel_representation_for_three-dimensional_object",
      "skos:broader",
      "Entity-three-dimensional_object"
    ],
    [
      "Entity-the_proposed_approach",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-multi-view_constraint",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-matching_and_reconstruction",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-proposed_approach_doe_not_require_a_separate_segmentation_stage",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-single_photograph_taken_from_an_arbitrary_viewpoint",
      "skos:broader",
      "Entity-multiple_image"
    ],
    [
      "Entity-normalized_representation_of_their_appearance",
      "skos:broader",
      "Entity-appearance"
    ],
    [
      "Entity-novel_representation",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image",
      "skos:broader",
      "Entity-multiple_image"
    ],
    [
      "Entity-applicable_to_cluttered_scene",
      "skos:broader",
      "Entity-cluttered_scene"
    ],
    [
      "Entity-affine-invariant_image_patch_and_their_spatial_relationship",
      "skos:broader",
      "Entity-spatial_relationship"
    ]
  ],
  "predicates": {
    "Predicate-presents": {
      "label": "presents",
      "description": "The predicate 'presents' indicates that the subject provides or offers something to someone or something else. It implies a sense of introduction, display, or revelation, connecting the subject with an idea, concept, or representation.",
      "disambiguation_index": 0
    },
    "Predicate-associated_with": {
      "label": "associated with",
      "description": "The predicate 'associated with' indicates a connection between two entities where one entity (the subject) has some relationship or correspondence to another entity (the object). This relationship can be based on various aspects such as classification, categorization, grouping, or identification. The association may imply similarity, equivalence, membership, or other forms of connection.",
      "disambiguation_index": 0
    },
    "Predicate-are_combined_with": {
      "label": "are combined with",
      "description": "The predicate 'are combined with' indicates that two or more entities (in this case, the subject and object) are merged into a single entity, resulting in a unified representation. This combination can be seen as an integration of their respective properties, characteristics, or features to form a new whole.",
      "disambiguation_index": 0
    },
    "Predicate-guide": {
      "label": "guide",
      "description": "To guide means to lead or direct someone or something through a process, providing guidance, support, or instruction. The predicate 'guide' establishes a relationship between the subject and object where the subject provides direction or assistance for the object's understanding, interpretation, or action.",
      "disambiguation_index": 0
    },
    "Predicate-does_not_require": {
      "label": "does not require",
      "description": "The predicate 'does not require' indicates that a certain condition or process (the subject) does not necessitate or demand the presence of something else (the object). In general, this predicate suggests an absence of necessity or obligation between the subject and the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_applicable_to": {
      "label": "is applicable to",
      "description": "This predicate indicates a relationship where the subject (a concept, method, or solution) has relevance and effectiveness for addressing or solving issues related to the object. The connection between the subject and object is one of suitability, feasibility, or practicality.",
      "disambiguation_index": 0
    },
    "Predicate-are": {
      "label": "are",
      "description": "The predicate 'are' indicates a state of being or equivalence between two entities. It connects the subject and object by stating that they share a common characteristic, property, or classification.",
      "disambiguation_index": 0
    },
    "Predicate-represents": {
      "label": "represents",
      "description": "The predicate 'represents' indicates a conceptual connection between its subject and object, suggesting that the subject serves as an abstract or concrete embodiment of the meaning conveyed by the object. In other words, it implies that the subject provides a symbolic, figurative, or literal representation of the information, concept, or idea expressed in the object.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' indicates that the subject concept is a specific or more detailed instance of the object concept. In other words, it suggests a hierarchical relationship where the subject represents a narrower or more specialized aspect within the scope defined by the object.",
      "disambiguation_index": 0
    }
  }
}