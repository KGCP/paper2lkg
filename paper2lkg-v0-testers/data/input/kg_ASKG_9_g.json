{
  "iri": "Paper-HDGI_A_Human_Device_Gesture_Interaction_Ontology_for_the_Internet_of_Things",
  "title": "HDGI: A Human Device Gesture Interaction Ontology for the Internet of Things",
  "authors": [
    "Madhawa Perera",
    "Armin Haller",
    "Sergio J. Rodr\u0131\u0301guez M\u00e9ndez",
    "and Matt Adcock"
  ],
  "keywords": [
    "ontology",
    "gesture",
    "semantic web",
    "Internet of Things",
    "gesture interfaces"
  ],
  "sections": [
    {
      "iri": "Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-1-Paragraph-1-Sentence-1",
              "text": "Gesture-controlled interfaces are becoming increasingly popular with the growing use of Internet of Things (IoT) systems."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-2",
              "text": "In particular, in automobiles, smart homes, computer games, and Augmented Reality (AR) / Virtual Reality (VR) applications, gestures have become prevalent due to their accessibility to everyone."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-3",
              "text": "Designers, producers, and vendors integrating gesture interfaces into their products have also increased in numbers, giving rise to a greater variation of standards in utilizing them."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-4",
              "text": "This variety can confuse a user who is accustomed to a set of conventional controls and has their own preferences."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-5",
              "text": "The only option for a user is to adjust to the system even when the provided gestures are not intuitive and contrary to a user\u2019s expectations."
            }
          ]
        },
        {
          "iri": "Section-1-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-1-Paragraph-2-Sentence-1",
              "text": "This paper addresses the problem of the absence of a systematic analysis and description of gestures and develops an ontology which formally describes gestures used in Human Device Interactions (HDI)."
            },
            {
              "iri": "Section-1-Paragraph-2-Sentence-2",
              "text": "The presented ontology is based on Semantic Web standards (RDF, RDFS, and OWL2)."
            },
            {
              "iri": "Section-1-Paragraph-2-Sentence-3",
              "text": "It is capable of describing a human gesture semantically, along with relevant mappings to affordances and user/device contexts, in an extensible way."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-2",
      "subtitle": "Introduction",
      "paragraphs": [
        {
          "iri": "Section-2-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-1-Sentence-1",
              "text": "Gesture-based systems are becoming widely available and explored as methods for controlling interactive systems."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-2",
              "text": "Especially in modern automobiles, smart homes, computer games, and Augmented Reality (AR) and Virtual Reality (VR) applications, gestures have become prevalent due to their accessibility to everyone."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-3",
              "text": "Most of these gesture interactions consist of physical movements of the face, limbs, or body and allow users to express their interaction intentions and send out corresponding interactive information to a device or a system."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-4",
              "text": "However, most of the gestural interfaces are built based on a manufacturer\u2019s design decision."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-2-Sentence-1",
              "text": "Introducing the concept of 'guessability of a system' in 2005, Wobbrock et al. emphasize that a user\u2019s initial attempts at performing gestures, typing commands, or using buttons or menu items must be met with success despite the user\u2019s lack of knowledge of the relevant symbols."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-2",
              "text": "Their study enables the collection of end users\u2019 preferences for symbolic input and is considered the introduction of Gesture Elicitation Studies (GES)."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-3",
              "text": "Since then, many researchers have attempted to define multiple gesture vocabularies."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-4",
              "text": "However, a majority of them are limited in their scope and specific uses."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-5",
              "text": "As a result, an impressive amount of knowledge has resulted from these GES, but it is currently cluttered."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-3-Sentence-1",
              "text": "There are multiple studies that show 'best gestures' for the same referent, where the referent is the effect of a gesture or the desired effect of an action which the gestural sign refers to."
            },
            {
              "iri": "Section-2-Paragraph-3-Sentence-2",
              "text": "Hence, there are redundant gesture vocabularies."
            },
            {
              "iri": "Section-2-Paragraph-3-Sentence-3",
              "text": "If all the knowledge of GES is properly linked, researchers could find gesture vocabularies that are defined for similar referents."
            },
            {
              "iri": "Section-2-Paragraph-3-Sentence-4",
              "text": "However, a lack of linked data in this area has resulted in researchers conducting new GES whenever they need a particular gesture-referent mapping instead of using existing knowledge."
            },
            {
              "iri": "Section-2-Paragraph-3-Sentence-5",
              "text": "Hence, we see the necessity of a gesture ontology that can describe gestures with their related referents and facilitate automated reasoning."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-4-Sentence-1",
              "text": "Further, there currently exist several sensors, such as Microsoft Kinect, allowing out-of-the-box posture or movement recognition, which allows developers to define and capture mid-air gestures and use them in various applications."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-2",
              "text": "With the advancements in AR and VR, the use of gestural interfaces has increased as these immersive technologies tend to use more intuitive Human-Computer Interaction (HCI) techniques."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-3",
              "text": "All these systems have the capability to detect rich gestural inputs."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-4",
              "text": "This has resulted in designers, developers, producers, and vendors integrating gesture interfaces into their products, contributing to a surge in their numbers and causing greater variation in ways of utilizing them."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-5",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-5-Sentence-1",
              "text": "Riener et al. also show that, most of the time, system designers define gestures based on their own preferences, evaluate them in small-scale user studies, apply modifications, and teach end users how to employ certain gestures."
            },
            {
              "iri": "Section-2-Paragraph-5-Sentence-2",
              "text": "Further, they state that this is problematic because people have different expectations of how to interact with an interface to perform a certain task."
            },
            {
              "iri": "Section-2-Paragraph-5-Sentence-3",
              "text": "This could confuse users who are accustomed to a set of conventional controls."
            },
            {
              "iri": "Section-2-Paragraph-5-Sentence-4",
              "text": "Most of the time, these systems have either binary or a few choices when it comes to gesture selection."
            },
            {
              "iri": "Section-2-Paragraph-5-Sentence-5",
              "text": "Therefore, users do not have much of a choice even though the manufacturer-defined gestures are undesirable or counter-intuitive."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-6",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-6-Sentence-1",
              "text": "For example, if we take Microsoft HoloLens, its first version has a 'bloom' gesture to open its 'start' menu."
            },
            {
              "iri": "Section-2-Paragraph-6-Sentence-2",
              "text": "In contrast, in HoloLens 2, a user has to pinch their thumb and index finger together while looking at the start icon that appears near a user\u2019s wrist when they hold out their hand with their palm facing up, to open the start menu."
            },
            {
              "iri": "Section-2-Paragraph-6-Sentence-3",
              "text": "Optionally, they can also tap the icon that appears near the wrist using their other hand."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-7",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-7-Sentence-1",
              "text": "BMW\u2019s iDrive infotainment system expects users to point a finger to the BMW iDrive touchscreen to accept a call, whereas Mercedes-Benz\u2019 User Experience (MBUX) multimedia infotainment system uses the same gesture to select an icon on their touchscreen."
            },
            {
              "iri": "Section-2-Paragraph-7-Sentence-2",
              "text": "Further, online search engines currently do not provide sufficient information for gesture-related semantics."
            },
            {
              "iri": "Section-2-Paragraph-7-Sentence-3",
              "text": "For example, a search query to retrieve gestures to answer a call in a car would not provide relevant gesture vocabularies supported by different vendors."
            },
            {
              "iri": "Section-2-Paragraph-7-Sentence-4",
              "text": "Designers and developers have to find individual studies separately and read or learn necessary data manually."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-8",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-8-Sentence-1",
              "text": "Being able to retrieve semantics and refer to a central location that maps all the available gestures to the affordance of answering a call in a car would be convenient for designers and developers in such situations."
            },
            {
              "iri": "Section-2-Paragraph-8-Sentence-2",
              "text": "Additionally, understanding the semantics of these gestures and inter-mapping them will help to bring interoperability among interfaces, increasing User Experience (UX)."
            },
            {
              "iri": "Section-2-Paragraph-8-Sentence-3",
              "text": "The problem is how to do this mapping."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-9",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-9-Sentence-1",
              "text": "Our approach is to design an ontology to map existing and increasingly prolific gesture vocabularies and their relationships to systems with the intention of providing the ability to understand and interpret user gestures."
            },
            {
              "iri": "Section-2-Paragraph-9-Sentence-2",
              "text": "Henceforth, users are individually shown the desired effect of an action, called a referent, to their preferred gestures."
            },
            {
              "iri": "Section-2-Paragraph-9-Sentence-3",
              "text": "Villarreal-Narvaez et al.'s most recent survey paper shows that a majority of gestures are performed using the upper limbs of the human body, i.e., hands."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-10",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-10-Sentence-1",
              "text": "Thereby keeping extensibility in mind, we designed a Human Device Gesture Interaction (HDGI) ontology to describe and map existing and upcoming upper limb related gestures along with relevant device affordances."
            },
            {
              "iri": "Section-2-Paragraph-10-Sentence-2",
              "text": "This allows systems to query the ontology after recognizing the gesture to understand its referents without having to be pre-programmed."
            },
            {
              "iri": "Section-2-Paragraph-10-Sentence-3",
              "text": "This further helps the personalization of gestures for particular sets of users."
            },
            {
              "iri": "Section-2-Paragraph-10-Sentence-4",
              "text": "As such, a user does not have to memorize a particular gesture for each different system, which improves system reliability."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-11",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-11-Sentence-1",
              "text": "This paper describes the HDGI ontology and its sample usage and state of the art in this area."
            },
            {
              "iri": "Section-2-Paragraph-11-Sentence-2",
              "text": "First, in Section 2, we discuss existing approaches to address the problem of ubiquitousness in human-device gesture interactions."
            },
            {
              "iri": "Section-2-Paragraph-11-Sentence-3",
              "text": "In Section 3, we describe the syntax, semantics, design, and formalization of HDGI v0.1, and the rationale behind such a design."
            },
            {
              "iri": "Section-2-Paragraph-11-Sentence-4",
              "text": "In Section 4, we illustrate tools for mapping HDGI v0.1 to Leap Motion and the Oculus Quest devices."
            },
            {
              "iri": "Section-2-Paragraph-11-Sentence-5",
              "text": "This serves as an evaluation of the expressive power of our ontology and provides developers and designers with a tool on how to integrate the HDGI ontology in their development."
            },
            {
              "iri": "Section-2-Paragraph-11-Sentence-6",
              "text": "We conclude and discuss future work in Section 5."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-3",
      "subtitle": "Related Work",
      "paragraphs": [
        {
          "iri": "Section-3-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-1-Sentence-1",
              "text": "A large number of studies can be found dealing with the problem of hand gesture recognition and its incorporation into the design and development of gestural interfaces."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-2",
              "text": "In most of these cases, gestures are predefined with their meaning and actions."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-3",
              "text": "Yet, the studies do seem to explore the capability of identifying the relationship beyond predefined mappings of a gesture."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-4",
              "text": "Thus, we see very few studies that have attempted to define and formalise the relationship between each gesture."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-5",
              "text": "A review conducted by Villarreal Narvaez et al. in 2020 shows that gesture recognition has not yet reached its peak, which indicates that there will be many more gesture-related vocabularies in the future, consequently increasing the need to have interoperability between them."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-2-Sentence-1",
              "text": "One approach that has been adopted by researchers is to define taxonomies, enabling designers and manufacturers to use standard definitions when defining gesture vocabularies."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-2",
              "text": "Following this path, Scoditti et al. proposed a gestural interaction taxonomy in order to guide designers and researchers, who need an overall systematic structure that helps them to reason, compare, elicit, and create the appropriate techniques for the problem at hand."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-3",
              "text": "Their intention is to introduce system-wide consistent languages with specific attention for gestures."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-4",
              "text": "However, those authors do not map existing gesture vocabularies with semantical relationships."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-5",
              "text": "Following this, Choi et al. developed a 3D hand gesture taxonomy and notation method."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-6",
              "text": "The results of this study can be used as a guideline to organize hand gestures for enhancing the usability of gesture-based interfaces."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-7",
              "text": "This again follows a similar approach to Scoditti et al."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-8",
              "text": "However, this research is restricted to 6 commands (43 gestures) of a TV and blinds that were used in the experiment."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-9",
              "text": "Therefore, further experiments with an increased number of commands are necessary to see the capability and adaptability of the proposed taxonomy and notation method."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-10",
              "text": "Also, this notation uses numeric terminology which is not easily readable unless designers strictly follow a reference guide that is provided."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-11",
              "text": "In addition, they mention that the size or speed of hand gestures have not been considered in their approach."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-3-Sentence-1",
              "text": "Moving beyond taxonomies, there is also existing research using ontologies."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-2",
              "text": "Osumar et al. have modelled a gesture ontology based on a Microsoft Kinect-based skeleton which aims to describe mid-air gestures of the human body."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-3",
              "text": "Their ontology mainly focuses on capturing the holistic posture of the human body, hence misses details like the finger pose or movements and a detailed representation of the hand."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-4",
              "text": "In addition, the ontology is not openly shared, hence it prevents use and extensibility."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-5",
              "text": "Their main contribution is to have a sensor-independent ontology of body-based contextual gestures, with intrinsic and extrinsic properties, where mapping different gestures with their semantic relationships to affordances is not considered."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-4-Sentence-1",
              "text": "Khairunizam et al. have conducted a similar study with the intention of addressing the challenge of how to increase the knowledge level of computational systems to recognize gestural information with regard to arm movements."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-2",
              "text": "In their research, they have tried to describe knowledge of the arm gestures and attempted to recognize it with a higher accuracy."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-3",
              "text": "This can be identified as an interesting study where the authors have used Qualisys motion capture to capture the movement of the user\u2019s right arm when they perform an arm gesture."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-4",
              "text": "However, their focus was mainly on recognizing geometrical gestures and the gesture set was limited to 5 geometrical shapes."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-5",
              "text": "Again, their ontological framework does not consider the mapping of other gestures that carry similar referents."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-5",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-5-Sentence-1",
              "text": "Overall, the attempts above have a different scope compared to our ontology."
            },
            {
              "iri": "Section-3-Paragraph-5-Sentence-2",
              "text": "Our focus is not on modelling the infinite set of concepts, features, attributes, and relationships attached to arm-based gestures."
            },
            {
              "iri": "Section-3-Paragraph-5-Sentence-3",
              "text": "We do not consider gestures that do not carry a referent to a particular affordance of a device."
            },
            {
              "iri": "Section-3-Paragraph-5-Sentence-4",
              "text": "Nonetheless, our ontology is extensible to allow the addition of emerging gestures with a referent to an affordance or to be extended to other body parts, i.e., extending the gestures beyond the upper limbs of the human body."
            },
            {
              "iri": "Section-3-Paragraph-5-Sentence-5",
              "text": "As a best practice, we have used existing ontologies whenever they fit and provided mappings to concepts and properties in these ontologies."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-4",
      "subtitle": "Human Device Gesture Interaction (HDGI) Ontology",
      "paragraphs": [
        {
          "iri": "Section-4-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-1-Sentence-1",
              "text": "The HDGI ontology models the pose and movement of human upper limbs that are used to interact with devices."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-2",
              "text": "This ontology describes gestures related to device interactions and which are performed using a human's upper limb region."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-3",
              "text": "It maps affordances and human gestures to facilitate devices and automated systems to understand different gestures that humans perform to interact with the same affordances."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-4",
              "text": "Additionally, it acts as a dictionary for manufacturers, designers, and developers to search and identify the commonly used gestures for certain affordances, and to understand the shape and dynamics of a certain gesture."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-5",
              "text": "The ontology is developed with a strong focus on flexibility and extensibility, allowing device manufacturers, designers, and users to introduce new gestures and map their relations to necessary affordances."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-6",
              "text": "Most importantly, this does not enforce designers and manufacturers to follow a standard but maps the ubiquitousness in gesture vocabularies by linking them appropriately."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-7",
              "text": "The aim of this study is to define a semantic model of gestures combined with its associated knowledge."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-8",
              "text": "As such, GES becomes more permissive, which opens up the opportunity to introduce a shareable and reusable gesture representation that can be mapped according to the relationships introduced in HDGI."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-2-Sentence-1",
              "text": "We defined a new namespace https://w3id.org/hdgi with the prefix hdgi for all the classes used in the ontology to be independent of external ontologies."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-2",
              "text": "However, we have provided relevant mappings to external ontologies where appropriate."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-3",
              "text": "We are using w3id.org as the permanent URL service."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-4",
              "text": "Furthermore, the relevant code, data, and ontology are made available for the community via GitHub, allowing anyone interested to join as a contributor."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-3-Sentence-1",
              "text": "Design Rationale"
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-2",
              "text": "We have arranged the classes and properties of the HDGI ontology to represent human upper limb region gestures with their associated affordances and context."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-3",
              "text": "The ontology is designed around a core that consists of seven main classes: hdgi:Gesture, hdgi:BodyPart, hdgi:Pose, hdgi:Movement, hdgi:Affordance, hdgi:Device, and hdgi:Human, establishing the basic relationships between those along with hdgi:Observer and hdgi:Context classes."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-4",
              "text": "This core ontology design pattern will be registered in the ontology design pattern initiative."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-5",
              "text": "Please note that the ontology introduces all classes and relationships in its own namespace, but for illustration purposes, we use their equivalent classes and properties from external ontologies when appropriate."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-6",
              "text": "All the classes and properties are expressed in OWL2 and we use Turtle syntax throughout our modelling."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-7",
              "text": "We use global domain and range restrictions on properties sparingly, but as much as possible, we use guarded local restrictions instead, i.e., universal and existential class restrictions for a specific property such that only for instances of that property with that class as the subject, the range of the property is asserted."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-8",
              "text": "This helps in the alignment of the ontology with other external ontologies, particularly if they also use guarded local restrictions."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-9",
              "text": "We provide alignments to these ontologies as separate ontology files in GitHub."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-5",
      "subtitle": "Human Device Gesture Interaction (HDGI) Ontolog: Gesture",
      "paragraphs": [
        {
          "iri": "Section-5-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-1-Sentence-1",
              "text": "Gesture A hdgi:Gesture is defined in such a way that it distinguishes two atomic types of gestures, namely static and dynamic gestures."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-2",
              "text": "A dynamic gesture consists of exactly one start hdgi:Pose at a given time, exactly one end hdgi:Pose at a given time, an atomic hdgi:Movement, and involves a single hdgi:BodyPart at a time."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-3",
              "text": "However, since a gesture can have multiple poses and movements of multiple body parts, we provide a means to define a sequence of gestures."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-4",
              "text": "Since the ontology is designed in a way that it can capture and describe individual body parts separately, a gesture that involves multiple movements and poses of body parts can be described using the object property hdgi:includesGesture that aggregates hdgi:Gesture and through their mapping to Allen time puts them in sequence or concurrent."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-5",
              "text": "That is, a gesture can contain one or more gestures."
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-2-Sentence-1",
              "text": "To give a concrete example of the modeling of a dynamic gesture, we use a 'swipe gesture' performed with the right hand (named 'right hand swipe left') illustrated below in Listing 1.1 and Figure 2."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-2",
              "text": "As per the description above, 'right hand swipe left' consists of eight atomic gestures."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-3",
              "text": "Only some of these atomic gestures are shown in Figure 2 and listed in Listing 1.1 and each of those include a single body part, a start pose and an end pose, with a movement."
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-3-Sentence-1",
              "text": "For extensibility, we added several possible gesture subclasses such as hdgi:HandGesture, hdgi:ForearmGesture, hdgi:FacialGesture, hdgi:LegGesture, hdgi:UpperArmGesture etc."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-2",
              "text": "However, at this moment only hand, forearm, and upper arm gestures are modeled in detail in HDGI."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-6",
      "subtitle": "Human Device Gesture Interaction (HDGI) Ontolog: BodyPart",
      "paragraphs": [
        {
          "iri": "Section-6-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-1-Sentence-1",
              "text": "For modeling body parts, we reuse and extend concepts and classes in the Foundational Model of Anatomy (FMA) ontology."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-2",
              "text": "Again, though we focus only on a human's upper limb region, the hdgi:BodyPart class is defined in an extensible way with the motive of allowing representation of further body parts to describe new poses in the future."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-3",
              "text": "We are not modeling all the biological concepts that are described in FMA, but only the relevant classes for HDI."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-4",
              "text": "While preserving FMA class definitions and structures, we define hdgi:UpperArm, hdgi:Forearm, hdgi:Palm, and hdgi:Finger as the basic building blocks of the 'upper limb region'."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-5",
              "text": "The hdgi:UpperArm class is an equivalent class to the Arm class in FMA."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-6",
              "text": "The hdgi:Finger class is further divided to represent each individual finger as hdgi:Thumb, hdgi:IndexFinger, hdgi:MiddleFinger, hdgi:RingFinger, and hdgi:LittleFinger and are mapped to the respective subclasses of a 'Region of hand' in FMA."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-7",
              "text": "These fingers are further divided into left and right entities."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-8",
              "text": "Figure 3 depicts each of these sections of the 'upper limb region'."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-9",
              "text": "Thus, we define a gesture as a combination of one or more poses and-or movements involved by one or more of these eight sections of upper limb region."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-7",
      "subtitle": "Human Device Gesture Interaction (HDGI) Ontolog: Post",
      "paragraphs": [
        {
          "iri": "Section-7-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-7-Paragraph-1-Sentence-1",
              "text": "Each body part can be involved in a pose."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-2",
              "text": "In other words, a Pose must hdgi:involves one hdgi:BodyPart at a point in time."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-3",
              "text": "For each body part there is a corresponding, potential pose."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-4",
              "text": "Stepping down a layer of abstraction, the hdgi:Pose class describes the exact placement of a pose in a 3D space, by modeling the 'position' and 'rotation' of a pose."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-5",
              "text": "The hdgi:hasPosition and hdgi:hasRotation relationships are used for this mapping; e.g. hdgi:ThumbCurled -> hdgi:hasPosition -> xPosition."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-6",
              "text": "In order to avoid the problem of having different origin points based on the gesture recognition device configurations, the HDGI ontology always considers relative positions."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-7",
              "text": "That is, upper arm positions are always relative to the shoulder joint (Refer to Figure 3 - point A)."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-8",
              "text": "The position of a hdgi:ForearmPose is always relative to the elbow joint (cf. Figure 3 - point B)."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-9",
              "text": "Palm and finger positions are always relative to the wrist (cf. Figure 3 - point C)."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-10",
              "text": "Further, the hdgi:Position class must describe the local coordinate system that its hdgi:xPosition, hdgi:yPosition, and zPosition values are based on."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-11",
              "text": "Thus, every hdgi:Position must have a hdgi:hasLocalCoordinateSystem object property with a hdgi:LocalCoordinateSystem as its range."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-12",
              "text": "This is to avoid problems, such as different SDKs-systems using slightly different coordinate systems."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-13",
              "text": "For example, Unity3D11 is using a left-hand rule coordinate system where the Z-axis always points outwards from the users."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-14",
              "text": "In contrast, the leap-motion SDK uses a right-hand rule where the Z-axis is pointed inwards."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-15",
              "text": "In order to allow either type of modeling and to avoid unnecessary conversions steps, we separately model the hdgi:LocalCoordinateSystem class and hdgi:Position class relationship."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-16",
              "text": "The rotation of a pose can be represented in two different ways."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-17",
              "text": "Some systems use yaw (angle with y-axis), pitch (angle with x-axis), and roll (angle with z-axis) angles to describe the rotation of a 3D rigid body, whereas some systems use quaternions."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-18",
              "text": "By allowing support for both of these representations (yet one at a time), we keep our model flexible and able to model data received from different manufacturers-devices."
            }
          ]
        },
        {
          "iri": "Section-7-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-7-Paragraph-2-Sentence-1",
              "text": "Further, a hdgi:Pose represents a static gesture."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-2",
              "text": "Thus, similar to the hdgi:Gesture class, a hdgi:Pose can contain one or more poses within itself."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-3",
              "text": "A hdgi:Pose always has a time stamp and involves a single body part at a time (thus, individual body parts can be modeled separately)."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-4",
              "text": "Again, for extensibility, we added several possible poses as subclasses such as hdgi:LegPose, hdgi:FootPose, etc."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-5",
              "text": "However, at the moment we only model hdgi:UpperArm, hdgi:Forearm, hdgi:Palm, and each individual hdgi:Finger poses."
            }
          ]
        },
        {
          "iri": "Section-7-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-7-Paragraph-3-Sentence-1",
              "text": "Listing 1.2 provides an example of a pose modeling related to the gesture 'Right Hand Swipe Left'."
            },
            {
              "iri": "Section-7-Paragraph-3-Sentence-2",
              "text": "The example models the start pose and the end pose of the right forearm and the right palm."
            },
            {
              "iri": "Section-7-Paragraph-3-Sentence-3",
              "text": "As per the description above, each hdgi:Pose hdgi:used only hdgi:BodyPart and has exactly one hdgi:timestamp with a maximum of one hdgi:Position and a hdgi:Rotation (hdgi:Rotation could be modeled either using Euler angles (hdgi:xRotation (roll), hdgi:yRotation (pitch), hdgi:zRotation (yaw)) or hdgi:Quaternion based on received data)."
            },
            {
              "iri": "Section-7-Paragraph-3-Sentence-4",
              "text": "Listing 1.3 further explains the hdgi:Position and hasLocalCoordinateSystem mappings."
            },
            {
              "iri": "Section-7-Paragraph-3-Sentence-5",
              "text": "Each hdgi:Position has a maximum of one hdgi:xPosition, hdgi:yPosition, and hdgi:zPosition and exactly one hdgi:LocalCoordinateSystem."
            },
            {
              "iri": "Section-7-Paragraph-3-Sentence-6",
              "text": "Notice in hdgi:LocalCoordinateSystem, each axis direction is pre-known (enum), hence for hdgi:xAxisDirection it is either 'leftward' or 'rightward', for hdgi:yAxisDirection it is either 'upward' or 'downward', and for hdgi:zAxisDirection it is either 'outward' or 'inward'."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-8",
      "subtitle": "Human Device Gesture Interaction (HDGI) Ontolog: Movement",
      "paragraphs": [
        {
          "iri": "Section-8-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-8-Paragraph-1-Sentence-1",
              "text": "The hdgi:Movement class only relates to dynamic gestures and has no relationship to a hdgi:Pose."
            },
            {
              "iri": "Section-8-Paragraph-1-Sentence-2",
              "text": "A hdgi:Movement consists of a predefined set of movements that we identified as sufficient to describe the movements of hdgi:UpperArm, hdgi:Forearm, hdgi:Palm, and hdgi:Finger."
            },
            {
              "iri": "Section-8-Paragraph-1-Sentence-3",
              "text": "This is extensible for designers and developers to include their own new movements."
            },
            {
              "iri": "Section-8-Paragraph-1-Sentence-4",
              "text": "As this is not tightly-coupled with other classes such as hdgi:Gesture, hdgi:Pose, and hdgi:BodyPart, the flexibility is there for customizations."
            },
            {
              "iri": "Section-8-Paragraph-1-Sentence-5",
              "text": "Each hdgi:Movement is atomic (that is related to only one position change or one rotation change) and must have exactly a single hdgi:Duration."
            },
            {
              "iri": "Section-8-Paragraph-1-Sentence-6",
              "text": "This can be derived from hdgi:timestamp difference between start hdgi:Pose and end hdgi:Pose."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-9",
      "subtitle": "Human Device Gesture Interaction (HDGI) Ontolog: Affordances",
      "paragraphs": [
        {
          "iri": "Section-9-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-9-Paragraph-1-Sentence-1",
              "text": "According to Norman the term affordance refers to the perceived and actual properties of the thing that determines just how the thing could possibly be used."
            },
            {
              "iri": "Section-9-Paragraph-1-Sentence-2",
              "text": "Later on, this view has become standard in Human Computer Interaction and Design."
            },
            {
              "iri": "Section-9-Paragraph-1-Sentence-3",
              "text": "Further, Maier et al. define affordances to be potential uses of a device."
            },
            {
              "iri": "Section-9-Paragraph-1-Sentence-4",
              "text": "This implies that the human is able to do something using the device."
            },
            {
              "iri": "Section-9-Paragraph-1-Sentence-5",
              "text": "Hence affordances of a device can be stated as the set of all potential human behaviors that the device might allow."
            },
            {
              "iri": "Section-9-Paragraph-1-Sentence-6",
              "text": "Therefore, Brown et al. conclude that affordances are context dependent action or manipulation possibilities from the point of view of a particular actor."
            },
            {
              "iri": "Section-9-Paragraph-1-Sentence-7",
              "text": "This highlighted the necessity for us to model both an hdgi:Affordance and a hdgi:Context (both hdgi:UserContext and hdgi:DeviceContext) class when modeling Human Device Gesture Interactions."
            },
            {
              "iri": "Section-9-Paragraph-1-Sentence-8",
              "text": "As a user's choice of gestures is heavily based on their context, to understand the correct intent it is important that HDGI can map both the context and affordance."
            },
            {
              "iri": "Section-9-Paragraph-1-Sentence-9",
              "text": "This helps systems to understand user specific gesture semantics and behave accordingly."
            }
          ]
        },
        {
          "iri": "Section-9-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-9-Paragraph-2-Sentence-1",
              "text": "In gesture interactions, necessary affordances are communicated by the user to a device via a gesture that is supported by the device."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-2",
              "text": "If there is an openly accessible gesture affordance mapping with automated reasoning, we could integrate multiple gesture recognition systems to cater for user needs, and thereby increase user experience (UX)."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-3",
              "text": "For example, assume that Device A has an affordance X and Device B has affordance Y."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-4",
              "text": "If a user performs a gesture which can only be detected by Device B but the user's intent is to interact with affordance X, by using the mappings in hdgi-ontology and the use of automated reasoning, Device B would be able to understand the user intent and communicate that to Device A accordingly."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-5",
              "text": "This further implies that it is the affordance that should be mapped to a gesture rather than the device."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-6",
              "text": "This is modeled as hdgi:Affordance -> hdgi:supportsGesture -> hdgi:Gesture, where an affordance can have none to many supported gestures."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-7",
              "text": "A hdgi:Device can be a host to multiple affordances and the same affordance can be hosted by multiple devices."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-8",
              "text": "Hence, hdgi:Affordance -> hdgi:affordedBy -> hdgi:Device has cardinality of many to many."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-9",
              "text": "Here, hdgi:Device is a sub class of sosa:Platform."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-10",
              "text": "SOSA (Sensor, Observation, Sample, and Actuator) is a lightweight but self-contained core ontology which itself is the core of the new Semantic Sensor Network (SSN) ontology."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-11",
              "text": "The SSN ontology describes sensors and their observations, involved procedures, studied features of interest, samples, and observed properties, as well as actuators."
            },
            {
              "iri": "Section-9-Paragraph-2-Sentence-12",
              "text": "We further reuse sosa:Sensor and sosa:Actuator and hdgi:ActuatableAffordance and hdgi:ObservableAffordance are subclasses of sosa:ActuatableProperty and sosa:ObservableProperty."
            }
          ]
        },
        {
          "iri": "Section-9-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-9-Paragraph-3-Sentence-1",
              "text": "In addition, the HDGI ontology models the relationship between hdgi:Device and a hdgi:DeviceManufacturer as there can be the same gesture mapped to different affordances by different vendors or the same affordance can be mapped to different gestures (refer to the BMW and Mercedes-Benz example in Section 1)."
            },
            {
              "iri": "Section-9-Paragraph-3-Sentence-2",
              "text": "We model this in HDGI through the hdgi:Device hdgi:manufacturedBy a hdgi:DeviceManufacturer relationship where a device must have just one manufacturer."
            }
          ]
        },
        {
          "iri": "Section-9-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-9-Paragraph-4-Sentence-1",
              "text": "Listing 1.4 provides an example modeling of hdgi:Affordance, hdgi:Device and hdgi:Context relationships corresponding to the description above."
            },
            {
              "iri": "Section-9-Paragraph-4-Sentence-2",
              "text": "Most importantly, this is one of the major contributions in this ontology and when correctly modeled, this will help systems to automatically identify the semantics of a user's gesture and perform the necessary affordance mapping through an interconnected knowledge base instead of predefined one to one mappings."
            },
            {
              "iri": "Section-9-Paragraph-4-Sentence-3",
              "text": "This allows gesture recognition systems to run gesture recognition, detection, mappings, and communication separately in independent layers."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-10",
      "subtitle": "Device Mappings to HDGI",
      "paragraphs": [
        {
          "iri": "Section-10-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-10-Paragraph-1-Sentence-1",
              "text": "In addition to ontology building and annotating, it is equally important to consider its integration and documentation as a part of ontology engineering."
            },
            {
              "iri": "Section-10-Paragraph-1-Sentence-2",
              "text": "Figure 4 illustrates a proof-of-concept implementation of the HDGI ontology."
            },
            {
              "iri": "Section-10-Paragraph-1-Sentence-3",
              "text": "Here we wrapped a set of predefined SPARQL endpoints with RESTful APIs, in order to make the integration with third party Software Development Kits and Services easier and faster."
            }
          ]
        },
        {
          "iri": "Section-10-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-10-Paragraph-2-Sentence-1",
              "text": "The HDGI-Mapping Service is a fully API-driven RESTful web service, where designers, device manufacturers, and developers can refer to one place - the HDGI-gesture repository - to find currently available and contemporary gestures and their relevant mappings to device affordances."
            },
            {
              "iri": "Section-10-Paragraph-2-Sentence-2",
              "text": "In addition, APIs further allow them to define their own gesture vocabularies and map them and upload them to the gesture repository."
            },
            {
              "iri": "Section-10-Paragraph-2-Sentence-3",
              "text": "This means that their gesture vocabularies will be easily accessible to the research community."
            },
            {
              "iri": "Section-10-Paragraph-2-Sentence-4",
              "text": "We anticipate that this will help to reduce the redundant gesture vocabularies and increase the reuse of existing ones, eventually helping to reduce the ubiquitousness currently prominent in gestural interfaces."
            }
          ]
        },
        {
          "iri": "Section-10-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-10-Paragraph-3-Sentence-1",
              "text": "In our study, we looked at the gesture vocabularies in the current literature and tried to map them into the ontology as a starting point."
            },
            {
              "iri": "Section-10-Paragraph-3-Sentence-2",
              "text": "This allows using the HDGI-service endpoints to query about available gesture vocabularies."
            },
            {
              "iri": "Section-10-Paragraph-3-Sentence-3",
              "text": "As we have made this an OpenSource project under Apache 2.0 license, anyone can contribute to the open GitHub code repository for further improvements."
            },
            {
              "iri": "Section-10-Paragraph-3-Sentence-4",
              "text": "In addition, they can deploy this service in their own private cloud, if necessary."
            },
            {
              "iri": "Section-10-Paragraph-3-Sentence-5",
              "text": "Either way, adhering to the HDGI ontology mappings will allow universal integration of gesture data instead of having a universal gesture standard that is not yet available and may never emerge."
            }
          ]
        },
        {
          "iri": "Section-10-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-10-Paragraph-4-Sentence-1",
              "text": "Further information on HDGI mappings can be explored."
            },
            {
              "iri": "Section-10-Paragraph-4-Sentence-2",
              "text": "Sample mapping service (the web application) code is available to anyone to download locally, and continue the integration with their gesture recognition software tools."
            },
            {
              "iri": "Section-10-Paragraph-4-Sentence-3",
              "text": "The prerequisites to run the web application are Java version 1.9 or higher and an Apache Tomcat server."
            },
            {
              "iri": "Section-10-Paragraph-4-Sentence-4",
              "text": "A 'how-to' documentation is provided."
            },
            {
              "iri": "Section-10-Paragraph-4-Sentence-5",
              "text": "We have further added an API and architecture documentation which helps if someone needs to customize the web application itself, if they want to make customized SPARQL endpoints and to define new RESTful endpoints to suit any customizable needs, and to run as a private service."
            },
            {
              "iri": "Section-10-Paragraph-4-Sentence-6",
              "text": "A complete API documentation can also be found, and we are currently working on integrating the Swagger UI and Swagger codegen capabilities to the HDGI web app."
            }
          ]
        },
        {
          "iri": "Section-10-Paragraph-5",
          "sentences": [
            {
              "iri": "Section-10-Paragraph-5-Sentence-1",
              "text": "Thus, users can get a comprehensive view of the API, understand endpoint structures and try it online in real-time."
            },
            {
              "iri": "Section-10-Paragraph-5-Sentence-2",
              "text": "Further, with the integration of Swagger codegen, we will allow instant generation of API client stubs (client SDKs for APIs) from different languages including JavaScript, Java, Python, Swift, Android, etc., which will make the integration of the APIs into different gesture recognition software/services even faster and easier."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-11",
      "subtitle": "Conclusion",
      "paragraphs": [
        {
          "iri": "Section-11-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-11-Paragraph-1-Sentence-1",
              "text": "This work presents the Human Device Gesture Interaction (HDGI) ontology, a model of human device gesture interactions that describes gestures related to human device interactions and maps them with corresponding affordances."
            },
            {
              "iri": "Section-11-Paragraph-1-Sentence-2",
              "text": "This is an initial step towards building a comprehensive human device gesture interaction knowledge base with the ultimate purpose of bringing better user experience."
            },
            {
              "iri": "Section-11-Paragraph-1-Sentence-3",
              "text": "The HDGI ontology can assist gesture recognition systems, designers, manufacturers, and developers to formally express gestures and to carry automated reasoning tasks based on relationships between gestures and device affordances."
            }
          ]
        },
        {
          "iri": "Section-11-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-11-Paragraph-2-Sentence-1",
              "text": "While developing the ontology, we extracted elements observed from existing gesture vocabularies defined in previous studies."
            },
            {
              "iri": "Section-11-Paragraph-2-Sentence-2",
              "text": "We also present a Web service interface, the HDGI Mapping service, that can be integrated with existing gesture recognition systems."
            }
          ]
        },
        {
          "iri": "Section-11-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-11-Paragraph-3-Sentence-1",
              "text": "The intention and scope of the HDGI ontology can be summarized as follows: first, to describe gestures related to human device interaction performed using the human upper-limb region; second, to map the relationship between affordances and a particular gesture based on the user context, allowing devices to understand different gestures that humans perform to interact with the same affordances; and third, to act as a dictionary and a repository for manufacturers, developers, and designers to identify commonly used gestures for certain affordances, specify formally what a certain gesture means, and introduce new gestures if necessary."
            }
          ]
        },
        {
          "iri": "Section-11-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-11-Paragraph-4-Sentence-1",
              "text": "As future work, there are several possible extensions that can be made to the ontology by incorporating more gesture types such as facial gestures and head gestures."
            },
            {
              "iri": "Section-11-Paragraph-4-Sentence-2",
              "text": "Furthermore, we are planning to release and deploy the HDGI RESTful service in the Cloud and release API clients to leading hand-gesture supported systems such as Microsoft HoloLens 2, Microsoft Kinect, and Soli."
            },
            {
              "iri": "Section-11-Paragraph-4-Sentence-3",
              "text": "Since gesture interactions in Mixed Reality are becoming increasingly popular, we plan to conduct several gesture elicitation studies using Microsoft HoloLens 2, especially to map gesture interactions in Mixed Reality to the HDGI ontology."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.0006263256072998047,
    897.0688350200653,
    1000.9757041931152,
    972.9109811782837,
    3.1842029094696045,
    0.0029180049896240234,
    0.003968000411987305,
    896.9317610263824,
    1533.066861152649,
    78.24288725852966,
    54.69246315956116,
    0.5391390323638916,
    0.010291099548339844,
    790.3108017444611,
    3.3191440105438232,
    1.2242941856384277,
    30.04455304145813,
    61.615028858184814,
    277.4741449356079,
    249.15346670150757,
    1013.0123898983002,
    115.00431990623474,
    1980.414226770401,
    120.38283634185791,
    0.08121919631958008,
    0.4570739269256592
  ],
  "nodes": {
    "Entity-gesture_used_in_human_device_interaction__hdi_": {
      "node_id": "gesture_used_in_human_device_interaction__hdi_",
      "disambiguation_index": 0,
      "label": "gestures used in Human Device Interactions (HDI)",
      "aliases": [
        "gestures used in Human Device Interactions (HDI)"
      ],
      "types": [
        "Human Device Interaction",
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Gestures used in Human Device Interactions (HDI) refer to the various physical movements and signals employed by users to interact with devices, particularly in the context of gesture-controlled interfaces within the Internet of Things (IoT), which are systematically analyzed and described through an ontology based on Semantic Web standards.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "gestures used in Human Device Interactions (HDI)",
          "local_types": [
            "Human Device Interaction",
            "gesture"
          ],
          "iri": "Entity-gesture_used_in_human_device_interaction__hdi_-Mention-1"
        }
      ],
      "relevance": 0.81640625
    },
    "Entity-human_device_gesture_interaction__hdgi_": {
      "node_id": "human_device_gesture_interaction__hdgi_",
      "disambiguation_index": 0,
      "label": "Human Device Gesture Interaction (HDGI)",
      "aliases": [
        "Human Device Gesture Interaction (HDGI)",
        "Human Device Gesture Interaction (HDGI) ontology"
      ],
      "types": [
        "model",
        "ontology",
        "framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Human Device Gesture Interaction (HDGI) refers to an ontology designed to describe and map upper limb gestures and their associated device affordances, facilitating the understanding and interpretation of user gestures in various interactive systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-1",
          "local_name": "Human Device Gesture Interaction (HDGI)",
          "local_types": [
            "ontology",
            "framework"
          ],
          "iri": "Entity-human_device_gesture_interaction__hdgi_-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-1",
          "local_name": "Human Device Gesture Interaction (HDGI)",
          "local_types": [
            "model",
            "ontology"
          ],
          "iri": "Entity-human_device_gesture_interaction__hdgi_-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-1",
          "local_name": "Human Device Gesture Interaction (HDGI) ontology",
          "local_types": [
            "ontology",
            "framework"
          ],
          "iri": "Entity-human_device_gesture_interaction__hdgi_-Mention-3"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-1",
          "local_name": "Human Device Gesture Interaction (HDGI) ontology",
          "local_types": [
            "model",
            "ontology"
          ],
          "iri": "Entity-human_device_gesture_interaction__hdgi_-Mention-4"
        }
      ],
      "relevance": 0.80908203125
    },
    "Entity-hdgi_ontology": {
      "node_id": "hdgi_ontology",
      "disambiguation_index": 0,
      "label": "HDGI ontology",
      "aliases": [
        "HDGI ontology",
        "The HDGI ontology",
        "hdgi-ontology",
        "the HDGI ontology"
      ],
      "types": [
        "data model",
        "framework",
        "HDGI",
        "data structure",
        "ontology",
        "concept",
        "model",
        "semantic model",
        "knowledge representation"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The HDGI ontology is a formal framework designed to describe and map human gestures used in Human Device Interactions, facilitating the understanding and interpretation of gestures in various applications, particularly within the context of the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-1",
          "local_name": "HDGI ontology",
          "local_types": [
            "ontology",
            "framework",
            "concept",
            "knowledge representation"
          ],
          "iri": "Entity-hdgi_ontology-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "HDGI ontology",
          "local_types": [
            "ontology",
            "concept",
            "knowledge representation"
          ],
          "iri": "Entity-hdgi_ontology-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "HDGI ontology",
          "local_types": [
            "model",
            "ontology",
            "semantic model"
          ],
          "iri": "Entity-hdgi_ontology-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-2",
          "local_name": "HDGI ontology",
          "local_types": [
            "framework",
            "ontology",
            "model",
            "semantic model",
            "knowledge representation"
          ],
          "iri": "Entity-hdgi_ontology-Mention-4"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-6",
          "local_name": "HDGI ontology",
          "local_types": [
            "ontology",
            "concept",
            "framework"
          ],
          "iri": "Entity-hdgi_ontology-Mention-5"
        },
        {
          "reference": "Section-10-Paragraph-1-Sentence-2",
          "local_name": "HDGI ontology",
          "local_types": [
            "data structure",
            "concept",
            "knowledge representation",
            "ontology"
          ],
          "iri": "Entity-hdgi_ontology-Mention-6"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-3",
          "local_name": "HDGI ontology",
          "local_types": [
            "ontology",
            "knowledge representation",
            "framework"
          ],
          "iri": "Entity-hdgi_ontology-Mention-7"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "HDGI ontology",
          "local_types": [
            "ontology",
            "concept",
            "framework"
          ],
          "iri": "Entity-hdgi_ontology-Mention-8"
        },
        {
          "reference": "Section-11-Paragraph-4-Sentence-3",
          "local_name": "HDGI ontology",
          "local_types": [
            "ontology",
            "knowledge representation",
            "framework"
          ],
          "iri": "Entity-hdgi_ontology-Mention-9"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "HDGI ontology",
          "local_types": [
            "ontology",
            "data model"
          ],
          "iri": "Entity-hdgi_ontology-Mention-10"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-5",
          "local_name": "HDGI ontology",
          "local_types": [
            "data structure",
            "concept",
            "framework",
            "ontology"
          ],
          "iri": "Entity-hdgi_ontology-Mention-11"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-4",
          "local_name": "hdgi-ontology",
          "local_types": [
            "ontology",
            "knowledge representation",
            "framework"
          ],
          "iri": "Entity-hdgi_ontology-Mention-12"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-1",
          "local_name": "the HDGI ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-hdgi_ontology-Mention-13"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "the HDGI ontology",
          "local_types": [
            "ontology",
            "HDGI"
          ],
          "iri": "Entity-hdgi_ontology-Mention-14"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "The HDGI ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-hdgi_ontology-Mention-15"
        }
      ],
      "relevance": 0.806640625
    },
    "Entity-this_ontology": {
      "node_id": "this_ontology",
      "disambiguation_index": 0,
      "label": "this ontology",
      "aliases": [
        "This ontology",
        "The ontology",
        "this ontology",
        "the ontology",
        "the HDGI ontology"
      ],
      "types": [
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "This ontology refers to the Human Device Gesture Interaction (HDGI) ontology, which systematically describes gestures used in Human Device Interactions and models the relationships between gestures, affordances, and device contexts to enhance gesture recognition and user experience.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "this ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-2",
          "local_name": "the ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "This ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "The ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-4"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "The ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-5"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "the ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-6"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-6",
          "local_name": "the HDGI ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-7"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-1",
          "local_name": "the ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-8"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "the HDGI ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-9"
        },
        {
          "reference": "Section-11-Paragraph-4-Sentence-1",
          "local_name": "the ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-this_ontology-Mention-10"
        }
      ],
      "relevance": 0.80322265625
    },
    "Entity-this_paper": {
      "node_id": "this_paper",
      "disambiguation_index": 0,
      "label": "This paper",
      "aliases": [
        "This paper"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "This paper presents a systematic analysis and ontology for formally describing gestures used in Human Device Interactions (HDI), addressing the lack of standardization in gesture-controlled interfaces within the Internet of Things (IoT).",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "This paper",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_paper-Mention-1"
        }
      ],
      "relevance": 0.80078125
    },
    "Entity-hdgi": {
      "node_id": "hdgi",
      "disambiguation_index": 0,
      "label": "HDGI",
      "aliases": [
        "HDGI",
        "hdgi"
      ],
      "types": [
        "method",
        "organization",
        "standard",
        "acronym",
        "framework",
        "abbreviation",
        "ontology",
        "technology",
        "concept",
        "prefix",
        "software",
        "model",
        "identifier",
        "system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "HDGI refers to a Human Device Gesture Interaction Ontology designed to systematically describe and represent gestures used in interactions between humans and devices, facilitating the understanding and mapping of these gestures to various affordances in the context of the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-8",
          "local_name": "HDGI",
          "local_types": [
            "method",
            "framework",
            "system"
          ],
          "iri": "Entity-hdgi-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-3-Sentence-2",
          "local_name": "HDGI",
          "local_types": [
            "model",
            "system"
          ],
          "iri": "Entity-hdgi-Mention-2"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-8",
          "local_name": "HDGI",
          "local_types": [
            "model",
            "technology",
            "system"
          ],
          "iri": "Entity-hdgi-Mention-3"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "framework",
            "system"
          ],
          "iri": "Entity-hdgi-Mention-4"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-5",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "standard"
          ],
          "iri": "Entity-hdgi-Mention-5"
        },
        {
          "reference": "Section-10-Paragraph-4-Sentence-1",
          "local_name": "HDGI",
          "local_types": [
            "software",
            "organization",
            "acronym",
            "concept"
          ],
          "iri": "Entity-hdgi-Mention-6"
        },
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "hdgi",
          "local_types": [
            "prefix",
            "identifier",
            "ontology"
          ],
          "iri": "Entity-hdgi-Mention-7"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "framework"
          ],
          "iri": "Entity-hdgi-Mention-8"
        },
        {
          "reference": "Section-5-Paragraph-3-Sentence-1",
          "local_name": "HDGI",
          "local_types": [
            "model",
            "ontology",
            "framework",
            "system"
          ],
          "iri": "Entity-hdgi-Mention-9"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-7",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "framework",
            "system"
          ],
          "iri": "Entity-hdgi-Mention-10"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-6",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "system"
          ],
          "iri": "Entity-hdgi-Mention-11"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-2",
          "local_name": "HDGI",
          "local_types": [
            "model",
            "framework"
          ],
          "iri": "Entity-hdgi-Mention-12"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-1",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "system"
          ],
          "iri": "Entity-hdgi-Mention-13"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-1",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "abbreviation"
          ],
          "iri": "Entity-hdgi-Mention-14"
        },
        {
          "reference": "Section-11-Paragraph-2-Sentence-2",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "abbreviation"
          ],
          "iri": "Entity-hdgi-Mention-15"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "abbreviation"
          ],
          "iri": "Entity-hdgi-Mention-16"
        },
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "HDGI",
          "local_types": [
            "ontology",
            "abbreviation"
          ],
          "iri": "Entity-hdgi-Mention-17"
        }
      ],
      "relevance": 0.7841796875
    },
    "Entity-hdgi_v0.1": {
      "node_id": "hdgi_v0.1",
      "disambiguation_index": 0,
      "label": "HDGI v0.1",
      "aliases": [
        "HDGI v0.1"
      ],
      "types": [
        "software",
        "model",
        "ontology",
        "version"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "HDGI v0.1 is a version of the Human Device Gesture Interaction ontology designed to systematically describe and map upper limb gestures to their corresponding device affordances, facilitating improved user interaction with gesture-controlled systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "HDGI v0.1",
          "local_types": [
            "software",
            "model",
            "ontology",
            "version"
          ],
          "iri": "Entity-hdgi_v0.1-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-4",
          "local_name": "HDGI v0.1",
          "local_types": [
            "software",
            "version"
          ],
          "iri": "Entity-hdgi_v0.1-Mention-2"
        }
      ],
      "relevance": 0.76953125
    },
    "Entity-hdgi_ontology_mapping": {
      "node_id": "hdgi_ontology_mapping",
      "disambiguation_index": 0,
      "label": "HDGI ontology mappings",
      "aliases": [
        "HDGI ontology mappings"
      ],
      "types": [
        "data standard",
        "ontology",
        "ontology mapping",
        "data mapping",
        "knowledge representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "HDGI ontology mappings refer to the structured connections and relationships defined within the HDGI ontology that facilitate the integration and interoperability of gesture data across various devices and applications in Human Device Interaction.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-5",
          "local_name": "HDGI ontology mappings",
          "local_types": [
            "data standard",
            "ontology",
            "ontology mapping",
            "data mapping",
            "knowledge representation"
          ],
          "iri": "Entity-hdgi_ontology_mapping-Mention-1"
        }
      ],
      "relevance": 0.76904296875
    },
    "Entity-the_presented_ontology": {
      "node_id": "the_presented_ontology",
      "disambiguation_index": 0,
      "label": "The presented ontology",
      "aliases": [
        "The presented ontology"
      ],
      "types": [
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The presented ontology is a formal representation of gestures used in Human Device Interactions (HDI), developed according to Semantic Web standards such as RDF, RDFS, and OWL2, enabling semantic description and extensible mapping of gestures to user and device contexts.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-2",
          "local_name": "The presented ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-the_presented_ontology-Mention-1"
        }
      ],
      "relevance": 0.765625
    },
    "Entity-gesture_representation": {
      "node_id": "gesture_representation",
      "disambiguation_index": 0,
      "label": "gesture representation",
      "aliases": [
        "gesture representation"
      ],
      "types": [
        "gesture",
        "concept",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gesture representation refers to a systematic and semantic model of human gestures used in device interactions, allowing for the mapping of gestures to affordances and contexts within the HDGI ontology, facilitating a shareable and reusable framework for understanding and implementing gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-8",
          "local_name": "gesture representation",
          "local_types": [
            "gesture",
            "concept",
            "representation"
          ],
          "iri": "Entity-gesture_representation-Mention-1"
        }
      ],
      "relevance": 0.7587890625
    },
    "Entity-hdgi_mapping": {
      "node_id": "hdgi_mapping",
      "disambiguation_index": 0,
      "label": "HDGI mappings",
      "aliases": [
        "HDGI mappings"
      ],
      "types": [
        "data structure",
        "mapping"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "HDGI mappings refer to the structured connections and relationships between human gestures and their corresponding device affordances within the HDGI ontology, facilitating the integration and documentation of gesture vocabularies for gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-1",
          "local_name": "HDGI mappings",
          "local_types": [
            "data structure",
            "mapping"
          ],
          "iri": "Entity-hdgi_mapping-Mention-1"
        }
      ],
      "relevance": 0.7529296875
    },
    "Entity-human_device_gesture_interaction": {
      "node_id": "human_device_gesture_interaction",
      "disambiguation_index": 0,
      "label": "Human Device Gesture Interaction",
      "aliases": [
        "gestures related to human device interaction",
        "human-device gesture interactions",
        "Human Device Gesture Interactions",
        "gestures related to human device interactions",
        "human device gesture interaction",
        "Human Device Gesture Interaction",
        "human device gesture interactions"
      ],
      "types": [
        "framework",
        "field of study",
        "ontology",
        "communication",
        "concept",
        "interaction",
        "user interface",
        "gesture",
        "model",
        "interaction type",
        "human-computer interaction",
        "field"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Human Device Gesture Interaction refers to the study and design of interactions between humans and devices through the use of gestures, encompassing frameworks, models, and ontologies that facilitate understanding and implementation of such interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-1",
          "local_name": "Human Device Gesture Interaction",
          "local_types": [
            "ontology",
            "concept",
            "framework"
          ],
          "iri": "Entity-human_device_gesture_interaction-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-1",
          "local_name": "Human Device Gesture Interaction",
          "local_types": [
            "gesture",
            "model",
            "ontology",
            "interaction"
          ],
          "iri": "Entity-human_device_gesture_interaction-Mention-2"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-7",
          "local_name": "Human Device Gesture Interactions",
          "local_types": [
            "field of study",
            "interaction type",
            "field",
            "human-computer interaction",
            "interaction"
          ],
          "iri": "Entity-human_device_gesture_interaction-Mention-3"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-2",
          "local_name": "human device gesture interaction",
          "local_types": [
            "interaction type",
            "user interface"
          ],
          "iri": "Entity-human_device_gesture_interaction-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-2",
          "local_name": "human-device gesture interactions",
          "local_types": [
            "communication",
            "human-computer interaction",
            "interaction"
          ],
          "iri": "Entity-human_device_gesture_interaction-Mention-5"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "gestures related to human device interaction",
          "local_types": [
            "gesture",
            "interaction"
          ],
          "iri": "Entity-human_device_gesture_interaction-Mention-6"
        }
      ],
      "relevance": 0.75
    },
    "Entity-our_approach": {
      "node_id": "our_approach",
      "disambiguation_index": 0,
      "label": "Our approach",
      "aliases": [
        "Our approach"
      ],
      "types": [
        "methodology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Our approach refers to the design of a Human Device Gesture Interaction (HDGI) ontology aimed at mapping existing gesture vocabularies and their relationships to systems, facilitating the understanding and interpretation of user gestures.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-1",
          "local_name": "Our approach",
          "local_types": [
            "methodology"
          ],
          "iri": "Entity-our_approach-Mention-1"
        }
      ],
      "relevance": 0.75
    },
    "Entity-hdgi__human": {
      "node_id": "hdgi__human",
      "disambiguation_index": 0,
      "label": "hdgi:Human",
      "aliases": [
        "hdgi:Human"
      ],
      "types": [
        "ontology class",
        "ontology",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Human refers to a class within the HDGI ontology that represents the human entity involved in gesture-based interactions with devices, specifically focusing on the upper limb gestures used in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Human",
          "local_types": [
            "ontology class",
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__human-Mention-1"
        }
      ],
      "relevance": 0.7490234375
    },
    "Entity-our_ontology": {
      "node_id": "our_ontology",
      "disambiguation_index": 0,
      "label": "our ontology",
      "aliases": [
        "our ontology"
      ],
      "types": [
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Our ontology refers to a formalized framework that systematically describes human gestures used in Human Device Interactions (HDI), focusing on gestures with specific referents to device affordances, and is designed to be extensible for incorporating new gestures and extending beyond upper limb gestures.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "our ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-our_ontology-Mention-1"
        }
      ],
      "relevance": 0.74658203125
    },
    "Entity-this_mapping": {
      "node_id": "this_mapping",
      "disambiguation_index": 0,
      "label": "this mapping",
      "aliases": [
        "this mapping"
      ],
      "types": [
        "process"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This mapping refers to the process of linking existing gesture vocabularies and their relationships to specific system affordances within the Human Device Gesture Interaction (HDGI) ontology, enabling a better understanding and interpretation of user gestures across different interactive systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-3",
          "local_name": "this mapping",
          "local_types": [
            "process"
          ],
          "iri": "Entity-this_mapping-Mention-1"
        }
      ],
      "relevance": 0.7451171875
    },
    "Entity-gesture_related_to_device_interaction": {
      "node_id": "gesture_related_to_device_interaction",
      "disambiguation_index": 0,
      "label": "gestures related to device interactions",
      "aliases": [
        "gestures related to device interactions",
        "gestures related to human device interactions"
      ],
      "types": [
        "gesture",
        "interaction"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Gestures related to device interactions refer to the specific movements and poses of the human upper limbs that are utilized to control and communicate with devices, as defined within the HDGI ontology, which maps these gestures to their corresponding affordances and contexts.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "gestures related to device interactions",
          "local_types": [
            "gesture",
            "interaction"
          ],
          "iri": "Entity-gesture_related_to_device_interaction-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-1",
          "local_name": "gestures related to human device interactions",
          "local_types": [
            "gesture",
            "interaction"
          ],
          "iri": "Entity-gesture_related_to_device_interaction-Mention-2"
        }
      ],
      "relevance": 0.7451171875
    },
    "Entity-formalization_of_hdgi_v0.1": {
      "node_id": "formalization_of_hdgi_v0.1",
      "disambiguation_index": 0,
      "label": "formalization of HDGI v0.1",
      "aliases": [
        "formalization of HDGI v0.1"
      ],
      "types": [
        "formalization"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'formalization of HDGI v0.1' refers to the structured representation and design of the Human Device Gesture Interaction ontology version 0.1, which systematically describes and maps gestures used in human-device interactions to enhance interoperability and user experience in gesture-controlled systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "formalization of HDGI v0.1",
          "local_types": [
            "formalization"
          ],
          "iri": "Entity-formalization_of_hdgi_v0.1-Mention-1"
        }
      ],
      "relevance": 0.7412109375
    },
    "Entity-device_interaction": {
      "node_id": "device_interaction",
      "disambiguation_index": 0,
      "label": "device interactions",
      "aliases": [
        "device interactions"
      ],
      "types": [
        "interaction",
        "interaction type",
        "human-computer interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Device interactions refer to the gestures performed by humans using their upper limbs to interact with devices, as described in the HDGI ontology, which maps these gestures to their corresponding affordances and contexts.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "device interactions",
          "local_types": [
            "interaction",
            "interaction type",
            "human-computer interaction"
          ],
          "iri": "Entity-device_interaction-Mention-1"
        }
      ],
      "relevance": 0.740234375
    },
    "Entity-gesture_ontology": {
      "node_id": "gesture_ontology",
      "disambiguation_index": 0,
      "label": "gesture ontology",
      "aliases": [
        "gesture ontology"
      ],
      "types": [
        "framework",
        "ontology",
        "concept",
        "gesture",
        "gesture representation",
        "conceptual model",
        "knowledge representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The gesture ontology refers to a formal framework designed to systematically describe and map human gestures and their associated meanings or referents, facilitating automated reasoning and interoperability in gesture-based human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-5",
          "local_name": "gesture ontology",
          "local_types": [
            "framework",
            "ontology",
            "concept",
            "gesture",
            "knowledge representation"
          ],
          "iri": "Entity-gesture_ontology-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-2",
          "local_name": "gesture ontology",
          "local_types": [
            "framework",
            "ontology",
            "concept",
            "gesture",
            "gesture representation",
            "conceptual model"
          ],
          "iri": "Entity-gesture_ontology-Mention-2"
        }
      ],
      "relevance": 0.73974609375
    },
    "Entity-hdgi__gesture": {
      "node_id": "hdgi__gesture",
      "disambiguation_index": 0,
      "label": "hdgi:Gesture",
      "aliases": [
        "hdgi:Gesture",
        "Gesture A hdgi:Gesture"
      ],
      "types": [
        "programming construct",
        "gesture type",
        "ontology class",
        "ontology",
        "concept",
        "ontology term",
        "gesture",
        "entity",
        "gesture representation",
        "action",
        "type",
        "class",
        "movement"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Gesture refers to a class within the HDGI ontology that models the various poses and movements of human upper limbs used for interacting with devices, facilitating a semantic understanding of gestures in the context of Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Gesture",
          "local_types": [
            "ontology class",
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__gesture-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-2",
          "local_name": "hdgi:Gesture",
          "local_types": [
            "programming construct",
            "concept",
            "gesture",
            "gesture representation",
            "class"
          ],
          "iri": "Entity-hdgi__gesture-Mention-2"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-4",
          "local_name": "hdgi:Gesture",
          "local_types": [
            "entity",
            "concept",
            "class",
            "gesture type"
          ],
          "iri": "Entity-hdgi__gesture-Mention-3"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "hdgi:Gesture",
          "local_types": [
            "ontology",
            "concept"
          ],
          "iri": "Entity-hdgi__gesture-Mention-4"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "hdgi:Gesture",
          "local_types": [
            "gesture",
            "ontology class"
          ],
          "iri": "Entity-hdgi__gesture-Mention-5"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-6",
          "local_name": "hdgi:Gesture",
          "local_types": [
            "ontology class",
            "concept",
            "ontology term",
            "action",
            "movement"
          ],
          "iri": "Entity-hdgi__gesture-Mention-6"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "Gesture A hdgi:Gesture",
          "local_types": [
            "gesture",
            "type"
          ],
          "iri": "Entity-hdgi__gesture-Mention-7"
        }
      ],
      "relevance": 0.73876953125
    },
    "Entity-relationship_introduced_in_hdgi": {
      "node_id": "relationship_introduced_in_hdgi",
      "disambiguation_index": 0,
      "label": "relationships introduced in HDGI",
      "aliases": [
        "relationships introduced in HDGI"
      ],
      "types": [
        "relationships",
        "HDGI"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The 'relationships introduced in HDGI' refer to the connections and mappings defined within the HDGI ontology that link human gestures performed with the upper limbs to their corresponding affordances and contexts in Human Device Interactions, facilitating a flexible and extensible framework for gesture representation.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-8",
          "local_name": "relationships introduced in HDGI",
          "local_types": [
            "relationships",
            "HDGI"
          ],
          "iri": "Entity-relationship_introduced_in_hdgi-Mention-1"
        }
      ],
      "relevance": 0.73828125
    },
    "Entity-hdgi_restful_service": {
      "node_id": "hdgi_restful_service",
      "disambiguation_index": 0,
      "label": "HDGI RESTful service",
      "aliases": [
        "HDGI RESTful service"
      ],
      "types": [
        "technology",
        "service",
        "software",
        "software service",
        "web service"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The HDGI RESTful service is a web service designed to facilitate the integration of the Human Device Gesture Interaction ontology with gesture recognition systems, enabling developers to access and utilize standardized gesture mappings and affordances in cloud-based applications.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "HDGI RESTful service",
          "local_types": [
            "technology",
            "service",
            "software",
            "software service",
            "web service"
          ],
          "iri": "Entity-hdgi_restful_service-Mention-1"
        }
      ],
      "relevance": 0.73583984375
    },
    "Entity-relationship_between_gesture_and_device_affordances": {
      "node_id": "relationship_between_gesture_and_device_affordances",
      "disambiguation_index": 0,
      "label": "relationships between gestures and device affordances",
      "aliases": [
        "the relationship between affordances and a particular gesture",
        "relationships between gestures and device affordances"
      ],
      "types": [
        "relationship",
        "gesture",
        "affordance"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The entity 'relationships between gestures and device affordances' refers to the systematic connections and mappings established within the HDGI ontology that link specific human gestures to the functional capabilities (affordances) of devices, facilitating better understanding and interaction in human-device interfaces.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-1-Sentence-3",
          "local_name": "relationships between gestures and device affordances",
          "local_types": [
            "relationship",
            "gesture",
            "affordance"
          ],
          "iri": "Entity-relationship_between_gesture_and_device_affordances-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "the relationship between affordances and a particular gesture",
          "local_types": [
            "relationship",
            "affordance",
            "gesture"
          ],
          "iri": "Entity-relationship_between_gesture_and_device_affordances-Mention-2"
        }
      ],
      "relevance": 0.73486328125
    },
    "Entity-hdgi_mapping_service": {
      "node_id": "hdgi_mapping_service",
      "disambiguation_index": 0,
      "label": "HDGI Mapping service",
      "aliases": [
        "HDGI Mapping service"
      ],
      "types": [
        "technology",
        "service",
        "software",
        "web service",
        "software tool"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The HDGI Mapping service is a web service interface designed to integrate with existing gesture recognition systems, facilitating the application of the Human Device Gesture Interaction ontology in recognizing and interpreting human gestures in relation to device affordances.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-2-Sentence-2",
          "local_name": "HDGI Mapping service",
          "local_types": [
            "technology",
            "service",
            "software",
            "web service",
            "software tool"
          ],
          "iri": "Entity-hdgi_mapping_service-Mention-1"
        }
      ],
      "relevance": 0.734375
    },
    "Entity-it_sample_usage": {
      "node_id": "it_sample_usage",
      "disambiguation_index": 0,
      "label": "its sample usage",
      "aliases": [
        "its sample usage"
      ],
      "types": [
        "usage"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'its sample usage' refers to the practical application examples of the Human Device Gesture Interaction (HDGI) ontology, which is designed to facilitate the understanding and interpretation of gestures in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-1",
          "local_name": "its sample usage",
          "local_types": [
            "usage"
          ],
          "iri": "Entity-it_sample_usage-Mention-1"
        }
      ],
      "relevance": 0.73046875
    },
    "Entity-the_design_and_development_of_gestural_interface": {
      "node_id": "the_design_and_development_of_gestural_interface",
      "disambiguation_index": 0,
      "label": "the design and development of gestural interfaces",
      "aliases": [
        "the design and development of gestural interfaces"
      ],
      "types": [
        "design",
        "development",
        "gestural interface"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The design and development of gestural interfaces refers to the systematic process of creating user interfaces that utilize hand gestures for interaction, focusing on gesture recognition, standardization, and the integration of gestures into various applications, particularly in the context of the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "the design and development of gestural interfaces",
          "local_types": [
            "design",
            "development",
            "gestural interface"
          ],
          "iri": "Entity-the_design_and_development_of_gestural_interface-Mention-1"
        }
      ],
      "relevance": 0.73046875
    },
    "Entity-systematic_analysis_and_description_of_gesture": {
      "node_id": "systematic_analysis_and_description_of_gesture",
      "disambiguation_index": 0,
      "label": "systematic analysis and description of gestures",
      "aliases": [
        "systematic analysis and description of gestures"
      ],
      "types": [
        "analysis",
        "gesture"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The systematic analysis and description of gestures refers to the formal examination and characterization of human gestures utilized in Human Device Interactions (HDI), aimed at creating an ontology that standardizes and semantically describes these gestures within the context of the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "systematic analysis and description of gestures",
          "local_types": [
            "analysis",
            "gesture"
          ],
          "iri": "Entity-systematic_analysis_and_description_of_gesture-Mention-1"
        }
      ],
      "relevance": 0.7294921875
    },
    "Entity-user_s_gesture": {
      "node_id": "user_s_gesture",
      "disambiguation_index": 0,
      "label": "user's gesture",
      "aliases": [
        "user's gesture"
      ],
      "types": [
        "gesture",
        "human action",
        "interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'user's gesture' refers to the specific physical actions or movements performed by a user to communicate intent or interact with a device, which are semantically analyzed and mapped to affordances within the context of Human Device Gesture Interactions as described in the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "user's gesture",
          "local_types": [
            "gesture",
            "human action",
            "interaction"
          ],
          "iri": "Entity-user_s_gesture-Mention-1"
        }
      ],
      "relevance": 0.72900390625
    },
    "Entity-a_tool_on_how_to_integrate_the_hdgi_ontology": {
      "node_id": "a_tool_on_how_to_integrate_the_hdgi_ontology",
      "disambiguation_index": 0,
      "label": "a tool on how to integrate the HDGI ontology",
      "aliases": [
        "a tool on how to integrate the HDGI ontology"
      ],
      "types": [
        "tool",
        "integration"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A tool designed to assist developers and designers in incorporating the Human Device Gesture Interaction (HDGI) ontology into their applications, facilitating the integration of gesture recognition and interaction semantics.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "a tool on how to integrate the HDGI ontology",
          "local_types": [
            "tool",
            "integration"
          ],
          "iri": "Entity-a_tool_on_how_to_integrate_the_hdgi_ontology-Mention-1"
        }
      ],
      "relevance": 0.72802734375
    },
    "Entity-semantic_model_of_gesture": {
      "node_id": "semantic_model_of_gesture",
      "disambiguation_index": 0,
      "label": "semantic model of gestures",
      "aliases": [
        "semantic model of gestures",
        "a semantic model of gestures"
      ],
      "types": [
        "gestures",
        "model"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'semantic model of gestures' refers to a formal representation within the HDGI ontology that describes human gestures used in device interactions, incorporating their associated knowledge, affordances, and contexts to facilitate understanding and mapping of gestures for various applications.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-7",
          "local_name": "semantic model of gestures",
          "local_types": [
            "model"
          ],
          "iri": "Entity-semantic_model_of_gesture-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-7",
          "local_name": "a semantic model of gestures",
          "local_types": [
            "model",
            "gestures"
          ],
          "iri": "Entity-semantic_model_of_gesture-Mention-2"
        }
      ],
      "relevance": 0.7275390625
    },
    "Entity-our_model": {
      "node_id": "our_model",
      "disambiguation_index": 0,
      "label": "our model",
      "aliases": [
        "our model"
      ],
      "types": [
        "model"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Our model refers to the HDGI ontology, which is designed to flexibly represent and describe human gestures and poses in Human Device Interactions, accommodating various data representations from different gesture recognition devices.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-18",
          "local_name": "our model",
          "local_types": [
            "model"
          ],
          "iri": "Entity-our_model-Mention-1"
        }
      ],
      "relevance": 0.7275390625
    },
    "Entity-this_study": {
      "node_id": "this_study",
      "disambiguation_index": 0,
      "label": "this study",
      "aliases": [
        "this study"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This study aims to define a semantic model of gestures used in Human Device Interactions (HDI), incorporating associated knowledge to facilitate understanding and mapping of gestures to device affordances.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-7",
          "local_name": "this study",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_study-Mention-1"
        }
      ],
      "relevance": 0.72705078125
    },
    "Entity-gesture": {
      "node_id": "gesture",
      "disambiguation_index": 0,
      "label": "Gesture",
      "aliases": [
        "gestures",
        "gesture",
        "Gesture"
      ],
      "types": [
        "sign language",
        "communication method",
        "class",
        "term",
        "interaction technique",
        "non-verbal communication",
        "user interface element",
        "human-device interaction",
        "movement",
        "non-verbal cue",
        "interaction",
        "concept",
        "action",
        "input technique",
        "interaction method",
        "nonverbal communication",
        "physical action",
        "communication",
        "human behavior",
        "human action",
        "gesture",
        "input method"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Gesture refers to a defined concept in the HDGI ontology that categorizes gestures into static and dynamic types, with specific characteristics such as poses, movements, and body parts involved in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "Gesture",
          "local_types": [
            "action",
            "term",
            "concept"
          ],
          "iri": "Entity-gesture-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "interaction method",
            "human action",
            "input method",
            "action",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "gestures",
          "local_types": [
            "input method",
            "interaction technique"
          ],
          "iri": "Entity-gesture-Mention-3"
        },
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "interaction method",
            "human behavior",
            "human action",
            "action",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "interaction method",
            "interaction technique",
            "communication",
            "gesture",
            "input method"
          ],
          "iri": "Entity-gesture-Mention-5"
        },
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "input method",
            "action",
            "gesture",
            "interaction technique"
          ],
          "iri": "Entity-gesture-Mention-6"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "interaction technique",
            "nonverbal communication",
            "communication method",
            "non-verbal communication",
            "gesture",
            "input method",
            "action"
          ],
          "iri": "Entity-gesture-Mention-7"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-5",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "action",
            "communication"
          ],
          "iri": "Entity-gesture-Mention-8"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "input method",
            "gesture",
            "interaction technique"
          ],
          "iri": "Entity-gesture-Mention-9"
        },
        {
          "reference": "Section-2-Paragraph-5-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "interaction method",
            "interaction technique",
            "user interface element",
            "concept",
            "gesture",
            "input method"
          ],
          "iri": "Entity-gesture-Mention-10"
        },
        {
          "reference": "Section-2-Paragraph-5-Sentence-5",
          "local_name": "gestures",
          "local_types": [
            "input method",
            "interaction technique"
          ],
          "iri": "Entity-gesture-Mention-11"
        },
        {
          "reference": "Section-2-Paragraph-6-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "input method",
            "gesture",
            "interaction technique"
          ],
          "iri": "Entity-gesture-Mention-12"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "input method",
            "gesture",
            "interaction technique"
          ],
          "iri": "Entity-gesture-Mention-13"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-3",
          "local_name": "gestures",
          "local_types": [
            "action",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-14"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "communication method",
            "interaction technique",
            "gesture",
            "input method",
            "action",
            "non-verbal cue"
          ],
          "iri": "Entity-gesture-Mention-15"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "action",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-16"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "interaction technique",
            "gesture",
            "human action",
            "input method",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-17"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "physical action",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-18"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "communication method",
            "human action"
          ],
          "iri": "Entity-gesture-Mention-19"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "interaction technique",
            "gesture",
            "input method",
            "action",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-20"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-2",
          "local_name": "gesture",
          "local_types": [
            "action",
            "input method"
          ],
          "iri": "Entity-gesture-Mention-21"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-3",
          "local_name": "gestures",
          "local_types": [
            "interaction method",
            "user interface element"
          ],
          "iri": "Entity-gesture-Mention-22"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-4",
          "local_name": "gesture",
          "local_types": [
            "action",
            "input method"
          ],
          "iri": "Entity-gesture-Mention-23"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "input method",
            "gesture",
            "interaction technique"
          ],
          "iri": "Entity-gesture-Mention-24"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "action",
            "communication",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-25"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "non-verbal communication",
            "gesture",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-26"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "gesture",
          "local_types": [
            "action",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-27"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "gesture",
          "local_types": [
            "action",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-28"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "action",
            "communication"
          ],
          "iri": "Entity-gesture-Mention-29"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-3",
          "local_name": "gestures",
          "local_types": [
            "non-verbal communication",
            "gesture",
            "sign language"
          ],
          "iri": "Entity-gesture-Mention-30"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "gestures",
          "local_types": [
            "action",
            "input method"
          ],
          "iri": "Entity-gesture-Mention-31"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "action",
            "communication"
          ],
          "iri": "Entity-gesture-Mention-32"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "action"
          ],
          "iri": "Entity-gesture-Mention-33"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "action",
            "communication"
          ],
          "iri": "Entity-gesture-Mention-34"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-5",
          "local_name": "gestures",
          "local_types": [
            "non-verbal communication",
            "sign language"
          ],
          "iri": "Entity-gesture-Mention-35"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "action",
            "gesture",
            "human action",
            "communication"
          ],
          "iri": "Entity-gesture-Mention-36"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-3",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "action",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-37"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "gestures",
          "local_types": [
            "physical action",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-38"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "action",
            "interaction",
            "communication method"
          ],
          "iri": "Entity-gesture-Mention-39"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "gestures",
          "local_types": [
            "action",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-40"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "gestures",
          "local_types": [
            "interaction method",
            "input technique"
          ],
          "iri": "Entity-gesture-Mention-41"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-7",
          "local_name": "gestures",
          "local_types": [
            "communication",
            "non-verbal cue"
          ],
          "iri": "Entity-gesture-Mention-42"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-2",
          "local_name": "gestures",
          "local_types": [
            "concept",
            "gesture",
            "action",
            "class",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-43"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "gesture",
          "local_types": [
            "action",
            "movement"
          ],
          "iri": "Entity-gesture-Mention-44"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "gesture",
          "local_types": [
            "gesture",
            "action",
            "movement"
          ],
          "iri": "Entity-gesture-Mention-45"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-5",
          "local_name": "gesture",
          "local_types": [
            "action",
            "communication"
          ],
          "iri": "Entity-gesture-Mention-46"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-1",
          "local_name": "Gesture",
          "local_types": [
            "concept",
            "action"
          ],
          "iri": "Entity-gesture-Mention-47"
        },
        {
          "reference": "Section-5-Paragraph-3-Sentence-1",
          "local_name": "Gesture",
          "local_types": [
            "concept",
            "action"
          ],
          "iri": "Entity-gesture-Mention-48"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-9",
          "local_name": "gesture",
          "local_types": [
            "action",
            "concept",
            "movement"
          ],
          "iri": "Entity-gesture-Mention-49"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-1",
          "local_name": "gesture",
          "local_types": [
            "action",
            "movement"
          ],
          "iri": "Entity-gesture-Mention-50"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-7",
          "local_name": "gesture",
          "local_types": [
            "action",
            "interaction method"
          ],
          "iri": "Entity-gesture-Mention-51"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-1",
          "local_name": "gesture",
          "local_types": [
            "interaction method",
            "communication method",
            "gesture",
            "input method",
            "action"
          ],
          "iri": "Entity-gesture-Mention-52"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-5",
          "local_name": "gesture",
          "local_types": [
            "action",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-53"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "gesture",
          "local_types": [
            "action",
            "interaction method",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-54"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "gesture",
          "local_types": [
            "action",
            "interaction method"
          ],
          "iri": "Entity-gesture-Mention-55"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "input method",
            "gesture",
            "action",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-56"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "action",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-57"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-3",
          "local_name": "gestures",
          "local_types": [
            "gesture",
            "action",
            "communication"
          ],
          "iri": "Entity-gesture-Mention-58"
        },
        {
          "reference": "Section-11-Paragraph-2-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "action",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-59"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "action",
            "human-device interaction",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-60"
        },
        {
          "reference": "Section-11-Paragraph-4-Sentence-1",
          "local_name": "gestures",
          "local_types": [
            "action",
            "interaction"
          ],
          "iri": "Entity-gesture-Mention-61"
        }
      ],
      "relevance": 0.7255859375
    },
    "Entity-gesture-controlled_interface": {
      "node_id": "gesture-controlled_interface",
      "disambiguation_index": 0,
      "label": "Gesture-controlled interfaces",
      "aliases": [
        "gesture-based interfaces",
        "Gesture-controlled interfaces",
        "gesture interfaces"
      ],
      "types": [
        "gesture-based",
        "interaction technique",
        "technology",
        "gesture-based interface",
        "interface"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Gesture-controlled interfaces are interactive systems that allow users to control devices and applications through hand movements and gestures, often utilizing sensors and cameras to interpret user actions.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "Gesture-controlled interfaces",
          "local_types": [
            "interface",
            "technology"
          ],
          "iri": "Entity-gesture-controlled_interface-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "gesture interfaces",
          "local_types": [
            "interface",
            "technology"
          ],
          "iri": "Entity-gesture-controlled_interface-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "gesture interfaces",
          "local_types": [
            "interface",
            "technology",
            "interaction technique"
          ],
          "iri": "Entity-gesture-controlled_interface-Mention-3"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-6",
          "local_name": "gesture-based interfaces",
          "local_types": [
            "gesture-based interface",
            "interface",
            "technology",
            "gesture-based"
          ],
          "iri": "Entity-gesture-controlled_interface-Mention-4"
        }
      ],
      "relevance": 0.72314453125
    },
    "Entity-new_gesture": {
      "node_id": "new_gesture",
      "disambiguation_index": 0,
      "label": "new gestures",
      "aliases": [
        "new gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "New gestures refer to the innovative and flexible hand movements or poses that can be introduced by device manufacturers, designers, and users for interaction with devices, as defined within the HDGI ontology, which maps these gestures to specific affordances and contexts.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "new gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-new_gesture-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "new gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-new_gesture-Mention-2"
        }
      ],
      "relevance": 0.72265625
    },
    "Entity-namespace_http__w3id.orghdgi": {
      "node_id": "namespace_http__w3id.orghdgi",
      "disambiguation_index": 0,
      "label": "namespace https://w3id.org/hdgi",
      "aliases": [
        "namespace https://w3id.org/hdgi"
      ],
      "types": [
        "namespace"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The namespace https://w3id.org/hdgi is defined for the HDGI ontology, which encompasses all classes related to human gesture interactions in device contexts, ensuring independence from external ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "namespace https://w3id.org/hdgi",
          "local_types": [
            "namespace"
          ],
          "iri": "Entity-namespace_http__w3id.orghdgi-Mention-1"
        }
      ],
      "relevance": 0.72216796875
    },
    "Entity-supported_gesture": {
      "node_id": "supported_gesture",
      "disambiguation_index": 0,
      "label": "supported gestures",
      "aliases": [
        "supported gestures"
      ],
      "types": [
        "concept"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Supported gestures refer to the specific gestures that a device can recognize and respond to, which are associated with particular affordances in the context of Human Device Interactions as defined in the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-6",
          "local_name": "supported gestures",
          "local_types": [
            "concept"
          ],
          "iri": "Entity-supported_gesture-Mention-1"
        }
      ],
      "relevance": 0.72119140625
    },
    "Entity-this_area": {
      "node_id": "this_area",
      "disambiguation_index": 0,
      "label": "this area",
      "aliases": [
        "this area"
      ],
      "types": [
        "field"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This area refers to the current state of research and development in human-device gesture interactions, particularly focusing on the integration and standardization of gesture vocabularies within the context of the Human Device Gesture Interaction (HDGI) ontology.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-1",
          "local_name": "this area",
          "local_types": [
            "field"
          ],
          "iri": "Entity-this_area-Mention-1"
        }
      ],
      "relevance": 0.72021484375
    },
    "Entity-hdi": {
      "node_id": "hdi",
      "disambiguation_index": 0,
      "label": "HDI",
      "aliases": [
        "HDI"
      ],
      "types": [
        "health data integration",
        "framework",
        "concept",
        "index"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "HDI refers to Human Device Interaction, which encompasses the systematic analysis and description of gestures used in interactions between humans and devices.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "HDI",
          "local_types": [
            "health data integration",
            "framework",
            "concept",
            "index"
          ],
          "iri": "Entity-hdi-Mention-1"
        }
      ],
      "relevance": 0.71826171875
    },
    "Entity-gestural_interface": {
      "node_id": "gestural_interface",
      "disambiguation_index": 0,
      "label": "gestural interfaces",
      "aliases": [
        "gestural interfaces"
      ],
      "types": [
        "interaction design",
        "interaction method",
        "interaction technique",
        "technology",
        "user interface",
        "interface",
        "gestural interface",
        "gestural"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Gestural interfaces are user interfaces that allow users to interact with devices or systems through hand gestures and body movements, enabling a natural and intuitive form of communication.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "gestural interfaces",
          "local_types": [
            "interaction design",
            "technology",
            "user interface",
            "gestural interface",
            "interface"
          ],
          "iri": "Entity-gestural_interface-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "gestural interfaces",
          "local_types": [
            "user interface",
            "interface",
            "technology"
          ],
          "iri": "Entity-gestural_interface-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-2",
          "local_name": "gestural interfaces",
          "local_types": [
            "interface",
            "technology",
            "interaction method",
            "interaction technique"
          ],
          "iri": "Entity-gestural_interface-Mention-3"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-4",
          "local_name": "gestural interfaces",
          "local_types": [
            "interaction method",
            "technology",
            "user interface",
            "interface",
            "gestural"
          ],
          "iri": "Entity-gestural_interface-Mention-4"
        }
      ],
      "relevance": 0.7177734375
    },
    "Entity-device": {
      "node_id": "device",
      "disambiguation_index": 0,
      "label": "Device",
      "aliases": [
        "a device",
        "device",
        "devices",
        "Device"
      ],
      "types": [
        "object",
        "product",
        "technology",
        "concept",
        "tool",
        "device",
        "hardware",
        "entity",
        "equipment",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The 'Device' refers to a component or system within the HDGI ontology that can host multiple affordances and is capable of being associated with various gestures, highlighting its role in facilitating human-device interactions in the context of gesture recognition.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "Device",
          "local_types": [
            "concept",
            "entity"
          ],
          "iri": "Entity-device-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "device",
          "local_types": [
            "device",
            "hardware",
            "technology"
          ],
          "iri": "Entity-device-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-3",
          "local_name": "device",
          "local_types": [
            "object",
            "tool"
          ],
          "iri": "Entity-device-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "devices",
          "local_types": [
            "product",
            "device",
            "technology",
            "object"
          ],
          "iri": "Entity-device-Mention-4"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "devices",
          "local_types": [
            "device",
            "hardware",
            "technology"
          ],
          "iri": "Entity-device-Mention-5"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "devices",
          "local_types": [
            "concept",
            "product",
            "technology",
            "class"
          ],
          "iri": "Entity-device-Mention-6"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-3",
          "local_name": "device",
          "local_types": [
            "tool",
            "object"
          ],
          "iri": "Entity-device-Mention-7"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-4",
          "local_name": "device",
          "local_types": [
            "tool",
            "equipment"
          ],
          "iri": "Entity-device-Mention-8"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-5",
          "local_name": "device",
          "local_types": [
            "object",
            "technology"
          ],
          "iri": "Entity-device-Mention-9"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-1",
          "local_name": "device",
          "local_types": [
            "device",
            "hardware",
            "technology"
          ],
          "iri": "Entity-device-Mention-10"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-5",
          "local_name": "device",
          "local_types": [
            "object",
            "technology"
          ],
          "iri": "Entity-device-Mention-11"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-7",
          "local_name": "devices",
          "local_types": [
            "device",
            "entity"
          ],
          "iri": "Entity-device-Mention-12"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-2",
          "local_name": "Device",
          "local_types": [
            "entity",
            "product"
          ],
          "iri": "Entity-device-Mention-13"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "devices",
          "local_types": [
            "device",
            "hardware",
            "technology"
          ],
          "iri": "Entity-device-Mention-14"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-2",
          "local_name": "a device",
          "local_types": [
            "device"
          ],
          "iri": "Entity-device-Mention-15"
        }
      ],
      "relevance": 0.71630859375
    },
    "Entity-hdgi__supportsgesture": {
      "node_id": "hdgi__supportsgesture",
      "disambiguation_index": 0,
      "label": "hdgi:supportsGesture",
      "aliases": [
        "hdgi:supportsGesture"
      ],
      "types": [
        "relationship",
        "action",
        "ontology property",
        "ontology term"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:supportsGesture is an ontology property that represents the relationship between an affordance and the gestures that the affordance can support in the context of Human Device Gesture Interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-6",
          "local_name": "hdgi:supportsGesture",
          "local_types": [
            "relationship",
            "action",
            "ontology property",
            "ontology term"
          ],
          "iri": "Entity-hdgi__supportsgesture-Mention-1"
        }
      ],
      "relevance": 0.71630859375
    },
    "Entity-hdgi__observer": {
      "node_id": "hdgi__observer",
      "disambiguation_index": 0,
      "label": "hdgi:Observer",
      "aliases": [
        "Observer",
        "hdgi:Observer"
      ],
      "types": [
        "ontology class",
        "ontology",
        "concept",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Observer is an ontology class within the HDGI ontology that represents the entity observing human gestures and interactions with devices, facilitating the understanding and mapping of gestures in the context of Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Observer",
          "local_types": [
            "ontology class",
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__observer-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "Observer",
          "local_types": [
            "class",
            "concept"
          ],
          "iri": "Entity-hdgi__observer-Mention-2"
        }
      ],
      "relevance": 0.7158203125
    },
    "Entity-expressive_power_of_our_ontology": {
      "node_id": "expressive_power_of_our_ontology",
      "disambiguation_index": 0,
      "label": "expressive power of our ontology",
      "aliases": [
        "an evaluation of the expressive power of our ontology",
        "expressive power of our ontology"
      ],
      "types": [
        "evaluation",
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'expressive power of our ontology' refers to the capability of the Human Device Gesture Interaction (HDGI) ontology to effectively describe, map, and facilitate the integration of various gesture vocabularies and their relationships to device affordances, thereby enhancing user interaction and personalization in gesture-controlled systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "expressive power of our ontology",
          "local_types": [
            "evaluation"
          ],
          "iri": "Entity-expressive_power_of_our_ontology-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "an evaluation of the expressive power of our ontology",
          "local_types": [
            "evaluation",
            "ontology"
          ],
          "iri": "Entity-expressive_power_of_our_ontology-Mention-2"
        }
      ],
      "relevance": 0.7158203125
    },
    "Entity-manufacturer__developer__and_designer": {
      "node_id": "manufacturer__developer__and_designer",
      "disambiguation_index": 0,
      "label": "manufacturers, developers, and designers",
      "aliases": [
        "manufacturers, developers, and designers"
      ],
      "types": [
        "stakeholders"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Manufacturers, developers, and designers are stakeholders involved in the creation and implementation of gesture-controlled interfaces, utilizing the HDGI ontology to standardize and formalize the understanding of gestures in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "manufacturers, developers, and designers",
          "local_types": [
            "stakeholders"
          ],
          "iri": "Entity-manufacturer__developer__and_designer-Mention-1"
        }
      ],
      "relevance": 0.7158203125
    },
    "Entity-hdgi__device": {
      "node_id": "hdgi__device",
      "disambiguation_index": 0,
      "label": "hdgi:Device",
      "aliases": [
        "hdgi:Device"
      ],
      "types": [
        "relationship",
        "modeling term",
        "object",
        "ontology class",
        "ontology",
        "concept",
        "ontology term",
        "model",
        "device",
        "ontology concept",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Device refers to a class within the HDGI ontology that represents devices involved in human-device interactions, specifically in the context of gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Device",
          "local_types": [
            "ontology class",
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__device-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-9",
          "local_name": "hdgi:Device",
          "local_types": [
            "device",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__device-Mention-2"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-1",
          "local_name": "hdgi:Device",
          "local_types": [
            "relationship",
            "modeling term",
            "ontology class",
            "concept",
            "ontology term",
            "model",
            "ontology concept"
          ],
          "iri": "Entity-hdgi__device-Mention-3"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-7",
          "local_name": "hdgi:Device",
          "local_types": [
            "ontology class",
            "concept",
            "ontology term",
            "device",
            "entity"
          ],
          "iri": "Entity-hdgi__device-Mention-4"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-8",
          "local_name": "hdgi:Device",
          "local_types": [
            "device",
            "concept",
            "entity",
            "object"
          ],
          "iri": "Entity-hdgi__device-Mention-5"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "hdgi:Device",
          "local_types": [
            "ontology class",
            "concept",
            "ontology term",
            "device",
            "entity"
          ],
          "iri": "Entity-hdgi__device-Mention-6"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-2",
          "local_name": "hdgi:Device",
          "local_types": [
            "device"
          ],
          "iri": "Entity-hdgi__device-Mention-7"
        }
      ],
      "relevance": 0.71484375
    },
    "Entity-hdgi__upperarmgesture": {
      "node_id": "hdgi__upperarmgesture",
      "disambiguation_index": 0,
      "label": "hdgi:UpperArmGesture",
      "aliases": [
        "hdgi:UpperArmGesture"
      ],
      "types": [
        "ontology",
        "subclass",
        "gesture",
        "gesture subclass",
        "class",
        "type"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:UpperArmGesture refers to a specific subclass of dynamic gestures within the HDGI ontology that involves movements and poses of the upper arm, allowing for the systematic analysis and description of gestures used in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-1",
          "local_name": "hdgi:UpperArmGesture",
          "local_types": [
            "ontology",
            "subclass",
            "gesture",
            "gesture subclass",
            "class",
            "type"
          ],
          "iri": "Entity-hdgi__upperarmgesture-Mention-1"
        }
      ],
      "relevance": 0.71435546875
    },
    "Entity-manufacturers-devices": {
      "node_id": "manufacturers-devices",
      "disambiguation_index": 0,
      "label": "manufacturers-devices",
      "aliases": [
        "manufacturers-devices"
      ],
      "types": [
        "hardware",
        "device"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'manufacturers-devices' refers to various gesture recognition devices produced by different manufacturers that can utilize distinct coordinate systems and data representations for modeling human gestures in the context of the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-18",
          "local_name": "manufacturers-devices",
          "local_types": [
            "hardware",
            "device"
          ],
          "iri": "Entity-manufacturers-devices-Mention-1"
        }
      ],
      "relevance": 0.71435546875
    },
    "Entity-hdgi__usercontext": {
      "node_id": "hdgi__usercontext",
      "disambiguation_index": 0,
      "label": "hdgi:UserContext",
      "aliases": [
        "hdgi:UserContext"
      ],
      "types": [
        "ontology class",
        "concept",
        "ontology term",
        "model",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:UserContext refers to a class in the HDGI ontology that represents the contextual factors influencing a user's gesture interactions with devices, essential for understanding user intent and facilitating effective gesture recognition in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-7",
          "local_name": "hdgi:UserContext",
          "local_types": [
            "ontology class",
            "concept",
            "ontology term",
            "model",
            "class"
          ],
          "iri": "Entity-hdgi__usercontext-Mention-1"
        }
      ],
      "relevance": 0.7138671875
    },
    "Entity-device_b": {
      "node_id": "device_b",
      "disambiguation_index": 0,
      "label": "Device B",
      "aliases": [
        "Device B"
      ],
      "types": [
        "hardware",
        "product",
        "device",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Device B is a hardware device capable of detecting user gestures and interpreting them to facilitate interaction with other devices, specifically in the context of affordance mapping within the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-4",
          "local_name": "Device B",
          "local_types": [
            "device",
            "hardware",
            "technology"
          ],
          "iri": "Entity-device_b-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-3",
          "local_name": "Device B",
          "local_types": [
            "device",
            "product",
            "hardware"
          ],
          "iri": "Entity-device_b-Mention-2"
        }
      ],
      "relevance": 0.71337890625
    },
    "Entity-the_description_above": {
      "node_id": "the_description_above",
      "disambiguation_index": 0,
      "label": "the description above",
      "aliases": [
        "the description above"
      ],
      "types": [
        "description"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The description above refers to the example modeling of the relationships between hdgi:Affordance, hdgi:Device, and hdgi:Context in the HDGI ontology, which illustrates how these elements interact to enhance gesture recognition and user intent understanding in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-1",
          "local_name": "the description above",
          "local_types": [
            "description"
          ],
          "iri": "Entity-the_description_above-Mention-1"
        }
      ],
      "relevance": 0.712890625
    },
    "Entity-hdgi__handgesture": {
      "node_id": "hdgi__handgesture",
      "disambiguation_index": 0,
      "label": "hdgi:HandGesture",
      "aliases": [
        "hdgi:HandGesture"
      ],
      "types": [
        "ontology",
        "subclass",
        "gesture",
        "gesture subclass",
        "class",
        "type"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:HandGesture refers to a subclass of gestures within the HDGI ontology that specifically encompasses gestures performed using the hands, allowing for detailed modeling and semantic description of hand movements in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-1",
          "local_name": "hdgi:HandGesture",
          "local_types": [
            "ontology",
            "subclass",
            "gesture",
            "gesture subclass",
            "class",
            "type"
          ],
          "iri": "Entity-hdgi__handgesture-Mention-1"
        }
      ],
      "relevance": 0.71142578125
    },
    "Entity-class_and_property_of_the_hdgi_ontology": {
      "node_id": "class_and_property_of_the_hdgi_ontology",
      "disambiguation_index": 0,
      "label": "classes and properties of the HDGI ontology",
      "aliases": [
        "the classes and properties of the HDGI ontology",
        "classes and properties of the HDGI ontology"
      ],
      "types": [
        "ontology component",
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The classes and properties of the HDGI ontology are structured components that define and represent the gestures of the human upper limb, along with their associated affordances and contextual relationships, facilitating a semantic understanding of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-2",
          "local_name": "classes and properties of the HDGI ontology",
          "local_types": [
            "ontology component"
          ],
          "iri": "Entity-class_and_property_of_the_hdgi_ontology-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-2",
          "local_name": "the classes and properties of the HDGI ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-class_and_property_of_the_hdgi_ontology-Mention-2"
        }
      ],
      "relevance": 0.7109375
    },
    "Entity-a_new_namespace_http__w3id.orghdgi": {
      "node_id": "a_new_namespace_http__w3id.orghdgi",
      "disambiguation_index": 0,
      "label": "a new namespace https://w3id.org/hdgi",
      "aliases": [
        "a new namespace https://w3id.org/hdgi"
      ],
      "types": [
        "namespace",
        "URL"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The entity 'a new namespace https://w3id.org/hdgi' refers to a dedicated namespace created for the HDGI ontology, which is designed to define and categorize gestures used in Human Device Interactions, ensuring independence from external ontologies while facilitating relevant mappings.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "a new namespace https://w3id.org/hdgi",
          "local_types": [
            "namespace",
            "URL"
          ],
          "iri": "Entity-a_new_namespace_http__w3id.orghdgi-Mention-1"
        }
      ],
      "relevance": 0.71044921875
    },
    "Entity-hdgi__gesture_class": {
      "node_id": "hdgi__gesture_class",
      "disambiguation_index": 0,
      "label": "hdgi:Gesture class",
      "aliases": [
        "hdgi:Gesture class"
      ],
      "types": [
        "class"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The hdgi:Gesture class is a component of the HDGI ontology that represents a collection of poses, allowing for the modeling and semantic description of gestures used in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-2-Sentence-2",
          "local_name": "hdgi:Gesture class",
          "local_types": [
            "class"
          ],
          "iri": "Entity-hdgi__gesture_class-Mention-1"
        }
      ],
      "relevance": 0.708984375
    },
    "Entity-this_core_ontology_design_pattern": {
      "node_id": "this_core_ontology_design_pattern",
      "disambiguation_index": 0,
      "label": "This core ontology design pattern",
      "aliases": [
        "This core ontology design pattern"
      ],
      "types": [
        "ontology design pattern"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This core ontology design pattern refers to the foundational structure of the HDGI ontology, which encompasses key classes and relationships for modeling human upper limb gestures and their interactions with devices, designed for flexibility and extensibility in gesture representation.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-4",
          "local_name": "This core ontology design pattern",
          "local_types": [
            "ontology design pattern"
          ],
          "iri": "Entity-this_core_ontology_design_pattern-Mention-1"
        }
      ],
      "relevance": 0.70703125
    },
    "Entity-an_ontology": {
      "node_id": "an_ontology",
      "disambiguation_index": 0,
      "label": "an ontology",
      "aliases": [
        "our ontology",
        "the ontology",
        "an ontology"
      ],
      "types": [
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "An ontology in this context refers to a formal representation that systematically describes and categorizes gestures used in Human Device Interactions (HDI), utilizing Semantic Web standards to enable semantic understanding and extensibility.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "an ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-an_ontology-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-4",
          "local_name": "the ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-an_ontology-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-1",
          "local_name": "our ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-an_ontology-Mention-3"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "the ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-an_ontology-Mention-4"
        },
        {
          "reference": "Section-11-Paragraph-2-Sentence-1",
          "local_name": "the ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-an_ontology-Mention-5"
        }
      ],
      "relevance": 0.70556640625
    },
    "Entity-possible_extension": {
      "node_id": "possible_extension",
      "disambiguation_index": 0,
      "label": "possible extensions",
      "aliases": [
        "possible extensions"
      ],
      "types": [
        "extension"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Possible extensions refer to the potential enhancements to the Human Device Gesture Interaction (HDGI) ontology, specifically the incorporation of additional gesture types, such as facial and head gestures, to broaden its applicability and comprehensiveness in gesture recognition systems.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-1",
          "local_name": "possible extensions",
          "local_types": [
            "extension"
          ],
          "iri": "Entity-possible_extension-Mention-1"
        }
      ],
      "relevance": 0.70556640625
    },
    "Entity-these_system": {
      "node_id": "these_system",
      "disambiguation_index": 0,
      "label": "these systems",
      "aliases": [
        "these systems"
      ],
      "types": [
        "system"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "These systems refer to gesture-controlled interfaces in various applications, such as automobiles and smart homes, which typically offer limited gesture selection options, often defined by manufacturers.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-4",
          "local_name": "these systems",
          "local_types": [
            "system"
          ],
          "iri": "Entity-these_system-Mention-1"
        }
      ],
      "relevance": 0.705078125
    },
    "Entity-currently_available_and_contemporary_gesture": {
      "node_id": "currently_available_and_contemporary_gesture",
      "disambiguation_index": 0,
      "label": "currently available and contemporary gestures",
      "aliases": [
        "currently available and contemporary gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Currently available and contemporary gestures refer to the predefined set of gestures that are accessible through the HDGI-gesture repository, which designers, device manufacturers, and developers can utilize to map these gestures to specific device affordances within the context of Human Device Interaction.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "currently available and contemporary gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-currently_available_and_contemporary_gesture-Mention-1"
        }
      ],
      "relevance": 0.705078125
    },
    "Entity-hdgi_web_app": {
      "node_id": "hdgi_web_app",
      "disambiguation_index": 0,
      "label": "HDGI web app",
      "aliases": [
        "HDGI web app"
      ],
      "types": [
        "software",
        "web app",
        "application",
        "web application"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The HDGI web app is a RESTful web application that serves as a comprehensive API-driven service for accessing and managing gesture vocabularies and their mappings to device affordances, facilitating integration with gesture recognition software and promoting collaboration within the research community.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-6",
          "local_name": "HDGI web app",
          "local_types": [
            "software",
            "web app",
            "application",
            "web application"
          ],
          "iri": "Entity-hdgi_web_app-Mention-1"
        }
      ],
      "relevance": 0.70458984375
    },
    "Entity-a_gesture_(1)": {
      "node_id": "a_gesture_(1)",
      "disambiguation_index": 1,
      "label": "a gesture",
      "aliases": [
        "a gesture"
      ],
      "types": [
        "action"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A gesture refers to a specific action performed by a user to communicate intent or affordance to a device within the context of Human Device Interactions, as modeled in the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-5",
          "local_name": "a gesture",
          "local_types": [
            "action"
          ],
          "iri": "Entity-a_gesture_(1)-Mention-1"
        }
      ],
      "relevance": 0.703125
    },
    "Entity-hdgi__movement": {
      "node_id": "hdgi__movement",
      "disambiguation_index": 0,
      "label": "hdgi:Movement",
      "aliases": [
        "A hdgi:Movement",
        "hdgi:Movement"
      ],
      "types": [
        "term",
        "programming construct",
        "movement type",
        "gesture type",
        "ontology class",
        "ontology",
        "concept",
        "entity",
        "movement",
        "action",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Movement refers to a class within the HDGI ontology that models the dynamics and characteristics of human upper limb movements used in gesture-controlled interactions with devices.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Movement",
          "local_types": [
            "ontology class",
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__movement-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "hdgi:Movement",
          "local_types": [
            "term",
            "ontology",
            "concept",
            "action",
            "movement"
          ],
          "iri": "Entity-hdgi__movement-Mention-2"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-2",
          "local_name": "hdgi:Movement",
          "local_types": [
            "term",
            "concept",
            "movement type"
          ],
          "iri": "Entity-hdgi__movement-Mention-3"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-1",
          "local_name": "hdgi:Movement",
          "local_types": [
            "gesture type",
            "concept",
            "programming construct",
            "class"
          ],
          "iri": "Entity-hdgi__movement-Mention-4"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-5",
          "local_name": "hdgi:Movement",
          "local_types": [
            "entity",
            "concept",
            "movement"
          ],
          "iri": "Entity-hdgi__movement-Mention-5"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-2",
          "local_name": "A hdgi:Movement",
          "local_types": [
            "movement"
          ],
          "iri": "Entity-hdgi__movement-Mention-6"
        }
      ],
      "relevance": 0.70263671875
    },
    "Entity-gesture_recognition_system": {
      "node_id": "gesture_recognition_system",
      "disambiguation_index": 0,
      "label": "gesture recognition systems",
      "aliases": [
        "gesture recognition systems"
      ],
      "types": [
        "gesture recognition",
        "technology",
        "system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Gesture recognition systems are technological systems designed to interpret and analyze human gestures as input for various applications, enabling interaction between users and devices.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-2",
          "local_name": "gesture recognition systems",
          "local_types": [
            "gesture recognition",
            "technology",
            "system"
          ],
          "iri": "Entity-gesture_recognition_system-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-3",
          "local_name": "gesture recognition systems",
          "local_types": [
            "gesture recognition",
            "technology",
            "system"
          ],
          "iri": "Entity-gesture_recognition_system-Mention-2"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-3",
          "local_name": "gesture recognition systems",
          "local_types": [
            "gesture recognition",
            "technology",
            "system"
          ],
          "iri": "Entity-gesture_recognition_system-Mention-3"
        },
        {
          "reference": "Section-11-Paragraph-2-Sentence-2",
          "local_name": "gesture recognition systems",
          "local_types": [
            "gesture recognition",
            "technology",
            "system"
          ],
          "iri": "Entity-gesture_recognition_system-Mention-4"
        }
      ],
      "relevance": 0.7021484375
    },
    "Entity-the_provided_gesture": {
      "node_id": "the_provided_gesture",
      "disambiguation_index": 0,
      "label": "the provided gestures",
      "aliases": [
        "the provided gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The provided gestures refer to the specific hand or body movements utilized in gesture-controlled interfaces that may not align with user expectations or intuitiveness, particularly in the context of Human Device Interactions within Internet of Things systems.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "the provided gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-the_provided_gesture-Mention-1"
        }
      ],
      "relevance": 0.70166015625
    },
    "Entity-gesture_affordance_mapping": {
      "node_id": "gesture_affordance_mapping",
      "disambiguation_index": 0,
      "label": "gesture affordance mapping",
      "aliases": [
        "gesture affordance mapping"
      ],
      "types": [
        "gesture recognition",
        "concept",
        "methodology",
        "gesture",
        "mapping"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Gesture affordance mapping refers to the systematic process of linking user gestures to the potential actions or functionalities (affordances) they represent within a device context, enabling enhanced interaction and understanding between users and gesture recognition systems.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-2",
          "local_name": "gesture affordance mapping",
          "local_types": [
            "gesture recognition",
            "concept",
            "methodology",
            "gesture",
            "mapping"
          ],
          "iri": "Entity-gesture_affordance_mapping-Mention-1"
        }
      ],
      "relevance": 0.701171875
    },
    "Entity-human_device_interaction__hdi_": {
      "node_id": "human_device_interaction__hdi_",
      "disambiguation_index": 0,
      "label": "Human Device Interactions (HDI)",
      "aliases": [
        "Human Device Interactions (HDI)"
      ],
      "types": [
        "field of study",
        "HDI",
        "human-computer interaction",
        "interaction field",
        "interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Human Device Interactions (HDI) refers to the interdisciplinary field of study focused on the ways in which humans interact with various devices, particularly through gestures and other forms of communication.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "Human Device Interactions (HDI)",
          "local_types": [
            "field of study",
            "HDI",
            "human-computer interaction",
            "interaction field",
            "interaction"
          ],
          "iri": "Entity-human_device_interaction__hdi_-Mention-1"
        }
      ],
      "relevance": 0.70068359375
    },
    "Entity-one_or_more_gesture": {
      "node_id": "one_or_more_gesture",
      "disambiguation_index": 0,
      "label": "one or more gestures",
      "aliases": [
        "one or more gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'one or more gestures' refers to the concept within the HDGI ontology that allows for the aggregation of multiple gestures, enabling the representation of complex movements involving various body parts and poses in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-5",
          "local_name": "one or more gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-one_or_more_gesture-Mention-1"
        }
      ],
      "relevance": 0.70068359375
    },
    "Entity-it_associated_knowledge": {
      "node_id": "it_associated_knowledge",
      "disambiguation_index": 0,
      "label": "its associated knowledge",
      "aliases": [
        "its associated knowledge"
      ],
      "types": [
        "knowledge"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'its associated knowledge' refers to the contextual and semantic information related to gestures used in Human Device Interactions, which includes mappings to affordances and user/device contexts within the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-7",
          "local_name": "its associated knowledge",
          "local_types": [
            "knowledge"
          ],
          "iri": "Entity-it_associated_knowledge-Mention-1"
        }
      ],
      "relevance": 0.7001953125
    },
    "Entity-mapping": {
      "node_id": "mapping",
      "disambiguation_index": 0,
      "label": "mapping",
      "aliases": [
        "mappings",
        "mapping"
      ],
      "types": [
        "method",
        "relationship",
        "process",
        "data structure",
        "methodology",
        "function",
        "mapping",
        "correspondence"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the paper, 'mapping' refers to the process of linking existing gesture vocabularies to their corresponding referents and device affordances within the Human Device Gesture Interaction ontology, facilitating a better understanding and interpretation of user gestures across different systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-3",
          "local_name": "mapping",
          "local_types": [
            "method",
            "methodology",
            "process"
          ],
          "iri": "Entity-mapping-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-2-Sentence-2",
          "local_name": "mappings",
          "local_types": [
            "data structure",
            "relationship"
          ],
          "iri": "Entity-mapping-Mention-2"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "mappings",
          "local_types": [
            "relationship",
            "mapping",
            "correspondence"
          ],
          "iri": "Entity-mapping-Mention-3"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-3",
          "local_name": "mappings",
          "local_types": [
            "function",
            "process"
          ],
          "iri": "Entity-mapping-Mention-4"
        }
      ],
      "relevance": 0.69921875
    },
    "Entity-hdgi__context": {
      "node_id": "hdgi__context",
      "disambiguation_index": 0,
      "label": "hdgi:Context",
      "aliases": [
        "hdgi:Context"
      ],
      "types": [
        "relationship",
        "modeling term",
        "ontology class",
        "ontology",
        "concept",
        "ontology term",
        "model",
        "ontology concept",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Context refers to a class within the HDGI ontology that represents the contextual information related to human gestures and their interactions with devices, facilitating the understanding of how gestures are influenced by and mapped to specific user and device scenarios.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Context",
          "local_types": [
            "ontology class",
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__context-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-7",
          "local_name": "hdgi:Context",
          "local_types": [
            "ontology class",
            "concept",
            "ontology term",
            "model",
            "class"
          ],
          "iri": "Entity-hdgi__context-Mention-2"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-1",
          "local_name": "hdgi:Context",
          "local_types": [
            "relationship",
            "modeling term",
            "ontology class",
            "concept",
            "ontology term",
            "model",
            "ontology concept"
          ],
          "iri": "Entity-hdgi__context-Mention-3"
        }
      ],
      "relevance": 0.69873046875
    },
    "Entity-hdgi__devicecontext": {
      "node_id": "hdgi__devicecontext",
      "disambiguation_index": 0,
      "label": "hdgi:DeviceContext",
      "aliases": [
        "hdgi:DeviceContext"
      ],
      "types": [
        "ontology class",
        "concept",
        "ontology term",
        "model",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:DeviceContext refers to a class in the HDGI ontology that models the contextual factors related to a device in Human Device Gesture Interactions, enabling the understanding of user gestures based on the specific characteristics and affordances of the device.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-7",
          "local_name": "hdgi:DeviceContext",
          "local_types": [
            "ontology class",
            "concept",
            "ontology term",
            "model",
            "class"
          ],
          "iri": "Entity-hdgi__devicecontext-Mention-1"
        }
      ],
      "relevance": 0.69873046875
    },
    "Entity-http__w3id.orghdgi": {
      "node_id": "http__w3id.orghdgi",
      "disambiguation_index": 0,
      "label": "https://w3id.org/hdgi",
      "aliases": [
        "https://w3id.org/hdgi"
      ],
      "types": [
        "URI",
        "web resource",
        "URL",
        "ontology",
        "namespace"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The entity 'https://w3id.org/hdgi' refers to a newly defined namespace for the HDGI ontology, which encompasses classes related to human gestures in device interactions, ensuring independence from external ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "https://w3id.org/hdgi",
          "local_types": [
            "URI",
            "web resource",
            "URL",
            "ontology",
            "namespace"
          ],
          "iri": "Entity-http__w3id.orghdgi-Mention-1"
        }
      ],
      "relevance": 0.6982421875
    },
    "Entity-hdgi-gesture_repository": {
      "node_id": "hdgi-gesture_repository",
      "disambiguation_index": 0,
      "label": "HDGI-gesture repository",
      "aliases": [
        "HDGI-gesture repository",
        "the HDGI-gesture repository"
      ],
      "types": [
        "resource",
        "gesture",
        "database",
        "data storage",
        "repository"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The HDGI-gesture repository is a centralized database that provides access to contemporary gestures and their mappings to device affordances, facilitating integration and documentation for designers, device manufacturers, and developers in the context of Human Device Interaction.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "HDGI-gesture repository",
          "local_types": [
            "resource",
            "gesture",
            "database",
            "data storage",
            "repository"
          ],
          "iri": "Entity-hdgi-gesture_repository-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "the HDGI-gesture repository",
          "local_types": [
            "repository"
          ],
          "iri": "Entity-hdgi-gesture_repository-Mention-2"
        }
      ],
      "relevance": 0.69775390625
    },
    "Entity-gesture-related_vocabulary": {
      "node_id": "gesture-related_vocabulary",
      "disambiguation_index": 0,
      "label": "gesture-related vocabularies",
      "aliases": [
        "gesture-related vocabularies"
      ],
      "types": [
        "language",
        "gesture",
        "terminology",
        "vocabulary"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gesture-related vocabularies refer to the specific terms and definitions used to describe and categorize gestures in the context of human-device interactions, which are essential for ensuring interoperability and understanding in the design of gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "gesture-related vocabularies",
          "local_types": [
            "language",
            "gesture",
            "terminology",
            "vocabulary"
          ],
          "iri": "Entity-gesture-related_vocabulary-Mention-1"
        }
      ],
      "relevance": 0.6962890625
    },
    "Entity-the_shape_and_dynamic_of_a_certain_gesture": {
      "node_id": "the_shape_and_dynamic_of_a_certain_gesture",
      "disambiguation_index": 0,
      "label": "the shape and dynamics of a certain gesture",
      "aliases": [
        "the shape and dynamics of a certain gesture"
      ],
      "types": [
        "gesture",
        "shape",
        "dynamics"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The shape and dynamics of a certain gesture refer to the specific form and movement characteristics of human gestures used in device interactions, as described within the HDGI ontology, which aims to facilitate understanding and mapping of these gestures to their corresponding affordances and contexts.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "the shape and dynamics of a certain gesture",
          "local_types": [
            "gesture",
            "shape",
            "dynamics"
          ],
          "iri": "Entity-the_shape_and_dynamic_of_a_certain_gesture-Mention-1"
        }
      ],
      "relevance": 0.6962890625
    },
    "Entity-gesture-based_system": {
      "node_id": "gesture-based_system",
      "disambiguation_index": 0,
      "label": "Gesture-based systems",
      "aliases": [
        "Gesture-based systems"
      ],
      "types": [
        "technology",
        "interaction method",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Gesture-based systems are interactive technologies that utilize human gestures as input methods to control and communicate with digital devices and applications.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "Gesture-based systems",
          "local_types": [
            "technology",
            "interaction method",
            "system"
          ],
          "iri": "Entity-gesture-based_system-Mention-1"
        }
      ],
      "relevance": 0.6943359375
    },
    "Entity-human_device_gesture_interaction_knowledge_base": {
      "node_id": "human_device_gesture_interaction_knowledge_base",
      "disambiguation_index": 0,
      "label": "human device gesture interaction knowledge base",
      "aliases": [
        "comprehensive human device gesture interaction knowledge base",
        "human device gesture interaction knowledge base"
      ],
      "types": [
        "knowledge base",
        "interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The human device gesture interaction knowledge base refers to a systematic repository that encompasses a comprehensive collection of gestures used in human-device interactions, aimed at enhancing user experience by mapping gestures to their corresponding affordances and contexts.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-1-Sentence-2",
          "local_name": "human device gesture interaction knowledge base",
          "local_types": [
            "knowledge base"
          ],
          "iri": "Entity-human_device_gesture_interaction_knowledge_base-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-2",
          "local_name": "comprehensive human device gesture interaction knowledge base",
          "local_types": [
            "knowledge base",
            "interaction"
          ],
          "iri": "Entity-human_device_gesture_interaction_knowledge_base-Mention-2"
        }
      ],
      "relevance": 0.69384765625
    },
    "Entity-tool_for_mapping_hdgi_v0.1_to_leap_motion_and_the_oculus_quest_device": {
      "node_id": "tool_for_mapping_hdgi_v0.1_to_leap_motion_and_the_oculus_quest_device",
      "disambiguation_index": 0,
      "label": "tools for mapping HDGI v0.1 to Leap Motion and the Oculus Quest devices",
      "aliases": [
        "tools for mapping HDGI v0.1 to Leap Motion and the Oculus Quest devices"
      ],
      "types": [
        "tools",
        "devices",
        "mapping"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'tools for mapping HDGI v0.1 to Leap Motion and the Oculus Quest devices' refers to software or methodologies designed to facilitate the integration and application of the Human Device Gesture Interaction ontology version 0.1 with the Leap Motion and Oculus Quest hardware, enabling developers to utilize gesture recognition in their interactive systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-4",
          "local_name": "tools for mapping HDGI v0.1 to Leap Motion and the Oculus Quest devices",
          "local_types": [
            "tools",
            "devices",
            "mapping"
          ],
          "iri": "Entity-tool_for_mapping_hdgi_v0.1_to_leap_motion_and_the_oculus_quest_device-Mention-1"
        }
      ],
      "relevance": 0.69384765625
    },
    "Entity-better_user_experience": {
      "node_id": "better_user_experience",
      "disambiguation_index": 0,
      "label": "better user experience",
      "aliases": [
        "better user experience"
      ],
      "types": [
        "user experience"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'better user experience' refers to the enhanced satisfaction and usability achieved through the systematic analysis and formal description of gestures in human-device interactions, as facilitated by the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-1-Sentence-2",
          "local_name": "better user experience",
          "local_types": [
            "user experience"
          ],
          "iri": "Entity-better_user_experience-Mention-1"
        }
      ],
      "relevance": 0.69287109375
    },
    "Entity-element": {
      "node_id": "element",
      "disambiguation_index": 0,
      "label": "elements",
      "aliases": [
        "elements"
      ],
      "types": [
        "element"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'elements' refer to the fundamental components or units of gestures that have been identified and extracted from existing gesture vocabularies in prior research, which are used to formally describe and categorize human device interactions.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-2-Sentence-1",
          "local_name": "elements",
          "local_types": [
            "element"
          ],
          "iri": "Entity-element-Mention-1"
        }
      ],
      "relevance": 0.69189453125
    },
    "Entity-ubiquitousness_in_human-device_gesture_interaction": {
      "node_id": "ubiquitousness_in_human-device_gesture_interaction",
      "disambiguation_index": 0,
      "label": "ubiquitousness in human-device gesture interactions",
      "aliases": [
        "the problem of ubiquitousness in human-device gesture interactions",
        "ubiquitousness in human-device gesture interactions"
      ],
      "types": [
        "problem",
        "interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'ubiquitousness in human-device gesture interactions' refers to the widespread and varied use of gesture-based controls across different devices and systems, highlighting the challenges and inconsistencies that arise from the lack of standardized gesture vocabularies and user expectations in interacting with these technologies.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-2",
          "local_name": "ubiquitousness in human-device gesture interactions",
          "local_types": [
            "problem"
          ],
          "iri": "Entity-ubiquitousness_in_human-device_gesture_interaction-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-2",
          "local_name": "the problem of ubiquitousness in human-device gesture interactions",
          "local_types": [
            "problem",
            "interaction"
          ],
          "iri": "Entity-ubiquitousness_in_human-device_gesture_interaction-Mention-2"
        }
      ],
      "relevance": 0.69140625
    },
    "Entity-developer_and_designer": {
      "node_id": "developer_and_designer",
      "disambiguation_index": 0,
      "label": "developers and designers",
      "aliases": [
        "developers and designers"
      ],
      "types": [
        "professionals",
        "audience"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Developers and designers refer to the professionals involved in creating and implementing gesture-controlled interfaces and systems, utilizing the HDGI ontology to enhance user interaction and experience in various applications.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "developers and designers",
          "local_types": [
            "professionals",
            "audience"
          ],
          "iri": "Entity-developer_and_designer-Mention-1"
        }
      ],
      "relevance": 0.69091796875
    },
    "Entity-a_hdgi__devicemanufacturer_relationship": {
      "node_id": "a_hdgi__devicemanufacturer_relationship",
      "disambiguation_index": 0,
      "label": "a hdgi:DeviceManufacturer relationship",
      "aliases": [
        "a hdgi:DeviceManufacturer relationship"
      ],
      "types": [
        "relationship"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The hdgi:DeviceManufacturer relationship refers to the association in the HDGI ontology that links a device to its single manufacturer, highlighting the necessity of identifying the manufacturer for effective gesture affordance mapping in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-3-Sentence-2",
          "local_name": "a hdgi:DeviceManufacturer relationship",
          "local_types": [
            "relationship"
          ],
          "iri": "Entity-a_hdgi__devicemanufacturer_relationship-Mention-1"
        }
      ],
      "relevance": 0.68994140625
    },
    "Entity-area": {
      "node_id": "area",
      "disambiguation_index": 0,
      "label": "area",
      "aliases": [
        "area"
      ],
      "types": [
        "field of study",
        "domain"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'area' in this context refers to the field of study related to Human Device Gesture Interaction (HDGI) and the development of an ontology that systematically describes and maps gesture vocabularies used in interactive systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-1",
          "local_name": "area",
          "local_types": [
            "field of study",
            "domain"
          ],
          "iri": "Entity-area-Mention-1"
        }
      ],
      "relevance": 0.68896484375
    },
    "Entity-application": {
      "node_id": "application",
      "disambiguation_index": 0,
      "label": "applications",
      "aliases": [
        "applications"
      ],
      "types": [
        "software",
        "technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'applications' refers to various software systems and technologies that utilize gesture recognition capabilities, such as those enabled by sensors like Microsoft Kinect, for interactive user interfaces in contexts like gaming, smart homes, and augmented or virtual reality.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "applications",
          "local_types": [
            "software",
            "technology"
          ],
          "iri": "Entity-application-Mention-1"
        }
      ],
      "relevance": 0.6884765625
    },
    "Entity-evaluation": {
      "node_id": "evaluation",
      "disambiguation_index": 0,
      "label": "evaluation",
      "aliases": [
        "evaluation"
      ],
      "types": [
        "assessment",
        "analysis"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'evaluation' in this context refers to the assessment of the expressive power of the Human Device Gesture Interaction (HDGI) ontology, which aids developers and designers in integrating the ontology into their applications.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "evaluation",
          "local_types": [
            "assessment",
            "analysis"
          ],
          "iri": "Entity-evaluation-Mention-1"
        }
      ],
      "relevance": 0.6884765625
    },
    "Entity-gesture_recognition_device_configuration": {
      "node_id": "gesture_recognition_device_configuration",
      "disambiguation_index": 0,
      "label": "gesture recognition device configurations",
      "aliases": [
        "gesture recognition device configurations"
      ],
      "types": [
        "device",
        "configuration"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Gesture recognition device configurations refer to the specific setups and parameters of devices that capture and interpret human gestures, which can vary between different manufacturers and systems, affecting how gestures are recognized and represented in a consistent manner.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-6",
          "local_name": "gesture recognition device configurations",
          "local_types": [
            "device",
            "configuration"
          ],
          "iri": "Entity-gesture_recognition_device_configuration-Mention-1"
        }
      ],
      "relevance": 0.68798828125
    },
    "Entity-different_gesture": {
      "node_id": "different_gesture",
      "disambiguation_index": 0,
      "label": "different gestures",
      "aliases": [
        "different gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Different gestures refer to the various body movements and postures used in human-device interactions, which can convey specific meanings or actions, and are essential for the development of gesture-controlled interfaces in the context of the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "different gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-different_gesture-Mention-1"
        }
      ],
      "relevance": 0.6875
    },
    "Entity-hdgi__pose": {
      "node_id": "hdgi__pose",
      "disambiguation_index": 0,
      "label": "hdgi:Pose",
      "aliases": [
        "poses",
        "Pose",
        "pose",
        "hdgi:Pose"
      ],
      "types": [
        "state",
        "object",
        "data structure",
        "software component",
        "class",
        "term",
        "modeling concept",
        "programming construct",
        "data type",
        "ontology term",
        "model",
        "position",
        "movement",
        "physical stance",
        "gesture type",
        "physical position",
        "ontology class",
        "concept",
        "pose",
        "entity",
        "action",
        "body position",
        "representation",
        "configuration",
        "posture",
        "ontology",
        "gesture",
        "body posture",
        "gesture representation"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Pose refers to a class within the HDGI ontology that models the specific configurations or positions of human upper limbs used in gesture-based interactions with devices.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Pose",
          "local_types": [
            "ontology class",
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__pose-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "hdgi:Pose",
          "local_types": [
            "term",
            "state",
            "ontology",
            "concept",
            "pose",
            "position"
          ],
          "iri": "Entity-hdgi__pose-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-4",
          "local_name": "hdgi:Pose",
          "local_types": [
            "ontology class",
            "data structure",
            "ontology",
            "ontology term",
            "pose",
            "gesture representation",
            "software component",
            "class"
          ],
          "iri": "Entity-hdgi__pose-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-2",
          "local_name": "hdgi:Pose",
          "local_types": [
            "programming construct",
            "concept",
            "class"
          ],
          "iri": "Entity-hdgi__pose-Mention-4"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-4",
          "local_name": "hdgi:Pose",
          "local_types": [
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__pose-Mention-5"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-1",
          "local_name": "hdgi:Pose",
          "local_types": [
            "ontology class",
            "ontology",
            "gesture",
            "gesture representation",
            "class",
            "representation"
          ],
          "iri": "Entity-hdgi__pose-Mention-6"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-3",
          "local_name": "hdgi:Pose",
          "local_types": [
            "pose",
            "modeling concept"
          ],
          "iri": "Entity-hdgi__pose-Mention-7"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Pose",
          "local_types": [
            "ontology class",
            "data structure",
            "ontology",
            "concept",
            "model",
            "pose",
            "entity",
            "gesture representation",
            "class"
          ],
          "iri": "Entity-hdgi__pose-Mention-8"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-1",
          "local_name": "hdgi:Pose",
          "local_types": [
            "class",
            "concept",
            "programming construct",
            "gesture type"
          ],
          "iri": "Entity-hdgi__pose-Mention-9"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-6",
          "local_name": "hdgi:Pose",
          "local_types": [
            "data type",
            "pose"
          ],
          "iri": "Entity-hdgi__pose-Mention-10"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "Pose",
          "local_types": [
            "class",
            "concept"
          ],
          "iri": "Entity-hdgi__pose-Mention-11"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "poses",
          "local_types": [
            "body position",
            "movement"
          ],
          "iri": "Entity-hdgi__pose-Mention-12"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "poses",
          "local_types": [
            "physical position",
            "action",
            "body posture",
            "concept"
          ],
          "iri": "Entity-hdgi__pose-Mention-13"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-9",
          "local_name": "poses",
          "local_types": [
            "body position",
            "physical stance"
          ],
          "iri": "Entity-hdgi__pose-Mention-14"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-1",
          "local_name": "pose",
          "local_types": [
            "posture",
            "concept",
            "pose",
            "position",
            "gesture representation",
            "class"
          ],
          "iri": "Entity-hdgi__pose-Mention-15"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-2",
          "local_name": "Pose",
          "local_types": [
            "concept",
            "movement"
          ],
          "iri": "Entity-hdgi__pose-Mention-16"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-3",
          "local_name": "pose",
          "local_types": [
            "position",
            "posture"
          ],
          "iri": "Entity-hdgi__pose-Mention-17"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-4",
          "local_name": "pose",
          "local_types": [
            "configuration",
            "state"
          ],
          "iri": "Entity-hdgi__pose-Mention-18"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-16",
          "local_name": "pose",
          "local_types": [
            "configuration",
            "position"
          ],
          "iri": "Entity-hdgi__pose-Mention-19"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-1",
          "local_name": "Pose",
          "local_types": [
            "pose",
            "class",
            "gesture representation"
          ],
          "iri": "Entity-hdgi__pose-Mention-20"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-2",
          "local_name": "poses",
          "local_types": [
            "object",
            "entity"
          ],
          "iri": "Entity-hdgi__pose-Mention-21"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-1",
          "local_name": "Pose",
          "local_types": [
            "pose",
            "class",
            "gesture representation"
          ],
          "iri": "Entity-hdgi__pose-Mention-22"
        }
      ],
      "relevance": 0.68701171875
    },
    "Entity-gesture-related_semantics": {
      "node_id": "gesture-related_semantics",
      "disambiguation_index": 0,
      "label": "gesture-related semantics",
      "aliases": [
        "gesture semantics",
        "gesture-related semantics"
      ],
      "types": [
        "communication",
        "concept",
        "interaction",
        "gesture",
        "linguistics",
        "semantics"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gesture-related semantics refers to the meanings and interpretations associated with gestures used in human-device interactions, which are essential for understanding how users convey intentions and commands through physical movements in various interactive systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-2",
          "local_name": "gesture-related semantics",
          "local_types": [
            "concept",
            "communication",
            "gesture",
            "linguistics",
            "semantics"
          ],
          "iri": "Entity-gesture-related_semantics-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-9",
          "local_name": "gesture semantics",
          "local_types": [
            "concept",
            "interaction"
          ],
          "iri": "Entity-gesture-related_semantics-Mention-2"
        }
      ],
      "relevance": 0.68701171875
    },
    "Entity-the_system": {
      "node_id": "the_system",
      "disambiguation_index": 0,
      "label": "the system",
      "aliases": [
        "the system"
      ],
      "types": [
        "system"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The system refers to the gesture-controlled interface that users must adapt to, despite its potentially non-intuitive gestures, within the context of Human Device Interactions in Internet of Things applications.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "the system",
          "local_types": [
            "system"
          ],
          "iri": "Entity-the_system-Mention-1"
        }
      ],
      "relevance": 0.68701171875
    },
    "Entity-gesture_recognition_device": {
      "node_id": "gesture_recognition_device",
      "disambiguation_index": 0,
      "label": "gesture recognition device",
      "aliases": [
        "gesture recognition device"
      ],
      "types": [
        "device",
        "technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A gesture recognition device is a technological tool that interprets human gestures through sensors and algorithms to enable interaction with digital systems.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-6",
          "local_name": "gesture recognition device",
          "local_types": [
            "device",
            "technology"
          ],
          "iri": "Entity-gesture_recognition_device-Mention-1"
        }
      ],
      "relevance": 0.6865234375
    },
    "Entity-the_relevant_code__data__and_ontology": {
      "node_id": "the_relevant_code__data__and_ontology",
      "disambiguation_index": 0,
      "label": "the relevant code, data, and ontology",
      "aliases": [
        "the relevant code, data, and ontology"
      ],
      "types": [
        "code",
        "data",
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The relevant code, data, and ontology refer to the resources associated with the HDGI ontology, which models human gestures for device interaction and is made accessible to the community through GitHub for collaborative contributions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "the relevant code, data, and ontology",
          "local_types": [
            "code",
            "data",
            "ontology"
          ],
          "iri": "Entity-the_relevant_code__data__and_ontology-Mention-1"
        }
      ],
      "relevance": 0.68603515625
    },
    "Entity-hdgi__affordedby": {
      "node_id": "hdgi__affordedby",
      "disambiguation_index": 0,
      "label": "hdgi:affordedBy",
      "aliases": [
        "hdgi:affordedBy"
      ],
      "types": [
        "relationship",
        "conceptual link"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The entity 'hdgi:affordedBy' refers to a relationship in the HDGI ontology that models the many-to-many mapping between affordances and devices, indicating which devices can provide or support specific affordances in human-device gesture interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-8",
          "local_name": "hdgi:affordedBy",
          "local_types": [
            "relationship",
            "conceptual link"
          ],
          "iri": "Entity-hdgi__affordedby-Mention-1"
        }
      ],
      "relevance": 0.68603515625
    },
    "Entity-a_user_(3)": {
      "node_id": "a_user_(3)",
      "disambiguation_index": 3,
      "label": "a user",
      "aliases": [
        "a user"
      ],
      "types": [
        "user"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A user refers to an individual interacting with gesture-controlled systems, who benefits from a gesture ontology that allows for personalized and intuitive gesture recognition across different devices without the need to memorize specific gestures.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-4",
          "local_name": "a user",
          "local_types": [
            "user"
          ],
          "iri": "Entity-a_user_(3)-Mention-1"
        }
      ],
      "relevance": 0.685546875
    },
    "Entity-relevant_mapping_to_device_affordances": {
      "node_id": "relevant_mapping_to_device_affordances",
      "disambiguation_index": 0,
      "label": "relevant mappings to device affordances",
      "aliases": [
        "relevant mappings to device affordances"
      ],
      "types": [
        "mapping",
        "device affordance"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Relevant mappings to device affordances refer to the connections and associations established between specific gestures and the functional capabilities of devices, as documented in the HDGI-gesture repository, which aids designers and developers in understanding how gestures can be effectively utilized within various device contexts.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "relevant mappings to device affordances",
          "local_types": [
            "mapping",
            "device affordance"
          ],
          "iri": "Entity-relevant_mapping_to_device_affordances-Mention-1"
        }
      ],
      "relevance": 0.685546875
    },
    "Entity-manufacturer-defined_gesture": {
      "node_id": "manufacturer-defined_gesture",
      "disambiguation_index": 0,
      "label": "manufacturer-defined gestures",
      "aliases": [
        "the manufacturer-defined gestures",
        "manufacturer-defined gestures"
      ],
      "types": [
        "interaction method",
        "user interface",
        "gesture",
        "design choice",
        "manufacturer-defined",
        "design element"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Manufacturer-defined gestures refer to specific gestures that are designed and implemented by manufacturers of interactive systems, which may not align with user expectations or preferences, often leading to confusion and a lack of intuitive interaction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-5",
          "local_name": "manufacturer-defined gestures",
          "local_types": [
            "interaction method",
            "user interface",
            "gesture",
            "design choice",
            "design element"
          ],
          "iri": "Entity-manufacturer-defined_gesture-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-5-Sentence-5",
          "local_name": "the manufacturer-defined gestures",
          "local_types": [
            "gesture",
            "manufacturer-defined"
          ],
          "iri": "Entity-manufacturer-defined_gesture-Mention-2"
        }
      ],
      "relevance": 0.68505859375
    },
    "Entity-rationale_behind_such_a_design": {
      "node_id": "rationale_behind_such_a_design",
      "disambiguation_index": 0,
      "label": "rationale behind such a design",
      "aliases": [
        "the rationale behind such a design",
        "rationale behind such a design"
      ],
      "types": [
        "rationale"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'rationale behind such a design' refers to the underlying reasoning and principles guiding the development of the Human Device Gesture Interaction (HDGI) ontology, which aims to systematically describe and map gesture vocabularies for improved user interaction with devices.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "rationale behind such a design",
          "local_types": [
            "rationale"
          ],
          "iri": "Entity-rationale_behind_such_a_design-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "the rationale behind such a design",
          "local_types": [
            "rationale"
          ],
          "iri": "Entity-rationale_behind_such_a_design-Mention-2"
        }
      ],
      "relevance": 0.6845703125
    },
    "Entity-hdgi__includesgesture": {
      "node_id": "hdgi__includesgesture",
      "disambiguation_index": 0,
      "label": "hdgi:includesGesture",
      "aliases": [
        "hdgi:includesGesture",
        "object property hdgi:includesGesture"
      ],
      "types": [
        "relationship",
        "object property",
        "ontology relation",
        "ontology",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:includesGesture is an object property in the HDGI ontology that aggregates multiple gestures, allowing for the representation of complex gestures involving various body parts and their sequential or concurrent movements.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "hdgi:includesGesture",
          "local_types": [
            "relationship",
            "object property",
            "ontology relation",
            "ontology",
            "property"
          ],
          "iri": "Entity-hdgi__includesgesture-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "object property hdgi:includesGesture",
          "local_types": [
            "object property",
            "property"
          ],
          "iri": "Entity-hdgi__includesgesture-Mention-2"
        }
      ],
      "relevance": 0.6845703125
    },
    "Entity-device_a": {
      "node_id": "device_a",
      "disambiguation_index": 0,
      "label": "Device A",
      "aliases": [
        "Device A"
      ],
      "types": [
        "hardware",
        "product",
        "device",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Device A refers to a hardware device that can host multiple affordances and is capable of receiving gesture-based interactions from users, as defined within the context of the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-4",
          "local_name": "Device A",
          "local_types": [
            "device",
            "hardware",
            "technology"
          ],
          "iri": "Entity-device_a-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-3",
          "local_name": "Device A",
          "local_types": [
            "device",
            "product",
            "hardware"
          ],
          "iri": "Entity-device_a-Mention-2"
        }
      ],
      "relevance": 0.6826171875
    },
    "Entity-the_prefix_hdgi": {
      "node_id": "the_prefix_hdgi",
      "disambiguation_index": 0,
      "label": "the prefix hdgi",
      "aliases": [
        "the prefix hdgi"
      ],
      "types": [
        "prefix"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The prefix hdgi refers to a newly defined namespace used in the HDGI ontology, which encompasses all classes related to human gesture interactions in the context of the Internet of Things, allowing for independence from external ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "the prefix hdgi",
          "local_types": [
            "prefix"
          ],
          "iri": "Entity-the_prefix_hdgi-Mention-1"
        }
      ],
      "relevance": 0.68212890625
    },
    "Entity-a_device": {
      "node_id": "a_device",
      "disambiguation_index": 0,
      "label": "a device",
      "aliases": [
        "a device",
        "the device"
      ],
      "types": [
        "device",
        "object"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A device refers to an entity that can host multiple affordances and support various gestures for user interactions, as defined within the context of Human Device Gesture Interactions (HDGI) ontology.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-1",
          "local_name": "a device",
          "local_types": [
            "device"
          ],
          "iri": "Entity-a_device-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-5",
          "local_name": "the device",
          "local_types": [
            "object"
          ],
          "iri": "Entity-a_device-Mention-2"
        }
      ],
      "relevance": 0.68212890625
    },
    "Entity-hdgi-service": {
      "node_id": "hdgi-service",
      "disambiguation_index": 0,
      "label": "HDGI-service",
      "aliases": [
        "HDGI-service"
      ],
      "types": [
        "software",
        "technology",
        "service",
        "software tool"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "HDGI-service refers to a fully API-driven RESTful web service that provides access to a repository of gesture vocabularies and their mappings to device affordances, facilitating integration with gesture recognition software and allowing users to define and upload their own gesture vocabularies.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-2",
          "local_name": "HDGI-service",
          "local_types": [
            "software",
            "technology",
            "service",
            "software tool"
          ],
          "iri": "Entity-hdgi-service-Mention-1"
        }
      ],
      "relevance": 0.681640625
    },
    "Entity-gesture_interaction": {
      "node_id": "gesture_interaction",
      "disambiguation_index": 0,
      "label": "gesture interactions",
      "aliases": [
        "gesture interactions"
      ],
      "types": [
        "user interface",
        "interaction type",
        "communication method",
        "human-computer interaction",
        "interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Gesture interactions refer to the use of physical movements, such as those of the face, limbs, or body, to convey intentions and facilitate communication between users and devices or systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "gesture interactions",
          "local_types": [
            "communication method",
            "interaction type",
            "interaction"
          ],
          "iri": "Entity-gesture_interaction-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-1",
          "local_name": "gesture interactions",
          "local_types": [
            "interaction",
            "interaction type",
            "human-computer interaction"
          ],
          "iri": "Entity-gesture_interaction-Mention-2"
        },
        {
          "reference": "Section-11-Paragraph-4-Sentence-3",
          "local_name": "gesture interactions",
          "local_types": [
            "user interface",
            "interaction type",
            "interaction"
          ],
          "iri": "Entity-gesture_interaction-Mention-3"
        }
      ],
      "relevance": 0.68115234375
    },
    "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances": {
      "node_id": "mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "disambiguation_index": 0,
      "label": "mapping different gestures with their semantic relationships to affordances",
      "aliases": [
        "mapping different gestures with their semantic relationships to affordances"
      ],
      "types": [
        "mapping",
        "gesture",
        "affordance"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The entity 'mapping different gestures with their semantic relationships to affordances' refers to the process of establishing connections between various hand gestures and their meanings or functions in relation to the capabilities or actions that can be performed with devices, which is a key aspect of developing a comprehensive ontology for gesture-based human-device interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "mapping different gestures with their semantic relationships to affordances",
          "local_types": [
            "mapping",
            "gesture",
            "affordance"
          ],
          "iri": "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances-Mention-1"
        }
      ],
      "relevance": 0.68115234375
    },
    "Entity-system_(1)": {
      "node_id": "system_(1)",
      "disambiguation_index": 1,
      "label": "systems",
      "aliases": [
        "systems"
      ],
      "types": [
        "system"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In this context, 'systems' refers to interactive platforms or devices that utilize gesture-based interfaces for user interaction, particularly in applications such as automobiles, smart homes, and virtual reality environments.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-1",
          "local_name": "systems",
          "local_types": [
            "system"
          ],
          "iri": "Entity-system_(1)-Mention-1"
        }
      ],
      "relevance": 0.68115234375
    },
    "Entity-gesture_type": {
      "node_id": "gesture_type",
      "disambiguation_index": 0,
      "label": "gesture types",
      "aliases": [
        "gesture types"
      ],
      "types": [
        "classification",
        "gesture type",
        "gesture",
        "interaction type",
        "human-computer interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'gesture types' refers to the various classifications of gestures that can be used in human-device interactions, including but not limited to upper-limb gestures, facial gestures, and head gestures, as defined within the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-1",
          "local_name": "gesture types",
          "local_types": [
            "classification",
            "gesture type",
            "gesture",
            "interaction type",
            "human-computer interaction"
          ],
          "iri": "Entity-gesture_type-Mention-1"
        }
      ],
      "relevance": 0.68017578125
    },
    "Entity-shape": {
      "node_id": "shape",
      "disambiguation_index": 0,
      "label": "shape",
      "aliases": [
        "shape"
      ],
      "types": [
        "characteristic",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'shape' refers to the specific form and configuration of a gesture performed by the human upper limb, which is essential for understanding its dynamics and how it relates to device interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "shape",
          "local_types": [
            "characteristic",
            "property"
          ],
          "iri": "Entity-shape-Mention-1"
        }
      ],
      "relevance": 0.67919921875
    },
    "Entity-user": {
      "node_id": "user",
      "disambiguation_index": 0,
      "label": "user",
      "aliases": [
        "user",
        "users"
      ],
      "types": [
        "end user",
        "stakeholders",
        "consumer",
        "actor",
        "group",
        "participants",
        "individuals",
        "user",
        "stakeholder",
        "participant",
        "end users",
        "people",
        "individual"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'user' refers to individuals who interact with gesture-controlled interfaces in various applications, such as IoT systems, and who may experience confusion due to the variability in gesture standards.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "user",
          "local_types": [
            "end user",
            "individual",
            "consumer"
          ],
          "iri": "Entity-user-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "user",
          "local_types": [
            "individual",
            "end user"
          ],
          "iri": "Entity-user-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "users",
          "local_types": [
            "participant",
            "individual",
            "user"
          ],
          "iri": "Entity-user-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "user",
          "local_types": [
            "individual",
            "participant"
          ],
          "iri": "Entity-user-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-5-Sentence-3",
          "local_name": "users",
          "local_types": [
            "end users",
            "people",
            "individuals"
          ],
          "iri": "Entity-user-Mention-5"
        },
        {
          "reference": "Section-2-Paragraph-5-Sentence-5",
          "local_name": "users",
          "local_types": [
            "stakeholders",
            "user",
            "individuals"
          ],
          "iri": "Entity-user-Mention-6"
        },
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "user",
          "local_types": [
            "individual",
            "participant"
          ],
          "iri": "Entity-user-Mention-7"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-2",
          "local_name": "users",
          "local_types": [
            "user",
            "participants",
            "individuals"
          ],
          "iri": "Entity-user-Mention-8"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-3",
          "local_name": "users",
          "local_types": [
            "stakeholders",
            "end user",
            "group",
            "individuals",
            "stakeholder",
            "individual"
          ],
          "iri": "Entity-user-Mention-9"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-4",
          "local_name": "user",
          "local_types": [
            "individual",
            "participant"
          ],
          "iri": "Entity-user-Mention-10"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "users",
          "local_types": [
            "end user",
            "user",
            "stakeholder"
          ],
          "iri": "Entity-user-Mention-11"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-13",
          "local_name": "users",
          "local_types": [
            "end user",
            "individual",
            "user"
          ],
          "iri": "Entity-user-Mention-12"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-1",
          "local_name": "user",
          "local_types": [
            "participant",
            "individual",
            "actor"
          ],
          "iri": "Entity-user-Mention-13"
        },
        {
          "reference": "Section-10-Paragraph-5-Sentence-1",
          "local_name": "users",
          "local_types": [
            "stakeholders",
            "user",
            "individuals"
          ],
          "iri": "Entity-user-Mention-14"
        }
      ],
      "relevance": 0.6787109375
    },
    "Entity-sample_usage": {
      "node_id": "sample_usage",
      "disambiguation_index": 0,
      "label": "sample usage",
      "aliases": [
        "sample usage"
      ],
      "types": [
        "usage",
        "demonstration",
        "application"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'sample usage' refers to the practical application and demonstration of the HDGI ontology in the context of human-device gesture interactions as discussed in the paper.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-1",
          "local_name": "sample usage",
          "local_types": [
            "usage",
            "demonstration",
            "application"
          ],
          "iri": "Entity-sample_usage-Mention-1"
        }
      ],
      "relevance": 0.677734375
    },
    "Entity-hdgi__affordance": {
      "node_id": "hdgi__affordance",
      "disambiguation_index": 0,
      "label": "hdgi:Affordance",
      "aliases": [
        "hdgi:Affordance"
      ],
      "types": [
        "relationship",
        "modeling term",
        "ontology class",
        "ontology",
        "concept",
        "ontology term",
        "theoretical construct",
        "model",
        "ontology concept",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Affordance refers to a class within the HDGI ontology that represents the potential actions or interactions that can be performed by a user with a device, specifically in the context of gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Affordance",
          "local_types": [
            "ontology class",
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__affordance-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-7",
          "local_name": "hdgi:Affordance",
          "local_types": [
            "ontology class",
            "concept",
            "ontology term",
            "model",
            "class"
          ],
          "iri": "Entity-hdgi__affordance-Mention-2"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-1",
          "local_name": "hdgi:Affordance",
          "local_types": [
            "relationship",
            "modeling term",
            "ontology class",
            "concept",
            "ontology term",
            "model",
            "ontology concept"
          ],
          "iri": "Entity-hdgi__affordance-Mention-3"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-6",
          "local_name": "hdgi:Affordance",
          "local_types": [
            "theoretical construct",
            "ontology class",
            "concept",
            "ontology term"
          ],
          "iri": "Entity-hdgi__affordance-Mention-4"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-8",
          "local_name": "hdgi:Affordance",
          "local_types": [
            "theoretical construct",
            "concept"
          ],
          "iri": "Entity-hdgi__affordance-Mention-5"
        }
      ],
      "relevance": 0.6767578125
    },
    "Entity-commonly_used_gesture": {
      "node_id": "commonly_used_gesture",
      "disambiguation_index": 0,
      "label": "commonly used gestures",
      "aliases": [
        "commonly used gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Commonly used gestures refer to the standardized movements and poses of the human upper limbs that are frequently employed in human-device interactions, serving as a reference for manufacturers, designers, and developers to identify and understand the dynamics and characteristics of these gestures in relation to specific affordances.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "commonly used gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-commonly_used_gesture-Mention-1"
        }
      ],
      "relevance": 0.6767578125
    },
    "Entity-class": {
      "node_id": "class",
      "disambiguation_index": 0,
      "label": "classes",
      "aliases": [
        "classes"
      ],
      "types": [
        "ontology component",
        "OWL component",
        "classification",
        "concept",
        "theoretical construct",
        "category",
        "categorization"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'classes' refer to the fundamental components that represent various concepts related to human gestures and their interactions with devices, including categories such as Gesture, BodyPart, Pose, Movement, Affordance, Device, and Human.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "classes",
          "local_types": [
            "ontology component",
            "concept"
          ],
          "iri": "Entity-class-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "classes",
          "local_types": [
            "category",
            "classification"
          ],
          "iri": "Entity-class-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-6",
          "local_name": "classes",
          "local_types": [
            "concept",
            "OWL component"
          ],
          "iri": "Entity-class-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "classes",
          "local_types": [
            "categorization",
            "theoretical construct"
          ],
          "iri": "Entity-class-Mention-4"
        }
      ],
      "relevance": 0.67578125
    },
    "Entity-their_product": {
      "node_id": "their_product",
      "disambiguation_index": 0,
      "label": "their products",
      "aliases": [
        "their products"
      ],
      "types": [
        "product"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their products' refers to the various devices and systems developed by designers, producers, and vendors that incorporate gesture interfaces for interaction, particularly within the context of Internet of Things (IoT) applications.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "their products",
          "local_types": [
            "product"
          ],
          "iri": "Entity-their_product-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "their products",
          "local_types": [
            "product"
          ],
          "iri": "Entity-their_product-Mention-2"
        }
      ],
      "relevance": 0.6748046875
    },
    "Entity-an_ontology_(1)": {
      "node_id": "an_ontology_(1)",
      "disambiguation_index": 1,
      "label": "an ontology",
      "aliases": [
        "an ontology"
      ],
      "types": [
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "An ontology in this context refers to a formal representation that systematically describes and maps gesture vocabularies and their relationships to facilitate the understanding and interpretation of user gestures in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-1",
          "local_name": "an ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-an_ontology_(1)-Mention-1"
        }
      ],
      "relevance": 0.6748046875
    },
    "Entity-hdgi-mapping_service": {
      "node_id": "hdgi-mapping_service",
      "disambiguation_index": 0,
      "label": "HDGI-Mapping Service",
      "aliases": [
        "the HDGI Mapping service",
        "The HDGI-Mapping Service",
        "HDGI-Mapping Service"
      ],
      "types": [
        "API",
        "web service",
        "service"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The HDGI-Mapping Service is a fully API-driven RESTful web service that provides access to a repository of contemporary gestures and their mappings to device affordances, enabling designers and developers to define and upload their own gesture vocabularies for broader accessibility and integration.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "HDGI-Mapping Service",
          "local_types": [
            "API",
            "web service",
            "service"
          ],
          "iri": "Entity-hdgi-mapping_service-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-2-Sentence-2",
          "local_name": "the HDGI Mapping service",
          "local_types": [
            "service"
          ],
          "iri": "Entity-hdgi-mapping_service-Mention-2"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "The HDGI-Mapping Service",
          "local_types": [
            "service"
          ],
          "iri": "Entity-hdgi-mapping_service-Mention-3"
        }
      ],
      "relevance": 0.67431640625
    },
    "Entity-product": {
      "node_id": "product",
      "disambiguation_index": 0,
      "label": "products",
      "aliases": [
        "products"
      ],
      "types": [
        "product",
        "goods",
        "technology",
        "items"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'products' refers to the various goods and technologies developed by designers, producers, and vendors that incorporate gesture interfaces for use in Internet of Things (IoT) systems.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "products",
          "local_types": [
            "product",
            "goods",
            "items"
          ],
          "iri": "Entity-product-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "products",
          "local_types": [
            "product",
            "goods",
            "technology",
            "items"
          ],
          "iri": "Entity-product-Mention-2"
        }
      ],
      "relevance": 0.67333984375
    },
    "Entity-hdgi-service_endpoint": {
      "node_id": "hdgi-service_endpoint",
      "disambiguation_index": 0,
      "label": "HDGI-service endpoints",
      "aliases": [
        "HDGI-service endpoints"
      ],
      "types": [
        "endpoint",
        "service"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "HDGI-service endpoints are API-driven RESTful web services that enable querying and accessing available gesture vocabularies and their mappings within the HDGI ontology, facilitating integration with gesture recognition systems.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-2",
          "local_name": "HDGI-service endpoints",
          "local_types": [
            "endpoint",
            "service"
          ],
          "iri": "Entity-hdgi-service_endpoint-Mention-1"
        }
      ],
      "relevance": 0.6728515625
    },
    "Entity-body-based_contextual_gesture": {
      "node_id": "body-based_contextual_gesture",
      "disambiguation_index": 0,
      "label": "body-based contextual gestures",
      "aliases": [
        "body-based contextual gestures"
      ],
      "types": [
        "gesture",
        "concept",
        "contextual interaction",
        "human-computer interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Body-based contextual gestures refer to a category of gestures that are defined within a sensor-independent ontology, focusing on the intrinsic and extrinsic properties of gestures performed by the human body, particularly in the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "body-based contextual gestures",
          "local_types": [
            "gesture",
            "concept",
            "contextual interaction",
            "human-computer interaction"
          ],
          "iri": "Entity-body-based_contextual_gesture-Mention-1"
        }
      ],
      "relevance": 0.67236328125
    },
    "Entity-gestural_input": {
      "node_id": "gestural_input",
      "disambiguation_index": 0,
      "label": "gestural inputs",
      "aliases": [
        "gestural inputs"
      ],
      "types": [
        "input method",
        "human-computer interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Gestural inputs refer to non-verbal commands or signals made by users through physical movements, typically used in human-computer interaction to control devices or software.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-3",
          "local_name": "gestural inputs",
          "local_types": [
            "input method",
            "human-computer interaction"
          ],
          "iri": "Entity-gestural_input-Mention-1"
        }
      ],
      "relevance": 0.67138671875
    },
    "Entity-people": {
      "node_id": "people",
      "disambiguation_index": 0,
      "label": "people",
      "aliases": [
        "people"
      ],
      "types": [
        "individual",
        "individuals",
        "users"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'people' refers to users or individuals who interact with gesture-based interfaces and have varying expectations and preferences for how to perform tasks within those systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-2",
          "local_name": "people",
          "local_types": [
            "individual",
            "individuals",
            "users"
          ],
          "iri": "Entity-people-Mention-1"
        }
      ],
      "relevance": 0.67138671875
    },
    "Entity-personalization_of_gesture": {
      "node_id": "personalization_of_gesture",
      "disambiguation_index": 0,
      "label": "personalization of gestures",
      "aliases": [
        "personalization of gestures",
        "the personalization of gestures"
      ],
      "types": [
        "gesture",
        "process",
        "personalization"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The personalization of gestures refers to the adaptation and customization of gesture-based interactions to suit the individual preferences and expectations of different users, enhancing their experience with gesture-controlled systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-3",
          "local_name": "personalization of gestures",
          "local_types": [
            "personalization"
          ],
          "iri": "Entity-personalization_of_gesture-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-3",
          "local_name": "the personalization of gestures",
          "local_types": [
            "process",
            "gesture"
          ],
          "iri": "Entity-personalization_of_gesture-Mention-2"
        }
      ],
      "relevance": 0.67138671875
    },
    "Entity-class_and_property": {
      "node_id": "class_and_property",
      "disambiguation_index": 0,
      "label": "classes and properties",
      "aliases": [
        "classes and properties"
      ],
      "types": [
        "concept"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'classes and properties' refers to the structured elements within the HDGI ontology that define the various types of gestures, body parts, poses, movements, affordances, devices, and human interactions, which are formally represented using OWL2 and Turtle syntax to facilitate semantic understanding and interoperability in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-6",
          "local_name": "classes and properties",
          "local_types": [
            "concept"
          ],
          "iri": "Entity-class_and_property-Mention-1"
        }
      ],
      "relevance": 0.6708984375
    },
    "Entity-user_gesture": {
      "node_id": "user_gesture",
      "disambiguation_index": 0,
      "label": "user gestures",
      "aliases": [
        "user gestures"
      ],
      "types": [
        "interaction method",
        "user",
        "gesture",
        "human action",
        "input method",
        "human-computer interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "User gestures refer to physical movements made by individuals to communicate or interact with systems, often utilized in human-computer interaction as a form of input method.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-1",
          "local_name": "user gestures",
          "local_types": [
            "interaction method",
            "user",
            "gesture",
            "human action",
            "input method",
            "human-computer interaction"
          ],
          "iri": "Entity-user_gesture-Mention-1"
        }
      ],
      "relevance": 0.67041015625
    },
    "Entity-the_pose_and_movement_of_human_upper_limb": {
      "node_id": "the_pose_and_movement_of_human_upper_limb",
      "disambiguation_index": 0,
      "label": "the pose and movement of human upper limbs",
      "aliases": [
        "the pose and movement of human upper limbs"
      ],
      "types": [
        "pose",
        "movement",
        "human upper limbs"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The pose and movement of human upper limbs refers to the specific gestures and physical actions performed by the arms and hands of humans when interacting with devices, as modeled in the HDGI ontology to facilitate understanding and representation of these gestures in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "the pose and movement of human upper limbs",
          "local_types": [
            "pose",
            "movement",
            "human upper limbs"
          ],
          "iri": "Entity-the_pose_and_movement_of_human_upper_limb-Mention-1"
        }
      ],
      "relevance": 0.67041015625
    },
    "Entity-future_work_(1)": {
      "node_id": "future_work_(1)",
      "disambiguation_index": 1,
      "label": "future work",
      "aliases": [
        "future work"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Future work refers to the planned extensions and enhancements to the Human Device Gesture Interaction ontology, including the incorporation of additional gesture types and the deployment of related services to improve gesture recognition in various applications.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-1",
          "local_name": "future work",
          "local_types": [
            "research"
          ],
          "iri": "Entity-future_work_(1)-Mention-1"
        }
      ],
      "relevance": 0.67041015625
    },
    "Entity-hdgi__observableaffordance": {
      "node_id": "hdgi__observableaffordance",
      "disambiguation_index": 0,
      "label": "hdgi:ObservableAffordance",
      "aliases": [
        "hdgi:ObservableAffordance"
      ],
      "types": [
        "ontology class",
        "ontology",
        "concept",
        "ontology term",
        "affordance",
        "entity",
        "observable affordance",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:ObservableAffordance is an ontology class that represents a type of affordance in the context of Human Device Gesture Interactions, specifically focusing on the observable properties that can be sensed or detected by devices.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-12",
          "local_name": "hdgi:ObservableAffordance",
          "local_types": [
            "ontology class",
            "ontology",
            "concept",
            "ontology term",
            "affordance",
            "entity",
            "observable affordance",
            "class"
          ],
          "iri": "Entity-hdgi__observableaffordance-Mention-1"
        }
      ],
      "relevance": 0.669921875
    },
    "Entity-gesture__typing_command__or_using_button_or_menu_item": {
      "node_id": "gesture__typing_command__or_using_button_or_menu_item",
      "disambiguation_index": 0,
      "label": "gestures, typing commands, or using buttons or menu items",
      "aliases": [
        "gestures, typing commands, or using buttons or menu items"
      ],
      "types": [
        "interaction method"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'gestures, typing commands, or using buttons or menu items' refers to various interaction methods employed by users to communicate their intentions and control devices or systems, emphasizing the importance of intuitive and successful user experiences in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "gestures, typing commands, or using buttons or menu items",
          "local_types": [
            "interaction method"
          ],
          "iri": "Entity-gesture__typing_command__or_using_button_or_menu_item-Mention-1"
        }
      ],
      "relevance": 0.669921875
    },
    "Entity-user_specific_gesture_semantics": {
      "node_id": "user_specific_gesture_semantics",
      "disambiguation_index": 0,
      "label": "user specific gesture semantics",
      "aliases": [
        "user specific gesture semantics"
      ],
      "types": [
        "gesture recognition",
        "concept",
        "gesture",
        "human-computer interaction",
        "semantics"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "User specific gesture semantics refers to the understanding and interpretation of gestures performed by an individual user, taking into account their unique context and preferences, to enable systems to respond appropriately in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-9",
          "local_name": "user specific gesture semantics",
          "local_types": [
            "gesture recognition",
            "concept",
            "gesture",
            "human-computer interaction",
            "semantics"
          ],
          "iri": "Entity-user_specific_gesture_semantics-Mention-1"
        }
      ],
      "relevance": 0.66943359375
    },
    "Entity-a_user_(1)": {
      "node_id": "a_user_(1)",
      "disambiguation_index": 1,
      "label": "a user",
      "aliases": [
        "the user",
        "a user"
      ],
      "types": [
        "user"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A user refers to an individual who interacts with gesture-controlled interfaces in various applications, such as IoT systems, and may experience confusion due to the variability in gesture standards and their own established preferences for conventional controls.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "a user",
          "local_types": [
            "user"
          ],
          "iri": "Entity-a_user_(1)-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-1",
          "local_name": "the user",
          "local_types": [
            "user"
          ],
          "iri": "Entity-a_user_(1)-Mention-2"
        }
      ],
      "relevance": 0.66943359375
    },
    "Entity-their_preferred_gesture": {
      "node_id": "their_preferred_gesture",
      "disambiguation_index": 0,
      "label": "their preferred gestures",
      "aliases": [
        "their preferred gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their preferred gestures' refers to the specific physical movements or actions that individual users favor or find intuitive for interacting with gesture-controlled systems, which are intended to convey their interaction intentions and achieve desired outcomes in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-2",
          "local_name": "their preferred gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-their_preferred_gesture-Mention-1"
        }
      ],
      "relevance": 0.66943359375
    },
    "Entity-use": {
      "node_id": "use",
      "disambiguation_index": 0,
      "label": "use",
      "aliases": [
        "use"
      ],
      "types": [
        "application",
        "utilization"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'use' refers to the ability to access and apply the ontology for gesture recognition and interaction, which is hindered by its lack of open sharing.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-4",
          "local_name": "use",
          "local_types": [
            "application",
            "utilization"
          ],
          "iri": "Entity-use-Mention-1"
        }
      ],
      "relevance": 0.6689453125
    },
    "Entity-gesture_interaction_in_mixed_reality": {
      "node_id": "gesture_interaction_in_mixed_reality",
      "disambiguation_index": 0,
      "label": "gesture interactions in Mixed Reality",
      "aliases": [
        "gesture interactions in Mixed Reality"
      ],
      "types": [
        "Mixed Reality",
        "interaction"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Gesture interactions in Mixed Reality refer to the use of hand and body movements to control and interact with digital content and devices within a Mixed Reality environment, which combines real and virtual elements, and is increasingly facilitated by technologies such as Microsoft HoloLens 2.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-3",
          "local_name": "gesture interactions in Mixed Reality",
          "local_types": [
            "Mixed Reality",
            "interaction"
          ],
          "iri": "Entity-gesture_interaction_in_mixed_reality-Mention-1"
        }
      ],
      "relevance": 0.6689453125
    },
    "Entity-geometrical_gesture": {
      "node_id": "geometrical_gesture",
      "disambiguation_index": 0,
      "label": "geometrical gestures",
      "aliases": [
        "geometrical gestures"
      ],
      "types": [
        "concept",
        "gesture",
        "geometrical",
        "shape",
        "motion"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Geometrical gestures refer to specific hand movements that represent or correspond to distinct geometric shapes, which are utilized in gesture recognition systems to facilitate human-device interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-4",
          "local_name": "geometrical gestures",
          "local_types": [
            "concept",
            "gesture",
            "geometrical",
            "shape",
            "motion"
          ],
          "iri": "Entity-geometrical_gesture-Mention-1"
        }
      ],
      "relevance": 0.66845703125
    },
    "Entity-detection": {
      "node_id": "detection",
      "disambiguation_index": 0,
      "label": "detection",
      "aliases": [
        "detection"
      ],
      "types": [
        "function",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture-controlled interfaces, 'detection' refers to the process by which gesture recognition systems identify and interpret user gestures to facilitate interaction with devices.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-3",
          "local_name": "detection",
          "local_types": [
            "function",
            "process"
          ],
          "iri": "Entity-detection-Mention-1"
        }
      ],
      "relevance": 0.66845703125
    },
    "Entity-hdgi__forearmgesture": {
      "node_id": "hdgi__forearmgesture",
      "disambiguation_index": 0,
      "label": "hdgi:ForearmGesture",
      "aliases": [
        "hdgi:ForearmGesture"
      ],
      "types": [
        "ontology",
        "subclass",
        "gesture",
        "gesture subclass",
        "class",
        "type"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:ForearmGesture refers to a subclass of gestures within the HDGI ontology that specifically involves movements and poses of the forearm as part of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-1",
          "local_name": "hdgi:ForearmGesture",
          "local_types": [
            "ontology",
            "subclass",
            "gesture",
            "gesture subclass",
            "class",
            "type"
          ],
          "iri": "Entity-hdgi__forearmgesture-Mention-1"
        }
      ],
      "relevance": 0.66796875
    },
    "Entity-user_s_choice_of_gesture": {
      "node_id": "user_s_choice_of_gesture",
      "disambiguation_index": 0,
      "label": "user's choice of gestures",
      "aliases": [
        "user's choice of gestures"
      ],
      "types": [
        "user behavior",
        "gesture",
        "behavior",
        "interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'user's choice of gestures' refers to the specific gestures selected by an individual based on their contextual understanding and preferences, which are crucial for accurately interpreting their intent in Human Device Gesture Interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-8",
          "local_name": "user's choice of gestures",
          "local_types": [
            "user behavior",
            "gesture",
            "behavior",
            "interaction"
          ],
          "iri": "Entity-user_s_choice_of_gesture-Mention-1"
        }
      ],
      "relevance": 0.66796875
    },
    "Entity-upper_arm_gesture": {
      "node_id": "upper_arm_gesture",
      "disambiguation_index": 0,
      "label": "upper arm gestures",
      "aliases": [
        "upper arm gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Upper arm gestures refer to a specific category of dynamic gestures that involve movements and poses of the upper arm, which are modeled in detail within the Human Device Gesture Interaction ontology for the purpose of describing human gestures in the context of interactions with devices.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-2",
          "local_name": "upper arm gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-upper_arm_gesture-Mention-1"
        }
      ],
      "relevance": 0.66748046875
    },
    "Entity-preference": {
      "node_id": "preference",
      "disambiguation_index": 0,
      "label": "preferences",
      "aliases": [
        "preferences"
      ],
      "types": [
        "user preference",
        "behavioral trait"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'preferences' refers to the individual choices and inclinations of users regarding gesture controls in Human Device Interactions, particularly in the context of varying standards in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "preferences",
          "local_types": [
            "user preference",
            "behavioral trait"
          ],
          "iri": "Entity-preference-Mention-1"
        }
      ],
      "relevance": 0.66650390625
    },
    "Entity-userdevice_context": {
      "node_id": "userdevice_context",
      "disambiguation_index": 0,
      "label": "user/device contexts",
      "aliases": [
        "user/device contexts"
      ],
      "types": [
        "interaction design",
        "interaction scenario",
        "interaction context",
        "context",
        "environment"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "User/device contexts refer to the specific situations and environments in which users interact with devices, particularly in relation to gesture-controlled interfaces, highlighting the importance of understanding user preferences and the variability of interaction standards.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-3",
          "local_name": "user/device contexts",
          "local_types": [
            "interaction design",
            "interaction scenario",
            "interaction context",
            "context",
            "environment"
          ],
          "iri": "Entity-userdevice_context-Mention-1"
        }
      ],
      "relevance": 0.66650390625
    },
    "Entity-context": {
      "node_id": "context",
      "disambiguation_index": 0,
      "label": "context",
      "aliases": [
        "context",
        "Context"
      ],
      "types": [
        "situation",
        "concept",
        "environmental factor",
        "context",
        "environment",
        "class",
        "situational aspect"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the HDGI ontology, 'context' refers to the situational aspects and environmental factors that influence the interpretation and application of human gestures in device interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-2",
          "local_name": "context",
          "local_types": [
            "situation",
            "concept",
            "environmental factor",
            "context",
            "environment",
            "class",
            "situational aspect"
          ],
          "iri": "Entity-context-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-8",
          "local_name": "context",
          "local_types": [
            "context",
            "environment",
            "situation"
          ],
          "iri": "Entity-context-Mention-2"
        }
      ],
      "relevance": 0.66650390625
    },
    "Entity-gesture_repository": {
      "node_id": "gesture_repository",
      "disambiguation_index": 0,
      "label": "gesture repository",
      "aliases": [
        "gesture repository"
      ],
      "types": [
        "resource",
        "gesture",
        "storage system",
        "database",
        "repository"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The gesture repository is a centralized storage system that allows designers, device manufacturers, and developers to access, define, and upload gesture vocabularies along with their mappings to device affordances, facilitating the integration and reuse of gesture data in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-2",
          "local_name": "gesture repository",
          "local_types": [
            "resource",
            "gesture",
            "storage system",
            "database",
            "repository"
          ],
          "iri": "Entity-gesture_repository-Mention-1"
        }
      ],
      "relevance": 0.66650390625
    },
    "Entity-interoperability_among_interface": {
      "node_id": "interoperability_among_interface",
      "disambiguation_index": 0,
      "label": "interoperability among interfaces",
      "aliases": [
        "interoperability among interfaces"
      ],
      "types": [
        "interface",
        "interoperability",
        "concept"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Interoperability among interfaces refers to the ability of different gesture-controlled systems to understand and utilize a common set of gestures, thereby enhancing user experience by allowing seamless interaction across various devices and platforms.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-2",
          "local_name": "interoperability among interfaces",
          "local_types": [
            "interface",
            "interoperability",
            "concept"
          ],
          "iri": "Entity-interoperability_among_interface-Mention-1"
        }
      ],
      "relevance": 0.666015625
    },
    "Entity-tool": {
      "node_id": "tool",
      "disambiguation_index": 0,
      "label": "tool",
      "aliases": [
        "tool"
      ],
      "types": [
        "resource",
        "software"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'tool' refers to a software resource designed to assist developers and designers in integrating the Human Device Gesture Interaction (HDGI) ontology into their applications.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "tool",
          "local_types": [
            "resource",
            "software"
          ],
          "iri": "Entity-tool-Mention-1"
        }
      ],
      "relevance": 0.66552734375
    },
    "Entity-our_study": {
      "node_id": "our_study",
      "disambiguation_index": 0,
      "label": "our study",
      "aliases": [
        "our study"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Our study refers to the research conducted to analyze and map existing gesture vocabularies from current literature into the HDGI ontology, serving as a foundational step for the development of a comprehensive gesture interaction framework.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-1",
          "local_name": "our study",
          "local_types": [
            "research"
          ],
          "iri": "Entity-our_study-Mention-1"
        }
      ],
      "relevance": 0.66552734375
    },
    "Entity-solo": {
      "node_id": "solo",
      "disambiguation_index": 0,
      "label": "Soli",
      "aliases": [
        "Soli"
      ],
      "types": [
        "gesture recognition",
        "product",
        "gesture recognition system",
        "technology",
        "device",
        "system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Soli is a gesture recognition technology developed by Google that enables users to interact with devices through hand gestures, and it is designed to be integrated with various systems to enhance user experience in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "Soli",
          "local_types": [
            "gesture recognition",
            "product",
            "gesture recognition system",
            "technology",
            "device",
            "system"
          ],
          "iri": "Entity-solo-Mention-1"
        }
      ],
      "relevance": 0.6650390625
    },
    "Entity-hdgi__devicemanufacturer": {
      "node_id": "hdgi__devicemanufacturer",
      "disambiguation_index": 0,
      "label": "hdgi:DeviceManufacturer",
      "aliases": [
        "hdgi:DeviceManufacturer"
      ],
      "types": [
        "manufacturer",
        "ontology class",
        "concept",
        "ontology term",
        "entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:DeviceManufacturer refers to the entity that produces or manufactures devices within the context of the HDGI ontology, which models the relationship between devices and their respective manufacturers to facilitate gesture recognition and affordance mapping.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "hdgi:DeviceManufacturer",
          "local_types": [
            "manufacturer",
            "ontology class",
            "concept",
            "ontology term",
            "entity"
          ],
          "iri": "Entity-hdgi__devicemanufacturer-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-2",
          "local_name": "hdgi:DeviceManufacturer",
          "local_types": [
            "manufacturer"
          ],
          "iri": "Entity-hdgi__devicemanufacturer-Mention-2"
        }
      ],
      "relevance": 0.6650390625
    },
    "Entity-system": {
      "node_id": "system",
      "disambiguation_index": 0,
      "label": "system",
      "aliases": [
        "systems",
        "system"
      ],
      "types": [
        "software",
        "technology",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'system' refers to the collection of Internet of Things (IoT) technologies and frameworks that enable gesture-controlled interfaces in various applications such as automobiles, smart homes, and virtual reality.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "system",
          "local_types": [
            "system"
          ],
          "iri": "Entity-system-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "system",
          "local_types": [
            "software",
            "technology"
          ],
          "iri": "Entity-system-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "system",
          "local_types": [
            "software",
            "technology",
            "system"
          ],
          "iri": "Entity-system-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-3",
          "local_name": "systems",
          "local_types": [
            "technology",
            "software"
          ],
          "iri": "Entity-system-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-5-Sentence-4",
          "local_name": "systems",
          "local_types": [
            "technology",
            "software"
          ],
          "iri": "Entity-system-Mention-5"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-2",
          "local_name": "systems",
          "local_types": [
            "software",
            "technology",
            "system"
          ],
          "iri": "Entity-system-Mention-6"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-4",
          "local_name": "system",
          "local_types": [
            "technology",
            "software"
          ],
          "iri": "Entity-system-Mention-7"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-9",
          "local_name": "systems",
          "local_types": [
            "software",
            "technology",
            "system"
          ],
          "iri": "Entity-system-Mention-8"
        }
      ],
      "relevance": 0.66455078125
    },
    "Entity-symbolic_input": {
      "node_id": "symbolic_input",
      "disambiguation_index": 0,
      "label": "symbolic input",
      "aliases": [
        "symbolic input"
      ],
      "types": [
        "input method",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Symbolic input refers to the gestures or commands that users prefer to use when interacting with gesture-based systems, as identified through Gesture Elicitation Studies (GES).",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-2",
          "local_name": "symbolic input",
          "local_types": [
            "input method",
            "data type"
          ],
          "iri": "Entity-symbolic_input-Mention-1"
        }
      ],
      "relevance": 0.66455078125
    },
    "Entity-method_for_controlling_interactive_system": {
      "node_id": "method_for_controlling_interactive_system",
      "disambiguation_index": 0,
      "label": "methods for controlling interactive systems",
      "aliases": [
        "methods for controlling interactive systems"
      ],
      "types": [
        "method",
        "interactive system"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Methods for controlling interactive systems refer to the various approaches and techniques employed to utilize gesture-based interactions, allowing users to manipulate and communicate with devices through physical movements, particularly in the context of modern technologies such as the Internet of Things, augmented reality, and virtual reality.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "methods for controlling interactive systems",
          "local_types": [
            "method",
            "interactive system"
          ],
          "iri": "Entity-method_for_controlling_interactive_system-Mention-1"
        }
      ],
      "relevance": 0.66455078125
    },
    "Entity-their_relationship": {
      "node_id": "their_relationship",
      "disambiguation_index": 0,
      "label": "their relationships",
      "aliases": [
        "their relationships"
      ],
      "types": [
        "relationship"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their relationships' refers to the connections and mappings between various gesture vocabularies and the systems they interact with, as outlined in the context of developing an ontology for understanding and interpreting user gestures in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-1",
          "local_name": "their relationships",
          "local_types": [
            "relationship"
          ],
          "iri": "Entity-their_relationship-Mention-1"
        }
      ],
      "relevance": 0.66455078125
    },
    "Entity-hdgi__leggesture": {
      "node_id": "hdgi__leggesture",
      "disambiguation_index": 0,
      "label": "hdgi:LegGesture",
      "aliases": [
        "hdgi:LegGesture"
      ],
      "types": [
        "ontology",
        "subclass",
        "gesture",
        "gesture subclass",
        "class",
        "type"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:LegGesture refers to a subclass of gestures within the HDGI ontology that specifically involves movements and poses of the legs in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-1",
          "local_name": "hdgi:LegGesture",
          "local_types": [
            "ontology",
            "subclass",
            "gesture",
            "gesture subclass",
            "class",
            "type"
          ],
          "iri": "Entity-hdgi__leggesture-Mention-1"
        }
      ],
      "relevance": 0.66357421875
    },
    "Entity-gesture_recognition_softwareservices": {
      "node_id": "gesture_recognition_softwareservices",
      "disambiguation_index": 0,
      "label": "gesture recognition software/services",
      "aliases": [
        "gesture recognition software/services"
      ],
      "types": [
        "software",
        "service"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Gesture recognition software/services refer to applications or platforms that utilize algorithms and technologies to interpret human gestures as input commands, enabling interaction with devices through physical movements.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-2",
          "local_name": "gesture recognition software/services",
          "local_types": [
            "software",
            "service"
          ],
          "iri": "Entity-gesture_recognition_softwareservices-Mention-1"
        }
      ],
      "relevance": 0.66357421875
    },
    "Entity-api-driven_restful_web_service": {
      "node_id": "api-driven_restful_web_service",
      "disambiguation_index": 0,
      "label": "API-driven RESTful web service",
      "aliases": [
        "API-driven RESTful web service"
      ],
      "types": [
        "API",
        "web service",
        "service"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "An API-driven RESTful web service that provides a centralized repository for designers, device manufacturers, and developers to access contemporary gestures and their mappings to device affordances, facilitating the integration and customization of gesture vocabularies in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "API-driven RESTful web service",
          "local_types": [
            "API",
            "web service",
            "service"
          ],
          "iri": "Entity-api-driven_restful_web_service-Mention-1"
        }
      ],
      "relevance": 0.66357421875
    },
    "Entity-predefined_one_to_one_mapping": {
      "node_id": "predefined_one_to_one_mapping",
      "disambiguation_index": 0,
      "label": "predefined one to one mappings",
      "aliases": [
        "predefined one to one mappings"
      ],
      "types": [
        "mapping"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Predefined one to one mappings refer to fixed associations between specific gestures and their corresponding affordances in gesture recognition systems, which the HDGI ontology aims to replace with a more flexible and context-aware approach.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "predefined one to one mappings",
          "local_types": [
            "mapping"
          ],
          "iri": "Entity-predefined_one_to_one_mapping-Mention-1"
        }
      ],
      "relevance": 0.6630859375
    },
    "Entity-section_4": {
      "node_id": "section_4",
      "disambiguation_index": 0,
      "label": "Section 4",
      "aliases": [
        "Section 4"
      ],
      "types": [
        "section",
        "part of paper"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Section 4 refers to the part of the paper where the authors illustrate tools for mapping the Human Device Gesture Interaction (HDGI) ontology version 0.1 to the Leap Motion and Oculus Quest devices, serving as an evaluation of the ontology's expressive power.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-4",
          "local_name": "Section 4",
          "local_types": [
            "section",
            "part of paper"
          ],
          "iri": "Entity-section_4-Mention-1"
        }
      ],
      "relevance": 0.662109375
    },
    "Entity-mapping_to_concept_and_property": {
      "node_id": "mapping_to_concept_and_property",
      "disambiguation_index": 0,
      "label": "mappings to concepts and properties",
      "aliases": [
        "mappings to concepts and properties"
      ],
      "types": [
        "mapping",
        "concept",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Mappings to concepts and properties refer to the connections established between the gestures defined in the ontology and the relevant concepts and properties from existing ontologies, facilitating interoperability and semantic understanding in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-5",
          "local_name": "mappings to concepts and properties",
          "local_types": [
            "mapping",
            "concept",
            "property"
          ],
          "iri": "Entity-mapping_to_concept_and_property-Mention-1"
        }
      ],
      "relevance": 0.662109375
    },
    "Entity-gesture_recognition_software_tool": {
      "node_id": "gesture_recognition_software_tool",
      "disambiguation_index": 0,
      "label": "gesture recognition software tools",
      "aliases": [
        "gesture recognition software tools"
      ],
      "types": [
        "tool",
        "software",
        "application",
        "software tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Gesture recognition software tools are applications or software designed to interpret and analyze human gestures as input commands, enabling interaction with devices through motion and body language.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-2",
          "local_name": "gesture recognition software tools",
          "local_types": [
            "tool",
            "software",
            "application",
            "software tool"
          ],
          "iri": "Entity-gesture_recognition_software_tool-Mention-1"
        }
      ],
      "relevance": 0.662109375
    },
    "Entity-leading_hand-gesture_supported_system": {
      "node_id": "leading_hand-gesture_supported_system",
      "disambiguation_index": 0,
      "label": "leading hand-gesture supported systems",
      "aliases": [
        "leading hand-gesture supported systems"
      ],
      "types": [
        "system"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Leading hand-gesture supported systems refer to advanced technological platforms and devices, such as Microsoft HoloLens 2, Microsoft Kinect, and Soli, that utilize hand gestures as a primary means of user interaction, enabling intuitive control and engagement in various applications including augmented and virtual reality.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "leading hand-gesture supported systems",
          "local_types": [
            "system"
          ],
          "iri": "Entity-leading_hand-gesture_supported_system-Mention-1"
        }
      ],
      "relevance": 0.66162109375
    },
    "Entity-hand_gesture_recognition": {
      "node_id": "hand_gesture_recognition",
      "disambiguation_index": 0,
      "label": "hand gesture recognition",
      "aliases": [
        "gesture recognition",
        "hand gesture recognition"
      ],
      "types": [
        "gesture recognition",
        "process",
        "problem",
        "recognition",
        "field of study",
        "technology",
        "computer vision",
        "research area",
        "research topic",
        "field"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Hand gesture recognition is a technology and research area focused on identifying and interpreting human hand movements as a form of input for various applications, particularly in computer vision and interactive systems.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "hand gesture recognition",
          "local_types": [
            "gesture recognition",
            "problem",
            "technology",
            "computer vision",
            "research area",
            "research topic"
          ],
          "iri": "Entity-hand_gesture_recognition-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "gesture recognition",
          "local_types": [
            "gesture recognition",
            "technology",
            "field",
            "research area"
          ],
          "iri": "Entity-hand_gesture_recognition-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "gesture recognition",
          "local_types": [
            "gesture recognition",
            "technology",
            "field of study"
          ],
          "iri": "Entity-hand_gesture_recognition-Mention-3"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-3",
          "local_name": "gesture recognition",
          "local_types": [
            "gesture recognition",
            "process",
            "technology",
            "recognition"
          ],
          "iri": "Entity-hand_gesture_recognition-Mention-4"
        }
      ],
      "relevance": 0.66015625
    },
    "Entity-predefined_mapping": {
      "node_id": "predefined_mapping",
      "disambiguation_index": 0,
      "label": "predefined mappings",
      "aliases": [
        "predefined mappings"
      ],
      "types": [
        "concept",
        "framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Predefined mappings refer to the established associations between specific gestures and their corresponding meanings or actions within gesture-controlled interfaces, which are essential for understanding and implementing gesture recognition in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "predefined mappings",
          "local_types": [
            "concept",
            "framework"
          ],
          "iri": "Entity-predefined_mapping-Mention-1"
        }
      ],
      "relevance": 0.66015625
    },
    "Entity-instance": {
      "node_id": "instance",
      "disambiguation_index": 0,
      "label": "instances",
      "aliases": [
        "instances"
      ],
      "types": [
        "object",
        "entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'instances' refer to specific occurrences or examples of properties that are defined within the ontology, particularly those that relate to gestures, body parts, poses, movements, affordances, devices, and human interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "instances",
          "local_types": [
            "object",
            "entity"
          ],
          "iri": "Entity-instance-Mention-1"
        }
      ],
      "relevance": 0.66015625
    },
    "Entity-a_user_(2)": {
      "node_id": "a_user_(2)",
      "disambiguation_index": 2,
      "label": "a user",
      "aliases": [
        "a user"
      ],
      "types": [
        "user"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A user refers to an individual interacting with gesture-controlled interfaces in Internet of Things (IoT) systems, who may face challenges in adapting to non-intuitive gestures that differ from their conventional control preferences.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "a user",
          "local_types": [
            "user"
          ],
          "iri": "Entity-a_user_(2)-Mention-1"
        }
      ],
      "relevance": 0.66015625
    },
    "Entity-predefined_mapping_of_a_gesture": {
      "node_id": "predefined_mapping_of_a_gesture",
      "disambiguation_index": 0,
      "label": "predefined mappings of a gesture",
      "aliases": [
        "predefined mappings of a gesture"
      ],
      "types": [
        "gesture",
        "mapping"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Predefined mappings of a gesture refer to the established associations between specific hand gestures and their corresponding meanings or actions within gesture-controlled interfaces, which are crucial for enabling intuitive human-device interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "predefined mappings of a gesture",
          "local_types": [
            "gesture",
            "mapping"
          ],
          "iri": "Entity-predefined_mapping_of_a_gesture-Mention-1"
        }
      ],
      "relevance": 0.66015625
    },
    "Entity-standard": {
      "node_id": "standard",
      "disambiguation_index": 0,
      "label": "standards",
      "aliases": [
        "standards",
        "standard"
      ],
      "types": [
        "standard",
        "guidelines",
        "concept",
        "criteria",
        "norm",
        "guideline"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'standards' refers to the varying guidelines and criteria established for the implementation and use of gesture interfaces in products, which have proliferated due to the increasing integration of such interfaces in various applications.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "standards",
          "local_types": [
            "standard",
            "criteria",
            "guidelines"
          ],
          "iri": "Entity-standard-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "standard",
          "local_types": [
            "norm",
            "concept",
            "guideline"
          ],
          "iri": "Entity-standard-Mention-2"
        }
      ],
      "relevance": 0.65966796875
    },
    "Entity-the_gesture": {
      "node_id": "the_gesture",
      "disambiguation_index": 0,
      "label": "the gesture",
      "aliases": [
        "a gesture",
        "the gesture"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The gesture refers to a physical movement made by a user, typically involving the face, limbs, or body, that conveys interaction intentions and communicates information to a device or system within the context of Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-2",
          "local_name": "the gesture",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-the_gesture-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "a gesture",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-the_gesture-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-5",
          "local_name": "a gesture",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-the_gesture-Mention-3"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-1",
          "local_name": "a gesture",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-the_gesture-Mention-4"
        }
      ],
      "relevance": 0.65966796875
    },
    "Entity-commonly_used_gesture_for_certain_affordances": {
      "node_id": "commonly_used_gesture_for_certain_affordances",
      "disambiguation_index": 0,
      "label": "commonly used gestures for certain affordances",
      "aliases": [
        "commonly used gestures for certain affordances"
      ],
      "types": [
        "gesture",
        "affordance"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Commonly used gestures for certain affordances refer to standardized hand movements that are recognized and interpreted by devices to facilitate user interactions with various functionalities, as outlined in the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "commonly used gestures for certain affordances",
          "local_types": [
            "gesture",
            "affordance"
          ],
          "iri": "Entity-commonly_used_gesture_for_certain_affordances-Mention-1"
        }
      ],
      "relevance": 0.65966796875
    },
    "Entity-interface": {
      "node_id": "interface",
      "disambiguation_index": 0,
      "label": "interface",
      "aliases": [
        "interface",
        "interfaces"
      ],
      "types": [
        "user interface",
        "system component",
        "interface",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'interface' refers to the system or medium through which users interact with devices, particularly in the realm of gesture-based controls, highlighting the varying expectations users have when performing tasks.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-2",
          "local_name": "interface",
          "local_types": [
            "user interface",
            "interface",
            "system"
          ],
          "iri": "Entity-interface-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-2",
          "local_name": "interfaces",
          "local_types": [
            "user interface",
            "system component"
          ],
          "iri": "Entity-interface-Mention-2"
        }
      ],
      "relevance": 0.6591796875
    },
    "Entity-existing_research_using_ontology": {
      "node_id": "existing_research_using_ontology",
      "disambiguation_index": 0,
      "label": "existing research using ontologies",
      "aliases": [
        "existing research using ontologies"
      ],
      "types": [
        "research",
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention 'existing research using ontologies' refers to studies that have developed formal ontological frameworks to describe and analyze gestures in human-device interactions, highlighting their semantic relationships and contextual mappings, as opposed to merely categorizing gestures through taxonomies.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-1",
          "local_name": "existing research using ontologies",
          "local_types": [
            "research",
            "ontology"
          ],
          "iri": "Entity-existing_research_using_ontology-Mention-1"
        }
      ],
      "relevance": 0.6591796875
    },
    "Entity-hand-gesture_supported_system": {
      "node_id": "hand-gesture_supported_system",
      "disambiguation_index": 0,
      "label": "hand-gesture supported systems",
      "aliases": [
        "hand-gesture supported systems"
      ],
      "types": [
        "technology",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Hand-gesture supported systems are technological platforms or devices that utilize hand gestures as a primary means of user interaction and control.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "hand-gesture supported systems",
          "local_types": [
            "technology",
            "system"
          ],
          "iri": "Entity-hand-gesture_supported_system-Mention-1"
        }
      ],
      "relevance": 0.6591796875
    },
    "Entity-various_application": {
      "node_id": "various_application",
      "disambiguation_index": 0,
      "label": "various applications",
      "aliases": [
        "various applications"
      ],
      "types": [
        "application"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'various applications' refers to the diverse contexts and systems, such as gaming, smart home devices, and augmented reality, where gesture recognition technology can be implemented to enhance user interaction through mid-air gestures.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "various applications",
          "local_types": [
            "application"
          ],
          "iri": "Entity-various_application-Mention-1"
        }
      ],
      "relevance": 0.65869140625
    },
    "Entity-this_service": {
      "node_id": "this_service",
      "disambiguation_index": 0,
      "label": "this service",
      "aliases": [
        "this service"
      ],
      "types": [
        "service"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "this service refers to the HDGI-Mapping Service, a fully API-driven RESTful web service that allows designers, device manufacturers, and developers to access a repository of gesture vocabularies and their mappings to device affordances, and to define and upload their own gesture vocabularies.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-4",
          "local_name": "this service",
          "local_types": [
            "service"
          ],
          "iri": "Entity-this_service-Mention-1"
        }
      ],
      "relevance": 0.65869140625
    },
    "Entity-designer": {
      "node_id": "designer",
      "disambiguation_index": 0,
      "label": "Designers",
      "aliases": [
        "Designers",
        "designers"
      ],
      "types": [
        "roles",
        "stakeholders",
        "industry stakeholder",
        "professionals",
        "user group",
        "individuals",
        "creative role",
        "stakeholder",
        "user",
        "user experience designers",
        "role",
        "entity",
        "designer",
        "professional",
        "industry",
        "individual",
        "profession"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Designers refer to professionals who create and integrate gesture interfaces into products, contributing to the development and standardization of user interactions in various applications such as IoT systems, automobiles, and AR/VR environments.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "Designers",
          "local_types": [
            "individual",
            "role",
            "profession"
          ],
          "iri": "Entity-designer-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "designers",
          "local_types": [
            "role",
            "profession"
          ],
          "iri": "Entity-designer-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-4",
          "local_name": "Designers",
          "local_types": [
            "roles",
            "professionals",
            "role",
            "profession"
          ],
          "iri": "Entity-designer-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "designers",
          "local_types": [
            "creative role",
            "profession",
            "stakeholder"
          ],
          "iri": "Entity-designer-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "designers",
          "local_types": [
            "professionals",
            "stakeholder",
            "profession",
            "user experience designers"
          ],
          "iri": "Entity-designer-Mention-5"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-1",
          "local_name": "designers",
          "local_types": [
            "professionals",
            "individuals",
            "designer"
          ],
          "iri": "Entity-designer-Mention-6"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "designers",
          "local_types": [
            "professional",
            "stakeholder"
          ],
          "iri": "Entity-designer-Mention-7"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-10",
          "local_name": "designers",
          "local_types": [
            "stakeholders",
            "professionals",
            "profession"
          ],
          "iri": "Entity-designer-Mention-8"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "designers",
          "local_types": [
            "role",
            "industry",
            "entity",
            "profession"
          ],
          "iri": "Entity-designer-Mention-9"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "designers",
          "local_types": [
            "industry stakeholder",
            "profession",
            "designer"
          ],
          "iri": "Entity-designer-Mention-10"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "designers",
          "local_types": [
            "individual",
            "profession"
          ],
          "iri": "Entity-designer-Mention-11"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-3",
          "local_name": "designers",
          "local_types": [
            "role",
            "profession"
          ],
          "iri": "Entity-designer-Mention-12"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "designers",
          "local_types": [
            "user group",
            "user",
            "profession"
          ],
          "iri": "Entity-designer-Mention-13"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-3",
          "local_name": "designers",
          "local_types": [
            "individual",
            "role",
            "profession"
          ],
          "iri": "Entity-designer-Mention-14"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "designers",
          "local_types": [
            "creative role",
            "stakeholder",
            "role",
            "industry",
            "profession"
          ],
          "iri": "Entity-designer-Mention-15"
        }
      ],
      "relevance": 0.658203125
    },
    "Entity-arm-based_gesture": {
      "node_id": "arm-based_gesture",
      "disambiguation_index": 0,
      "label": "arm-based gestures",
      "aliases": [
        "arm-based gestures"
      ],
      "types": [
        "arm-based gesture",
        "gesture",
        "human-computer interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Arm-based gestures are movements of the arms that convey information or facilitate communication, often used in human-computer interaction to enhance user engagement and control.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-2",
          "local_name": "arm-based gestures",
          "local_types": [
            "arm-based gesture",
            "gesture",
            "human-computer interaction"
          ],
          "iri": "Entity-arm-based_gesture-Mention-1"
        }
      ],
      "relevance": 0.658203125
    },
    "Entity-gesture_vocabulary": {
      "node_id": "gesture_vocabulary",
      "disambiguation_index": 0,
      "label": "gesture vocabularies",
      "aliases": [
        "gesture vocabularies",
        "multiple gesture vocabularies"
      ],
      "types": [
        "linguistic construct",
        "interaction design",
        "communication tool",
        "communication system",
        "communication method",
        "linguistic feature",
        "lexicon",
        "vocabulary",
        "data",
        "data set",
        "communication resource",
        "linguistic concept",
        "linguistic resource",
        "gesture vocabulary",
        "concept",
        "language",
        "field",
        "communication",
        "gesture",
        "gesture language",
        "gesture system",
        "gesture representation",
        "set of gestures",
        "linguistic system"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gesture vocabularies refer to the various sets of defined gestures that researchers have created to represent specific actions or commands in gesture-based interaction systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-3",
          "local_name": "gesture vocabularies",
          "local_types": [
            "interaction design",
            "linguistic concept",
            "communication",
            "concept",
            "communication system",
            "language",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-2",
          "local_name": "gesture vocabularies",
          "local_types": [
            "communication resource",
            "linguistic resource",
            "communication",
            "gesture",
            "language",
            "communication method",
            "lexicon",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-3",
          "local_name": "gesture vocabularies",
          "local_types": [
            "communication tool",
            "gesture",
            "linguistic resource",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-3",
          "local_name": "gesture vocabularies",
          "local_types": [
            "communication",
            "gesture",
            "gesture language",
            "communication system",
            "language",
            "lexicon",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-1",
          "local_name": "gesture vocabularies",
          "local_types": [
            "gesture vocabulary",
            "communication",
            "gesture",
            "gesture system",
            "language",
            "communication method",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-5"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-1",
          "local_name": "gesture vocabularies",
          "local_types": [
            "vocabulary",
            "gesture vocabulary",
            "concept",
            "gesture",
            "communication system",
            "gesture system",
            "language",
            "field"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-6"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-4",
          "local_name": "gesture vocabularies",
          "local_types": [
            "linguistic resource",
            "communication system"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-7"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "gesture vocabularies",
          "local_types": [
            "gesture",
            "communication",
            "linguistic system",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-8"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-2",
          "local_name": "gesture vocabularies",
          "local_types": [
            "linguistic construct",
            "communication method",
            "concept",
            "gesture",
            "set of gestures",
            "data",
            "lexicon",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-9"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-3",
          "local_name": "gesture vocabularies",
          "local_types": [
            "communication tool",
            "linguistic resource",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-10"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-4",
          "local_name": "gesture vocabularies",
          "local_types": [
            "linguistic resource",
            "communication method"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-11"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-1",
          "local_name": "gesture vocabularies",
          "local_types": [
            "linguistic concept",
            "concept",
            "gesture",
            "communication method",
            "data",
            "linguistic feature",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-12"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-2",
          "local_name": "gesture vocabularies",
          "local_types": [
            "gesture",
            "data set",
            "linguistic resource",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-13"
        },
        {
          "reference": "Section-11-Paragraph-2-Sentence-1",
          "local_name": "gesture vocabularies",
          "local_types": [
            "linguistic resource",
            "gesture",
            "communication system",
            "gesture representation",
            "vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-14"
        },
        {
          "reference": "Section-2-Paragraph-2-Sentence-3",
          "local_name": "multiple gesture vocabularies",
          "local_types": [
            "gesture vocabulary"
          ],
          "iri": "Entity-gesture_vocabulary-Mention-15"
        }
      ],
      "relevance": 0.65771484375
    },
    "Entity-concept_and_property_in_these_ontology": {
      "node_id": "concept_and_property_in_these_ontology",
      "disambiguation_index": 0,
      "label": "concepts and properties in these ontologies",
      "aliases": [
        "concepts and properties in these ontologies",
        "concepts and properties"
      ],
      "types": [
        "property",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'concepts and properties in these ontologies' refers to the specific elements and characteristics defined within existing ontologies that are utilized to enhance the understanding and interoperability of gesture-related vocabularies in the context of Human Device Interaction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-5",
          "local_name": "concepts and properties in these ontologies",
          "local_types": [
            "concept",
            "property"
          ],
          "iri": "Entity-concept_and_property_in_these_ontology-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-5",
          "local_name": "concepts and properties",
          "local_types": [
            "concept",
            "property"
          ],
          "iri": "Entity-concept_and_property_in_these_ontology-Mention-2"
        }
      ],
      "relevance": 0.65771484375
    },
    "Entity-emerging_gesture": {
      "node_id": "emerging_gesture",
      "disambiguation_index": 0,
      "label": "emerging gestures",
      "aliases": [
        "emerging gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Emerging gestures refer to new or developing hand and body movements that can be integrated into gesture-controlled interfaces, which are designed to convey specific meanings or actions related to device affordances, and can extend beyond traditional upper limb gestures.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "emerging gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-emerging_gesture-Mention-1"
        }
      ],
      "relevance": 0.65771484375
    },
    "Entity-rich_gestural_input": {
      "node_id": "rich_gestural_input",
      "disambiguation_index": 0,
      "label": "rich gestural inputs",
      "aliases": [
        "rich gestural inputs"
      ],
      "types": [
        "input",
        "gestural input"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Rich gestural inputs refer to the diverse and complex physical movements of the body, particularly the upper limbs, that can be recognized and interpreted by gesture-based systems to facilitate user interaction with devices in a more intuitive and accessible manner.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-3",
          "local_name": "rich gestural inputs",
          "local_types": [
            "input",
            "gestural input"
          ],
          "iri": "Entity-rich_gestural_input-Mention-1"
        }
      ],
      "relevance": 0.6572265625
    },
    "Entity-gesture_set": {
      "node_id": "gesture_set",
      "disambiguation_index": 0,
      "label": "gesture set",
      "aliases": [
        "gesture set",
        "the gesture set"
      ],
      "types": [
        "collection",
        "set",
        "gesture",
        "gesture set"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'gesture set' refers to a defined collection of specific gestures, in this case limited to 5 geometrical shapes, that are recognized and utilized within the context of gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-4",
          "local_name": "gesture set",
          "local_types": [
            "collection",
            "gesture",
            "set"
          ],
          "iri": "Entity-gesture_set-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-4",
          "local_name": "the gesture set",
          "local_types": [
            "gesture set",
            "gesture",
            "set"
          ],
          "iri": "Entity-gesture_set-Mention-2"
        }
      ],
      "relevance": 0.65673828125
    },
    "Entity-existing_gesture_recognition_system": {
      "node_id": "existing_gesture_recognition_system",
      "disambiguation_index": 0,
      "label": "existing gesture recognition systems",
      "aliases": [
        "existing gesture recognition systems"
      ],
      "types": [
        "system",
        "gesture recognition"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Existing gesture recognition systems refer to currently implemented technologies and frameworks that are capable of detecting and interpreting human gestures for various applications.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-2-Sentence-2",
          "local_name": "existing gesture recognition systems",
          "local_types": [
            "system",
            "gesture recognition"
          ],
          "iri": "Entity-existing_gesture_recognition_system-Mention-1"
        }
      ],
      "relevance": 0.65625
    },
    "Entity-communication": {
      "node_id": "communication",
      "disambiguation_index": 0,
      "label": "communication",
      "aliases": [
        "communication"
      ],
      "types": [
        "function",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture-controlled interfaces, 'communication' refers to the process by which users convey their intended actions or affordances to devices through gestures, enabling the devices to interpret and respond to user inputs effectively.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-3",
          "local_name": "communication",
          "local_types": [
            "function",
            "process"
          ],
          "iri": "Entity-communication-Mention-1"
        }
      ],
      "relevance": 0.65576171875
    },
    "Entity-section_3": {
      "node_id": "section_3",
      "disambiguation_index": 0,
      "label": "Section 3",
      "aliases": [
        "Section 3"
      ],
      "types": [
        "section",
        "part of paper"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Section 3 refers to the part of the paper where the authors describe the syntax, semantics, design, and formalization of the Human Device Gesture Interaction (HDGI) ontology version 0.1, along with the rationale behind its design.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "Section 3",
          "local_types": [
            "section",
            "part of paper"
          ],
          "iri": "Entity-section_3-Mention-1"
        }
      ],
      "relevance": 0.6552734375
    },
    "Entity-hand_gesture": {
      "node_id": "hand_gesture",
      "disambiguation_index": 0,
      "label": "hand gestures",
      "aliases": [
        "hand gestures"
      ],
      "types": [
        "gesture",
        "human action",
        "communication",
        "human-computer interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Hand gestures are movements of the hands that convey meaning or facilitate communication, often used in both human interaction and human-computer interaction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "hand gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-hand_gesture-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-5",
          "local_name": "hand gestures",
          "local_types": [
            "gesture",
            "communication"
          ],
          "iri": "Entity-hand_gesture-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-6",
          "local_name": "hand gestures",
          "local_types": [
            "gesture",
            "human-computer interaction"
          ],
          "iri": "Entity-hand_gesture-Mention-3"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-11",
          "local_name": "hand gestures",
          "local_types": [
            "gesture",
            "human action"
          ],
          "iri": "Entity-hand_gesture-Mention-4"
        }
      ],
      "relevance": 0.65380859375
    },
    "Entity-property": {
      "node_id": "property",
      "disambiguation_index": 0,
      "label": "properties",
      "aliases": [
        "properties"
      ],
      "types": [
        "OWL component",
        "attribute",
        "property",
        "concept",
        "characteristic",
        "attributes",
        "mathematical object",
        "characteristics"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the paper, 'properties' refers to the characteristics and attributes associated with gestures that are defined and mapped within the ontology for Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-5",
          "local_name": "properties",
          "local_types": [
            "attribute",
            "characteristic"
          ],
          "iri": "Entity-property-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "properties",
          "local_types": [
            "attribute",
            "characteristic"
          ],
          "iri": "Entity-property-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-6",
          "local_name": "properties",
          "local_types": [
            "concept",
            "OWL component"
          ],
          "iri": "Entity-property-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "properties",
          "local_types": [
            "attribute",
            "property",
            "mathematical object"
          ],
          "iri": "Entity-property-Mention-4"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-1",
          "local_name": "properties",
          "local_types": [
            "characteristics",
            "attributes"
          ],
          "iri": "Entity-property-Mention-5"
        }
      ],
      "relevance": 0.65380859375
    },
    "Entity-the_web_application_(1)": {
      "node_id": "the_web_application_(1)",
      "disambiguation_index": 1,
      "label": "the web application",
      "aliases": [
        "the web application"
      ],
      "types": [
        "application"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The web application refers to the HDGI-Mapping Service, a fully API-driven RESTful web service designed to facilitate the integration and documentation of gesture vocabularies and their mappings to device affordances, which can be deployed locally or in a private cloud.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-3",
          "local_name": "the web application",
          "local_types": [
            "application"
          ],
          "iri": "Entity-the_web_application_(1)-Mention-1"
        }
      ],
      "relevance": 0.65234375
    },
    "Entity-ge": {
      "node_id": "ge",
      "disambiguation_index": 0,
      "label": "GES",
      "aliases": [
        "GES"
      ],
      "types": [
        "method",
        "organization",
        "acronym",
        "framework",
        "abbreviation",
        "research method",
        "research framework",
        "ontology",
        "model",
        "system",
        "research methodology",
        "knowledge system",
        "gesture-referent mapping",
        "gesture expression system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "GES refers to Gesture Elicitation Studies, which are research studies aimed at collecting and analyzing user preferences for gesture-based interactions in order to define gesture vocabularies for human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-5",
          "local_name": "GES",
          "local_types": [
            "organization",
            "acronym",
            "framework",
            "system"
          ],
          "iri": "Entity-ge-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-3",
          "local_name": "GES",
          "local_types": [
            "organization",
            "research framework",
            "system",
            "knowledge system",
            "gesture expression system"
          ],
          "iri": "Entity-ge-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-8",
          "local_name": "GES",
          "local_types": [
            "method",
            "framework",
            "ontology",
            "model",
            "system"
          ],
          "iri": "Entity-ge-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-2-Sentence-2",
          "local_name": "GES",
          "local_types": [
            "abbreviation",
            "research methodology"
          ],
          "iri": "Entity-ge-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-4",
          "local_name": "GES",
          "local_types": [
            "research method",
            "gesture-referent mapping"
          ],
          "iri": "Entity-ge-Mention-5"
        }
      ],
      "relevance": 0.65185546875
    },
    "Entity-dynamic": {
      "node_id": "dynamic",
      "disambiguation_index": 0,
      "label": "dynamics",
      "aliases": [
        "dynamics"
      ],
      "types": [
        "characteristic",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'dynamics' refers to the characteristics of a gesture, specifically its shape and movement patterns, which are essential for understanding how gestures interact with device affordances in the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "dynamics",
          "local_types": [
            "characteristic",
            "property"
          ],
          "iri": "Entity-dynamic-Mention-1"
        }
      ],
      "relevance": 0.650390625
    },
    "Entity-a_greater_variation_of_standard": {
      "node_id": "a_greater_variation_of_standard",
      "disambiguation_index": 0,
      "label": "a greater variation of standards",
      "aliases": [
        "a greater variation of standards"
      ],
      "types": [
        "standard"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'a greater variation of standards' refers to the diverse and inconsistent set of guidelines and practices that have emerged among designers, producers, and vendors in the implementation of gesture-controlled interfaces across various applications in the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "a greater variation of standards",
          "local_types": [
            "standard"
          ],
          "iri": "Entity-a_greater_variation_of_standard-Mention-1"
        }
      ],
      "relevance": 0.650390625
    },
    "Entity-hdgi__facialgesture": {
      "node_id": "hdgi__facialgesture",
      "disambiguation_index": 0,
      "label": "hdgi:FacialGesture",
      "aliases": [
        "hdgi:FacialGesture"
      ],
      "types": [
        "ontology",
        "subclass",
        "gesture",
        "gesture subclass",
        "class",
        "type"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:FacialGesture refers to a subclass of gestures within the HDGI ontology that specifically encompasses gestures performed using facial movements.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-1",
          "local_name": "hdgi:FacialGesture",
          "local_types": [
            "ontology",
            "subclass",
            "gesture",
            "gesture subclass",
            "class",
            "type"
          ],
          "iri": "Entity-hdgi__facialgesture-Mention-1"
        }
      ],
      "relevance": 0.64990234375
    },
    "Entity-5_geometrical_shape": {
      "node_id": "5_geometrical_shape",
      "disambiguation_index": 0,
      "label": "5 geometrical shapes",
      "aliases": [
        "5 geometrical shapes"
      ],
      "types": [
        "geometric figure",
        "concept",
        "geometrical",
        "shape",
        "geometrical shape"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention '5 geometrical shapes' refers to a specific set of hand gestures that are defined and recognized within the context of gesture-controlled interfaces, particularly focusing on the geometric forms used in gestural interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-4",
          "local_name": "5 geometrical shapes",
          "local_types": [
            "geometric figure",
            "concept",
            "geometrical",
            "shape",
            "geometrical shape"
          ],
          "iri": "Entity-5_geometrical_shape-Mention-1"
        }
      ],
      "relevance": 0.64990234375
    },
    "Entity-new_movement": {
      "node_id": "new_movement",
      "disambiguation_index": 0,
      "label": "new movements",
      "aliases": [
        "new movements"
      ],
      "types": [
        "concept"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "New movements refer to custom-defined dynamic gestures that designers and developers can incorporate into the Human Device Gesture Interaction ontology to enhance gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-3",
          "local_name": "new movements",
          "local_types": [
            "concept"
          ],
          "iri": "Entity-new_movement-Mention-1"
        }
      ],
      "relevance": 0.64892578125
    },
    "Entity-sensor-independent_ontology": {
      "node_id": "sensor-independent_ontology",
      "disambiguation_index": 0,
      "label": "sensor-independent ontology",
      "aliases": [
        "sensor-independent ontology",
        "sensor-independent ontology of body-based contextual gestures"
      ],
      "types": [
        "framework",
        "ontology",
        "concept",
        "contextual representation",
        "gesture"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The sensor-independent ontology refers to a formal framework that describes body-based contextual gestures without reliance on specific sensors, focusing on intrinsic and extrinsic properties of gestures while not addressing the semantic relationships between gestures and their corresponding affordances.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "sensor-independent ontology",
          "local_types": [
            "contextual representation",
            "ontology",
            "concept",
            "framework"
          ],
          "iri": "Entity-sensor-independent_ontology-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "sensor-independent ontology of body-based contextual gestures",
          "local_types": [
            "ontology",
            "gesture"
          ],
          "iri": "Entity-sensor-independent_ontology-Mention-2"
        }
      ],
      "relevance": 0.6484375
    },
    "Entity-a_predefined_set_of_movement": {
      "node_id": "a_predefined_set_of_movement",
      "disambiguation_index": 0,
      "label": "a predefined set of movements",
      "aliases": [
        "a predefined set of movements"
      ],
      "types": [
        "movement"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A predefined set of movements refers to the specific dynamic gestures identified in the HDGI ontology that describe the motion of body parts such as the upper arm, forearm, palm, and finger, which can be customized and are essential for human-device interactions.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-2",
          "local_name": "a predefined set of movements",
          "local_types": [
            "movement"
          ],
          "iri": "Entity-a_predefined_set_of_movement-Mention-1"
        }
      ],
      "relevance": 0.6484375
    },
    "Entity-affordance_mapping": {
      "node_id": "affordance_mapping",
      "disambiguation_index": 0,
      "label": "affordance mapping",
      "aliases": [
        "affordance mapping"
      ],
      "types": [
        "interaction design",
        "affordance",
        "mapping",
        "cognitive process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Affordance mapping refers to the process of linking user gestures to the potential actions or uses that a device can support, enabling systems to interpret user intent and facilitate interaction across different devices through an interconnected knowledge base.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "affordance mapping",
          "local_types": [
            "interaction design",
            "affordance",
            "mapping",
            "cognitive process"
          ],
          "iri": "Entity-affordance_mapping-Mention-1"
        }
      ],
      "relevance": 0.6484375
    },
    "Entity-automated_reasoning_(1)": {
      "node_id": "automated_reasoning_(1)",
      "disambiguation_index": 1,
      "label": "automated reasoning",
      "aliases": [
        "automated reasoning"
      ],
      "types": [
        "process"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Automated reasoning refers to the process by which a system can infer or deduce user intent and affordance mappings from gesture interactions, enabling effective communication between devices in a gesture-controlled interface.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-4",
          "local_name": "automated reasoning",
          "local_types": [
            "process"
          ],
          "iri": "Entity-automated_reasoning_(1)-Mention-1"
        }
      ],
      "relevance": 0.6484375
    },
    "Entity-gesture_selection": {
      "node_id": "gesture_selection",
      "disambiguation_index": 0,
      "label": "gesture selection",
      "aliases": [
        "gesture selection"
      ],
      "types": [
        "interaction method",
        "user interface",
        "selection",
        "gesture",
        "user choice"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gesture selection refers to the process of choosing from a limited set of predefined gestures that users can perform to interact with a system, often resulting in a binary or restricted range of options for user input.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-4",
          "local_name": "gesture selection",
          "local_types": [
            "interaction method",
            "user interface",
            "selection",
            "gesture",
            "user choice"
          ],
          "iri": "Entity-gesture_selection-Mention-1"
        }
      ],
      "relevance": 0.64794921875
    },
    "Entity-gesture_a": {
      "node_id": "gesture_a",
      "disambiguation_index": 0,
      "label": "Gesture A",
      "aliases": [
        "Gesture A"
      ],
      "types": [
        "gesture",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gesture A refers to a defined type of gesture within the HDGI ontology that categorizes gestures into two atomic types: static and dynamic gestures.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "Gesture A",
          "local_types": [
            "gesture",
            "concept"
          ],
          "iri": "Entity-gesture_a-Mention-1"
        }
      ],
      "relevance": 0.64794921875
    },
    "Entity-endpoint_structure": {
      "node_id": "endpoint_structure",
      "disambiguation_index": 0,
      "label": "endpoint structures",
      "aliases": [
        "endpoint structures"
      ],
      "types": [
        "technical specification",
        "endpoint",
        "API component",
        "structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Endpoint structures refer to the organized configurations and specifications of API endpoints within the HDGI ontology framework, enabling users to effectively interact with and utilize the gesture recognition services provided by the API.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-1",
          "local_name": "endpoint structures",
          "local_types": [
            "technical specification",
            "endpoint",
            "API component",
            "structure"
          ],
          "iri": "Entity-endpoint_structure-Mention-1"
        }
      ],
      "relevance": 0.64794921875
    },
    "Entity-a_particular_gesture": {
      "node_id": "a_particular_gesture",
      "disambiguation_index": 0,
      "label": "a particular gesture",
      "aliases": [
        "a particular gesture"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A particular gesture refers to a specific physical movement or action performed by a user, which is utilized in gesture-controlled interfaces to convey interaction intentions and trigger corresponding responses from a device or system.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-4",
          "local_name": "a particular gesture",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-a_particular_gesture-Mention-1"
        }
      ],
      "relevance": 0.64794921875
    },
    "Entity-endpoint": {
      "node_id": "endpoint",
      "disambiguation_index": 0,
      "label": "endpoints",
      "aliases": [
        "endpoints"
      ],
      "types": [
        "API",
        "interface"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'endpoints' refers to the HDGI-service endpoints, which are specific access points in a RESTful API that allow users to query and interact with available gesture vocabularies within the HDGI ontology framework.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-2",
          "local_name": "endpoints",
          "local_types": [
            "API",
            "interface"
          ],
          "iri": "Entity-endpoint-Mention-1"
        }
      ],
      "relevance": 0.6474609375
    },
    "Entity-greater_variation_in_way_of_utilizing_them": {
      "node_id": "greater_variation_in_way_of_utilizing_them",
      "disambiguation_index": 0,
      "label": "greater variation in ways of utilizing them",
      "aliases": [
        "greater variation in ways of utilizing them"
      ],
      "types": [
        "variation",
        "utilization"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'greater variation in ways of utilizing them' refers to the diverse and inconsistent methods adopted by designers, developers, producers, and vendors in implementing gesture interfaces across different products and systems, leading to a lack of standardization and potential user confusion.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "greater variation in ways of utilizing them",
          "local_types": [
            "variation",
            "utilization"
          ],
          "iri": "Entity-greater_variation_in_way_of_utilizing_them-Mention-1"
        }
      ],
      "relevance": 0.6474609375
    },
    "Entity-expectation": {
      "node_id": "expectation",
      "disambiguation_index": 0,
      "label": "expectations",
      "aliases": [
        "expectations"
      ],
      "types": [
        "user experience",
        "cognitive model"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of user experience and cognitive models, 'expectations' refers to the preconceived notions and preferences that users have regarding the intuitiveness and functionality of gesture-controlled interfaces, which can lead to confusion when the actual gestures do not align with these expectations.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "expectations",
          "local_types": [
            "user experience",
            "cognitive model"
          ],
          "iri": "Entity-expectation-Mention-1"
        }
      ],
      "relevance": 0.64697265625
    },
    "Entity-end_user__preference_for_symbolic_input": {
      "node_id": "end_user__preference_for_symbolic_input",
      "disambiguation_index": 0,
      "label": "end users\u2019 preferences for symbolic input",
      "aliases": [
        "end users\u2019 preferences for symbolic input",
        "the collection of end users\u2019 preferences for symbolic input"
      ],
      "types": [
        "process",
        "user preference"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'end users\u2019 preferences for symbolic input' refers to the insights gathered from users regarding their favored gestures or symbolic commands for interacting with gesture-based systems, as established through Gesture Elicitation Studies (GES).",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-2",
          "local_name": "end users\u2019 preferences for symbolic input",
          "local_types": [
            "user preference"
          ],
          "iri": "Entity-end_user__preference_for_symbolic_input-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-2-Sentence-2",
          "local_name": "the collection of end users\u2019 preferences for symbolic input",
          "local_types": [
            "process",
            "user preference"
          ],
          "iri": "Entity-end_user__preference_for_symbolic_input-Mention-2"
        }
      ],
      "relevance": 0.64697265625
    },
    "Entity-the_semantics_of_these_gesture": {
      "node_id": "the_semantics_of_these_gesture",
      "disambiguation_index": 0,
      "label": "the semantics of these gestures",
      "aliases": [
        "the semantics of a user's gesture",
        "the semantics of these gestures"
      ],
      "types": [
        "gesture",
        "semantics"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The semantics of these gestures refers to the meanings and interpretations associated with various physical movements used in gesture-based interactions, which are essential for enhancing interoperability among different user interfaces and improving overall user experience.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-2",
          "local_name": "the semantics of these gestures",
          "local_types": [
            "semantics",
            "gesture"
          ],
          "iri": "Entity-the_semantics_of_these_gesture-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "the semantics of a user's gesture",
          "local_types": [
            "semantics",
            "gesture"
          ],
          "iri": "Entity-the_semantics_of_these_gesture-Mention-2"
        }
      ],
      "relevance": 0.646484375
    },
    "Entity-all_class_and_relationship": {
      "node_id": "all_class_and_relationship",
      "disambiguation_index": 0,
      "label": "all classes and relationships",
      "aliases": [
        "all classes and relationships"
      ],
      "types": [
        "classes",
        "relationships"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'all classes and relationships' refers to the complete set of defined classes and their interconnections within the HDGI ontology, which is specifically designed to model human gestures and their associated affordances in the context of Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "all classes and relationships",
          "local_types": [
            "classes",
            "relationships"
          ],
          "iri": "Entity-all_class_and_relationship-Mention-1"
        }
      ],
      "relevance": 0.646484375
    },
    "Entity-command": {
      "node_id": "command",
      "disambiguation_index": 0,
      "label": "commands",
      "aliases": [
        "commands"
      ],
      "types": [
        "interaction technique",
        "input",
        "instruction",
        "input method",
        "action"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture-controlled interfaces, 'commands' refer to the specific instructions or inputs that users can provide to a system through gestures, typing, or button interactions, which are essential for achieving successful interaction outcomes.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "commands",
          "local_types": [
            "input method",
            "interaction technique"
          ],
          "iri": "Entity-command-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "commands",
          "local_types": [
            "instruction",
            "action"
          ],
          "iri": "Entity-command-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-9",
          "local_name": "commands",
          "local_types": [
            "instruction",
            "input"
          ],
          "iri": "Entity-command-Mention-3"
        }
      ],
      "relevance": 0.64599609375
    },
    "Entity-gestural_interaction_taxonomy": {
      "node_id": "gestural_interaction_taxonomy",
      "disambiguation_index": 0,
      "label": "gestural interaction taxonomy",
      "aliases": [
        "gestural interaction taxonomy"
      ],
      "types": [
        "gestural interaction",
        "taxonomy",
        "framework",
        "interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The gestural interaction taxonomy is a systematic framework proposed by Scoditti et al. to assist designers and researchers in reasoning, comparing, eliciting, and creating effective techniques for gesture-based interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "gestural interaction taxonomy",
          "local_types": [
            "gestural interaction",
            "taxonomy",
            "framework",
            "interaction"
          ],
          "iri": "Entity-gestural_interaction_taxonomy-Mention-1"
        }
      ],
      "relevance": 0.64599609375
    },
    "Entity-gesture_elicitation_study__ge_": {
      "node_id": "gesture_elicitation_study__ge_",
      "disambiguation_index": 0,
      "label": "Gesture Elicitation Studies (GES)",
      "aliases": [
        "Their study",
        "Gesture Elicitation Studies (GES)"
      ],
      "types": [
        "research method",
        "study",
        "methodology",
        "research",
        "research methodology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gesture Elicitation Studies (GES) refer to research methodologies that collect and analyze end users' preferences for symbolic input gestures, aiming to improve the design and effectiveness of gesture-based interaction systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-2",
          "local_name": "Gesture Elicitation Studies (GES)",
          "local_types": [
            "study",
            "methodology",
            "research methodology",
            "research method"
          ],
          "iri": "Entity-gesture_elicitation_study__ge_-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-2-Sentence-2",
          "local_name": "Their study",
          "local_types": [
            "research"
          ],
          "iri": "Entity-gesture_elicitation_study__ge_-Mention-2"
        }
      ],
      "relevance": 0.6455078125
    },
    "Entity-universal_gesture_standard": {
      "node_id": "universal_gesture_standard",
      "disambiguation_index": 0,
      "label": "universal gesture standard",
      "aliases": [
        "universal gesture standard"
      ],
      "types": [
        "gesture protocol",
        "gesture",
        "standard",
        "communication framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'universal gesture standard' refers to a comprehensive and widely accepted set of gesture protocols that would enable consistent and intuitive gesture recognition across various devices and applications, which is currently lacking and may not be developed in the future.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-5",
          "local_name": "universal gesture standard",
          "local_types": [
            "gesture protocol",
            "gesture",
            "standard",
            "communication framework"
          ],
          "iri": "Entity-universal_gesture_standard-Mention-1"
        }
      ],
      "relevance": 0.6455078125
    },
    "Entity-their_ontological_framework": {
      "node_id": "their_ontological_framework",
      "disambiguation_index": 0,
      "label": "their ontological framework",
      "aliases": [
        "their ontological framework"
      ],
      "types": [
        "framework"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their ontological framework' refers to the structured representation of gestures and their relationships to affordances and user/device contexts, as developed by previous researchers, which lacks the capability to map gestures with similar referents.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-5",
          "local_name": "their ontological framework",
          "local_types": [
            "framework"
          ],
          "iri": "Entity-their_ontological_framework-Mention-1"
        }
      ],
      "relevance": 0.6455078125
    },
    "Entity-dictionary": {
      "node_id": "dictionary",
      "disambiguation_index": 0,
      "label": "dictionary",
      "aliases": [
        "dictionary"
      ],
      "types": [
        "reference material",
        "resource"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'dictionary' refers to a resource within the HDGI ontology that serves as a reference for manufacturers, designers, and developers to search for and identify commonly used gestures associated with specific affordances, as well as to understand the characteristics of those gestures.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "dictionary",
          "local_types": [
            "reference material",
            "resource"
          ],
          "iri": "Entity-dictionary-Mention-1"
        }
      ],
      "relevance": 0.64501953125
    },
    "Entity-existing_one": {
      "node_id": "existing_one",
      "disambiguation_index": 0,
      "label": "existing ones",
      "aliases": [
        "existing ones"
      ],
      "types": [
        "vocabulary"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'existing ones' refers to the currently available and contemporary gesture vocabularies that are already defined and can be reused within the context of the HDGI ontology for Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-4",
          "local_name": "existing ones",
          "local_types": [
            "vocabulary"
          ],
          "iri": "Entity-existing_one-Mention-1"
        }
      ],
      "relevance": 0.64501953125
    },
    "Entity-listing_1.4": {
      "node_id": "listing_1.4",
      "disambiguation_index": 0,
      "label": "Listing 1.4",
      "aliases": [
        "Listing 1.4"
      ],
      "types": [
        "reference",
        "example",
        "listing"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Listing 1.4 illustrates the modeling of relationships between hdgi:Affordance, hdgi:Device, and hdgi:Context within the HDGI ontology, highlighting a key contribution to understanding user gesture semantics and affordance mapping.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-1",
          "local_name": "Listing 1.4",
          "local_types": [
            "reference",
            "example",
            "listing"
          ],
          "iri": "Entity-listing_1.4-Mention-1"
        }
      ],
      "relevance": 0.64453125
    },
    "Entity-each_individual_hdgi__finger_pose": {
      "node_id": "each_individual_hdgi__finger_pose",
      "disambiguation_index": 0,
      "label": "each individual hdgi:Finger poses",
      "aliases": [
        "each individual hdgi:Finger poses"
      ],
      "types": [
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Each individual hdgi:Finger poses refers to the specific static gestures that can be performed by individual fingers, modeled within the HDGI ontology to represent their unique positions and rotations in a 3D space during human-device interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-2-Sentence-5",
          "local_name": "each individual hdgi:Finger poses",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-each_individual_hdgi__finger_pose-Mention-1"
        }
      ],
      "relevance": 0.64453125
    },
    "Entity-relevant_mapping": {
      "node_id": "relevant_mapping",
      "disambiguation_index": 0,
      "label": "relevant mappings",
      "aliases": [
        "relevant mappings"
      ],
      "types": [
        "mapping"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Relevant mappings refer to the connections and alignments established between the HDGI ontology and external ontologies, facilitating interoperability and integration of gesture-related data across different semantic frameworks.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-2",
          "local_name": "relevant mappings",
          "local_types": [
            "mapping"
          ],
          "iri": "Entity-relevant_mapping-Mention-1"
        }
      ],
      "relevance": 0.64404296875
    },
    "Entity-this_variety": {
      "node_id": "this_variety",
      "disambiguation_index": 0,
      "label": "This variety",
      "aliases": [
        "This variety"
      ],
      "types": [
        "variety"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This variety refers to the diverse range of gesture standards and interfaces used in Human Device Interactions, which can lead to confusion for users familiar with traditional control methods.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "This variety",
          "local_types": [
            "variety"
          ],
          "iri": "Entity-this_variety-Mention-1"
        }
      ],
      "relevance": 0.6416015625
    },
    "Entity-existing_gesture_vocabulary": {
      "node_id": "existing_gesture_vocabulary",
      "disambiguation_index": 0,
      "label": "existing gesture vocabularies",
      "aliases": [
        "existing gesture vocabularies"
      ],
      "types": [
        "gesture",
        "gesture vocabulary",
        "vocabulary"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Existing gesture vocabularies refer to the predefined sets of gestures that have been established and documented for use in gesture-controlled interfaces, which include their associated meanings and actions, but lack formal mappings of their semantic relationships.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-4",
          "local_name": "existing gesture vocabularies",
          "local_types": [
            "gesture",
            "gesture vocabulary",
            "vocabulary"
          ],
          "iri": "Entity-existing_gesture_vocabulary-Mention-1"
        }
      ],
      "relevance": 0.6416015625
    },
    "Entity-one_of_the_major_contribution_in_this_ontology": {
      "node_id": "one_of_the_major_contribution_in_this_ontology",
      "disambiguation_index": 0,
      "label": "one of the major contributions in this ontology",
      "aliases": [
        "one of the major contributions in this ontology"
      ],
      "types": [
        "contribution",
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'one of the major contributions in this ontology' refers to the modeling of the relationships between affordances, gestures, and contexts in the HDGI ontology, which enables systems to automatically identify gesture semantics and perform affordance mapping through an interconnected knowledge base.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "one of the major contributions in this ontology",
          "local_types": [
            "contribution",
            "ontology"
          ],
          "iri": "Entity-one_of_the_major_contribution_in_this_ontology-Mention-1"
        }
      ],
      "relevance": 0.640625
    },
    "Entity-gesture-referent_mapping": {
      "node_id": "gesture-referent_mapping",
      "disambiguation_index": 0,
      "label": "gesture-referent mapping",
      "aliases": [
        "gesture-referent mapping"
      ],
      "types": [
        "mapping technique",
        "concept",
        "gesture",
        "mapping",
        "referent"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gesture-referent mapping refers to the relationship between a specific gesture performed by a user and the intended action or effect (referent) that the gesture signifies within interactive systems, highlighting the need for a systematic approach to link existing gesture vocabularies to their corresponding referents.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-4",
          "local_name": "gesture-referent mapping",
          "local_types": [
            "mapping technique",
            "concept",
            "gesture",
            "mapping",
            "referent"
          ],
          "iri": "Entity-gesture-referent_mapping-Mention-1"
        }
      ],
      "relevance": 0.64013671875
    },
    "Entity-a_dictionary_for_manufacturer__designer__and_developer": {
      "node_id": "a_dictionary_for_manufacturer__designer__and_developer",
      "disambiguation_index": 0,
      "label": "a dictionary for manufacturers, designers, and developers",
      "aliases": [
        "a dictionary for manufacturers, designers, and developers"
      ],
      "types": [
        "resource",
        "dictionary"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A resource that serves as a comprehensive reference for manufacturers, designers, and developers to identify and understand commonly used gestures associated with specific affordances in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "a dictionary for manufacturers, designers, and developers",
          "local_types": [
            "resource",
            "dictionary"
          ],
          "iri": "Entity-a_dictionary_for_manufacturer__designer__and_developer-Mention-1"
        }
      ],
      "relevance": 0.64013671875
    },
    "Entity-hdgi__bodypart": {
      "node_id": "hdgi__bodypart",
      "disambiguation_index": 0,
      "label": "hdgi:BodyPart",
      "aliases": [
        "single hdgi:BodyPart",
        "hdgi:BodyPart"
      ],
      "types": [
        "term",
        "ontology class",
        "ontology",
        "anatomy",
        "concept",
        "anatomical entity",
        "body part",
        "data structure",
        "ontology term",
        "ontology concept",
        "anatomical structure",
        "anatomical term",
        "entity",
        "class",
        "component"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:BodyPart refers to a class within the HDGI ontology that represents the anatomical components of the human body involved in gesture interactions with devices.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "hdgi:BodyPart",
          "local_types": [
            "ontology class",
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__bodypart-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "hdgi:BodyPart",
          "local_types": [
            "term",
            "ontology",
            "anatomy",
            "concept",
            "anatomical entity",
            "body part"
          ],
          "iri": "Entity-hdgi__bodypart-Mention-2"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "hdgi:BodyPart",
          "local_types": [
            "data structure",
            "ontology",
            "concept",
            "ontology term",
            "body part",
            "ontology concept",
            "class"
          ],
          "iri": "Entity-hdgi__bodypart-Mention-3"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-4",
          "local_name": "hdgi:BodyPart",
          "local_types": [
            "concept",
            "anatomical structure",
            "class",
            "entity"
          ],
          "iri": "Entity-hdgi__bodypart-Mention-4"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-2",
          "local_name": "hdgi:BodyPart",
          "local_types": [
            "ontology class",
            "ontology",
            "anatomical entity",
            "ontology term",
            "body part",
            "class"
          ],
          "iri": "Entity-hdgi__bodypart-Mention-5"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "hdgi:BodyPart",
          "local_types": [
            "ontology class",
            "ontology",
            "anatomical entity",
            "concept",
            "body part",
            "anatomical term",
            "entity",
            "class",
            "component"
          ],
          "iri": "Entity-hdgi__bodypart-Mention-6"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "single hdgi:BodyPart",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-hdgi__bodypart-Mention-7"
        }
      ],
      "relevance": 0.6396484375
    },
    "Entity-existing_approach": {
      "node_id": "existing_approach",
      "disambiguation_index": 0,
      "label": "existing approaches",
      "aliases": [
        "existing approaches"
      ],
      "types": [
        "research approach",
        "methodology",
        "approach"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'existing approaches' refers to the various methodologies and research strategies that have been developed to tackle the challenges associated with the widespread use of human-device gesture interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-2",
          "local_name": "existing approaches",
          "local_types": [
            "research approach",
            "methodology",
            "approach"
          ],
          "iri": "Entity-existing_approach-Mention-1"
        }
      ],
      "relevance": 0.6396484375
    },
    "Entity-movement": {
      "node_id": "movement",
      "disambiguation_index": 0,
      "label": "movements",
      "aliases": [
        "Movement",
        "movements",
        "movement"
      ],
      "types": [
        "biomechanics",
        "trend",
        "physical action",
        "concept",
        "movement",
        "action",
        "class",
        "motion"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture recognition and interaction design, 'movements' refers to the specific actions or gestures performed by the human body, particularly those involving the hands and fingers, which are crucial for effective human-device communication.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "movements",
          "local_types": [
            "motion",
            "action"
          ],
          "iri": "Entity-movement-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "movement",
          "local_types": [
            "physical action",
            "biomechanics"
          ],
          "iri": "Entity-movement-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "Movement",
          "local_types": [
            "class",
            "concept"
          ],
          "iri": "Entity-movement-Mention-3"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "movement",
          "local_types": [
            "movement"
          ],
          "iri": "Entity-movement-Mention-4"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "movements",
          "local_types": [
            "action",
            "motion"
          ],
          "iri": "Entity-movement-Mention-5"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "movement",
          "local_types": [
            "action",
            "movement",
            "motion"
          ],
          "iri": "Entity-movement-Mention-6"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-9",
          "local_name": "movements",
          "local_types": [
            "action",
            "concept",
            "movement",
            "motion"
          ],
          "iri": "Entity-movement-Mention-7"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-3",
          "local_name": "movements",
          "local_types": [
            "concept",
            "trend"
          ],
          "iri": "Entity-movement-Mention-8"
        }
      ],
      "relevance": 0.6396484375
    },
    "Entity-new_ge": {
      "node_id": "new_ge",
      "disambiguation_index": 0,
      "label": "new GES",
      "aliases": [
        "new GES"
      ],
      "types": [
        "methodology",
        "GES"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'new GES' refers to newly conducted Gesture Elicitation Studies that aim to establish specific gesture-referent mappings in the context of human-device interactions, particularly when existing gesture vocabularies are insufficient or unavailable.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-4",
          "local_name": "new GES",
          "local_types": [
            "methodology",
            "GES"
          ],
          "iri": "Entity-new_ge-Mention-1"
        }
      ],
      "relevance": 0.638671875
    },
    "Entity-call": {
      "node_id": "call",
      "disambiguation_index": 0,
      "label": "call",
      "aliases": [
        "call"
      ],
      "types": [
        "action",
        "communication",
        "interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture-controlled interfaces, 'call' refers to the action of accepting a phone call through a specific gesture, such as pointing a finger to a touchscreen in BMW's iDrive infotainment system.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "call",
          "local_types": [
            "communication",
            "action"
          ],
          "iri": "Entity-call-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-3",
          "local_name": "call",
          "local_types": [
            "communication",
            "interaction"
          ],
          "iri": "Entity-call-Mention-2"
        }
      ],
      "relevance": 0.63818359375
    },
    "Entity-section_1": {
      "node_id": "section_1",
      "disambiguation_index": 0,
      "label": "Section 1",
      "aliases": [
        "Section 1"
      ],
      "types": [
        "document section",
        "reference",
        "section"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Section 1 refers to a specific part of the paper that discusses the relationship between gestures and affordances in the context of the HDGI ontology, using the example of BMW and Mercedes-Benz to illustrate how different manufacturers may map the same gesture to different affordances.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "Section 1",
          "local_types": [
            "document section",
            "reference",
            "section"
          ],
          "iri": "Entity-section_1-Mention-1"
        }
      ],
      "relevance": 0.63720703125
    },
    "Entity-all_these_system": {
      "node_id": "all_these_system",
      "disambiguation_index": 0,
      "label": "All these systems",
      "aliases": [
        "All these systems"
      ],
      "types": [
        "system"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "All these systems refer to various interactive technologies and devices, such as Microsoft Kinect, AR/VR systems, and automotive infotainment systems, that are equipped with the ability to recognize and interpret complex human gestures for user interaction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-3",
          "local_name": "All these systems",
          "local_types": [
            "system"
          ],
          "iri": "Entity-all_these_system-Mention-1"
        }
      ],
      "relevance": 0.63720703125
    },
    "Entity-the_problem_of_hand_gesture_recognition": {
      "node_id": "the_problem_of_hand_gesture_recognition",
      "disambiguation_index": 0,
      "label": "the problem of hand gesture recognition",
      "aliases": [
        "the problem of hand gesture recognition"
      ],
      "types": [
        "problem",
        "hand gesture recognition"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The problem of hand gesture recognition refers to the challenges and complexities involved in accurately identifying and interpreting human hand gestures for the purpose of developing effective gestural interfaces in various applications.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "the problem of hand gesture recognition",
          "local_types": [
            "problem",
            "hand gesture recognition"
          ],
          "iri": "Entity-the_problem_of_hand_gesture_recognition-Mention-1"
        }
      ],
      "relevance": 0.63671875
    },
    "Entity-gesture_subclass": {
      "node_id": "gesture_subclass",
      "disambiguation_index": 0,
      "label": "gesture subclasses",
      "aliases": [
        "gesture subclasses"
      ],
      "types": [
        "classification",
        "gesture type",
        "subclass",
        "gesture",
        "category"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gesture subclasses refer to the specific categories of gestures defined within the ontology, such as HandGesture, ForearmGesture, FacialGesture, LegGesture, and UpperArmGesture, which allow for the classification and detailed modeling of different types of gestures in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-1",
          "local_name": "gesture subclasses",
          "local_types": [
            "classification",
            "gesture type",
            "subclass",
            "gesture",
            "category"
          ],
          "iri": "Entity-gesture_subclass-Mention-1"
        }
      ],
      "relevance": 0.63623046875
    },
    "Entity-designer_and_developer_(1)": {
      "node_id": "designer_and_developer_(1)",
      "disambiguation_index": 1,
      "label": "Designers and developers",
      "aliases": [
        "Designers and developers",
        "designers and developers"
      ],
      "types": [
        "professionals"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Designers and developers are professionals involved in the creation and implementation of gesture-controlled interfaces and systems, requiring them to navigate and synthesize various studies and data related to gesture interactions manually.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-4",
          "local_name": "Designers and developers",
          "local_types": [
            "professionals"
          ],
          "iri": "Entity-designer_and_developer_(1)-Mention-1"
        }
      ],
      "relevance": 0.63623046875
    },
    "Entity-figure_4": {
      "node_id": "figure_4",
      "disambiguation_index": 0,
      "label": "Figure 4",
      "aliases": [
        "Figure 4"
      ],
      "types": [
        "illustration",
        "figure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Figure 4 illustrates a proof-of-concept implementation of the HDGI ontology, showcasing the integration of predefined SPARQL endpoints with RESTful APIs for easier access to gesture data.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-2",
          "local_name": "Figure 4",
          "local_types": [
            "illustration",
            "figure"
          ],
          "iri": "Entity-figure_4-Mention-1"
        }
      ],
      "relevance": 0.6357421875
    },
    "Entity-an_arm_gesture": {
      "node_id": "an_arm_gesture",
      "disambiguation_index": 0,
      "label": "an arm gesture",
      "aliases": [
        "an arm gesture"
      ],
      "types": [
        "gesture",
        "arm"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "An arm gesture refers to a specific movement or position of the arm that is used as a form of non-verbal communication or interaction, particularly in the context of gesture-controlled interfaces and human-device interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "an arm gesture",
          "local_types": [
            "gesture",
            "arm"
          ],
          "iri": "Entity-an_arm_gesture-Mention-1"
        }
      ],
      "relevance": 0.6357421875
    },
    "Entity-data_received_from_different_manufacturers-devices": {
      "node_id": "data_received_from_different_manufacturers-devices",
      "disambiguation_index": 0,
      "label": "data received from different manufacturers-devices",
      "aliases": [
        "data received from different manufacturers-devices"
      ],
      "types": [
        "data",
        "manufacturers",
        "devices"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'data received from different manufacturers-devices' refers to the diverse sets of information and measurements generated by various gesture recognition systems and devices, which may utilize different coordinate systems and representations for modeling human gestures and poses.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-18",
          "local_name": "data received from different manufacturers-devices",
          "local_types": [
            "data",
            "manufacturers",
            "devices"
          ],
          "iri": "Entity-data_received_from_different_manufacturers-devices-Mention-1"
        }
      ],
      "relevance": 0.634765625
    },
    "Entity-human_device_interaction": {
      "node_id": "human_device_interaction",
      "disambiguation_index": 0,
      "label": "Human Device Interactions",
      "aliases": [
        "human device interactions",
        "Human Device Interactions",
        "human device interaction"
      ],
      "types": [
        "user experience",
        "interaction field",
        "communication",
        "concept",
        "research area",
        "field",
        "human-computer interaction",
        "domain",
        "interaction"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Human Device Interactions refers to the study and analysis of how humans communicate and interact with various devices, particularly in the context of user experience and human-computer interaction.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "Human Device Interactions",
          "local_types": [
            "concept",
            "domain",
            "research area",
            "interaction field",
            "field"
          ],
          "iri": "Entity-human_device_interaction-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-1",
          "local_name": "human device interactions",
          "local_types": [
            "interaction",
            "communication",
            "user experience",
            "human-computer interaction"
          ],
          "iri": "Entity-human_device_interaction-Mention-2"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "human device interactions",
          "local_types": [
            "concept",
            "human-computer interaction",
            "interaction"
          ],
          "iri": "Entity-human_device_interaction-Mention-3"
        }
      ],
      "relevance": 0.63427734375
    },
    "Entity-element_observed_from_existing_gesture_vocabulary": {
      "node_id": "element_observed_from_existing_gesture_vocabulary",
      "disambiguation_index": 0,
      "label": "elements observed from existing gesture vocabularies",
      "aliases": [
        "elements observed from existing gesture vocabularies"
      ],
      "types": [
        "elements",
        "gesture vocabulary"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'elements observed from existing gesture vocabularies' refers to the specific components or characteristics of gestures that have been identified and documented in prior research on gesture vocabularies, which are then utilized to inform the development of the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-2-Sentence-1",
          "local_name": "elements observed from existing gesture vocabularies",
          "local_types": [
            "elements",
            "gesture vocabulary"
          ],
          "iri": "Entity-element_observed_from_existing_gesture_vocabulary-Mention-1"
        }
      ],
      "relevance": 0.63427734375
    },
    "Entity-best_gesture_": {
      "node_id": "best_gesture_",
      "disambiguation_index": 0,
      "label": "'best gestures'",
      "aliases": [
        "'best gestures'"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "'Best gestures' refer to the most effective and intuitive physical movements identified in various studies that correspond to specific actions or effects in gesture-controlled interfaces, aimed at enhancing user interaction and experience.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "'best gestures'",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-best_gesture_-Mention-1"
        }
      ],
      "relevance": 0.63427734375
    },
    "Entity-the_gestural_sign": {
      "node_id": "the_gestural_sign",
      "disambiguation_index": 0,
      "label": "the gestural sign",
      "aliases": [
        "the gestural sign"
      ],
      "types": [
        "gestural sign"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The gestural sign refers to a specific physical movement or action performed by a user, which conveys interaction intentions and corresponds to a desired effect or referent in the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "the gestural sign",
          "local_types": [
            "gestural sign"
          ],
          "iri": "Entity-the_gestural_sign-Mention-1"
        }
      ],
      "relevance": 0.63427734375
    },
    "Entity-their_touchscreen": {
      "node_id": "their_touchscreen",
      "disambiguation_index": 0,
      "label": "their touchscreen",
      "aliases": [
        "their touchscreen"
      ],
      "types": [
        "touchscreen",
        "product"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their touchscreen' refers to the interactive display interface used in automotive infotainment systems, such as BMW's iDrive and Mercedes-Benz's MBUX, which allows users to control functions through touch and gesture inputs.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "their touchscreen",
          "local_types": [
            "touchscreen",
            "product"
          ],
          "iri": "Entity-their_touchscreen-Mention-1"
        }
      ],
      "relevance": 0.63330078125
    },
    "Entity-intent": {
      "node_id": "intent",
      "disambiguation_index": 0,
      "label": "intent",
      "aliases": [
        "intent"
      ],
      "types": [
        "intent",
        "goal",
        "purpose"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of Human Device Gesture Interactions, 'intent' refers to the user's underlying purpose or goal when selecting a gesture, which is influenced by their specific context and the affordances provided by the device.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-8",
          "local_name": "intent",
          "local_types": [
            "intent",
            "goal",
            "purpose"
          ],
          "iri": "Entity-intent-Mention-1"
        }
      ],
      "relevance": 0.6328125
    },
    "Entity-sequence_of_gesture": {
      "node_id": "sequence_of_gesture",
      "disambiguation_index": 0,
      "label": "sequence of gestures",
      "aliases": [
        "a sequence of gestures",
        "sequence of gestures"
      ],
      "types": [
        "gesture pattern",
        "gesture",
        "sequence",
        "action sequence",
        "gesture sequence"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A sequence of gestures refers to a structured arrangement of multiple gestures that can include various poses and movements of different body parts, allowing for the representation of complex interactions in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "sequence of gestures",
          "local_types": [
            "action sequence",
            "gesture pattern",
            "gesture sequence"
          ],
          "iri": "Entity-sequence_of_gesture-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "a sequence of gestures",
          "local_types": [
            "sequence",
            "gesture"
          ],
          "iri": "Entity-sequence_of_gesture-Mention-2"
        }
      ],
      "relevance": 0.63232421875
    },
    "Entity-interaction_intention": {
      "node_id": "interaction_intention",
      "disambiguation_index": 0,
      "label": "interaction intentions",
      "aliases": [
        "interaction intentions"
      ],
      "types": [
        "communication intent",
        "user intention",
        "intention"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Interaction intentions refer to the user's expressed desires or goals communicated through physical gestures, enabling them to convey interactive information to devices or systems in gesture-based interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "interaction intentions",
          "local_types": [
            "communication intent",
            "user intention",
            "intention"
          ],
          "iri": "Entity-interaction_intention-Mention-1"
        }
      ],
      "relevance": 0.6318359375
    },
    "Entity-all_the_class_used_in_the_ontology": {
      "node_id": "all_the_class_used_in_the_ontology",
      "disambiguation_index": 0,
      "label": "all the classes used in the ontology",
      "aliases": [
        "all the classes used in the ontology"
      ],
      "types": [
        "classes",
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'all the classes used in the ontology' refers to the specific set of classes defined within the HDGI ontology, which includes core classes such as Gesture, BodyPart, Pose, Movement, Affordance, Device, and Human, all organized under a unique namespace to facilitate independent use and integration with external ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "all the classes used in the ontology",
          "local_types": [
            "classes",
            "ontology"
          ],
          "iri": "Entity-all_the_class_used_in_the_ontology-Mention-1"
        }
      ],
      "relevance": 0.63134765625
    },
    "Entity-osumar_et_al_.": {
      "node_id": "osumar_et_al_.",
      "disambiguation_index": 0,
      "label": "Osumar et al.",
      "aliases": [
        "Osumar et al.",
        "Osumar"
      ],
      "types": [
        "author",
        "researcher"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Osumar et al. refers to a group of researchers who developed a gesture ontology utilizing a Microsoft Kinect-based skeleton to describe mid-air gestures of the human body, focusing on holistic body posture but lacking detailed representation of hand movements.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-2",
          "local_name": "Osumar et al.",
          "local_types": [
            "author",
            "researcher"
          ],
          "iri": "Entity-osumar_et_al_.-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-2",
          "local_name": "Osumar",
          "local_types": [
            "author",
            "researcher"
          ],
          "iri": "Entity-osumar_et_al_.-Mention-2"
        }
      ],
      "relevance": 0.63037109375
    },
    "Entity-the_web_application": {
      "node_id": "the_web_application",
      "disambiguation_index": 0,
      "label": "the web application",
      "aliases": [
        "the web application"
      ],
      "types": [
        "application"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The web application refers to a sample mapping service code that can be downloaded and integrated with gesture recognition software tools, facilitating the use of the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-2",
          "local_name": "the web application",
          "local_types": [
            "application"
          ],
          "iri": "Entity-the_web_application-Mention-1"
        }
      ],
      "relevance": 0.63037109375
    },
    "Entity-variety": {
      "node_id": "variety",
      "disambiguation_index": 0,
      "label": "variety",
      "aliases": [
        "variety"
      ],
      "types": [
        "concept",
        "category"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'variety' refers to the diverse range of standards and implementations of gesture-controlled interfaces that can lead to user confusion due to differing expectations and preferences.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "variety",
          "local_types": [
            "concept",
            "category"
          ],
          "iri": "Entity-variety-Mention-1"
        }
      ],
      "relevance": 0.6298828125
    },
    "Entity-modelling": {
      "node_id": "modelling",
      "disambiguation_index": 0,
      "label": "modelling",
      "aliases": [
        "modelling"
      ],
      "types": [
        "process",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'modelling' refers to the process of creating a formal representation of the classes and properties of the HDGI ontology using OWL2 and Turtle syntax to describe human gestures and their interactions with devices.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-6",
          "local_name": "modelling",
          "local_types": [
            "process",
            "representation"
          ],
          "iri": "Entity-modelling-Mention-1"
        }
      ],
      "relevance": 0.62939453125
    },
    "Entity-annotating": {
      "node_id": "annotating",
      "disambiguation_index": 0,
      "label": "annotating",
      "aliases": [
        "annotating"
      ],
      "types": [
        "methodology",
        "process",
        "research activity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'annotating' refers to the process of adding descriptive information or metadata to the gesture vocabularies within the context of ontology engineering, which is essential for integrating and documenting the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-1",
          "local_name": "annotating",
          "local_types": [
            "methodology",
            "process",
            "research activity"
          ],
          "iri": "Entity-annotating-Mention-1"
        }
      ],
      "relevance": 0.62939453125
    },
    "Entity-user__s_expectation": {
      "node_id": "user__s_expectation",
      "disambiguation_index": 0,
      "label": "user\u2019s expectations",
      "aliases": [
        "user\u2019s expectations"
      ],
      "types": [
        "expectation"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "User's expectations refer to the preconceived notions and preferences that users have regarding the intuitiveness and functionality of gesture-controlled interfaces, which can lead to confusion when the actual gestures provided by the system do not align with these expectations.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "user\u2019s expectations",
          "local_types": [
            "expectation"
          ],
          "iri": "Entity-user__s_expectation-Mention-1"
        }
      ],
      "relevance": 0.62939453125
    },
    "Entity-each_hdgi__movement": {
      "node_id": "each_hdgi__movement",
      "disambiguation_index": 0,
      "label": "Each hdgi:Movement",
      "aliases": [
        "Each hdgi:Movement"
      ],
      "types": [
        "movement"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Each hdgi:Movement refers to a specific, atomic gesture that involves a single change in position or rotation, characterized by a defined duration, and is part of a broader ontology for describing human-device interactions.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-5",
          "local_name": "Each hdgi:Movement",
          "local_types": [
            "movement"
          ],
          "iri": "Entity-each_hdgi__movement-Mention-1"
        }
      ],
      "relevance": 0.62890625
    },
    "Entity-certain_affordances": {
      "node_id": "certain_affordances",
      "disambiguation_index": 0,
      "label": "certain affordances",
      "aliases": [
        "certain affordances"
      ],
      "types": [
        "affordance"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Certain affordances refer to the specific capabilities or functionalities that gestures can provide in the context of human-device interactions, enabling users to effectively communicate and control devices through intuitive movements.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "certain affordances",
          "local_types": [
            "affordance"
          ],
          "iri": "Entity-certain_affordances-Mention-1"
        }
      ],
      "relevance": 0.62890625
    },
    "Entity-2005": {
      "node_id": "2005",
      "disambiguation_index": 0,
      "label": "2005",
      "aliases": [
        "2005"
      ],
      "types": [
        "year",
        "date"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The mention '2005' refers to the year when Wobbrock et al. introduced the concept of 'guessability of a system' in their study on user interactions with gesture-based interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "2005",
          "local_types": [
            "year",
            "date"
          ],
          "iri": "Entity-2005-Mention-1"
        }
      ],
      "relevance": 0.62841796875
    },
    "Entity-icon": {
      "node_id": "icon",
      "disambiguation_index": 0,
      "label": "icon",
      "aliases": [
        "icon"
      ],
      "types": [
        "symbol",
        "interface element"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture-based interfaces, 'icon' refers to a visual symbol or graphical representation on a touchscreen that users can interact with, such as selecting options or commands in infotainment systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "icon",
          "local_types": [
            "symbol",
            "interface element"
          ],
          "iri": "Entity-icon-Mention-1"
        }
      ],
      "relevance": 0.62841796875
    },
    "Entity-the_problem_of_the_absence_of_a_systematic_analysis_and_description_of_gesture": {
      "node_id": "the_problem_of_the_absence_of_a_systematic_analysis_and_description_of_gesture",
      "disambiguation_index": 0,
      "label": "the problem of the absence of a systematic analysis and description of gestures",
      "aliases": [
        "the problem of the absence of a systematic analysis and description of gestures"
      ],
      "types": [
        "problem"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The problem of the absence of a systematic analysis and description of gestures refers to the lack of a structured framework for understanding and categorizing gestures used in Human Device Interactions, which can lead to confusion and inefficiency in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "the problem of the absence of a systematic analysis and description of gestures",
          "local_types": [
            "problem"
          ],
          "iri": "Entity-the_problem_of_the_absence_of_a_systematic_analysis_and_description_of_gesture-Mention-1"
        }
      ],
      "relevance": 0.62841796875
    },
    "Entity-redundant_gesture_vocabulary": {
      "node_id": "redundant_gesture_vocabulary",
      "disambiguation_index": 0,
      "label": "redundant gesture vocabularies",
      "aliases": [
        "redundant gesture vocabularies"
      ],
      "types": [
        "gesture",
        "vocabulary"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Redundant gesture vocabularies refer to the existence of multiple gestures that can represent the same referent or action within gesture-controlled interfaces, leading to confusion and inefficiency in user interaction due to the lack of a standardized mapping among these gestures.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-2",
          "local_name": "redundant gesture vocabularies",
          "local_types": [
            "gesture",
            "vocabulary"
          ],
          "iri": "Entity-redundant_gesture_vocabulary-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-4",
          "local_name": "redundant gesture vocabularies",
          "local_types": [
            "gesture",
            "vocabulary"
          ],
          "iri": "Entity-redundant_gesture_vocabulary-Mention-2"
        }
      ],
      "relevance": 0.62841796875
    },
    "Entity-semantical_relationship": {
      "node_id": "semantical_relationship",
      "disambiguation_index": 0,
      "label": "semantical relationships",
      "aliases": [
        "semantical relationships"
      ],
      "types": [
        "relationship type",
        "linguistic concept",
        "relationship"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'semantical relationships' refers to the connections and mappings between gestures and their meanings or actions, which are not predefined but rather defined and formalized to enhance the understanding and interoperability of gesture vocabularies in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-4",
          "local_name": "semantical relationships",
          "local_types": [
            "relationship type",
            "linguistic concept",
            "relationship"
          ],
          "iri": "Entity-semantical_relationship-Mention-1"
        }
      ],
      "relevance": 0.6279296875
    },
    "Entity-their_own_preference": {
      "node_id": "their_own_preference",
      "disambiguation_index": 0,
      "label": "their own preferences",
      "aliases": [
        "their own preferences"
      ],
      "types": [
        "preferences"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their own preferences' refers to the individual user's established habits and choices regarding control mechanisms in gesture-controlled interfaces, which may differ from the varying standards and gestures provided by different systems.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "their own preferences",
          "local_types": [
            "preferences"
          ],
          "iri": "Entity-their_own_preference-Mention-1"
        }
      ],
      "relevance": 0.6279296875
    },
    "Entity-3d_hand_gesture_taxonomy": {
      "node_id": "3d_hand_gesture_taxonomy",
      "disambiguation_index": 0,
      "label": "3D hand gesture taxonomy",
      "aliases": [
        "3D hand gesture taxonomy",
        "3D hand gesture taxonomy and notation method"
      ],
      "types": [
        "method",
        "methodology",
        "taxonomy",
        "framework"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A 3D hand gesture taxonomy is a systematic classification framework that categorizes various hand gestures in three-dimensional space, often used in fields such as human-computer interaction and computer vision.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-5",
          "local_name": "3D hand gesture taxonomy",
          "local_types": [
            "method",
            "methodology",
            "taxonomy",
            "framework"
          ],
          "iri": "Entity-3d_hand_gesture_taxonomy-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-5",
          "local_name": "3D hand gesture taxonomy and notation method",
          "local_types": [
            "method",
            "taxonomy"
          ],
          "iri": "Entity-3d_hand_gesture_taxonomy-Mention-2"
        }
      ],
      "relevance": 0.62744140625
    },
    "Entity-upper_limb_related_gesture": {
      "node_id": "upper_limb_related_gesture",
      "disambiguation_index": 0,
      "label": "upper limb related gestures",
      "aliases": [
        "upper limb related gestures"
      ],
      "types": [
        "gesture",
        "human action"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Upper limb related gestures refer to movements and actions performed by the arms and hands that convey meaning or facilitate interaction, often used in communication or control of devices.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-1",
          "local_name": "upper limb related gestures",
          "local_types": [
            "gesture",
            "human action"
          ],
          "iri": "Entity-upper_limb_related_gesture-Mention-1"
        }
      ],
      "relevance": 0.626953125
    },
    "Entity-microsoft_kinect": {
      "node_id": "microsoft_kinect",
      "disambiguation_index": 0,
      "label": "Microsoft Kinect",
      "aliases": [
        "Microsoft Kinect"
      ],
      "types": [
        "motion sensing device",
        "product",
        "technology",
        "motion sensing",
        "hardware",
        "device",
        "system",
        "sensor",
        "motion sensing input device"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Microsoft Kinect is a motion sensing input device developed by Microsoft that enables users to interact with computers through gestures and body movements.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "Microsoft Kinect",
          "local_types": [
            "sensor",
            "product",
            "technology"
          ],
          "iri": "Entity-microsoft_kinect-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "Microsoft Kinect",
          "local_types": [
            "motion sensing device",
            "product",
            "technology",
            "motion sensing",
            "hardware",
            "device",
            "system",
            "motion sensing input device"
          ],
          "iri": "Entity-microsoft_kinect-Mention-2"
        }
      ],
      "relevance": 0.62646484375
    },
    "Entity-inter-mapping": {
      "node_id": "inter-mapping",
      "disambiguation_index": 0,
      "label": "inter-mapping",
      "aliases": [
        "inter-mapping"
      ],
      "types": [
        "process"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Inter-mapping refers to the process of linking and understanding the semantics of various gesture vocabularies to enhance interoperability among different gesture-controlled interfaces, thereby improving user experience.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-2",
          "local_name": "inter-mapping",
          "local_types": [
            "process"
          ],
          "iri": "Entity-inter-mapping-Mention-1"
        }
      ],
      "relevance": 0.62646484375
    },
    "Entity-hdgi__finger": {
      "node_id": "hdgi__finger",
      "disambiguation_index": 0,
      "label": "hdgi:Finger",
      "aliases": [
        "hdgi:Finger"
      ],
      "types": [
        "upper limb",
        "data structure",
        "anatomy",
        "anatomical structure",
        "body part",
        "ontology",
        "subclass",
        "concept",
        "model",
        "pose",
        "entity",
        "pose representation",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Finger refers to a class in the HDGI ontology that represents the anatomical structure of a human finger, serving as a fundamental component of the upper limb region in the context of gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "hdgi:Finger",
          "local_types": [
            "upper limb",
            "anatomy",
            "anatomical structure",
            "body part",
            "class"
          ],
          "iri": "Entity-hdgi__finger-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "hdgi:Finger",
          "local_types": [
            "data structure",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__finger-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-5",
          "local_name": "hdgi:Finger",
          "local_types": [
            "ontology",
            "anatomical structure",
            "body part",
            "subclass",
            "model",
            "pose",
            "pose representation",
            "class"
          ],
          "iri": "Entity-hdgi__finger-Mention-3"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-2",
          "local_name": "hdgi:Finger",
          "local_types": [
            "anatomy",
            "concept",
            "body part"
          ],
          "iri": "Entity-hdgi__finger-Mention-4"
        }
      ],
      "relevance": 0.6259765625
    },
    "Entity-the_problem_at_hand": {
      "node_id": "the_problem_at_hand",
      "disambiguation_index": 0,
      "label": "the problem at hand",
      "aliases": [
        "the problem at hand"
      ],
      "types": [
        "problem"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The problem at hand refers to the need for a systematic structure to guide designers and researchers in developing appropriate techniques for gestural interaction in the context of Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "the problem at hand",
          "local_types": [
            "problem"
          ],
          "iri": "Entity-the_problem_at_hand-Mention-1"
        }
      ],
      "relevance": 0.6259765625
    },
    "Entity-the_concept_of_guessability_of_a_system_": {
      "node_id": "the_concept_of_guessability_of_a_system_",
      "disambiguation_index": 0,
      "label": "the concept of 'guessability of a system'",
      "aliases": [
        "the concept of 'guessability of a system'"
      ],
      "types": [
        "concept"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The concept of 'guessability of a system' refers to the idea that users should be able to successfully perform gestures, commands, or interactions with a system based on their initial attempts, even if they are unfamiliar with the specific symbols or gestures required, thereby enhancing user experience and accessibility.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "the concept of 'guessability of a system'",
          "local_types": [
            "concept"
          ],
          "iri": "Entity-the_concept_of_guessability_of_a_system_-Mention-1"
        }
      ],
      "relevance": 0.62548828125
    },
    "Entity-arm": {
      "node_id": "arm",
      "disambiguation_index": 0,
      "label": "Arm",
      "aliases": [
        "Arm"
      ],
      "types": [
        "anatomical structure",
        "ontology",
        "class",
        "body part"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The 'Arm' refers to the anatomical structure of the upper limb in humans, specifically represented as the 'hdgi:UpperArm' class in the context of the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "Arm",
          "local_types": [
            "anatomical structure",
            "ontology",
            "class",
            "body part"
          ],
          "iri": "Entity-arm-Mention-1"
        }
      ],
      "relevance": 0.62451171875
    },
    "Entity-study": {
      "node_id": "study",
      "disambiguation_index": 0,
      "label": "study",
      "aliases": [
        "study",
        "studies"
      ],
      "types": [
        "academic work",
        "project",
        "research program",
        "research",
        "research work",
        "academic publication"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The study refers to the research that facilitates the collection of end users' preferences for symbolic input, marking the inception of Gesture Elicitation Studies (GES).",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-2",
          "local_name": "study",
          "local_types": [
            "research program",
            "project"
          ],
          "iri": "Entity-study-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "studies",
          "local_types": [
            "academic work",
            "research"
          ],
          "iri": "Entity-study-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-4",
          "local_name": "studies",
          "local_types": [
            "research",
            "academic work"
          ],
          "iri": "Entity-study-Mention-3"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "studies",
          "local_types": [
            "research",
            "academic work"
          ],
          "iri": "Entity-study-Mention-4"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "studies",
          "local_types": [
            "research",
            "academic work"
          ],
          "iri": "Entity-study-Mention-5"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "studies",
          "local_types": [
            "research",
            "academic work"
          ],
          "iri": "Entity-study-Mention-6"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-6",
          "local_name": "study",
          "local_types": [
            "research program",
            "project"
          ],
          "iri": "Entity-study-Mention-7"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-1",
          "local_name": "study",
          "local_types": [
            "project",
            "research program"
          ],
          "iri": "Entity-study-Mention-8"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "study",
          "local_types": [
            "research program",
            "project"
          ],
          "iri": "Entity-study-Mention-9"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-7",
          "local_name": "study",
          "local_types": [
            "research program",
            "project"
          ],
          "iri": "Entity-study-Mention-10"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-1",
          "local_name": "study",
          "local_types": [
            "project",
            "research program"
          ],
          "iri": "Entity-study-Mention-11"
        },
        {
          "reference": "Section-11-Paragraph-2-Sentence-1",
          "local_name": "studies",
          "local_types": [
            "research work",
            "academic publication"
          ],
          "iri": "Entity-study-Mention-12"
        }
      ],
      "relevance": 0.62451171875
    },
    "Entity-subject": {
      "node_id": "subject",
      "disambiguation_index": 0,
      "label": "subject",
      "aliases": [
        "subject"
      ],
      "types": [
        "entity",
        "component"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'subject' refers to the specific class or instance that is being discussed in relation to the properties and restrictions defined within the ontology, particularly in terms of how gestures are semantically modeled and related to their affordances.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "subject",
          "local_types": [
            "entity",
            "component"
          ],
          "iri": "Entity-subject-Mention-1"
        }
      ],
      "relevance": 0.62451171875
    },
    "Entity-hdgi__indexfinger": {
      "node_id": "hdgi__indexfinger",
      "disambiguation_index": 0,
      "label": "hdgi:IndexFinger",
      "aliases": [
        "hdgi:IndexFinger"
      ],
      "types": [
        "anatomical structure",
        "body part",
        "finger",
        "subclass",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:IndexFinger refers to a specific anatomical structure representing the index finger of a human, categorized under the hdgi:Finger class in the context of a gesture interaction ontology.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "hdgi:IndexFinger",
          "local_types": [
            "anatomical structure",
            "body part",
            "finger",
            "subclass",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__indexfinger-Mention-1"
        }
      ],
      "relevance": 0.6240234375
    },
    "Entity-affordance_x": {
      "node_id": "affordance_x",
      "disambiguation_index": 0,
      "label": "affordance X",
      "aliases": [
        "affordance X"
      ],
      "types": [
        "feature",
        "concept",
        "affordance",
        "capability",
        "interaction feature",
        "interaction"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Affordance X refers to a specific potential use or interaction capability that a device can provide, which is context-dependent and can be communicated through gestures, allowing for user intent to be understood and acted upon by different devices in a gesture-controlled interface.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-4",
          "local_name": "affordance X",
          "local_types": [
            "affordance",
            "concept",
            "interaction"
          ],
          "iri": "Entity-affordance_x-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-3",
          "local_name": "affordance X",
          "local_types": [
            "capability",
            "affordance",
            "interaction feature",
            "feature"
          ],
          "iri": "Entity-affordance_x-Mention-2"
        }
      ],
      "relevance": 0.6240234375
    },
    "Entity-mapping_of_other_gesture": {
      "node_id": "mapping_of_other_gesture",
      "disambiguation_index": 0,
      "label": "mapping of other gestures",
      "aliases": [
        "the mapping of other gestures",
        "mapping of other gestures"
      ],
      "types": [
        "gesture",
        "process",
        "mapping",
        "gesture recognition"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'mapping of other gestures' refers to the process of establishing semantic relationships between various gestures that convey similar meanings or functions, which is not addressed in the existing ontological frameworks discussed in the paper.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-5",
          "local_name": "mapping of other gestures",
          "local_types": [
            "process",
            "gesture recognition"
          ],
          "iri": "Entity-mapping_of_other_gesture-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-5",
          "local_name": "the mapping of other gestures",
          "local_types": [
            "gesture",
            "mapping"
          ],
          "iri": "Entity-mapping_of_other_gesture-Mention-2"
        }
      ],
      "relevance": 0.62353515625
    },
    "Entity-the_study": {
      "node_id": "the_study",
      "disambiguation_index": 0,
      "label": "the studies",
      "aliases": [
        "the studies"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The studies refer to various research efforts that investigate hand gesture recognition and its integration into gestural interface design, focusing on the relationships between gestures and their meanings beyond predefined mappings.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "the studies",
          "local_types": [
            "research"
          ],
          "iri": "Entity-the_study-Mention-1"
        }
      ],
      "relevance": 0.62353515625
    },
    "Entity-seven_main_class": {
      "node_id": "seven_main_class",
      "disambiguation_index": 0,
      "label": "seven main classes",
      "aliases": [
        "seven main classes"
      ],
      "types": [
        "class"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'seven main classes' refers to the core components of the HDGI ontology, which includes the classes hdgi:Gesture, hdgi:BodyPart, hdgi:Pose, hdgi:Movement, hdgi:Affordance, hdgi:Device, and hdgi:Human, each representing essential elements for modeling human-device interactions through gestures.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "seven main classes",
          "local_types": [
            "class"
          ],
          "iri": "Entity-seven_main_class-Mention-1"
        }
      ],
      "relevance": 0.62353515625
    },
    "Entity-relationship": {
      "node_id": "relationship",
      "disambiguation_index": 0,
      "label": "relationship",
      "aliases": [
        "relationship",
        "relationships"
      ],
      "types": [
        "connection",
        "association",
        "concept",
        "relationship"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture recognition studies, the term 'relationship' refers to the connections and associations that exist between different gestures, particularly in terms of their meanings and actions, beyond the predefined mappings typically used in gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "relationship",
          "local_types": [
            "connection",
            "association"
          ],
          "iri": "Entity-relationship-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-2",
          "local_name": "relationships",
          "local_types": [
            "connection",
            "association"
          ],
          "iri": "Entity-relationship-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "relationships",
          "local_types": [
            "connection",
            "association"
          ],
          "iri": "Entity-relationship-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-15",
          "local_name": "relationship",
          "local_types": [
            "relationship",
            "association",
            "concept"
          ],
          "iri": "Entity-relationship-Mention-4"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-2",
          "local_name": "relationship",
          "local_types": [
            "concept",
            "association"
          ],
          "iri": "Entity-relationship-Mention-5"
        }
      ],
      "relevance": 0.623046875
    },
    "Entity-related_referent": {
      "node_id": "related_referent",
      "disambiguation_index": 0,
      "label": "related referents",
      "aliases": [
        "related referents"
      ],
      "types": [
        "referent"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Related referents refer to the specific effects or desired outcomes of gestures in Human Device Interactions, which are essential for linking gestures to their meanings within a gesture ontology.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-5",
          "local_name": "related referents",
          "local_types": [
            "referent"
          ],
          "iri": "Entity-related_referent-Mention-1"
        }
      ],
      "relevance": 0.623046875
    },
    "Entity-the_device": {
      "node_id": "the_device",
      "disambiguation_index": 0,
      "label": "the device",
      "aliases": [
        "the device"
      ],
      "types": [
        "device"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The device refers to any hardware or system that can be interacted with through gestures, enabling users to perform actions based on the affordances it provides.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-4",
          "local_name": "the device",
          "local_types": [
            "device"
          ],
          "iri": "Entity-the_device-Mention-1"
        }
      ],
      "relevance": 0.6220703125
    },
    "Entity-appropriate_technique": {
      "node_id": "appropriate_technique",
      "disambiguation_index": 0,
      "label": "appropriate techniques",
      "aliases": [
        "appropriate techniques"
      ],
      "types": [
        "technique"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'appropriate techniques' refers to systematic methods and structured approaches that designers and researchers can utilize to effectively reason, compare, elicit, and create gesture vocabularies and interactions in the context of gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "appropriate techniques",
          "local_types": [
            "technique"
          ],
          "iri": "Entity-appropriate_technique-Mention-1"
        }
      ],
      "relevance": 0.62158203125
    },
    "Entity-knowledge": {
      "node_id": "knowledge",
      "disambiguation_index": 0,
      "label": "knowledge",
      "aliases": [
        "knowledge"
      ],
      "types": [
        "information",
        "data",
        "cognitive resource"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'knowledge' refers to the understanding or awareness that users possess regarding the relevant symbols and gestures necessary for interacting with gesture-based systems, which is crucial for ensuring successful initial attempts at using these interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "knowledge",
          "local_types": [
            "information",
            "data"
          ],
          "iri": "Entity-knowledge-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-2-Sentence-5",
          "local_name": "knowledge",
          "local_types": [
            "information",
            "cognitive resource"
          ],
          "iri": "Entity-knowledge-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-4",
          "local_name": "knowledge",
          "local_types": [
            "information",
            "cognitive resource"
          ],
          "iri": "Entity-knowledge-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-7",
          "local_name": "knowledge",
          "local_types": [
            "information",
            "cognitive resource"
          ],
          "iri": "Entity-knowledge-Mention-4"
        }
      ],
      "relevance": 0.62109375
    },
    "Entity-this": {
      "node_id": "this",
      "disambiguation_index": 0,
      "label": "this",
      "aliases": [
        "this"
      ],
      "types": [
        "issue"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'this' refers to the problematic nature of system designers defining gestures based on their own preferences, which can lead to confusion among users who have varying expectations for interacting with interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-2",
          "local_name": "this",
          "local_types": [
            "issue"
          ],
          "iri": "Entity-this-Mention-1"
        }
      ],
      "relevance": 0.62109375
    },
    "Entity-knowledge_of_ge": {
      "node_id": "knowledge_of_ge",
      "disambiguation_index": 0,
      "label": "knowledge of GES",
      "aliases": [
        "the knowledge of GES",
        "knowledge of GES"
      ],
      "types": [
        "knowledge",
        "GES"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'knowledge of GES' refers to the accumulated understanding and insights gained from Gesture Elicitation Studies, which explore user preferences and behaviors regarding gesture-based interactions in various systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-3",
          "local_name": "knowledge of GES",
          "local_types": [
            "knowledge",
            "GES"
          ],
          "iri": "Entity-knowledge_of_ge-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-3",
          "local_name": "the knowledge of GES",
          "local_types": [
            "knowledge",
            "GES"
          ],
          "iri": "Entity-knowledge_of_ge-Mention-2"
        }
      ],
      "relevance": 0.62060546875
    },
    "Entity-hand": {
      "node_id": "hand",
      "disambiguation_index": 0,
      "label": "hand",
      "aliases": [
        "hands",
        "hand"
      ],
      "types": [
        "anatomy",
        "body part",
        "human body part",
        "gesture",
        "anatomical part",
        "hand"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'hand' refers to the anatomical part of the human body that is used in gesture-based interactions, specifically in the context of controlling devices like the HoloLens 2 by performing gestures such as pinching fingers together.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "hand",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-hand-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "hands",
          "local_types": [
            "anatomy",
            "body part",
            "human body part",
            "anatomical part",
            "hand"
          ],
          "iri": "Entity-hand-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "hand",
          "local_types": [
            "anatomy",
            "body part"
          ],
          "iri": "Entity-hand-Mention-3"
        },
        {
          "reference": "Section-5-Paragraph-3-Sentence-2",
          "local_name": "hand",
          "local_types": [
            "body part",
            "gesture"
          ],
          "iri": "Entity-hand-Mention-4"
        }
      ],
      "relevance": 0.62060546875
    },
    "Entity-static_gesture": {
      "node_id": "static_gesture",
      "disambiguation_index": 0,
      "label": "static gesture",
      "aliases": [
        "a static gesture",
        "static gesture"
      ],
      "types": [
        "action",
        "gesture",
        "static"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A static gesture refers to a pose that involves a single body part at a specific point in time, characterized by its position and rotation in a 3D space, as defined within the HDGI ontology for Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-2-Sentence-1",
          "local_name": "static gesture",
          "local_types": [
            "gesture",
            "action"
          ],
          "iri": "Entity-static_gesture-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-1",
          "local_name": "a static gesture",
          "local_types": [
            "gesture",
            "static"
          ],
          "iri": "Entity-static_gesture-Mention-2"
        }
      ],
      "relevance": 0.62060546875
    },
    "Entity-gesture_data": {
      "node_id": "gesture_data",
      "disambiguation_index": 0,
      "label": "gesture data",
      "aliases": [
        "gesture data"
      ],
      "types": [
        "gesture information",
        "communication data",
        "data type",
        "gesture",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Gesture data refers to the information collected about physical movements or signals made by individuals, often used in the context of communication and interaction analysis.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-5",
          "local_name": "gesture data",
          "local_types": [
            "gesture information",
            "communication data",
            "data type",
            "gesture",
            "data"
          ],
          "iri": "Entity-gesture_data-Mention-1"
        }
      ],
      "relevance": 0.62060546875
    },
    "Entity-higher_accuracy": {
      "node_id": "higher_accuracy",
      "disambiguation_index": 0,
      "label": "higher accuracy",
      "aliases": [
        "higher accuracy"
      ],
      "types": [
        "accuracy"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Higher accuracy refers to the improved capability of computational systems to correctly recognize and interpret arm gestures in gesture-based interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-2",
          "local_name": "higher accuracy",
          "local_types": [
            "accuracy"
          ],
          "iri": "Entity-higher_accuracy-Mention-1"
        }
      ],
      "relevance": 0.62060546875
    },
    "Entity-face": {
      "node_id": "face",
      "disambiguation_index": 0,
      "label": "face",
      "aliases": [
        "face"
      ],
      "types": [
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture interactions, 'face' refers to the physical movements and expressions of the human face that are utilized to convey interaction intentions and communicate with devices or systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "face",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-face-Mention-1"
        }
      ],
      "relevance": 0.6201171875
    },
    "Entity-hdgi__thumbcurled": {
      "node_id": "hdgi__thumbcurled",
      "disambiguation_index": 0,
      "label": "hdgi:ThumbCurled",
      "aliases": [
        "hdgi:ThumbCurled"
      ],
      "types": [
        "body part",
        "gesture",
        "pose",
        "entity",
        "identifier"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:ThumbCurled refers to a specific pose of the thumb where it is curled, used in the context of gesture recognition and human-device interaction.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-5",
          "local_name": "hdgi:ThumbCurled",
          "local_types": [
            "body part",
            "gesture",
            "pose",
            "entity",
            "identifier"
          ],
          "iri": "Entity-hdgi__thumbcurled-Mention-1"
        }
      ],
      "relevance": 0.6201171875
    },
    "Entity-position": {
      "node_id": "position",
      "disambiguation_index": 0,
      "label": "position",
      "aliases": [
        "'position'",
        "position"
      ],
      "types": [
        "position",
        "attribute",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'position' refers to the specific spatial placement of a pose in a 3D space, which is modeled relative to a local coordinate system to ensure consistency across different gesture recognition devices.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-6",
          "local_name": "position",
          "local_types": [
            "position",
            "attribute",
            "concept"
          ],
          "iri": "Entity-position-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "position",
          "local_types": [
            "attribute"
          ],
          "iri": "Entity-position-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-4",
          "local_name": "'position'",
          "local_types": [
            "attribute"
          ],
          "iri": "Entity-position-Mention-3"
        }
      ],
      "relevance": 0.6201171875
    },
    "Entity-symbol": {
      "node_id": "symbol",
      "disambiguation_index": 0,
      "label": "symbols",
      "aliases": [
        "symbols"
      ],
      "types": [
        "representation",
        "sign"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'symbols' refer to the visual representations or signs that users must understand in order to successfully interact with gesture-based systems, particularly when they are unfamiliar with the gestures required for operation.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "symbols",
          "local_types": [
            "representation",
            "sign"
          ],
          "iri": "Entity-symbol-Mention-1"
        }
      ],
      "relevance": 0.61962890625
    },
    "Entity-a_user": {
      "node_id": "a_user",
      "disambiguation_index": 0,
      "label": "a user",
      "aliases": [
        "a user"
      ],
      "types": [
        "user"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A user refers to an individual interacting with gesture-controlled interfaces, such as the HoloLens 2, who must perform specific gestures to execute commands within the system.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "a user",
          "local_types": [
            "user"
          ],
          "iri": "Entity-a_user-Mention-1"
        }
      ],
      "relevance": 0.619140625
    },
    "Entity-meaning": {
      "node_id": "meaning",
      "disambiguation_index": 0,
      "label": "meaning",
      "aliases": [
        "meaning"
      ],
      "types": [
        "concept",
        "semantic value"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture-controlled interfaces, 'meaning' refers to the predefined semantic value or interpretation associated with specific gestures and their corresponding actions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "meaning",
          "local_types": [
            "concept",
            "semantic value"
          ],
          "iri": "Entity-meaning-Mention-1"
        }
      ],
      "relevance": 0.619140625
    },
    "Entity-hdgi__movement_class": {
      "node_id": "hdgi__movement_class",
      "disambiguation_index": 0,
      "label": "hdgi:Movement class",
      "aliases": [
        "hdgi:Movement class"
      ],
      "types": [
        "class"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The hdgi:Movement class is a component of the HDGI ontology that specifically defines dynamic gestures, characterized by a set of atomic movements related to the positions and rotations of body parts, and is designed to be extensible for custom gesture definitions.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-1",
          "local_name": "hdgi:Movement class",
          "local_types": [
            "class"
          ],
          "iri": "Entity-hdgi__movement_class-Mention-1"
        }
      ],
      "relevance": 0.619140625
    },
    "Entity-microsoft_kinect-based_skeleton": {
      "node_id": "microsoft_kinect-based_skeleton",
      "disambiguation_index": 0,
      "label": "Microsoft Kinect-based skeleton",
      "aliases": [
        "Microsoft Kinect-based skeleton"
      ],
      "types": [
        "skeleton",
        "technology"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The Microsoft Kinect-based skeleton refers to a model used in gesture recognition research that captures the holistic posture and movements of the human body, specifically designed to describe mid-air gestures for the development of gesture interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-2",
          "local_name": "Microsoft Kinect-based skeleton",
          "local_types": [
            "skeleton",
            "technology"
          ],
          "iri": "Entity-microsoft_kinect-based_skeleton-Mention-1"
        }
      ],
      "relevance": 0.61865234375
    },
    "Entity-conventional_control": {
      "node_id": "conventional_control",
      "disambiguation_index": 0,
      "label": "conventional controls",
      "aliases": [
        "conventional controls"
      ],
      "types": [
        "interaction method",
        "user interface element",
        "user experience",
        "interface element",
        "control",
        "control system",
        "user interface",
        "interface",
        "control method"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Conventional controls refer to traditional user interface elements and interaction methods that users are familiar with, which may include physical buttons, knobs, or standard touch gestures, contrasting with newer gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "conventional controls",
          "local_types": [
            "user experience",
            "interface element",
            "user interface",
            "interface",
            "control method"
          ],
          "iri": "Entity-conventional_control-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-5-Sentence-3",
          "local_name": "conventional controls",
          "local_types": [
            "interaction method",
            "user interface element",
            "control",
            "control system",
            "user interface"
          ],
          "iri": "Entity-conventional_control-Mention-2"
        }
      ],
      "relevance": 0.6181640625
    },
    "Entity-a_surge_in_their_number": {
      "node_id": "a_surge_in_their_number",
      "disambiguation_index": 0,
      "label": "a surge in their numbers",
      "aliases": [
        "a surge in their numbers"
      ],
      "types": [
        "increase"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'a surge in their numbers' refers to the increasing quantity of designers, developers, producers, and vendors who are integrating gesture interfaces into their products, leading to a greater diversity in the implementation and utilization of these interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "a surge in their numbers",
          "local_types": [
            "increase"
          ],
          "iri": "Entity-a_surge_in_their_number-Mention-1"
        }
      ],
      "relevance": 0.6181640625
    },
    "Entity-villarreal-narvaez_et_al_._s_most_recent_survey_paper": {
      "node_id": "villarreal-narvaez_et_al_._s_most_recent_survey_paper",
      "disambiguation_index": 0,
      "label": "Villarreal-Narvaez et al.'s most recent survey paper",
      "aliases": [
        "Villarreal-Narvaez et al.'s most recent survey paper"
      ],
      "types": [
        "paper",
        "survey"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Villarreal-Narvaez et al.'s most recent survey paper is a scholarly work that analyzes the prevalence of upper limb gestures, particularly hand movements, in human-device interactions, contributing to the understanding of gesture-based systems in the context of the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "Villarreal-Narvaez et al.'s most recent survey paper",
          "local_types": [
            "paper",
            "survey"
          ],
          "iri": "Entity-villarreal-narvaez_et_al_._s_most_recent_survey_paper-Mention-1"
        }
      ],
      "relevance": 0.6181640625
    },
    "Entity-the_human": {
      "node_id": "the_human",
      "disambiguation_index": 0,
      "label": "the human",
      "aliases": [
        "the human"
      ],
      "types": [
        "entity",
        "human"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'the human' refers to an individual user who interacts with devices through gestures, possessing the ability to perform actions enabled by the affordances of those devices.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-4",
          "local_name": "the human",
          "local_types": [
            "entity",
            "human"
          ],
          "iri": "Entity-the_human-Mention-1"
        }
      ],
      "relevance": 0.6181640625
    },
    "Entity-third_party_software_development_kit_and_service": {
      "node_id": "third_party_software_development_kit_and_service",
      "disambiguation_index": 0,
      "label": "third party Software Development Kits and Services",
      "aliases": [
        "third party Software Development Kits and Services"
      ],
      "types": [
        "software",
        "service"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Third party Software Development Kits and Services refer to external software tools and services that facilitate the integration and development of applications, particularly in the context of gesture recognition and interaction with the HDGI ontology through standardized APIs.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-3",
          "local_name": "third party Software Development Kits and Services",
          "local_types": [
            "software",
            "service"
          ],
          "iri": "Entity-third_party_software_development_kit_and_service-Mention-1"
        }
      ],
      "relevance": 0.61767578125
    },
    "Entity-tv_and_blind": {
      "node_id": "tv_and_blind",
      "disambiguation_index": 0,
      "label": "TV and blinds",
      "aliases": [
        "TV and blinds"
      ],
      "types": [
        "product"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention 'TV and blinds' refers to the specific devices involved in a study that explored gesture recognition commands for controlling these products within a gestural interface framework.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "TV and blinds",
          "local_types": [
            "product"
          ],
          "iri": "Entity-tv_and_blind-Mention-1"
        }
      ],
      "relevance": 0.6171875
    },
    "Entity-our_focus": {
      "node_id": "our_focus",
      "disambiguation_index": 0,
      "label": "Our focus",
      "aliases": [
        "Our focus"
      ],
      "types": [
        "research focus"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Our focus refers to the specific aim of the ontology developed in the paper, which is to describe gestures that have a direct referent to the affordances of devices, rather than modeling the vast array of concepts and relationships associated with arm-based gestures.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-2",
          "local_name": "Our focus",
          "local_types": [
            "research focus"
          ],
          "iri": "Entity-our_focus-Mention-1"
        }
      ],
      "relevance": 0.6171875
    },
    "Entity-end_hdgi__pose": {
      "node_id": "end_hdgi__pose",
      "disambiguation_index": 0,
      "label": "end hdgi:Pose",
      "aliases": [
        "end hdgi:Pose"
      ],
      "types": [
        "gesture state",
        "instance",
        "state",
        "concept",
        "pose"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "end hdgi:Pose refers to the final state or position of a gesture in the context of human-device interaction, specifically indicating the conclusion of a movement sequence as defined within the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-6",
          "local_name": "end hdgi:Pose",
          "local_types": [
            "gesture state",
            "instance",
            "state",
            "concept",
            "pose"
          ],
          "iri": "Entity-end_hdgi__pose-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "end hdgi:Pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-end_hdgi__pose-Mention-2"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-these_ge": {
      "node_id": "these_ge",
      "disambiguation_index": 0,
      "label": "these GES",
      "aliases": [
        "these GES"
      ],
      "types": [
        "GES"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "These GES refers to Gesture Elicitation Studies, which are research efforts aimed at defining and understanding user-preferred gestures for interaction with systems, resulting in a collection of knowledge about gesture vocabularies that is currently disorganized.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-5",
          "local_name": "these GES",
          "local_types": [
            "GES"
          ],
          "iri": "Entity-these_ge-Mention-1"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-undesirable_or_counter-intuitive": {
      "node_id": "undesirable_or_counter-intuitive",
      "disambiguation_index": 0,
      "label": "undesirable or counter-intuitive",
      "aliases": [
        "undesirable or counter-intuitive"
      ],
      "types": [
        "quality"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'undesirable or counter-intuitive' refers to manufacturer-defined gestures in gesture-controlled interfaces that do not align with user expectations or preferences, leading to confusion and difficulty in interaction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-5",
          "local_name": "undesirable or counter-intuitive",
          "local_types": [
            "quality"
          ],
          "iri": "Entity-undesirable_or_counter-intuitive-Mention-1"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-hdgi__localcoordinatesystem": {
      "node_id": "hdgi__localcoordinatesystem",
      "disambiguation_index": 0,
      "label": "hdgi:LocalCoordinateSystem",
      "aliases": [
        "hdgi:LocalCoordinateSystem",
        "hdgi:hasLocalCoordinateSystem"
      ],
      "types": [
        "relationship",
        "object property",
        "data structure",
        "ontology",
        "coordinate system",
        "concept",
        "ontology term",
        "property",
        "model",
        "entity",
        "mathematical structure",
        "system",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:LocalCoordinateSystem refers to a class in the HDGI ontology that defines the local coordinate system used for positioning and rotation in 3D space, ensuring consistency across different gesture recognition devices.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-15",
          "local_name": "hdgi:LocalCoordinateSystem",
          "local_types": [
            "model",
            "data structure",
            "class"
          ],
          "iri": "Entity-hdgi__localcoordinatesystem-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "hdgi:LocalCoordinateSystem",
          "local_types": [
            "system",
            "concept",
            "mathematical structure",
            "coordinate system"
          ],
          "iri": "Entity-hdgi__localcoordinatesystem-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-11",
          "local_name": "hdgi:LocalCoordinateSystem",
          "local_types": [
            "data structure",
            "ontology",
            "concept",
            "coordinate system",
            "ontology term",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__localcoordinatesystem-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-5",
          "local_name": "hdgi:LocalCoordinateSystem",
          "local_types": [
            "data structure",
            "ontology",
            "concept",
            "coordinate system",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__localcoordinatesystem-Mention-4"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-11",
          "local_name": "hdgi:hasLocalCoordinateSystem",
          "local_types": [
            "object property",
            "relationship",
            "property"
          ],
          "iri": "Entity-hdgi__localcoordinatesystem-Mention-5"
        }
      ],
      "relevance": 0.6162109375
    },
    "Entity-vendor": {
      "node_id": "vendor",
      "disambiguation_index": 0,
      "label": "vendors",
      "aliases": [
        "vendors"
      ],
      "types": [
        "business",
        "supplier",
        "role",
        "organisation",
        "individual",
        "profession"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Vendors refer to businesses or organizations that produce and integrate gesture interfaces into their products for use in various applications, contributing to the diversity of standards in gesture-controlled systems.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "vendors",
          "local_types": [
            "individual",
            "role",
            "profession",
            "organisation"
          ],
          "iri": "Entity-vendor-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "vendors",
          "local_types": [
            "role",
            "profession",
            "organisation"
          ],
          "iri": "Entity-vendor-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-3",
          "local_name": "vendors",
          "local_types": [
            "business",
            "supplier"
          ],
          "iri": "Entity-vendor-Mention-3"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "vendors",
          "local_types": [
            "organisation",
            "business"
          ],
          "iri": "Entity-vendor-Mention-4"
        }
      ],
      "relevance": 0.6162109375
    },
    "Entity-mid-air_gesture_of_the_human_body": {
      "node_id": "mid-air_gesture_of_the_human_body",
      "disambiguation_index": 0,
      "label": "mid-air gestures of the human body",
      "aliases": [
        "mid-air gestures of the human body"
      ],
      "types": [
        "gesture",
        "human body"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'mid-air gestures of the human body' refers to the movements and postures of the human body, particularly the arms and hands, that are performed in the air without physical contact with any surface, and are often utilized in gesture recognition systems for human-device interaction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-2",
          "local_name": "mid-air gestures of the human body",
          "local_types": [
            "gesture",
            "human body"
          ],
          "iri": "Entity-mid-air_gesture_of_the_human_body-Mention-1"
        }
      ],
      "relevance": 0.6162109375
    },
    "Entity-a_how-to__documentation": {
      "node_id": "a_how-to__documentation",
      "disambiguation_index": 0,
      "label": "A 'how-to' documentation",
      "aliases": [
        "A 'how-to' documentation"
      ],
      "types": [
        "documentation"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A 'how-to' documentation refers to a guide that provides step-by-step instructions and information on how to use, integrate, or customize the HDGI web application and its associated APIs for gesture recognition software.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-4",
          "local_name": "A 'how-to' documentation",
          "local_types": [
            "documentation"
          ],
          "iri": "Entity-a_how-to__documentation-Mention-1"
        }
      ],
      "relevance": 0.6162109375
    },
    "Entity-different_vendor": {
      "node_id": "different_vendor",
      "disambiguation_index": 0,
      "label": "different vendors",
      "aliases": [
        "different vendors"
      ],
      "types": [
        "vendor"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Different vendors refer to various manufacturers and developers who create and implement gesture-controlled interfaces and systems, each with their own unique gesture vocabularies and interaction designs.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-3",
          "local_name": "different vendors",
          "local_types": [
            "vendor"
          ],
          "iri": "Entity-different_vendor-Mention-1"
        }
      ],
      "relevance": 0.61572265625
    },
    "Entity-leap-motion_sdk": {
      "node_id": "leap-motion_sdk",
      "disambiguation_index": 0,
      "label": "leap-motion SDK",
      "aliases": [
        "leap-motion SDK"
      ],
      "types": [
        "development kit",
        "SDK",
        "gesture recognition system",
        "technology",
        "tool",
        "software",
        "development tool",
        "software development kit"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The leap-motion SDK is a software development kit designed for creating applications that utilize gesture recognition technology, enabling interaction through hand movements.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-14",
          "local_name": "leap-motion SDK",
          "local_types": [
            "development kit",
            "SDK",
            "gesture recognition system",
            "technology",
            "tool",
            "software",
            "development tool",
            "software development kit"
          ],
          "iri": "Entity-leap-motion_sdk-Mention-1"
        }
      ],
      "relevance": 0.6142578125
    },
    "Entity-size_or_speed_of_hand_gesture": {
      "node_id": "size_or_speed_of_hand_gesture",
      "disambiguation_index": 0,
      "label": "size or speed of hand gestures",
      "aliases": [
        "size or speed of hand gestures",
        "the size or speed of hand gestures"
      ],
      "types": [
        "attributes",
        "characteristics",
        "gesture",
        "measurement"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'size or speed of hand gestures' refers to the physical attributes of hand movements, specifically their dimensions and the rate at which they are executed, which are important factors in the design and recognition of gesture-based interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-11",
          "local_name": "size or speed of hand gestures",
          "local_types": [
            "attributes",
            "characteristics",
            "gesture"
          ],
          "iri": "Entity-size_or_speed_of_hand_gesture-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-11",
          "local_name": "the size or speed of hand gestures",
          "local_types": [
            "measurement",
            "gesture"
          ],
          "iri": "Entity-size_or_speed_of_hand_gesture-Mention-2"
        }
      ],
      "relevance": 0.6142578125
    },
    "Entity-model": {
      "node_id": "model",
      "disambiguation_index": 0,
      "label": "model",
      "aliases": [
        "model"
      ],
      "types": [
        "machine learning model",
        "data representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'model' refers to a flexible machine learning model designed to represent and accommodate various data representations of poses and gestures in Human Device Interactions, allowing for compatibility with different gesture recognition devices.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-18",
          "local_name": "model",
          "local_types": [
            "machine learning model",
            "data representation"
          ],
          "iri": "Entity-model-Mention-1"
        }
      ],
      "relevance": 0.6142578125
    },
    "Entity-knowledge_of_the_arm_gesture": {
      "node_id": "knowledge_of_the_arm_gesture",
      "disambiguation_index": 0,
      "label": "knowledge of the arm gestures",
      "aliases": [
        "knowledge of the arm gestures"
      ],
      "types": [
        "gesture",
        "knowledge",
        "arm"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Knowledge of the arm gestures refers to the understanding and recognition of specific movements and postures of the arms that convey meaning or commands in gestural interfaces, aimed at enhancing the accuracy of gesture recognition systems.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-2",
          "local_name": "knowledge of the arm gestures",
          "local_types": [
            "gesture",
            "knowledge",
            "arm"
          ],
          "iri": "Entity-knowledge_of_the_arm_gesture-Mention-1"
        }
      ],
      "relevance": 0.6142578125
    },
    "Entity-finger": {
      "node_id": "finger",
      "disambiguation_index": 0,
      "label": "fingers",
      "aliases": [
        "finger",
        "fingers"
      ],
      "types": [
        "anatomical structure",
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'fingers' refers to the anatomical structures of the human hand, specifically the digits that can be categorized into left and right entities, and are essential for gesture-based interactions in the context of Human Device Interaction.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "fingers",
          "local_types": [
            "body part",
            "anatomical structure"
          ],
          "iri": "Entity-finger-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-9",
          "local_name": "finger",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-finger-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-5",
          "local_name": "finger",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-finger-Mention-3"
        }
      ],
      "relevance": 0.61376953125
    },
    "Entity-necessary_affordances": {
      "node_id": "necessary_affordances",
      "disambiguation_index": 0,
      "label": "necessary affordances",
      "aliases": [
        "necessary affordances"
      ],
      "types": [
        "affordance"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Necessary affordances refer to the essential properties or features of devices that enable specific gestures to be effectively utilized for interaction, allowing for a flexible and extensible mapping of gestures within the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "necessary affordances",
          "local_types": [
            "affordance"
          ],
          "iri": "Entity-necessary_affordances-Mention-1"
        }
      ],
      "relevance": 0.61376953125
    },
    "Entity-an_extensible_way": {
      "node_id": "an_extensible_way",
      "disambiguation_index": 0,
      "label": "an extensible way",
      "aliases": [
        "an extensible way"
      ],
      "types": [
        "methodology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention 'an extensible way' refers to the capability of the developed ontology to semantically describe human gestures and their mappings to affordances and user/device contexts, allowing for future enhancements and adaptations.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-3",
          "local_name": "an extensible way",
          "local_types": [
            "methodology"
          ],
          "iri": "Entity-an_extensible_way-Mention-1"
        }
      ],
      "relevance": 0.61328125
    },
    "Entity-modeling": {
      "node_id": "modeling",
      "disambiguation_index": 0,
      "label": "modeling",
      "aliases": [
        "modeling"
      ],
      "types": [
        "methodology",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'modeling' in this context refers to the process of creating a structured representation of the relationships between the hdgi:LocalCoordinateSystem and hdgi:Position classes within the HDGI ontology, facilitating the accurate depiction of spatial data for gesture recognition.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-15",
          "local_name": "modeling",
          "local_types": [
            "methodology",
            "process"
          ],
          "iri": "Entity-modeling-Mention-1"
        }
      ],
      "relevance": 0.61328125
    },
    "Entity-mid-air_gesture": {
      "node_id": "mid-air_gesture",
      "disambiguation_index": 0,
      "label": "mid-air gestures",
      "aliases": [
        "mid-air gestures"
      ],
      "types": [
        "interaction method",
        "interaction technique",
        "input",
        "gesture",
        "human action",
        "human-computer interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Mid-air gestures are movements made by a person's hands or body in the air, typically used as a form of input or interaction in human-computer interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "mid-air gestures",
          "local_types": [
            "input",
            "gesture",
            "interaction method",
            "interaction technique"
          ],
          "iri": "Entity-mid-air_gesture-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-2",
          "local_name": "mid-air gestures",
          "local_types": [
            "gesture",
            "human action",
            "human-computer interaction"
          ],
          "iri": "Entity-mid-air_gesture-Mention-2"
        }
      ],
      "relevance": 0.61279296875
    },
    "Entity-human_upper_limb_region_gesture": {
      "node_id": "human_upper_limb_region_gesture",
      "disambiguation_index": 0,
      "label": "human upper limb region gestures",
      "aliases": [
        "human upper limb region gestures"
      ],
      "types": [
        "gesture",
        "human movement",
        "human action"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Human upper limb region gestures refer to the various movements and postures made by the arms and hands of a human, often used for communication, expression, or interaction with the environment.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-2",
          "local_name": "human upper limb region gestures",
          "local_types": [
            "gesture",
            "human movement",
            "human action"
          ],
          "iri": "Entity-human_upper_limb_region_gesture-Mention-1"
        }
      ],
      "relevance": 0.61279296875
    },
    "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device": {
      "node_id": "gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "disambiguation_index": 0,
      "label": "gestures that do not carry a referent to a particular affordance of a device",
      "aliases": [
        "gestures that do not carry a referent to a particular affordance of a device"
      ],
      "types": [
        "gesture",
        "affordance"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gestures that do not carry a referent to a particular affordance of a device refer to hand movements or actions that lack a specific meaning or function related to the operation or interaction with a device, and are therefore excluded from the ontology developed in the paper.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-3",
          "local_name": "gestures that do not carry a referent to a particular affordance of a device",
          "local_types": [
            "gesture",
            "affordance"
          ],
          "iri": "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device-Mention-1"
        }
      ],
      "relevance": 0.6123046875
    },
    "Entity-a_large_number_of_study": {
      "node_id": "a_large_number_of_study",
      "disambiguation_index": 0,
      "label": "A large number of studies",
      "aliases": [
        "A large number of studies"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A large number of studies refers to the extensive body of research focused on hand gesture recognition and its application in the design and development of gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "A large number of studies",
          "local_types": [
            "research"
          ],
          "iri": "Entity-a_large_number_of_study-Mention-1"
        }
      ],
      "relevance": 0.6123046875
    },
    "Entity-new_pose": {
      "node_id": "new_pose",
      "disambiguation_index": 0,
      "label": "new poses",
      "aliases": [
        "new poses"
      ],
      "types": [
        "pose",
        "movement"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "New poses refer to additional configurations or arrangements of body parts that can be represented within the framework of the Human Device Gesture Interaction ontology, allowing for the extension and representation of gestures in future applications.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "new poses",
          "local_types": [
            "pose",
            "movement"
          ],
          "iri": "Entity-new_pose-Mention-1"
        }
      ],
      "relevance": 0.6123046875
    },
    "Entity-movement_recognition": {
      "node_id": "movement_recognition",
      "disambiguation_index": 0,
      "label": "movement recognition",
      "aliases": [
        "movement recognition"
      ],
      "types": [
        "technology",
        "recognition technology",
        "application"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Movement recognition refers to the technology and methods used to detect and interpret human movements and gestures, often utilizing sensors and algorithms for applications in various fields such as gaming, healthcare, and human-computer interaction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "movement recognition",
          "local_types": [
            "technology",
            "recognition technology",
            "application"
          ],
          "iri": "Entity-movement_recognition-Mention-1"
        }
      ],
      "relevance": 0.61181640625
    },
    "Entity-interconnected_knowledge_base": {
      "node_id": "interconnected_knowledge_base",
      "disambiguation_index": 0,
      "label": "interconnected knowledge base",
      "aliases": [
        "interconnected knowledge base",
        "an interconnected knowledge base"
      ],
      "types": [
        "knowledge base"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The interconnected knowledge base refers to a system that enables the automatic identification of gesture semantics and affordance mappings by integrating multiple gesture recognition systems, allowing for flexible and context-aware interactions rather than relying on fixed, predefined mappings.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "interconnected knowledge base",
          "local_types": [
            "knowledge base"
          ],
          "iri": "Entity-interconnected_knowledge_base-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "an interconnected knowledge base",
          "local_types": [
            "knowledge base"
          ],
          "iri": "Entity-interconnected_knowledge_base-Mention-2"
        }
      ],
      "relevance": 0.61181640625
    },
    "Entity-the_icon": {
      "node_id": "the_icon",
      "disambiguation_index": 0,
      "label": "the icon",
      "aliases": [
        "the icon"
      ],
      "types": [
        "icon"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The icon refers to a visual symbol or graphical representation that users can interact with in gesture-based interfaces, such as those found in augmented reality systems like Microsoft HoloLens.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-3",
          "local_name": "the icon",
          "local_types": [
            "icon"
          ],
          "iri": "Entity-the_icon-Mention-1"
        }
      ],
      "relevance": 0.61181640625
    },
    "Entity-relationship_between_each_gesture": {
      "node_id": "relationship_between_each_gesture",
      "disambiguation_index": 0,
      "label": "relationship between each gesture",
      "aliases": [
        "relationship between each gesture",
        "the relationship between each gesture"
      ],
      "types": [
        "relationship",
        "gesture"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'relationship between each gesture' refers to the systematic analysis and formalization of how different gestures are interconnected in terms of their meanings and actions within gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "relationship between each gesture",
          "local_types": [
            "relationship",
            "gesture"
          ],
          "iri": "Entity-relationship_between_each_gesture-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "the relationship between each gesture",
          "local_types": [
            "relationship",
            "gesture"
          ],
          "iri": "Entity-relationship_between_each_gesture-Mention-2"
        }
      ],
      "relevance": 0.611328125
    },
    "Entity-corresponding_affordances": {
      "node_id": "corresponding_affordances",
      "disambiguation_index": 0,
      "label": "corresponding affordances",
      "aliases": [
        "corresponding affordances"
      ],
      "types": [
        "affordance"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Corresponding affordances refer to the specific functionalities or actions that can be performed by a device in response to particular gestures, as defined within the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-1-Sentence-1",
          "local_name": "corresponding affordances",
          "local_types": [
            "affordance"
          ],
          "iri": "Entity-corresponding_affordances-Mention-1"
        }
      ],
      "relevance": 0.611328125
    },
    "Entity-the_proposed_taxonomy_and_notation_method": {
      "node_id": "the_proposed_taxonomy_and_notation_method",
      "disambiguation_index": 0,
      "label": "the proposed taxonomy and notation method",
      "aliases": [
        "the proposed taxonomy and notation method"
      ],
      "types": [
        "taxonomy",
        "method"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The proposed taxonomy and notation method refers to a systematic framework developed to categorize and represent hand gestures used in gestural interfaces, aimed at enhancing usability and interoperability among various gesture vocabularies.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-9",
          "local_name": "the proposed taxonomy and notation method",
          "local_types": [
            "taxonomy",
            "method"
          ],
          "iri": "Entity-the_proposed_taxonomy_and_notation_method-Mention-1"
        }
      ],
      "relevance": 0.61083984375
    },
    "Entity-hdgi__actuatableaffordance": {
      "node_id": "hdgi__actuatableaffordance",
      "disambiguation_index": 0,
      "label": "hdgi:ActuatableAffordance",
      "aliases": [
        "hdgi:ActuatableAffordance"
      ],
      "types": [
        "actuatable affordance",
        "ontology class",
        "ontology",
        "concept",
        "ontology term",
        "affordance",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:ActuatableAffordance refers to a subclass of sosa:ActuatableProperty within the HDGI ontology, representing affordances that can be activated or manipulated through user gestures in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-12",
          "local_name": "hdgi:ActuatableAffordance",
          "local_types": [
            "actuatable affordance",
            "ontology class",
            "ontology",
            "concept",
            "ontology term",
            "affordance",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__actuatableaffordance-Mention-1"
        }
      ],
      "relevance": 0.6103515625
    },
    "Entity-modelling_the_infinite_set_of_concept__feature__attribute__and_relationship": {
      "node_id": "modelling_the_infinite_set_of_concept__feature__attribute__and_relationship",
      "disambiguation_index": 0,
      "label": "modelling the infinite set of concepts, features, attributes, and relationships",
      "aliases": [
        "modelling the infinite set of concepts, features, attributes, and relationships"
      ],
      "types": [
        "modelling",
        "concepts",
        "features",
        "attributes",
        "relationships"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'modelling the infinite set of concepts, features, attributes, and relationships' refers to the comprehensive and systematic representation of the diverse and potentially limitless characteristics and interconnections associated with arm-based gestures in the context of gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-2",
          "local_name": "modelling the infinite set of concepts, features, attributes, and relationships",
          "local_types": [
            "modelling",
            "concepts",
            "features",
            "attributes",
            "relationships"
          ],
          "iri": "Entity-modelling_the_infinite_set_of_concept__feature__attribute__and_relationship-Mention-1"
        }
      ],
      "relevance": 0.6103515625
    },
    "Entity-riener_et_al_.": {
      "node_id": "riener_et_al_.",
      "disambiguation_index": 0,
      "label": "Riener et al.",
      "aliases": [
        "Riener et al."
      ],
      "types": [
        "author",
        "researcher"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Riener et al. refers to a group of researchers who have analyzed the design and evaluation processes of gesture-based systems, highlighting the issues arising from designers defining gestures based on personal preferences and the impact this has on user experience.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-1",
          "local_name": "Riener et al.",
          "local_types": [
            "author",
            "researcher"
          ],
          "iri": "Entity-riener_et_al_.-Mention-1"
        }
      ],
      "relevance": 0.60986328125
    },
    "Entity-approach": {
      "node_id": "approach",
      "disambiguation_index": 0,
      "label": "approach",
      "aliases": [
        "approach"
      ],
      "types": [
        "methodology",
        "strategy"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'approach' refers to the methodology employed by researchers to define and formalize the relationships between hand gestures in the context of gesture recognition and interaction design.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-11",
          "local_name": "approach",
          "local_types": [
            "methodology",
            "strategy"
          ],
          "iri": "Entity-approach-Mention-1"
        }
      ],
      "relevance": 0.60986328125
    },
    "Entity-gesture_elicitation_study": {
      "node_id": "gesture_elicitation_study",
      "disambiguation_index": 0,
      "label": "Gesture Elicitation Studies",
      "aliases": [
        "Gesture Elicitation Studies",
        "gesture elicitation studies"
      ],
      "types": [
        "research study",
        "experimental study",
        "study type",
        "gesture elicitation",
        "study",
        "methodology",
        "research",
        "research methodology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Gesture Elicitation Studies refer to research methodologies designed to systematically collect and analyze gestures made by individuals in response to specific stimuli or tasks, often to understand preferences or behaviors related to symbolic input.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-2",
          "local_name": "Gesture Elicitation Studies",
          "local_types": [
            "study",
            "methodology",
            "study type",
            "research methodology"
          ],
          "iri": "Entity-gesture_elicitation_study-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-4-Sentence-3",
          "local_name": "gesture elicitation studies",
          "local_types": [
            "research study",
            "experimental study",
            "gesture elicitation",
            "study",
            "methodology",
            "research"
          ],
          "iri": "Entity-gesture_elicitation_study-Mention-2"
        }
      ],
      "relevance": 0.609375
    },
    "Entity-finger_pose": {
      "node_id": "finger_pose",
      "disambiguation_index": 0,
      "label": "finger pose",
      "aliases": [
        "finger pose or movements",
        "finger pose"
      ],
      "types": [
        "hand movement",
        "body movement",
        "gesture",
        "finger"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'finger pose' refers to specific configurations or movements of the fingers that are significant in the context of gesture recognition and human-device interaction, which are often overlooked in broader gesture ontologies.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "finger pose",
          "local_types": [
            "hand movement",
            "body movement",
            "gesture"
          ],
          "iri": "Entity-finger_pose-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "finger pose or movements",
          "local_types": [
            "gesture",
            "finger"
          ],
          "iri": "Entity-finger_pose-Mention-2"
        }
      ],
      "relevance": 0.609375
    },
    "Entity-computational_system": {
      "node_id": "computational_system",
      "disambiguation_index": 0,
      "label": "computational systems",
      "aliases": [
        "computational systems"
      ],
      "types": [
        "technology",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Computational systems refer to advanced technological frameworks designed to process and analyze data, enabling the recognition and interpretation of gestural information, particularly in the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-1",
          "local_name": "computational systems",
          "local_types": [
            "technology",
            "system"
          ],
          "iri": "Entity-computational_system-Mention-1"
        }
      ],
      "relevance": 0.609375
    },
    "Entity-mapping_service": {
      "node_id": "mapping_service",
      "disambiguation_index": 0,
      "label": "mapping service",
      "aliases": [
        "mapping service"
      ],
      "types": [
        "service",
        "web application",
        "software tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mapping service refers to a web application that provides downloadable code for integrating gesture recognition software tools with the HDGI ontology, facilitating access to gesture vocabularies and their mappings.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-2",
          "local_name": "mapping service",
          "local_types": [
            "service",
            "web application",
            "software tool"
          ],
          "iri": "Entity-mapping_service-Mention-1"
        }
      ],
      "relevance": 0.609375
    },
    "Entity-designer_and_researcher": {
      "node_id": "designer_and_researcher",
      "disambiguation_index": 0,
      "label": "designers and researchers",
      "aliases": [
        "designers and researchers"
      ],
      "types": [
        "professionals",
        "researcher",
        "designer"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Designers and researchers refer to professionals involved in the creation and study of gestural interaction systems, who require structured frameworks to develop and analyze gesture vocabularies and techniques for effective human-device communication.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "designers and researchers",
          "local_types": [
            "professionals",
            "researcher",
            "designer"
          ],
          "iri": "Entity-designer_and_researcher-Mention-1"
        }
      ],
      "relevance": 0.609375
    },
    "Entity-systematic_structure": {
      "node_id": "systematic_structure",
      "disambiguation_index": 0,
      "label": "systematic structure",
      "aliases": [
        "systematic structure"
      ],
      "types": [
        "structure"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'systematic structure' refers to an organized framework or taxonomy that aids designers and researchers in understanding, comparing, and developing gestural interaction techniques within the context of Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "systematic structure",
          "local_types": [
            "structure"
          ],
          "iri": "Entity-systematic_structure-Mention-1"
        }
      ],
      "relevance": 0.609375
    },
    "Entity-the_right_palm": {
      "node_id": "the_right_palm",
      "disambiguation_index": 0,
      "label": "the right palm",
      "aliases": [
        "the right palm"
      ],
      "types": [
        "body part",
        "palm"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The right palm refers to the inner surface of the right hand, specifically the area that is used in gesture recognition and interaction within the context of Human Device Interactions (HDI) as described in the ontology for modeling poses and gestures.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "the right palm",
          "local_types": [
            "body part",
            "palm"
          ],
          "iri": "Entity-the_right_palm-Mention-1"
        }
      ],
      "relevance": 0.609375
    },
    "Entity-many_researcher": {
      "node_id": "many_researcher",
      "disambiguation_index": 0,
      "label": "many researchers",
      "aliases": [
        "many researchers"
      ],
      "types": [
        "researcher"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'many researchers' refers to a collective group of academic and industry professionals who have engaged in the study and definition of various gesture vocabularies for human-device interactions, particularly in the context of gesture-controlled systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-3",
          "local_name": "many researchers",
          "local_types": [
            "researcher"
          ],
          "iri": "Entity-many_researcher-Mention-1"
        }
      ],
      "relevance": 0.60888671875
    },
    "Entity-this_notation": {
      "node_id": "this_notation",
      "disambiguation_index": 0,
      "label": "this notation",
      "aliases": [
        "this notation"
      ],
      "types": [
        "notation"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This notation refers to a method of representing hand gestures using numeric terminology, which is intended to organize gestures for usability in gesture-based interfaces but is criticized for being difficult to read without a strict reference guide.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-10",
          "local_name": "this notation",
          "local_types": [
            "notation"
          ],
          "iri": "Entity-this_notation-Mention-1"
        }
      ],
      "relevance": 0.60888671875
    },
    "Entity-scoditti_et_al_.": {
      "node_id": "scoditti_et_al_.",
      "disambiguation_index": 0,
      "label": "Scoditti et al.",
      "aliases": [
        "Scoditti",
        "Scoditti et al."
      ],
      "types": [
        "author",
        "researchers",
        "researcher",
        "citation",
        "authors"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Scoditti et al. refers to a group of researchers who proposed a gestural interaction taxonomy aimed at providing a systematic structure for designers and researchers to effectively reason, compare, elicit, and create appropriate techniques for gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "Scoditti et al.",
          "local_types": [
            "author",
            "researchers",
            "researcher",
            "authors"
          ],
          "iri": "Entity-scoditti_et_al_.-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-7",
          "local_name": "Scoditti et al.",
          "local_types": [
            "author",
            "researcher",
            "citation"
          ],
          "iri": "Entity-scoditti_et_al_.-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "Scoditti",
          "local_types": [
            "author",
            "researcher"
          ],
          "iri": "Entity-scoditti_et_al_.-Mention-3"
        }
      ],
      "relevance": 0.6083984375
    },
    "Entity-existing_research": {
      "node_id": "existing_research",
      "disambiguation_index": 0,
      "label": "existing research",
      "aliases": [
        "existing research"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Existing research refers to the body of studies and scholarly work that has explored the use of ontologies in gesture recognition and interaction design, highlighting various approaches and limitations in defining and formalizing gesture vocabularies and their semantic relationships.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-1",
          "local_name": "existing research",
          "local_types": [
            "research"
          ],
          "iri": "Entity-existing_research-Mention-1"
        }
      ],
      "relevance": 0.60791015625
    },
    "Entity-figure_2": {
      "node_id": "figure_2",
      "disambiguation_index": 0,
      "label": "Figure 2",
      "aliases": [
        "Figure 2"
      ],
      "types": [
        "reference",
        "visual representation",
        "figure"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Figure 2 illustrates the 'right hand swipe left' dynamic gesture, showcasing some of the atomic gestures involved in its execution as part of the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-1",
          "local_name": "Figure 2",
          "local_types": [
            "reference",
            "visual representation",
            "figure"
          ],
          "iri": "Entity-figure_2-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "Figure 2",
          "local_types": [
            "reference",
            "visual representation",
            "figure"
          ],
          "iri": "Entity-figure_2-Mention-2"
        }
      ],
      "relevance": 0.607421875
    },
    "Entity-their_ontology": {
      "node_id": "their_ontology",
      "disambiguation_index": 0,
      "label": "Their ontology",
      "aliases": [
        "Their ontology"
      ],
      "types": [
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Their ontology refers to a framework that models the holistic posture of the human body in gesture recognition, but lacks detailed representation of finger poses and hand movements.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "Their ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-their_ontology-Mention-1"
        }
      ],
      "relevance": 0.60693359375
    },
    "Entity-human_gesture": {
      "node_id": "human_gesture",
      "disambiguation_index": 0,
      "label": "human gesture",
      "aliases": [
        "human gestures",
        "a human gesture",
        "human gesture"
      ],
      "types": [
        "physical movement",
        "gesture",
        "human behavior",
        "action",
        "communication method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A human gesture is a physical movement made by a person that conveys meaning or communicates information, often used in social interactions.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-3",
          "local_name": "human gesture",
          "local_types": [
            "action",
            "gesture",
            "physical movement",
            "communication method"
          ],
          "iri": "Entity-human_gesture-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "human gestures",
          "local_types": [
            "gesture",
            "human behavior"
          ],
          "iri": "Entity-human_gesture-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-2-Sentence-3",
          "local_name": "a human gesture",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-human_gesture-Mention-3"
        }
      ],
      "relevance": 0.6064453125
    },
    "Entity-hdgi__palm": {
      "node_id": "hdgi__palm",
      "disambiguation_index": 0,
      "label": "hdgi:Palm",
      "aliases": [
        "hdgi:Palm"
      ],
      "types": [
        "upper limb",
        "ontology",
        "anatomy",
        "anatomical structure",
        "body part",
        "concept",
        "subclass",
        "model",
        "pose",
        "pose representation",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Palm refers to the anatomical structure of the palm of the hand, which is defined as one of the basic building blocks of the upper limb region in the context of gesture modeling within the Human Device Gesture Interaction Ontology.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "hdgi:Palm",
          "local_types": [
            "upper limb",
            "anatomy",
            "anatomical structure",
            "body part",
            "class"
          ],
          "iri": "Entity-hdgi__palm-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-5",
          "local_name": "hdgi:Palm",
          "local_types": [
            "ontology",
            "anatomical structure",
            "body part",
            "subclass",
            "model",
            "pose",
            "pose representation",
            "class"
          ],
          "iri": "Entity-hdgi__palm-Mention-2"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-2",
          "local_name": "hdgi:Palm",
          "local_types": [
            "anatomy",
            "concept",
            "body part"
          ],
          "iri": "Entity-hdgi__palm-Mention-3"
        }
      ],
      "relevance": 0.60595703125
    },
    "Entity-start_hdgi__pose": {
      "node_id": "start_hdgi__pose",
      "disambiguation_index": 0,
      "label": "start hdgi:Pose",
      "aliases": [
        "start hdgi:Pose"
      ],
      "types": [
        "gesture state",
        "instance",
        "state",
        "concept",
        "pose"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The entity 'start hdgi:Pose' refers to the initial state or position of a gesture in the context of human-device interaction, marking the beginning of a specific pose before any movement occurs.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-6",
          "local_name": "start hdgi:Pose",
          "local_types": [
            "gesture state",
            "instance",
            "state",
            "concept",
            "pose"
          ],
          "iri": "Entity-start_hdgi__pose-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "start hdgi:Pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-start_hdgi__pose-Mention-2"
        }
      ],
      "relevance": 0.60595703125
    },
    "Entity-several_sensor": {
      "node_id": "several_sensor",
      "disambiguation_index": 0,
      "label": "several sensors",
      "aliases": [
        "several sensors"
      ],
      "types": [
        "sensor"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Several sensors refer to devices like Microsoft Kinect that enable posture and movement recognition, facilitating the capture and definition of mid-air gestures for use in various applications.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "several sensors",
          "local_types": [
            "sensor"
          ],
          "iri": "Entity-several_sensor-Mention-1"
        }
      ],
      "relevance": 0.60595703125
    },
    "Entity-idrive": {
      "node_id": "idrive",
      "disambiguation_index": 0,
      "label": "iDrive",
      "aliases": [
        "iDrive",
        "iDrive infotainment system"
      ],
      "types": [
        "infotainment system",
        "product",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "iDrive is BMW's infotainment system that allows users to interact with the vehicle's features through a touchscreen interface, utilizing gestures such as pointing to accept calls.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "iDrive",
          "local_types": [
            "infotainment system",
            "product"
          ],
          "iri": "Entity-idrive-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "iDrive infotainment system",
          "local_types": [
            "infotainment system",
            "technology"
          ],
          "iri": "Entity-idrive-Mention-2"
        }
      ],
      "relevance": 0.60546875
    },
    "Entity-technique": {
      "node_id": "technique",
      "disambiguation_index": 0,
      "label": "techniques",
      "aliases": [
        "techniques"
      ],
      "types": [
        "method",
        "approach"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'techniques' refers to the appropriate methods and approaches for designing and implementing gestural interactions, as outlined in the gestural interaction taxonomy proposed by Scoditti et al.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "techniques",
          "local_types": [
            "method",
            "approach"
          ],
          "iri": "Entity-technique-Mention-1"
        }
      ],
      "relevance": 0.60546875
    },
    "Entity-leap_motion": {
      "node_id": "leap_motion",
      "disambiguation_index": 0,
      "label": "Leap Motion",
      "aliases": [
        "Leap Motion"
      ],
      "types": [
        "device",
        "product",
        "hardware",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Leap Motion is a technology company known for its motion-sensing hardware that enables users to interact with digital devices through hand gestures.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-4",
          "local_name": "Leap Motion",
          "local_types": [
            "device",
            "product",
            "hardware",
            "technology"
          ],
          "iri": "Entity-leap_motion-Mention-1"
        }
      ],
      "relevance": 0.60498046875
    },
    "Entity-multiple_movement_and_pose_of_body_part": {
      "node_id": "multiple_movement_and_pose_of_body_part",
      "disambiguation_index": 0,
      "label": "multiple movements and poses of body parts",
      "aliases": [
        "multiple movements and poses of body parts"
      ],
      "types": [
        "movement",
        "pose",
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'multiple movements and poses of body parts' refers to the complex gestures in human-device interactions that consist of various dynamic movements and static poses involving different body parts, which can be sequenced or occur concurrently as defined in the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "multiple movements and poses of body parts",
          "local_types": [
            "movement",
            "pose",
            "body part"
          ],
          "iri": "Entity-multiple_movement_and_pose_of_body_part-Mention-1"
        }
      ],
      "relevance": 0.60498046875
    },
    "Entity-figure_3_-_point_c": {
      "node_id": "figure_3_-_point_c",
      "disambiguation_index": 0,
      "label": "Figure 3 - point C",
      "aliases": [
        "Figure 3 - point C"
      ],
      "types": [
        "figure",
        "reference"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Figure 3 - point C refers to the specific position of the palm and fingers in relation to the wrist within the context of the HDGI ontology for modeling human gestures.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-9",
          "local_name": "Figure 3 - point C",
          "local_types": [
            "figure",
            "reference"
          ],
          "iri": "Entity-figure_3_-_point_c-Mention-1"
        }
      ],
      "relevance": 0.6044921875
    },
    "Entity-bodypart": {
      "node_id": "bodypart",
      "disambiguation_index": 0,
      "label": "BodyPart",
      "aliases": [
        "BodyPart"
      ],
      "types": [
        "anatomical entity",
        "concept",
        "anatomy",
        "anatomical structure",
        "class",
        "physical entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "BodyPart refers to a class in the HDGI ontology that represents the anatomical structures of the human body involved in gesture interactions with devices.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "BodyPart",
          "local_types": [
            "class",
            "concept"
          ],
          "iri": "Entity-bodypart-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-2",
          "local_name": "BodyPart",
          "local_types": [
            "anatomy",
            "anatomical structure",
            "anatomical entity",
            "class",
            "physical entity"
          ],
          "iri": "Entity-bodypart-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "BodyPart",
          "local_types": [
            "class",
            "anatomical entity"
          ],
          "iri": "Entity-bodypart-Mention-3"
        }
      ],
      "relevance": 0.60400390625
    },
    "Entity-relative_position": {
      "node_id": "relative_position",
      "disambiguation_index": 0,
      "label": "relative positions",
      "aliases": [
        "relative positions"
      ],
      "types": [
        "spatial relation",
        "position",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'relative positions' refers to the spatial relationships of body parts in a gesture, defined in the HDGI ontology, where the positions of limbs are described in relation to specific joints to ensure consistency across different gesture recognition devices.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-6",
          "local_name": "relative positions",
          "local_types": [
            "spatial relation",
            "position",
            "concept"
          ],
          "iri": "Entity-relative_position-Mention-1"
        }
      ],
      "relevance": 0.60400390625
    },
    "Entity-similar_referent": {
      "node_id": "similar_referent",
      "disambiguation_index": 0,
      "label": "similar referents",
      "aliases": [
        "similar referents"
      ],
      "types": [
        "referent",
        "reference",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'similar referents' refers to gestures that have comparable meanings or functions in the context of human-device interactions, which are not adequately mapped in existing ontological frameworks.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-5",
          "local_name": "similar referents",
          "local_types": [
            "referent",
            "reference",
            "concept"
          ],
          "iri": "Entity-similar_referent-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-3",
          "local_name": "similar referents",
          "local_types": [
            "referent"
          ],
          "iri": "Entity-similar_referent-Mention-2"
        }
      ],
      "relevance": 0.603515625
    },
    "Entity-a_set_of_conventional_control": {
      "node_id": "a_set_of_conventional_control",
      "disambiguation_index": 0,
      "label": "a set of conventional controls",
      "aliases": [
        "a set of conventional controls"
      ],
      "types": [
        "controls",
        "conventional controls"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A set of conventional controls refers to the established and familiar user interface elements and interactions that users are accustomed to, which can include physical buttons, switches, and standard gesture commands that provide intuitive and predictable ways to operate devices.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "a set of conventional controls",
          "local_types": [
            "controls",
            "conventional controls"
          ],
          "iri": "Entity-a_set_of_conventional_control-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-5-Sentence-3",
          "local_name": "a set of conventional controls",
          "local_types": [
            "controls",
            "conventional controls"
          ],
          "iri": "Entity-a_set_of_conventional_control-Mention-2"
        }
      ],
      "relevance": 0.603515625
    },
    "Entity-small-scale_user_study": {
      "node_id": "small-scale_user_study",
      "disambiguation_index": 0,
      "label": "small-scale user studies",
      "aliases": [
        "small-scale user studies"
      ],
      "types": [
        "study",
        "user study"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Small-scale user studies refer to research evaluations conducted by system designers to assess and refine gesture interactions based on user preferences and experiences, often involving a limited number of participants to gather insights on the effectiveness and intuitiveness of defined gestures.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-1",
          "local_name": "small-scale user studies",
          "local_types": [
            "study",
            "user study"
          ],
          "iri": "Entity-small-scale_user_study-Mention-1"
        }
      ],
      "relevance": 0.603515625
    },
    "Entity-physical_movement": {
      "node_id": "physical_movement",
      "disambiguation_index": 0,
      "label": "physical movements",
      "aliases": [
        "physical movements"
      ],
      "types": [
        "action",
        "movement"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Physical movements refer to the actions performed by the face, limbs, or body that enable users to convey their interaction intentions and communicate interactive information to devices or systems in gesture-based interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "physical movements",
          "local_types": [
            "action",
            "movement"
          ],
          "iri": "Entity-physical_movement-Mention-1"
        }
      ],
      "relevance": 0.60302734375
    },
    "Entity-hdgi__involves": {
      "node_id": "hdgi__involves",
      "disambiguation_index": 0,
      "label": "hdgi:involves",
      "aliases": [
        "hdgi:involves"
      ],
      "types": [
        "action"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'hdgi:involves' refers to the requirement that a Pose must include one specific BodyPart at a given moment in time within the context of the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-2",
          "local_name": "hdgi:involves",
          "local_types": [
            "action"
          ],
          "iri": "Entity-hdgi__involves-Mention-1"
        }
      ],
      "relevance": 0.60302734375
    },
    "Entity-designer__producer__and_vendor": {
      "node_id": "designer__producer__and_vendor",
      "disambiguation_index": 0,
      "label": "Designers, producers, and vendors",
      "aliases": [
        "Designers, producers, and vendors",
        "designers, developers, producers, and vendors"
      ],
      "types": [
        "stakeholders",
        "professionals"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Designers, producers, and vendors refer to the stakeholders involved in the creation and distribution of products that incorporate gesture-controlled interfaces within the Internet of Things ecosystem.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "Designers, producers, and vendors",
          "local_types": [
            "stakeholders",
            "professionals"
          ],
          "iri": "Entity-designer__producer__and_vendor-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "designers, developers, producers, and vendors",
          "local_types": [
            "professionals",
            "stakeholders"
          ],
          "iri": "Entity-designer__producer__and_vendor-Mention-2"
        }
      ],
      "relevance": 0.6025390625
    },
    "Entity-hdgi__localcoordinatesystem_class": {
      "node_id": "hdgi__localcoordinatesystem_class",
      "disambiguation_index": 0,
      "label": "hdgi:LocalCoordinateSystem class",
      "aliases": [
        "hdgi:LocalCoordinateSystem class"
      ],
      "types": [
        "class"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The hdgi:LocalCoordinateSystem class represents a model for defining the local coordinate system used to describe the position and orientation of gestures in a 3D space, ensuring compatibility across different gesture recognition devices and their respective coordinate conventions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-15",
          "local_name": "hdgi:LocalCoordinateSystem class",
          "local_types": [
            "class"
          ],
          "iri": "Entity-hdgi__localcoordinatesystem_class-Mention-1"
        }
      ],
      "relevance": 0.6025390625
    },
    "Entity-posture_or_movement_recognition": {
      "node_id": "posture_or_movement_recognition",
      "disambiguation_index": 0,
      "label": "posture or movement recognition",
      "aliases": [
        "posture or movement recognition"
      ],
      "types": [
        "technology",
        "recognition"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Posture or movement recognition refers to the technological capability of detecting and interpreting physical movements of the human body, particularly through sensors like Microsoft Kinect, enabling the capture of gestures for interaction with various applications.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "posture or movement recognition",
          "local_types": [
            "technology",
            "recognition"
          ],
          "iri": "Entity-posture_or_movement_recognition-Mention-1"
        }
      ],
      "relevance": 0.60205078125
    },
    "Entity-their_meaning_and_action": {
      "node_id": "their_meaning_and_action",
      "disambiguation_index": 0,
      "label": "their meaning and actions",
      "aliases": [
        "their meaning and actions"
      ],
      "types": [
        "meaning",
        "action"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their meaning and actions' refers to the predefined semantic interpretations and corresponding physical movements associated with specific gestures used in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "their meaning and actions",
          "local_types": [
            "meaning",
            "action"
          ],
          "iri": "Entity-their_meaning_and_action-Mention-1"
        }
      ],
      "relevance": 0.60205078125
    },
    "Entity-facial_gesture": {
      "node_id": "facial_gesture",
      "disambiguation_index": 0,
      "label": "facial gestures",
      "aliases": [
        "facial gestures"
      ],
      "types": [
        "gesture type",
        "non-verbal communication",
        "facial gesture",
        "gesture",
        "human behavior",
        "facial expression",
        "action"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Facial gestures are non-verbal movements of the face that convey emotions, intentions, or reactions, often used in communication to enhance or complement verbal messages.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-1",
          "local_name": "facial gestures",
          "local_types": [
            "gesture type",
            "non-verbal communication",
            "facial gesture",
            "gesture",
            "human behavior",
            "facial expression",
            "action"
          ],
          "iri": "Entity-facial_gesture-Mention-1"
        }
      ],
      "relevance": 0.6015625
    },
    "Entity-body": {
      "node_id": "body",
      "disambiguation_index": 0,
      "label": "body",
      "aliases": [
        "body"
      ],
      "types": [
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture interactions, 'body' refers to the physical movements of the human body that are utilized to express interaction intentions and communicate with devices or systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "body",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-body-Mention-1"
        }
      ],
      "relevance": 0.6015625
    },
    "Entity-each_different_system": {
      "node_id": "each_different_system",
      "disambiguation_index": 0,
      "label": "each different system",
      "aliases": [
        "each different system"
      ],
      "types": [
        "system"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'each different system' refers to the various interactive systems that utilize gesture-based controls, where users are required to learn specific gestures unique to each system for effective interaction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-4",
          "local_name": "each different system",
          "local_types": [
            "system"
          ],
          "iri": "Entity-each_different_system-Mention-1"
        }
      ],
      "relevance": 0.6015625
    },
    "Entity-listing_1.3": {
      "node_id": "listing_1.3",
      "disambiguation_index": 0,
      "label": "Listing 1.3",
      "aliases": [
        "Listing 1.3"
      ],
      "types": [
        "listing",
        "example"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Listing 1.3 provides a detailed explanation of the mappings for hdgi:Position and hdgi:hasLocalCoordinateSystem within the HDGI ontology, specifying the relationships and constraints related to the spatial positioning and coordinate systems used in gesture modeling.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-4",
          "local_name": "Listing 1.3",
          "local_types": [
            "listing",
            "example"
          ],
          "iri": "Entity-listing_1.3-Mention-1"
        }
      ],
      "relevance": 0.6015625
    },
    "Entity-problem_of_ubiquitousness": {
      "node_id": "problem_of_ubiquitousness",
      "disambiguation_index": 0,
      "label": "problem of ubiquitousness",
      "aliases": [
        "problem of ubiquitousness"
      ],
      "types": [
        "issue",
        "challenge"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'problem of ubiquitousness' refers to the challenge of achieving consistency and interoperability in human-device gesture interactions across various systems and platforms, which is complicated by the diverse and often conflicting gesture vocabularies defined by different manufacturers.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-2",
          "local_name": "problem of ubiquitousness",
          "local_types": [
            "issue",
            "challenge"
          ],
          "iri": "Entity-problem_of_ubiquitousness-Mention-1"
        }
      ],
      "relevance": 0.60107421875
    },
    "Entity-zposition": {
      "node_id": "zposition",
      "disambiguation_index": 0,
      "label": "zPosition",
      "aliases": [
        "hdgi:zPosition",
        "zPosition"
      ],
      "types": [
        "spatial attribute",
        "attribute",
        "coordinate",
        "spatial coordinate",
        "concept",
        "data attribute",
        "spatial position",
        "position"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "zPosition refers to a spatial attribute within the hdgi:Position class that indicates the position value along the z-axis in a defined local coordinate system for modeling gestures in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-10",
          "local_name": "zPosition",
          "local_types": [
            "position",
            "spatial attribute",
            "attribute",
            "coordinate"
          ],
          "iri": "Entity-zposition-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-5",
          "local_name": "zPosition",
          "local_types": [
            "coordinate",
            "spatial attribute"
          ],
          "iri": "Entity-zposition-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-5",
          "local_name": "hdgi:zPosition",
          "local_types": [
            "attribute",
            "coordinate",
            "spatial coordinate",
            "concept",
            "data attribute",
            "spatial position",
            "position"
          ],
          "iri": "Entity-zposition-Mention-3"
        }
      ],
      "relevance": 0.60107421875
    },
    "Entity-hdgi__hasrotation": {
      "node_id": "hdgi__hasrotation",
      "disambiguation_index": 0,
      "label": "hdgi:hasRotation",
      "aliases": [
        "hdgi:hasRotation"
      ],
      "types": [
        "relationship",
        "ontology",
        "mapping",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:hasRotation is a property in the HDGI ontology that defines the relationship between a pose and its rotational representation in a 3D space, allowing for the modeling of gestures using either Euler angles or quaternions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-5",
          "local_name": "hdgi:hasRotation",
          "local_types": [
            "relationship",
            "ontology",
            "mapping",
            "property"
          ],
          "iri": "Entity-hdgi__hasrotation-Mention-1"
        }
      ],
      "relevance": 0.6005859375
    },
    "Entity-problem": {
      "node_id": "problem",
      "disambiguation_index": 0,
      "label": "problem",
      "aliases": [
        "The problem",
        "problem"
      ],
      "types": [
        "challenge",
        "issue"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The problem refers to the challenge of mapping existing and diverse gesture vocabularies to their corresponding actions or referents in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-3",
          "local_name": "problem",
          "local_types": [
            "issue",
            "challenge"
          ],
          "iri": "Entity-problem-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "problem",
          "local_types": [
            "issue",
            "challenge"
          ],
          "iri": "Entity-problem-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-3",
          "local_name": "The problem",
          "local_types": [
            "issue"
          ],
          "iri": "Entity-problem-Mention-3"
        }
      ],
      "relevance": 0.60009765625
    },
    "Entity-attempt": {
      "node_id": "attempt",
      "disambiguation_index": 0,
      "label": "attempts",
      "aliases": [
        "attempts"
      ],
      "types": [
        "efforts",
        "research activities"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'attempts' refers to the various research efforts and studies conducted by different authors to define, formalize, and improve gesture recognition and interaction in gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-1",
          "local_name": "attempts",
          "local_types": [
            "efforts",
            "research activities"
          ],
          "iri": "Entity-attempt-Mention-1"
        }
      ],
      "relevance": 0.60009765625
    },
    "Entity-alignment": {
      "node_id": "alignment",
      "disambiguation_index": 0,
      "label": "alignments",
      "aliases": [
        "alignments"
      ],
      "types": [
        "data mapping",
        "relationship"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'alignments' refers to the mappings and connections established between the HDGI ontology and external ontologies, which are provided as separate ontology files on GitHub to facilitate interoperability and integration.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-9",
          "local_name": "alignments",
          "local_types": [
            "data mapping",
            "relationship"
          ],
          "iri": "Entity-alignment-Mention-1"
        }
      ],
      "relevance": 0.60009765625
    },
    "Entity-integration": {
      "node_id": "integration",
      "disambiguation_index": 0,
      "label": "integration",
      "aliases": [
        "integration"
      ],
      "types": [
        "methodology",
        "process",
        "engineering activity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'integration' refers to the process of incorporating the HDGI ontology and its associated documentation into the broader framework of ontology engineering, ensuring that it can effectively interact with other systems and services.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-1",
          "local_name": "integration",
          "local_types": [
            "methodology",
            "process",
            "engineering activity"
          ],
          "iri": "Entity-integration-Mention-1"
        }
      ],
      "relevance": 0.60009765625
    },
    "Entity-human-computer_interaction__hci_": {
      "node_id": "human-computer_interaction__hci_",
      "disambiguation_index": 0,
      "label": "Human-Computer Interaction (HCI)",
      "aliases": [
        "Human-Computer Interaction (HCI)"
      ],
      "types": [
        "interaction design",
        "discipline",
        "field of study",
        "interaction",
        "HCI",
        "field"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Human-Computer Interaction (HCI) is a multidisciplinary field that studies the design and use of computer technology, focusing particularly on the interfaces between people (users) and computers.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-2",
          "local_name": "Human-Computer Interaction (HCI)",
          "local_types": [
            "interaction design",
            "discipline",
            "field of study",
            "interaction",
            "HCI",
            "field"
          ],
          "iri": "Entity-human-computer_interaction__hci_-Mention-1"
        }
      ],
      "relevance": 0.599609375
    },
    "Entity-system-wide_consistent_language": {
      "node_id": "system-wide_consistent_language",
      "disambiguation_index": 0,
      "label": "system-wide consistent languages",
      "aliases": [
        "system-wide consistent languages"
      ],
      "types": [
        "language",
        "communication system"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "System-wide consistent languages refer to standardized definitions and frameworks for gestures that facilitate interoperability and clarity in gestural communication across various devices and applications.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-3",
          "local_name": "system-wide consistent languages",
          "local_types": [
            "language",
            "communication system"
          ],
          "iri": "Entity-system-wide_consistent_language-Mention-1"
        }
      ],
      "relevance": 0.599609375
    },
    "Entity-point_c": {
      "node_id": "point_c",
      "disambiguation_index": 0,
      "label": "point C",
      "aliases": [
        "point C"
      ],
      "types": [
        "reference point"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "point C refers to the position of the palm and fingers in relation to the wrist within the context of the HDGI ontology for gesture modeling.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-9",
          "local_name": "point C",
          "local_types": [
            "reference point"
          ],
          "iri": "Entity-point_c-Mention-1"
        }
      ],
      "relevance": 0.599609375
    },
    "Entity-they": {
      "node_id": "they",
      "disambiguation_index": 0,
      "label": "they",
      "aliases": [
        "they"
      ],
      "types": [
        "group"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "They refers to system designers who define gestures based on their own preferences and evaluate them in small-scale user studies.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-2",
          "local_name": "they",
          "local_types": [
            "group"
          ],
          "iri": "Entity-they-Mention-1"
        }
      ],
      "relevance": 0.59912109375
    },
    "Entity-use_and_extensibility": {
      "node_id": "use_and_extensibility",
      "disambiguation_index": 0,
      "label": "use and extensibility",
      "aliases": [
        "use and extensibility"
      ],
      "types": [
        "concept"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'use and extensibility' refers to the capability of an ontology to be utilized effectively and to allow for the addition of new gestures or concepts, thereby enhancing its applicability and adaptability in the context of gesture recognition and interaction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-4",
          "local_name": "use and extensibility",
          "local_types": [
            "concept"
          ],
          "iri": "Entity-use_and_extensibility-Mention-1"
        }
      ],
      "relevance": 0.5986328125
    },
    "Entity-gestural_information": {
      "node_id": "gestural_information",
      "disambiguation_index": 0,
      "label": "gestural information",
      "aliases": [
        "gestural information"
      ],
      "types": [
        "gesture",
        "information",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Gestural information refers to the non-verbal cues and signals conveyed through body movements, particularly gestures, that can be interpreted as meaningful data in communication.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-1",
          "local_name": "gestural information",
          "local_types": [
            "gesture",
            "information",
            "data type"
          ],
          "iri": "Entity-gestural_information-Mention-1"
        }
      ],
      "relevance": 0.59814453125
    },
    "Entity-choi_et_al_.": {
      "node_id": "choi_et_al_.",
      "disambiguation_index": 0,
      "label": "Choi et al.",
      "aliases": [
        "Choi",
        "Choi et al."
      ],
      "types": [
        "author",
        "researchers",
        "authors",
        "researcher"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Choi et al. refers to a group of researchers who developed a 3D hand gesture taxonomy and notation method aimed at organizing hand gestures to enhance the usability of gesture-based interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-5",
          "local_name": "Choi et al.",
          "local_types": [
            "author",
            "researchers",
            "researcher",
            "authors"
          ],
          "iri": "Entity-choi_et_al_.-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-5",
          "local_name": "Choi",
          "local_types": [
            "author",
            "researcher"
          ],
          "iri": "Entity-choi_et_al_.-Mention-2"
        }
      ],
      "relevance": 0.59765625
    },
    "Entity-hdgi__duration": {
      "node_id": "hdgi__duration",
      "disambiguation_index": 0,
      "label": "hdgi:Duration",
      "aliases": [
        "hdgi:Duration"
      ],
      "types": [
        "attribute",
        "concept",
        "duration",
        "measurement",
        "entity",
        "time measurement"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:Duration refers to a specific time measurement associated with a single atomic movement in the context of gesture-controlled interfaces, defined as the difference in timestamps between the start and end poses of that movement.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-5",
          "local_name": "hdgi:Duration",
          "local_types": [
            "attribute",
            "concept",
            "duration",
            "measurement",
            "entity",
            "time measurement"
          ],
          "iri": "Entity-hdgi__duration-Mention-1"
        }
      ],
      "relevance": 0.59765625
    },
    "Entity-developer": {
      "node_id": "developer",
      "disambiguation_index": 0,
      "label": "developers",
      "aliases": [
        "developers"
      ],
      "types": [
        "roles",
        "professionals",
        "user group",
        "user",
        "stakeholder",
        "software engineer",
        "technical role",
        "role",
        "software engineers",
        "entity",
        "industry",
        "individual",
        "profession"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Developers are professionals who create and implement software applications, particularly in the context of integrating gesture recognition technologies into various interactive systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "developers",
          "local_types": [
            "profession",
            "role"
          ],
          "iri": "Entity-developer-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "developers",
          "local_types": [
            "role",
            "profession"
          ],
          "iri": "Entity-developer-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-4",
          "local_name": "developers",
          "local_types": [
            "roles",
            "professionals",
            "role",
            "profession"
          ],
          "iri": "Entity-developer-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "developers",
          "local_types": [
            "technical role",
            "profession",
            "stakeholder"
          ],
          "iri": "Entity-developer-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "developers",
          "local_types": [
            "profession",
            "professionals",
            "software engineers",
            "stakeholder"
          ],
          "iri": "Entity-developer-Mention-5"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "developers",
          "local_types": [
            "role",
            "industry",
            "entity",
            "profession"
          ],
          "iri": "Entity-developer-Mention-6"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-3",
          "local_name": "developers",
          "local_types": [
            "role",
            "profession"
          ],
          "iri": "Entity-developer-Mention-7"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "developers",
          "local_types": [
            "user group",
            "user",
            "profession"
          ],
          "iri": "Entity-developer-Mention-8"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-3",
          "local_name": "developers",
          "local_types": [
            "individual",
            "role",
            "profession"
          ],
          "iri": "Entity-developer-Mention-9"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "developers",
          "local_types": [
            "stakeholder",
            "software engineer",
            "role",
            "industry",
            "profession"
          ],
          "iri": "Entity-developer-Mention-10"
        }
      ],
      "relevance": 0.59716796875
    },
    "Entity-modern_automobile": {
      "node_id": "modern_automobile",
      "disambiguation_index": 0,
      "label": "modern automobiles",
      "aliases": [
        "modern automobiles"
      ],
      "types": [
        "automobile",
        "product"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Modern automobiles refer to contemporary vehicles equipped with advanced technologies, including gesture-controlled interfaces, that enhance user interaction and accessibility in driving and infotainment systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "modern automobiles",
          "local_types": [
            "automobile",
            "product"
          ],
          "iri": "Entity-modern_automobile-Mention-1"
        }
      ],
      "relevance": 0.5966796875
    },
    "Entity-particular_set_of_user": {
      "node_id": "particular_set_of_user",
      "disambiguation_index": 0,
      "label": "particular sets of users",
      "aliases": [
        "particular sets of users"
      ],
      "types": [
        "user group",
        "user",
        "users"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'particular sets of users' refers to distinct groups of individuals who have unique preferences and expectations regarding gesture interactions with devices, allowing for the customization and personalization of gesture controls to enhance user experience.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-3",
          "local_name": "particular sets of users",
          "local_types": [
            "user group",
            "user",
            "users"
          ],
          "iri": "Entity-particular_set_of_user-Mention-1"
        }
      ],
      "relevance": 0.5966796875
    },
    "Entity-the_alignment_of_the_ontology": {
      "node_id": "the_alignment_of_the_ontology",
      "disambiguation_index": 0,
      "label": "the alignment of the ontology",
      "aliases": [
        "the alignment of the ontology"
      ],
      "types": [
        "alignment",
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The alignment of the ontology refers to the process of ensuring that the HDGI ontology can effectively integrate and correspond with other external ontologies, particularly through the use of compatible structures such as guarded local restrictions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-8",
          "local_name": "the alignment of the ontology",
          "local_types": [
            "alignment",
            "ontology"
          ],
          "iri": "Entity-the_alignment_of_the_ontology-Mention-1"
        }
      ],
      "relevance": 0.5966796875
    },
    "Entity-notation_method": {
      "node_id": "notation_method",
      "disambiguation_index": 0,
      "label": "notation method",
      "aliases": [
        "notation method"
      ],
      "types": [
        "method",
        "technique",
        "methodology",
        "system",
        "representation technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'notation method' refers to a systematic approach developed by Choi et al. for categorizing and representing 3D hand gestures, aimed at enhancing the usability of gesture-based interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-5",
          "local_name": "notation method",
          "local_types": [
            "method",
            "methodology",
            "technique",
            "system"
          ],
          "iri": "Entity-notation_method-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-9",
          "local_name": "notation method",
          "local_types": [
            "representation technique",
            "methodology"
          ],
          "iri": "Entity-notation_method-Mention-2"
        }
      ],
      "relevance": 0.59619140625
    },
    "Entity-user__s_initial_attempt": {
      "node_id": "user__s_initial_attempt",
      "disambiguation_index": 0,
      "label": "user\u2019s initial attempts",
      "aliases": [
        "user\u2019s initial attempts"
      ],
      "types": [
        "user behavior",
        "user action"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'user\u2019s initial attempts' refers to the first efforts made by users to interact with a system through gestures, commands, or interface elements, which should ideally lead to successful outcomes even when users are unfamiliar with the specific symbols or gestures required.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "user\u2019s initial attempts",
          "local_types": [
            "user behavior",
            "user action"
          ],
          "iri": "Entity-user__s_initial_attempt-Mention-1"
        }
      ],
      "relevance": 0.59619140625
    },
    "Entity-the_result_of_this_study": {
      "node_id": "the_result_of_this_study",
      "disambiguation_index": 0,
      "label": "the results of this study",
      "aliases": [
        "the results of this study"
      ],
      "types": [
        "results",
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The results of this study refer to the findings that provide a guideline for organizing hand gestures to improve the usability of gesture-based interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-6",
          "local_name": "the results of this study",
          "local_types": [
            "results",
            "research"
          ],
          "iri": "Entity-the_result_of_this_study-Mention-1"
        }
      ],
      "relevance": 0.59619140625
    },
    "Entity-context_dependent_action_or_manipulation_possibility": {
      "node_id": "context_dependent_action_or_manipulation_possibility",
      "disambiguation_index": 0,
      "label": "context dependent action or manipulation possibilities",
      "aliases": [
        "context dependent action or manipulation possibilities"
      ],
      "types": [
        "manipulation",
        "action",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'context dependent action or manipulation possibilities' refers to the potential uses of a device that vary based on the specific circumstances and perspectives of the user, highlighting the importance of understanding both user and device contexts in Human Device Gesture Interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-6",
          "local_name": "context dependent action or manipulation possibilities",
          "local_types": [
            "manipulation",
            "action",
            "concept"
          ],
          "iri": "Entity-context_dependent_action_or_manipulation_possibility-Mention-1"
        }
      ],
      "relevance": 0.595703125
    },
    "Entity-effect_of_a_gesture": {
      "node_id": "effect_of_a_gesture",
      "disambiguation_index": 0,
      "label": "effect of a gesture",
      "aliases": [
        "effect of a gesture",
        "the effect of a gesture"
      ],
      "types": [
        "outcome",
        "gesture",
        "result",
        "effect"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'effect of a gesture' refers to the intended outcome or desired action that a specific gestural sign is meant to convey in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "effect of a gesture",
          "local_types": [
            "outcome",
            "result"
          ],
          "iri": "Entity-effect_of_a_gesture-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "the effect of a gesture",
          "local_types": [
            "gesture",
            "effect"
          ],
          "iri": "Entity-effect_of_a_gesture-Mention-2"
        }
      ],
      "relevance": 0.59521484375
    },
    "Entity-data": {
      "node_id": "data",
      "disambiguation_index": 0,
      "label": "data",
      "aliases": [
        "data"
      ],
      "types": [
        "resource",
        "knowledge",
        "information",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'data' refers to the necessary information and knowledge that designers and developers need to manually gather from individual studies related to gesture interactions and their semantics.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-4",
          "local_name": "data",
          "local_types": [
            "information",
            "knowledge"
          ],
          "iri": "Entity-data-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "data",
          "local_types": [
            "resource",
            "information",
            "data"
          ],
          "iri": "Entity-data-Mention-2"
        }
      ],
      "relevance": 0.5947265625
    },
    "Entity-device_affordances": {
      "node_id": "device_affordances",
      "disambiguation_index": 0,
      "label": "device affordances",
      "aliases": [
        "device affordances"
      ],
      "types": [
        "interaction design",
        "concept",
        "interaction capability",
        "interaction property",
        "affordance",
        "device",
        "device feature",
        "interaction feature"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Device affordances refer to the inherent properties and features of a device that enable specific interactions and functionalities for users.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-1",
          "local_name": "device affordances",
          "local_types": [
            "interaction capability",
            "interaction property",
            "affordance",
            "device",
            "device feature"
          ],
          "iri": "Entity-device_affordances-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "device affordances",
          "local_types": [
            "interaction design",
            "affordance",
            "concept"
          ],
          "iri": "Entity-device_affordances-Mention-2"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-3",
          "local_name": "device affordances",
          "local_types": [
            "interaction design",
            "affordance",
            "concept",
            "interaction feature"
          ],
          "iri": "Entity-device_affordances-Mention-3"
        }
      ],
      "relevance": 0.5947265625
    },
    "Entity-the_human_body": {
      "node_id": "the_human_body",
      "disambiguation_index": 0,
      "label": "the human body",
      "aliases": [
        "the human body"
      ],
      "types": [
        "human",
        "body",
        "entity"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The human body refers to the physical structure of a human being, particularly emphasizing the upper limbs, such as the hands, which are commonly used for performing gestures in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "the human body",
          "local_types": [
            "body"
          ],
          "iri": "Entity-the_human_body-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-2",
          "local_name": "the human body",
          "local_types": [
            "entity",
            "human"
          ],
          "iri": "Entity-the_human_body-Mention-2"
        }
      ],
      "relevance": 0.5947265625
    },
    "Entity-section_5": {
      "node_id": "section_5",
      "disambiguation_index": 0,
      "label": "Section 5",
      "aliases": [
        "Section 5"
      ],
      "types": [
        "reference",
        "part of paper",
        "section",
        "document section",
        "document part"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Section 5 refers to the concluding section of the paper where the authors summarize their findings and discuss potential future work related to the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-6",
          "local_name": "Section 5",
          "local_types": [
            "reference",
            "part of paper",
            "section",
            "document section",
            "document part"
          ],
          "iri": "Entity-section_5-Mention-1"
        }
      ],
      "relevance": 0.59423828125
    },
    "Entity-touchscreen": {
      "node_id": "touchscreen",
      "disambiguation_index": 0,
      "label": "touchscreen",
      "aliases": [
        "touchscreen"
      ],
      "types": [
        "interface",
        "technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A touchscreen is a display technology that allows users to interact with a device by touching the screen, enabling input through gestures and taps.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "touchscreen",
          "local_types": [
            "interface",
            "technology"
          ],
          "iri": "Entity-touchscreen-Mention-1"
        }
      ],
      "relevance": 0.59423828125
    },
    "Entity-sample_mapping_service": {
      "node_id": "sample_mapping_service",
      "disambiguation_index": 0,
      "label": "Sample mapping service",
      "aliases": [
        "Sample mapping service"
      ],
      "types": [
        "software",
        "service",
        "web application"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The Sample mapping service is a web application that provides downloadable code for integrating gesture recognition software tools with the HDGI ontology, allowing users to customize and deploy their own gesture vocabularies.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-2",
          "local_name": "Sample mapping service",
          "local_types": [
            "software",
            "service",
            "web application"
          ],
          "iri": "Entity-sample_mapping_service-Mention-1"
        }
      ],
      "relevance": 0.59423828125
    },
    "Entity-hdgi__littlefinger": {
      "node_id": "hdgi__littlefinger",
      "disambiguation_index": 0,
      "label": "hdgi:LittleFinger",
      "aliases": [
        "hdgi:LittleFinger"
      ],
      "types": [
        "anatomical structure",
        "body part",
        "finger",
        "subclass",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:LittleFinger refers to the anatomical structure representing the little finger of the human hand, classified within the hdgi:Finger class in the context of a gesture interaction ontology.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "hdgi:LittleFinger",
          "local_types": [
            "anatomical structure",
            "body part",
            "finger",
            "subclass",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__littlefinger-Mention-1"
        }
      ],
      "relevance": 0.59375
    },
    "Entity-gestural_sign": {
      "node_id": "gestural_sign",
      "disambiguation_index": 0,
      "label": "gestural sign",
      "aliases": [
        "gestural sign"
      ],
      "types": [
        "sign",
        "gesture",
        "symbol"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A gestural sign is a form of non-verbal communication that conveys meaning through specific movements or positions of the body, often used to represent concepts or ideas.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "gestural sign",
          "local_types": [
            "sign",
            "gesture",
            "symbol"
          ],
          "iri": "Entity-gestural_sign-Mention-1"
        }
      ],
      "relevance": 0.59375
    },
    "Entity-bmw_idrive_touchscreen": {
      "node_id": "bmw_idrive_touchscreen",
      "disambiguation_index": 0,
      "label": "BMW iDrive touchscreen",
      "aliases": [
        "BMW iDrive touchscreen"
      ],
      "types": [
        "product",
        "touchscreen"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The BMW iDrive touchscreen is an interactive display interface in BMW vehicles that allows users to control various infotainment functions through touch and gesture inputs.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "BMW iDrive touchscreen",
          "local_types": [
            "product",
            "touchscreen"
          ],
          "iri": "Entity-bmw_idrive_touchscreen-Mention-1"
        }
      ],
      "relevance": 0.59375
    },
    "Entity-hdgi__middlefinger": {
      "node_id": "hdgi__middlefinger",
      "disambiguation_index": 0,
      "label": "hdgi:MiddleFinger",
      "aliases": [
        "hdgi:MiddleFinger"
      ],
      "types": [
        "anatomical structure",
        "body part",
        "finger",
        "subclass",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:MiddleFinger refers to a specific anatomical structure representing the middle finger of the human hand, categorized under the hdgi:Finger class in the context of a gesture interaction ontology.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "hdgi:MiddleFinger",
          "local_types": [
            "anatomical structure",
            "body part",
            "finger",
            "subclass",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__middlefinger-Mention-1"
        }
      ],
      "relevance": 0.59326171875
    },
    "Entity-head_gesture": {
      "node_id": "head_gesture",
      "disambiguation_index": 0,
      "label": "head gestures",
      "aliases": [
        "head gestures"
      ],
      "types": [
        "gesture type",
        "non-verbal communication",
        "head gesture",
        "body language",
        "gesture",
        "human behavior",
        "action"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Head gestures are movements of the head that convey meaning or emotions, serving as a form of non-verbal communication and body language.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-1",
          "local_name": "head gestures",
          "local_types": [
            "gesture type",
            "non-verbal communication",
            "head gesture",
            "body language",
            "gesture",
            "human behavior",
            "action"
          ],
          "iri": "Entity-head_gesture-Mention-1"
        }
      ],
      "relevance": 0.5927734375
    },
    "Entity-hdgi__rotation": {
      "node_id": "hdgi__rotation",
      "disambiguation_index": 0,
      "label": "hdgi:Rotation",
      "aliases": [
        "hdgi:Rotation"
      ],
      "types": [
        "spatial transformation",
        "data structure",
        "concept",
        "data type",
        "entity",
        "rotation",
        "transformation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:Rotation refers to a data structure within the HDGI ontology that represents the rotational aspect of a pose in 3D space, which can be modeled using either Euler angles or quaternions to accommodate different gesture recognition systems.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Rotation",
          "local_types": [
            "spatial transformation",
            "data structure",
            "concept",
            "data type",
            "entity",
            "rotation",
            "transformation"
          ],
          "iri": "Entity-hdgi__rotation-Mention-1"
        }
      ],
      "relevance": 0.5927734375
    },
    "Entity-these_finger": {
      "node_id": "these_finger",
      "disambiguation_index": 0,
      "label": "These fingers",
      "aliases": [
        "These fingers"
      ],
      "types": [
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "These fingers refer to the individual digits of the human hand, specifically categorized into left and right entities within the context of gesture modeling in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "These fingers",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-these_finger-Mention-1"
        }
      ],
      "relevance": 0.5927734375
    },
    "Entity-brown_et_al_.": {
      "node_id": "brown_et_al_.",
      "disambiguation_index": 0,
      "label": "Brown et al.",
      "aliases": [
        "Brown et al."
      ],
      "types": [
        "author",
        "researchers",
        "researcher",
        "person",
        "authors"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Brown et al. refers to a group of researchers who concluded that affordances in human-device interactions are dependent on the context and the perspective of the user, emphasizing the need to model both affordances and contexts in gesture interactions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-6",
          "local_name": "Brown et al.",
          "local_types": [
            "author",
            "researchers",
            "researcher",
            "person",
            "authors"
          ],
          "iri": "Entity-brown_et_al_.-Mention-1"
        }
      ],
      "relevance": 0.59228515625
    },
    "Entity-gesture_right_hand_swipe_left_": {
      "node_id": "gesture_right_hand_swipe_left_",
      "disambiguation_index": 0,
      "label": "gesture 'Right Hand Swipe Left'",
      "aliases": [
        "the gesture 'Right Hand Swipe Left'",
        "gesture 'Right Hand Swipe Left'",
        "'right hand swipe left'"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The gesture 'Right Hand Swipe Left' refers to a specific pose involving the right hand, characterized by a swiping motion to the left, which is modeled within the HDGI ontology to describe its position and rotation in a 3D space.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-1",
          "local_name": "gesture 'Right Hand Swipe Left'",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-gesture_right_hand_swipe_left_-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-1",
          "local_name": "'right hand swipe left'",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-gesture_right_hand_swipe_left_-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-2",
          "local_name": "'right hand swipe left'",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-gesture_right_hand_swipe_left_-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-1",
          "local_name": "the gesture 'Right Hand Swipe Left'",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-gesture_right_hand_swipe_left_-Mention-4"
        }
      ],
      "relevance": 0.59228515625
    },
    "Entity-user__s_lack_of_knowledge_of_the_relevant_symbol": {
      "node_id": "user__s_lack_of_knowledge_of_the_relevant_symbol",
      "disambiguation_index": 0,
      "label": "user\u2019s lack of knowledge of the relevant symbols",
      "aliases": [
        "user\u2019s lack of knowledge of the relevant symbols"
      ],
      "types": [
        "user knowledge"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'user\u2019s lack of knowledge of the relevant symbols' refers to the situation where a user is unfamiliar with the specific gestures or symbolic inputs required to interact effectively with a gesture-based interface, which can hinder their ability to successfully perform actions within that system.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "user\u2019s lack of knowledge of the relevant symbols",
          "local_types": [
            "user knowledge"
          ],
          "iri": "Entity-user__s_lack_of_knowledge_of_the_relevant_symbol-Mention-1"
        }
      ],
      "relevance": 0.59228515625
    },
    "Entity-button": {
      "node_id": "button",
      "disambiguation_index": 0,
      "label": "buttons",
      "aliases": [
        "buttons"
      ],
      "types": [
        "input method",
        "interface element"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of user interaction with systems, 'buttons' refer to interface elements that allow users to perform actions or commands, often requiring a physical press or touch, and are integral to the usability and guessability of interactive systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "buttons",
          "local_types": [
            "input method",
            "interface element"
          ],
          "iri": "Entity-button-Mention-1"
        }
      ],
      "relevance": 0.591796875
    },
    "Entity-interactive_information": {
      "node_id": "interactive_information",
      "disambiguation_index": 0,
      "label": "interactive information",
      "aliases": [
        "interactive information"
      ],
      "types": [
        "communication",
        "information",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Interactive information refers to the data conveyed by users through physical gestures, which express their intentions and facilitate communication with devices or systems in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "interactive information",
          "local_types": [
            "communication",
            "information",
            "data"
          ],
          "iri": "Entity-interactive_information-Mention-1"
        }
      ],
      "relevance": 0.59130859375
    },
    "Entity-a_lack_of_linked_data": {
      "node_id": "a_lack_of_linked_data",
      "disambiguation_index": 0,
      "label": "a lack of linked data",
      "aliases": [
        "a lack of linked data"
      ],
      "types": [
        "data",
        "issue"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A lack of linked data refers to the insufficient interconnection and accessibility of existing gesture-related knowledge, which hinders researchers from utilizing established gesture-referent mappings and forces them to conduct new Gesture Elicitation Studies (GES) for each specific mapping need.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-4",
          "local_name": "a lack of linked data",
          "local_types": [
            "data",
            "issue"
          ],
          "iri": "Entity-a_lack_of_linked_data-Mention-1"
        }
      ],
      "relevance": 0.59130859375
    },
    "Entity-listing_1.1": {
      "node_id": "listing_1.1",
      "disambiguation_index": 0,
      "label": "Listing 1.1",
      "aliases": [
        "Listing 1.1"
      ],
      "types": [
        "document section",
        "reference",
        "listing",
        "code representation"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Listing 1.1 provides a detailed enumeration of the atomic gestures involved in the 'right hand swipe left' dynamic gesture, illustrating the components such as body parts, start and end poses, and movements as part of the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-1",
          "local_name": "Listing 1.1",
          "local_types": [
            "document section",
            "reference",
            "listing"
          ],
          "iri": "Entity-listing_1.1-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "Listing 1.1",
          "local_types": [
            "reference",
            "listing",
            "code representation"
          ],
          "iri": "Entity-listing_1.1-Mention-2"
        }
      ],
      "relevance": 0.5908203125
    },
    "Entity-hdgi__position": {
      "node_id": "hdgi__position",
      "disambiguation_index": 0,
      "label": "hdgi:Position",
      "aliases": [
        "hdgi:Position"
      ],
      "types": [
        "spatial representation",
        "data structure",
        "ontology",
        "concept",
        "ontology term",
        "data type",
        "spatial position",
        "model",
        "position",
        "entity",
        "spatial reference",
        "mapping",
        "identifier",
        "coordinate representation",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Position refers to a class in the HDGI ontology that describes the spatial placement of a pose in a 3D space, including its local coordinate system and relative positioning of body parts during gesture interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-15",
          "local_name": "hdgi:Position",
          "local_types": [
            "model",
            "data structure",
            "class"
          ],
          "iri": "Entity-hdgi__position-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-10",
          "local_name": "hdgi:Position",
          "local_types": [
            "spatial representation",
            "data structure",
            "ontology",
            "concept",
            "ontology term",
            "position",
            "class"
          ],
          "iri": "Entity-hdgi__position-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-11",
          "local_name": "hdgi:Position",
          "local_types": [
            "data structure",
            "entity"
          ],
          "iri": "Entity-hdgi__position-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Position",
          "local_types": [
            "spatial representation",
            "data structure",
            "ontology",
            "concept",
            "data type",
            "spatial position",
            "position",
            "spatial reference",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__position-Mention-4"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-4",
          "local_name": "hdgi:Position",
          "local_types": [
            "data structure",
            "mapping",
            "identifier"
          ],
          "iri": "Entity-hdgi__position-Mention-5"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-5",
          "local_name": "hdgi:Position",
          "local_types": [
            "data structure",
            "entity",
            "coordinate representation"
          ],
          "iri": "Entity-hdgi__position-Mention-6"
        }
      ],
      "relevance": 0.5908203125
    },
    "Entity-the_attempt_above": {
      "node_id": "the_attempt_above",
      "disambiguation_index": 0,
      "label": "the attempts above",
      "aliases": [
        "the attempts above"
      ],
      "types": [
        "attempt"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The attempts above refer to various research efforts and methodologies in gesture recognition and ontology development that differ in focus and scope from the proposed ontology in the paper.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-1",
          "local_name": "the attempts above",
          "local_types": [
            "attempt"
          ],
          "iri": "Entity-the_attempt_above-Mention-1"
        }
      ],
      "relevance": 0.59033203125
    },
    "Entity-pose_modeling": {
      "node_id": "pose_modeling",
      "disambiguation_index": 0,
      "label": "pose modeling",
      "aliases": [
        "pose modeling"
      ],
      "types": [
        "methodology",
        "gesture analysis",
        "modeling",
        "technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Pose modeling refers to the systematic representation of the position and rotation of body parts in a 3D space to describe static gestures, allowing for the analysis and recognition of human gestures in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-1",
          "local_name": "pose modeling",
          "local_types": [
            "methodology",
            "gesture analysis",
            "modeling",
            "technique"
          ],
          "iri": "Entity-pose_modeling-Mention-1"
        }
      ],
      "relevance": 0.58984375
    },
    "Entity-affordance_y": {
      "node_id": "affordance_y",
      "disambiguation_index": 0,
      "label": "affordance Y",
      "aliases": [
        "affordance Y"
      ],
      "types": [
        "capability",
        "affordance",
        "interaction feature",
        "feature"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Affordance Y refers to a specific potential use or interaction capability that Device B supports, allowing users to perform certain actions through gestures recognized by the device.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-3",
          "local_name": "affordance Y",
          "local_types": [
            "capability",
            "affordance",
            "interaction feature",
            "feature"
          ],
          "iri": "Entity-affordance_y-Mention-1"
        }
      ],
      "relevance": 0.58984375
    },
    "Entity-limb": {
      "node_id": "limb",
      "disambiguation_index": 0,
      "label": "limbs",
      "aliases": [
        "limbs"
      ],
      "types": [
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of gesture-based systems, 'limbs' refers specifically to the upper limbs of the human body, primarily the arms and hands, which are involved in physical movements to express interaction intentions with devices or systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "limbs",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-limb-Mention-1"
        }
      ],
      "relevance": 0.58935546875
    },
    "Entity-gesture_to_answer_a_call_in_a_car": {
      "node_id": "gesture_to_answer_a_call_in_a_car",
      "disambiguation_index": 0,
      "label": "gestures to answer a call in a car",
      "aliases": [
        "gestures to answer a call in a car"
      ],
      "types": [
        "action",
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Gestures to answer a call in a car refer to specific physical movements or actions that users perform to interact with a vehicle's infotainment system in order to accept incoming phone calls, which may vary across different automotive manufacturers and their respective gesture interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-3",
          "local_name": "gestures to answer a call in a car",
          "local_types": [
            "action",
            "gesture"
          ],
          "iri": "Entity-gesture_to_answer_a_call_in_a_car-Mention-1"
        }
      ],
      "relevance": 0.58935546875
    },
    "Entity-43_gesture": {
      "node_id": "43_gesture",
      "disambiguation_index": 0,
      "label": "43 gestures",
      "aliases": [
        "43 gestures"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term '43 gestures' refers to a specific set of six commands utilized in an experimental study focused on gesture recognition for controlling a TV and blinds.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "43 gestures",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-43_gesture-Mention-1"
        }
      ],
      "relevance": 0.5888671875
    },
    "Entity-speed": {
      "node_id": "speed",
      "disambiguation_index": 0,
      "label": "speed",
      "aliases": [
        "speed"
      ],
      "types": [
        "measurement",
        "velocity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'speed' refers to the rate at which hand gestures are performed, which has not been accounted for in the design and development of gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-11",
          "local_name": "speed",
          "local_types": [
            "measurement",
            "velocity"
          ],
          "iri": "Entity-speed-Mention-1"
        }
      ],
      "relevance": 0.58837890625
    },
    "Entity-a_gesture": {
      "node_id": "a_gesture",
      "disambiguation_index": 0,
      "label": "a gesture",
      "aliases": [
        "a gesture"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A gesture is defined as a combination of one or more poses and/or movements involving one or more sections of the upper limb region, specifically the upper arm, forearm, palm, and fingers.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-9",
          "local_name": "a gesture",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-a_gesture-Mention-1"
        }
      ],
      "relevance": 0.58837890625
    },
    "Entity-internet_of_thing__iot__system": {
      "node_id": "internet_of_thing__iot__system",
      "disambiguation_index": 0,
      "label": "Internet of Things (IoT) systems",
      "aliases": [
        "Internet of Things (IoT) systems"
      ],
      "types": [
        "IoT",
        "system"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Internet of Things (IoT) systems refer to interconnected devices and objects that communicate and exchange data over the internet, enabling automation and enhanced user interaction through various applications such as smart homes, automobiles, and augmented reality.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "Internet of Things (IoT) systems",
          "local_types": [
            "IoT",
            "system"
          ],
          "iri": "Entity-internet_of_thing__iot__system-Mention-1"
        }
      ],
      "relevance": 0.587890625
    },
    "Entity-success": {
      "node_id": "success",
      "disambiguation_index": 0,
      "label": "success",
      "aliases": [
        "success"
      ],
      "types": [
        "outcome"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of gesture-based systems, 'success' refers to the achievement of a user's initial attempts at performing gestures or commands, ensuring that these actions yield the expected outcomes even when the user is unfamiliar with the relevant symbols or controls.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "success",
          "local_types": [
            "outcome"
          ],
          "iri": "Entity-success-Mention-1"
        }
      ],
      "relevance": 0.587890625
    },
    "Entity-hdgi__quaternion": {
      "node_id": "hdgi__quaternion",
      "disambiguation_index": 0,
      "label": "hdgi:Quaternion",
      "aliases": [
        "hdgi:Quaternion"
      ],
      "types": [
        "entity",
        "mathematical concept",
        "mathematical representation",
        "rotation representation",
        "class",
        "quaternion"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:Quaternion refers to a mathematical representation used in the HDGI ontology to model the rotation of a pose in 3D space, allowing for flexible integration of gesture data from various devices.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "hdgi:Quaternion",
          "local_types": [
            "entity",
            "mathematical concept",
            "mathematical representation",
            "rotation representation",
            "class",
            "quaternion"
          ],
          "iri": "Entity-hdgi__quaternion-Mention-1"
        }
      ],
      "relevance": 0.58740234375
    },
    "Entity-documentation": {
      "node_id": "documentation",
      "disambiguation_index": 0,
      "label": "documentation",
      "aliases": [
        "documentation"
      ],
      "types": [
        "methodology",
        "process",
        "engineering activity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'documentation' refers to the comprehensive written materials that provide guidance on the integration and usage of the HDGI ontology and its associated APIs within the context of ontology engineering.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-1",
          "local_name": "documentation",
          "local_types": [
            "methodology",
            "process",
            "engineering activity"
          ],
          "iri": "Entity-documentation-Mention-1"
        }
      ],
      "relevance": 0.58740234375
    },
    "Entity-cardinality_of_many_to_many": {
      "node_id": "cardinality_of_many_to_many",
      "disambiguation_index": 0,
      "label": "cardinality of many to many",
      "aliases": [
        "cardinality of many to many"
      ],
      "types": [
        "cardinality"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The 'cardinality of many to many' refers to a relationship in the HDGI ontology where multiple affordances can be associated with multiple devices, allowing for flexible gesture recognition and interaction across different contexts and devices.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-8",
          "local_name": "cardinality of many to many",
          "local_types": [
            "cardinality"
          ],
          "iri": "Entity-cardinality_of_many_to_many-Mention-1"
        }
      ],
      "relevance": 0.5869140625
    },
    "Entity-hdgi__upperarm_class": {
      "node_id": "hdgi__upperarm_class",
      "disambiguation_index": 0,
      "label": "hdgi:UpperArm class",
      "aliases": [
        "hdgi:UpperArm class"
      ],
      "types": [
        "class"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The hdgi:UpperArm class represents a conceptual model of the upper arm in the context of Human Device Interaction, defined as equivalent to the Arm class in the Foundational Model of Anatomy (FMA).",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "hdgi:UpperArm class",
          "local_types": [
            "class"
          ],
          "iri": "Entity-hdgi__upperarm_class-Mention-1"
        }
      ],
      "relevance": 0.58642578125
    },
    "Entity-attribute": {
      "node_id": "attribute",
      "disambiguation_index": 0,
      "label": "attributes",
      "aliases": [
        "attributes"
      ],
      "types": [
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'attributes' refers to the specific properties and characteristics associated with arm-based gestures that the ontology aims to describe, without attempting to model every possible feature or relationship.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-2",
          "local_name": "attributes",
          "local_types": [
            "property"
          ],
          "iri": "Entity-attribute-Mention-1"
        }
      ],
      "relevance": 0.5859375
    },
    "Entity-hdgi__forearmpose": {
      "node_id": "hdgi__forearmpose",
      "disambiguation_index": 0,
      "label": "hdgi:ForearmPose",
      "aliases": [
        "hdgi:ForearmPose"
      ],
      "types": [
        "ontology",
        "concept",
        "body part",
        "ontology term",
        "gesture",
        "pose",
        "class",
        "biomechanical representation"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:ForearmPose refers to a specific static gesture representation that models the position and orientation of the forearm in a 3D space, with its coordinates defined relative to the elbow joint.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-8",
          "local_name": "hdgi:ForearmPose",
          "local_types": [
            "ontology",
            "concept",
            "body part",
            "ontology term",
            "gesture",
            "pose",
            "class",
            "biomechanical representation"
          ],
          "iri": "Entity-hdgi__forearmpose-Mention-1"
        }
      ],
      "relevance": 0.58544921875
    },
    "Entity-cloud": {
      "node_id": "cloud",
      "disambiguation_index": 0,
      "label": "Cloud",
      "aliases": [
        "Cloud"
      ],
      "types": [
        "computing environment",
        "technology",
        "platform",
        "infrastructure",
        "environment",
        "computing"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "In this context, 'Cloud' refers to a computing environment where the HDGI RESTful service will be deployed, enabling remote access and integration with various gesture recognition systems.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "Cloud",
          "local_types": [
            "computing environment",
            "technology",
            "platform",
            "infrastructure",
            "environment",
            "computing"
          ],
          "iri": "Entity-cloud-Mention-1"
        }
      ],
      "relevance": 0.58544921875
    },
    "Entity-the_challenge_of_how_to_increase_the_knowledge_level_of_computational_system": {
      "node_id": "the_challenge_of_how_to_increase_the_knowledge_level_of_computational_system",
      "disambiguation_index": 0,
      "label": "the challenge of how to increase the knowledge level of computational systems",
      "aliases": [
        "the challenge of how to increase the knowledge level of computational systems"
      ],
      "types": [
        "knowledge",
        "computational systems",
        "challenge"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The challenge of how to increase the knowledge level of computational systems refers to the difficulty in enhancing the ability of these systems to accurately recognize and interpret gestural information, particularly in relation to arm movements, through improved ontological frameworks and knowledge representation.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-1",
          "local_name": "the challenge of how to increase the knowledge level of computational systems",
          "local_types": [
            "knowledge",
            "computational systems",
            "challenge"
          ],
          "iri": "Entity-the_challenge_of_how_to_increase_the_knowledge_level_of_computational_system-Mention-1"
        }
      ],
      "relevance": 0.5849609375
    },
    "Entity-affordances_of_a_device": {
      "node_id": "affordances_of_a_device",
      "disambiguation_index": 0,
      "label": "affordances of a device",
      "aliases": [
        "affordances of a device"
      ],
      "types": [
        "concept",
        "device"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The affordances of a device refer to the set of all potential human behaviors and interactions that the device enables or supports, which are context-dependent and can vary based on user intent and device capabilities.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-5",
          "local_name": "affordances of a device",
          "local_types": [
            "concept",
            "device"
          ],
          "iri": "Entity-affordances_of_a_device-Mention-1"
        }
      ],
      "relevance": 0.5849609375
    },
    "Entity-sosa__actuatableproperty": {
      "node_id": "sosa__actuatableproperty",
      "disambiguation_index": 0,
      "label": "sosa:ActuatableProperty",
      "aliases": [
        "sosa:ActuatableProperty"
      ],
      "types": [
        "ontology class",
        "ontology",
        "property",
        "concept",
        "ontology term",
        "entity",
        "actuatable property",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "sosa:ActuatableProperty refers to a class in the SOSA ontology that encompasses properties which can be actuated or manipulated by devices, serving as a foundational element for modeling interactions between human gestures and device affordances in the context of the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-12",
          "local_name": "sosa:ActuatableProperty",
          "local_types": [
            "ontology class",
            "ontology",
            "property",
            "concept",
            "ontology term",
            "entity",
            "actuatable property",
            "class"
          ],
          "iri": "Entity-sosa__actuatableproperty-Mention-1"
        }
      ],
      "relevance": 0.58447265625
    },
    "Entity-a_guideline": {
      "node_id": "a_guideline",
      "disambiguation_index": 0,
      "label": "a guideline",
      "aliases": [
        "a guideline"
      ],
      "types": [
        "guideline"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A guideline refers to a systematic framework or set of recommendations derived from research findings that assists in organizing hand gestures to improve the usability of gesture-based interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-6",
          "local_name": "a guideline",
          "local_types": [
            "guideline"
          ],
          "iri": "Entity-a_guideline-Mention-1"
        }
      ],
      "relevance": 0.58447265625
    },
    "Entity-an_increased_number_of_command": {
      "node_id": "an_increased_number_of_command",
      "disambiguation_index": 0,
      "label": "an increased number of commands",
      "aliases": [
        "an increased number of commands"
      ],
      "types": [
        "commands"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "An increased number of commands refers to the necessity for additional gesture commands beyond the limited set previously studied, in order to evaluate the effectiveness and flexibility of a proposed gestural interaction taxonomy and notation method.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-9",
          "local_name": "an increased number of commands",
          "local_types": [
            "commands"
          ],
          "iri": "Entity-an_increased_number_of_command-Mention-1"
        }
      ],
      "relevance": 0.58447265625
    },
    "Entity-multiple_pose": {
      "node_id": "multiple_pose",
      "disambiguation_index": 0,
      "label": "multiple poses",
      "aliases": [
        "multiple poses"
      ],
      "types": [
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of gesture-controlled interfaces, 'multiple poses' refers to the various distinct positions or configurations that a body part can assume during the execution of a gesture, allowing for the representation of complex gestures that involve sequences of movements and interactions among different body parts.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "multiple poses",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-multiple_pose-Mention-1"
        }
      ],
      "relevance": 0.583984375
    },
    "Entity-a_movement": {
      "node_id": "a_movement",
      "disambiguation_index": 0,
      "label": "a movement",
      "aliases": [
        "a movement"
      ],
      "types": [
        "movement"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of gesture-controlled interfaces, 'a movement' refers to an atomic component of a dynamic gesture that involves a specific action performed by a single body part, characterized by a start pose and an end pose.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "a movement",
          "local_types": [
            "movement"
          ],
          "iri": "Entity-a_movement-Mention-1"
        }
      ],
      "relevance": 0.583984375
    },
    "Entity-individual_study": {
      "node_id": "individual_study",
      "disambiguation_index": 0,
      "label": "individual studies",
      "aliases": [
        "individual studies"
      ],
      "types": [
        "study",
        "academic work",
        "research"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'individual studies' refers to separate research investigations conducted to explore and define various gesture vocabularies and their effectiveness in human-device interactions, which designers and developers must locate and review independently.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-4",
          "local_name": "individual studies",
          "local_types": [
            "study",
            "academic work",
            "research"
          ],
          "iri": "Entity-individual_study-Mention-1"
        }
      ],
      "relevance": 0.58349609375
    },
    "Entity-the_research_community": {
      "node_id": "the_research_community",
      "disambiguation_index": 0,
      "label": "the research community",
      "aliases": [
        "the research community"
      ],
      "types": [
        "community",
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The research community refers to the collective group of scholars, researchers, and practitioners who study, develop, and contribute to the field of gesture-controlled interfaces and related technologies, particularly in the context of the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-3",
          "local_name": "the research community",
          "local_types": [
            "community",
            "research"
          ],
          "iri": "Entity-the_research_community-Mention-1"
        }
      ],
      "relevance": 0.58349609375
    },
    "Entity-swagger_ui": {
      "node_id": "swagger_ui",
      "disambiguation_index": 0,
      "label": "Swagger UI",
      "aliases": [
        "Swagger UI"
      ],
      "types": [
        "documentation tool",
        "documentation",
        "Swagger",
        "tool",
        "software",
        "user interface",
        "API documentation",
        "UI"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Swagger UI is an open-source tool that allows developers to visualize and interact with API endpoints through a user-friendly web interface, facilitating the understanding and testing of APIs.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-6",
          "local_name": "Swagger UI",
          "local_types": [
            "documentation tool",
            "documentation",
            "Swagger",
            "tool",
            "software",
            "user interface",
            "API documentation",
            "UI"
          ],
          "iri": "Entity-swagger_ui-Mention-1"
        }
      ],
      "relevance": 0.5830078125
    },
    "Entity-6_command__43_gesture_": {
      "node_id": "6_command__43_gesture_",
      "disambiguation_index": 0,
      "label": "6 commands (43 gestures)",
      "aliases": [
        "6 commands (43 gestures)",
        "6 commands"
      ],
      "types": [
        "command",
        "gesture"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The entity '6 commands (43 gestures)' refers to a specific set of predefined gestures and their corresponding commands used in an experimental study focused on gesture recognition for controlling a TV and blinds.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "6 commands (43 gestures)",
          "local_types": [
            "command",
            "gesture"
          ],
          "iri": "Entity-6_command__43_gesture_-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "6 commands",
          "local_types": [
            "command"
          ],
          "iri": "Entity-6_command__43_gesture_-Mention-2"
        }
      ],
      "relevance": 0.5830078125
    },
    "Entity-multiple_study": {
      "node_id": "multiple_study",
      "disambiguation_index": 0,
      "label": "multiple studies",
      "aliases": [
        "multiple studies"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'multiple studies' refers to various research efforts that have identified and analyzed the most effective gestures for specific referents in gesture-based human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "multiple studies",
          "local_types": [
            "research"
          ],
          "iri": "Entity-multiple_study-Mention-1"
        }
      ],
      "relevance": 0.5830078125
    },
    "Entity-standard_definition": {
      "node_id": "standard_definition",
      "disambiguation_index": 0,
      "label": "standard definitions",
      "aliases": [
        "standard definitions"
      ],
      "types": [
        "definition"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Standard definitions refer to established and widely accepted descriptions or meanings of gestures that serve as a consistent framework for designers and manufacturers when creating gesture vocabularies in gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-1",
          "local_name": "standard definitions",
          "local_types": [
            "definition"
          ],
          "iri": "Entity-standard_definition-Mention-1"
        }
      ],
      "relevance": 0.5830078125
    },
    "Entity-the_current_literature": {
      "node_id": "the_current_literature",
      "disambiguation_index": 0,
      "label": "the current literature",
      "aliases": [
        "the current literature"
      ],
      "types": [
        "literature"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The current literature refers to the existing body of research and published works that document and analyze gesture vocabularies relevant to Human Device Interactions, which the authors examined to inform the development of their gesture ontology.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-1",
          "local_name": "the current literature",
          "local_types": [
            "literature"
          ],
          "iri": "Entity-the_current_literature-Mention-1"
        }
      ],
      "relevance": 0.5830078125
    },
    "Entity-necessary_data": {
      "node_id": "necessary_data",
      "disambiguation_index": 0,
      "label": "necessary data",
      "aliases": [
        "necessary data"
      ],
      "types": [
        "information",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'necessary data' refers to the essential information that designers and developers need to manually gather from various individual studies related to gesture vocabularies and their semantics for effective implementation in gesture-controlled systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-4",
          "local_name": "necessary data",
          "local_types": [
            "information",
            "data"
          ],
          "iri": "Entity-necessary_data-Mention-1"
        }
      ],
      "relevance": 0.58251953125
    },
    "Entity-range_of_the_property": {
      "node_id": "range_of_the_property",
      "disambiguation_index": 0,
      "label": "range of the property",
      "aliases": [
        "range of the property",
        "the range of the property"
      ],
      "types": [
        "attribute",
        "concept",
        "range"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'range of the property' refers to the set of values or classes that a specific property can take within the context of the HDGI ontology, particularly in relation to the gestures and their associated affordances and contexts.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "range of the property",
          "local_types": [
            "concept",
            "attribute"
          ],
          "iri": "Entity-range_of_the_property-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "the range of the property",
          "local_types": [
            "range"
          ],
          "iri": "Entity-range_of_the_property-Mention-2"
        }
      ],
      "relevance": 0.58251953125
    },
    "Entity-detail_like_the_finger_pose_or_movement": {
      "node_id": "detail_like_the_finger_pose_or_movement",
      "disambiguation_index": 0,
      "label": "details like the finger pose or movements",
      "aliases": [
        "details like the finger pose or movements"
      ],
      "types": [
        "detail",
        "finger pose",
        "movement"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'details like the finger pose or movements' refers to the specific configurations and actions of the fingers that are essential for accurately representing and recognizing hand gestures in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "details like the finger pose or movements",
          "local_types": [
            "detail",
            "finger pose",
            "movement"
          ],
          "iri": "Entity-detail_like_the_finger_pose_or_movement-Mention-1"
        }
      ],
      "relevance": 0.58251953125
    },
    "Entity-hdgi__bodypart_class": {
      "node_id": "hdgi__bodypart_class",
      "disambiguation_index": 0,
      "label": "hdgi:BodyPart class",
      "aliases": [
        "hdgi:BodyPart class"
      ],
      "types": [
        "class",
        "data structure"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The hdgi:BodyPart class is a data structure within the HDGI ontology that represents human body parts, specifically designed to be extensible for future inclusion of additional body parts and poses relevant to Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "hdgi:BodyPart class",
          "local_types": [
            "class",
            "data structure"
          ],
          "iri": "Entity-hdgi__bodypart_class-Mention-1"
        }
      ],
      "relevance": 0.58203125
    },
    "Entity-task": {
      "node_id": "task",
      "disambiguation_index": 0,
      "label": "task",
      "aliases": [
        "task"
      ],
      "types": [
        "activity",
        "operation",
        "goal"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'task' refers to the specific action or goal that a user aims to achieve when interacting with a gesture-based interface.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-2",
          "local_name": "task",
          "local_types": [
            "activity",
            "operation",
            "goal"
          ],
          "iri": "Entity-task-Mention-1"
        }
      ],
      "relevance": 0.58154296875
    },
    "Entity-feature": {
      "node_id": "feature",
      "disambiguation_index": 0,
      "label": "features",
      "aliases": [
        "features"
      ],
      "types": [
        "characteristic"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'features' refers to the specific characteristics, attributes, and relationships associated with arm-based gestures that the ontology aims to describe and formalize.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-2",
          "local_name": "features",
          "local_types": [
            "characteristic"
          ],
          "iri": "Entity-feature-Mention-1"
        }
      ],
      "relevance": 0.58154296875
    },
    "Entity-atomic_gesture": {
      "node_id": "atomic_gesture",
      "disambiguation_index": 0,
      "label": "atomic gestures",
      "aliases": [
        "atomic gestures"
      ],
      "types": [
        "gesture type",
        "gesture",
        "movement",
        "component"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Atomic gestures refer to the fundamental components of a gesture, specifically the individual movements and poses associated with a single body part, which collectively form part of a larger gesture sequence in the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-2",
          "local_name": "atomic gestures",
          "local_types": [
            "component",
            "gesture",
            "movement",
            "gesture type"
          ],
          "iri": "Entity-atomic_gesture-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "atomic gestures",
          "local_types": [
            "gesture",
            "movement"
          ],
          "iri": "Entity-atomic_gesture-Mention-2"
        }
      ],
      "relevance": 0.58154296875
    },
    "Entity-integration_and_documentation": {
      "node_id": "integration_and_documentation",
      "disambiguation_index": 0,
      "label": "integration and documentation",
      "aliases": [
        "integration and documentation"
      ],
      "types": [
        "process",
        "documentation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'integration and documentation' refers to the essential processes involved in ontology engineering that ensure the seamless incorporation of the HDGI ontology into various applications and provide comprehensive guidelines and resources for its effective use.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-1",
          "local_name": "integration and documentation",
          "local_types": [
            "process",
            "documentation"
          ],
          "iri": "Entity-integration_and_documentation-Mention-1"
        }
      ],
      "relevance": 0.5810546875
    },
    "Entity-the_icon_that_appears_near_the_wrist": {
      "node_id": "the_icon_that_appears_near_the_wrist",
      "disambiguation_index": 0,
      "label": "the icon that appears near the wrist",
      "aliases": [
        "the icon that appears near the wrist"
      ],
      "types": [
        "icon"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The icon that appears near the wrist refers to a visual symbol displayed on the Microsoft HoloLens interface, which users can interact with by pinching their fingers or tapping it to access the start menu.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-3",
          "local_name": "the icon that appears near the wrist",
          "local_types": [
            "icon"
          ],
          "iri": "Entity-the_icon_that_appears_near_the_wrist-Mention-1"
        }
      ],
      "relevance": 0.58056640625
    },
    "Entity-movement_of_multiple_body_part": {
      "node_id": "movement_of_multiple_body_part",
      "disambiguation_index": 0,
      "label": "movements of multiple body parts",
      "aliases": [
        "movements of multiple body parts"
      ],
      "types": [
        "movement",
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'movements of multiple body parts' refers to the coordinated actions involving various segments of the human body during dynamic gestures, which can include a sequence of poses and movements that are captured and described within a gesture ontology for Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "movements of multiple body parts",
          "local_types": [
            "movement",
            "body part"
          ],
          "iri": "Entity-movement_of_multiple_body_part-Mention-1"
        }
      ],
      "relevance": 0.58056640625
    },
    "Entity-typing_command": {
      "node_id": "typing_command",
      "disambiguation_index": 0,
      "label": "typing commands",
      "aliases": [
        "typing commands"
      ],
      "types": [
        "action",
        "input method"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Typing commands refers to the action of inputting text or instructions into a system using a keyboard or similar input device, which is highlighted in the context of user interactions with gesture-based systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "typing commands",
          "local_types": [
            "action",
            "input method"
          ],
          "iri": "Entity-typing_command-Mention-1"
        }
      ],
      "relevance": 0.580078125
    },
    "Entity-this_research": {
      "node_id": "this_research",
      "disambiguation_index": 0,
      "label": "this research",
      "aliases": [
        "this research"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This research refers to a study that is limited to the analysis of 6 commands and 43 gestures specifically related to the control of a TV and blinds in the context of gesture recognition and interaction design.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "this research",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_research-Mention-1"
        }
      ],
      "relevance": 0.580078125
    },
    "Entity-their_approach": {
      "node_id": "their_approach",
      "disambiguation_index": 0,
      "label": "their approach",
      "aliases": [
        "their approach"
      ],
      "types": [
        "methodology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Their approach refers to the methodology employed by Choi et al. in developing a 3D hand gesture taxonomy and notation method, which focuses on organizing hand gestures for enhancing the usability of gesture-based interfaces, although it has limitations regarding the consideration of gesture size and speed.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-11",
          "local_name": "their approach",
          "local_types": [
            "methodology"
          ],
          "iri": "Entity-their_approach-Mention-1"
        }
      ],
      "relevance": 0.580078125
    },
    "Entity-producer": {
      "node_id": "producer",
      "disambiguation_index": 0,
      "label": "producers",
      "aliases": [
        "producers"
      ],
      "types": [
        "individual",
        "role",
        "profession",
        "organisation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Producers refer to individuals or organizations involved in the creation and integration of gesture interfaces into products for various applications, contributing to the diversity of standards in the field.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "producers",
          "local_types": [
            "individual",
            "role",
            "profession",
            "organisation"
          ],
          "iri": "Entity-producer-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-4-Sentence-4",
          "local_name": "producers",
          "local_types": [
            "role",
            "profession"
          ],
          "iri": "Entity-producer-Mention-2"
        }
      ],
      "relevance": 0.57958984375
    },
    "Entity-potential_human_behavior": {
      "node_id": "potential_human_behavior",
      "disambiguation_index": 0,
      "label": "potential human behaviors",
      "aliases": [
        "potential human behaviors"
      ],
      "types": [
        "behavior",
        "human"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Potential human behaviors refer to the various actions or interactions that a user can perform with a device, determined by the device's affordances and the context in which it is used.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-5",
          "local_name": "potential human behaviors",
          "local_types": [
            "behavior",
            "human"
          ],
          "iri": "Entity-potential_human_behavior-Mention-1"
        }
      ],
      "relevance": 0.5791015625
    },
    "Entity-it": {
      "node_id": "it",
      "disambiguation_index": 0,
      "label": "it",
      "aliases": [
        "it"
      ],
      "types": [
        "API"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'it' refers to the API that provides users with a comprehensive view of the endpoint structures and allows them to interact with the HDGI service online in real-time.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-1",
          "local_name": "it",
          "local_types": [
            "API"
          ],
          "iri": "Entity-it-Mention-1"
        }
      ],
      "relevance": 0.57861328125
    },
    "Entity-hdgi__ringfinger": {
      "node_id": "hdgi__ringfinger",
      "disambiguation_index": 0,
      "label": "hdgi:RingFinger",
      "aliases": [
        "hdgi:RingFinger"
      ],
      "types": [
        "anatomical structure",
        "body part",
        "finger",
        "subclass",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:RingFinger refers to a specific anatomical structure representing the ring finger of the human hand, categorized under the hdgi:Finger class in the context of a gesture interaction ontology.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "hdgi:RingFinger",
          "local_types": [
            "anatomical structure",
            "body part",
            "finger",
            "subclass",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__ringfinger-Mention-1"
        }
      ],
      "relevance": 0.578125
    },
    "Entity-independent_layer": {
      "node_id": "independent_layer",
      "disambiguation_index": 0,
      "label": "independent layers",
      "aliases": [
        "independent layers"
      ],
      "types": [
        "design",
        "architecture",
        "layer"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Independent layers refer to the distinct functional components within gesture recognition systems that operate separately for gesture recognition, detection, mappings, and communication, allowing for modular and flexible system design.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-3",
          "local_name": "independent layers",
          "local_types": [
            "design",
            "architecture",
            "layer"
          ],
          "iri": "Entity-independent_layer-Mention-1"
        }
      ],
      "relevance": 0.578125
    },
    "Entity-hdgi__finger_class": {
      "node_id": "hdgi__finger_class",
      "disambiguation_index": 0,
      "label": "hdgi:Finger class",
      "aliases": [
        "hdgi:Finger class"
      ],
      "types": [
        "class"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The hdgi:Finger class is a component of the HDGI ontology that categorizes and represents individual fingers of the human hand, including the Thumb, IndexFinger, MiddleFinger, RingFinger, and LittleFinger, and establishes their relationships to anatomical structures in the Foundational Model of Anatomy.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "hdgi:Finger class",
          "local_types": [
            "class"
          ],
          "iri": "Entity-hdgi__finger_class-Mention-1"
        }
      ],
      "relevance": 0.578125
    },
    "Entity-review_conducted_by_villarreal_narvaez_et_al_._in_2020": {
      "node_id": "review_conducted_by_villarreal_narvaez_et_al_._in_2020",
      "disambiguation_index": 0,
      "label": "review conducted by Villarreal Narvaez et al. in 2020",
      "aliases": [
        "review conducted by Villarreal Narvaez et al. in 2020",
        "A review conducted by Villarreal Narvaez et al.",
        "A review conducted by Villarreal Narvaez et al. in 2020"
      ],
      "types": [
        "study",
        "research",
        "review"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The review conducted by Villarreal Narvaez et al. in 2020 analyzes the current state of gesture recognition, highlighting its ongoing development and the anticipated emergence of additional gesture-related vocabularies, thereby emphasizing the necessity for interoperability among them.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "review conducted by Villarreal Narvaez et al. in 2020",
          "local_types": [
            "study",
            "review"
          ],
          "iri": "Entity-review_conducted_by_villarreal_narvaez_et_al_._in_2020-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "A review conducted by Villarreal Narvaez et al. in 2020",
          "local_types": [
            "review",
            "study"
          ],
          "iri": "Entity-review_conducted_by_villarreal_narvaez_et_al_._in_2020-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "A review conducted by Villarreal Narvaez et al.",
          "local_types": [
            "research",
            "review"
          ],
          "iri": "Entity-review_conducted_by_villarreal_narvaez_et_al_._in_2020-Mention-3"
        }
      ],
      "relevance": 0.57763671875
    },
    "Entity-pose_and-or_movement": {
      "node_id": "pose_and-or_movement",
      "disambiguation_index": 0,
      "label": "poses and-or movements",
      "aliases": [
        "poses and-or movements"
      ],
      "types": [
        "action",
        "movement"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'poses and-or movements' refers to the various configurations and actions of the upper limb sections that collectively constitute a gesture in the context of Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-9",
          "local_name": "poses and-or movements",
          "local_types": [
            "action",
            "movement"
          ],
          "iri": "Entity-pose_and-or_movement-Mention-1"
        }
      ],
      "relevance": 0.57763671875
    },
    "Entity-several_possible_pose": {
      "node_id": "several_possible_pose",
      "disambiguation_index": 0,
      "label": "several possible poses",
      "aliases": [
        "several possible poses"
      ],
      "types": [
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'several possible poses' refers to the various subclasses of the hdgi:Pose class in the HDGI ontology, which represent different static gestures involving specific body parts, such as hdgi:LegPose and hdgi:FootPose, allowing for extensibility in modeling human-device interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-2-Sentence-4",
          "local_name": "several possible poses",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-several_possible_pose-Mention-1"
        }
      ],
      "relevance": 0.57763671875
    },
    "Entity-hci": {
      "node_id": "hci",
      "disambiguation_index": 0,
      "label": "HCI",
      "aliases": [
        "HCI"
      ],
      "types": [
        "field of study",
        "discipline"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "HCI refers to the interdisciplinary field of study focused on the design, evaluation, and implementation of interactive computing systems for human use, emphasizing the interfaces between people and computers.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-2",
          "local_name": "HCI",
          "local_types": [
            "field of study",
            "discipline"
          ],
          "iri": "Entity-hci-Mention-1"
        }
      ],
      "relevance": 0.5771484375
    },
    "Entity-hand__forearm__and_upper_arm_gesture": {
      "node_id": "hand__forearm__and_upper_arm_gesture",
      "disambiguation_index": 0,
      "label": "hand, forearm, and upper arm gestures",
      "aliases": [
        "hand, forearm, and upper arm gestures"
      ],
      "types": [
        "gesture",
        "specific gestures"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Hand, forearm, and upper arm gestures refer to the movements and positions of the hands and arms that convey meaning or facilitate communication.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-2",
          "local_name": "hand, forearm, and upper arm gestures",
          "local_types": [
            "gesture",
            "specific gestures"
          ],
          "iri": "Entity-hand__forearm__and_upper_arm_gesture-Mention-1"
        }
      ],
      "relevance": 0.5771484375
    },
    "Entity-support_for_both_of_these_representation": {
      "node_id": "support_for_both_of_these_representation",
      "disambiguation_index": 0,
      "label": "support for both of these representations",
      "aliases": [
        "support for both of these representations"
      ],
      "types": [
        "support",
        "representation"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'support for both of these representations' refers to the capability of the HDGI ontology to accommodate two different methods of representing the rotation of a pose in 3D space\u2014either using Euler angles or quaternions\u2014thereby enhancing flexibility in modeling data from various gesture recognition devices.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-18",
          "local_name": "support for both of these representations",
          "local_types": [
            "support",
            "representation"
          ],
          "iri": "Entity-support_for_both_of_these_representation-Mention-1"
        }
      ],
      "relevance": 0.57666015625
    },
    "Entity-external_ontology": {
      "node_id": "external_ontology",
      "disambiguation_index": 0,
      "label": "external ontologies",
      "aliases": [
        "other external ontologies",
        "external ontologies"
      ],
      "types": [
        "ontology",
        "knowledge representation",
        "framework",
        "knowledge base"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "External ontologies refer to existing ontological frameworks and knowledge representations that are utilized for mapping and aligning concepts within the HDGI ontology, allowing for interoperability and integration with other semantic systems.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "external ontologies",
          "local_types": [
            "ontology",
            "knowledge base"
          ],
          "iri": "Entity-external_ontology-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-2-Sentence-2",
          "local_name": "external ontologies",
          "local_types": [
            "ontology",
            "knowledge representation"
          ],
          "iri": "Entity-external_ontology-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "external ontologies",
          "local_types": [
            "ontology",
            "framework",
            "knowledge base"
          ],
          "iri": "Entity-external_ontology-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-8",
          "local_name": "external ontologies",
          "local_types": [
            "ontology",
            "knowledge base"
          ],
          "iri": "Entity-external_ontology-Mention-4"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-8",
          "local_name": "other external ontologies",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-external_ontology-Mention-5"
        }
      ],
      "relevance": 0.576171875
    },
    "Entity-start__menu": {
      "node_id": "start__menu",
      "disambiguation_index": 0,
      "label": "'start' menu",
      "aliases": [
        "'start' menu"
      ],
      "types": [
        "menu"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The 'start' menu refers to a user interface element in computing devices, such as the Microsoft HoloLens, that provides access to applications, settings, and system functions, typically activated through specific gestures or commands.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-1",
          "local_name": "'start' menu",
          "local_types": [
            "menu"
          ],
          "iri": "Entity-start__menu-Mention-1"
        }
      ],
      "relevance": 0.57568359375
    },
    "Entity-villarreal-narvaez_et_al_.": {
      "node_id": "villarreal-narvaez_et_al_.",
      "disambiguation_index": 0,
      "label": "Villarreal-Narvaez et al.",
      "aliases": [
        "Villarreal-Narvaez et al."
      ],
      "types": [
        "author",
        "researcher"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Villarreal-Narvaez et al. refers to a group of researchers who conducted a recent survey on gesture interactions, highlighting that most gestures are performed using the upper limbs of the human body.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "Villarreal-Narvaez et al.",
          "local_types": [
            "author",
            "researcher"
          ],
          "iri": "Entity-villarreal-narvaez_et_al_.-Mention-1"
        }
      ],
      "relevance": 0.5751953125
    },
    "Entity-one_approach": {
      "node_id": "one_approach",
      "disambiguation_index": 0,
      "label": "One approach",
      "aliases": [
        "One approach"
      ],
      "types": [
        "method"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "One approach refers to the method of defining taxonomies for gesture vocabularies, which allows designers and manufacturers to utilize standardized definitions in the development of gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-1",
          "local_name": "One approach",
          "local_types": [
            "method"
          ],
          "iri": "Entity-one_approach-Mention-1"
        }
      ],
      "relevance": 0.5751953125
    },
    "Entity-sosa__platform": {
      "node_id": "sosa__platform",
      "disambiguation_index": 0,
      "label": "sosa:Platform",
      "aliases": [
        "sosa:Platform"
      ],
      "types": [
        "ontology class",
        "concept",
        "ontology term",
        "platform",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "sosa:Platform refers to an ontology class within the SOSA (Sensor, Observation, Sample, and Actuator) ontology that serves as a foundational concept for modeling devices in the context of sensor networks and their interactions with human gestures.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-9",
          "local_name": "sosa:Platform",
          "local_types": [
            "ontology class",
            "concept",
            "ontology term",
            "platform",
            "entity",
            "class"
          ],
          "iri": "Entity-sosa__platform-Mention-1"
        }
      ],
      "relevance": 0.57470703125
    },
    "Entity-design": {
      "node_id": "design",
      "disambiguation_index": 0,
      "label": "Design",
      "aliases": [
        "design",
        "Design"
      ],
      "types": [
        "discipline",
        "field of study",
        "component",
        "concept",
        "methodology",
        "field"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Design refers to the established principles and practices in Human-Computer Interaction that guide the creation and evaluation of user interfaces and experiences.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-2",
          "local_name": "Design",
          "local_types": [
            "discipline",
            "field",
            "field of study"
          ],
          "iri": "Entity-design-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "design",
          "local_types": [
            "methodology",
            "concept",
            "component"
          ],
          "iri": "Entity-design-Mention-2"
        }
      ],
      "relevance": 0.57421875
    },
    "Entity-xposition": {
      "node_id": "xposition",
      "disambiguation_index": 0,
      "label": "xPosition",
      "aliases": [
        "xPosition",
        "hdgi:xPosition"
      ],
      "types": [
        "spatial attribute",
        "attribute",
        "coordinate",
        "spatial coordinate",
        "concept",
        "data attribute",
        "spatial position",
        "position",
        "variable",
        "value"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "xPosition refers to a spatial attribute representing the horizontal coordinate of a pose in a 3D space within the HDGI ontology, which is used to define the position of body parts during gesture interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-5",
          "local_name": "xPosition",
          "local_types": [
            "spatial attribute",
            "coordinate",
            "position",
            "variable",
            "value"
          ],
          "iri": "Entity-xposition-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-5",
          "local_name": "xPosition",
          "local_types": [
            "coordinate",
            "spatial attribute"
          ],
          "iri": "Entity-xposition-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-10",
          "local_name": "hdgi:xPosition",
          "local_types": [
            "position",
            "attribute",
            "coordinate"
          ],
          "iri": "Entity-xposition-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-5",
          "local_name": "hdgi:xPosition",
          "local_types": [
            "attribute",
            "coordinate",
            "spatial coordinate",
            "concept",
            "data attribute",
            "spatial position",
            "position"
          ],
          "iri": "Entity-xposition-Mention-4"
        }
      ],
      "relevance": 0.57421875
    },
    "Entity-a_certain_task": {
      "node_id": "a_certain_task",
      "disambiguation_index": 0,
      "label": "a certain task",
      "aliases": [
        "a certain task"
      ],
      "types": [
        "task"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'a certain task' refers to the specific action or function that a user intends to accomplish through interaction with a gesture-based interface, which may vary based on individual user expectations and the design of the system.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-2",
          "local_name": "a certain task",
          "local_types": [
            "task"
          ],
          "iri": "Entity-a_certain_task-Mention-1"
        }
      ],
      "relevance": 0.57421875
    },
    "Entity-effect": {
      "node_id": "effect",
      "disambiguation_index": 0,
      "label": "effect",
      "aliases": [
        "effect"
      ],
      "types": [
        "outcome",
        "result"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'effect' refers to the desired outcome or referent of a gesture, which is the specific action or result that a user intends to achieve through their gesture in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-2",
          "local_name": "effect",
          "local_types": [
            "outcome",
            "result"
          ],
          "iri": "Entity-effect-Mention-1"
        }
      ],
      "relevance": 0.57373046875
    },
    "Entity-atomic_hdgi__movement": {
      "node_id": "atomic_hdgi__movement",
      "disambiguation_index": 0,
      "label": "atomic hdgi:Movement",
      "aliases": [
        "atomic hdgi:Movement"
      ],
      "types": [
        "movement"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'atomic hdgi:Movement' refers to a fundamental component of a dynamic gesture in the HDGI ontology, representing a specific movement associated with a single body part that occurs between a defined start and end pose.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "atomic hdgi:Movement",
          "local_types": [
            "movement"
          ],
          "iri": "Entity-atomic_hdgi__movement-Mention-1"
        }
      ],
      "relevance": 0.57373046875
    },
    "Entity-one_or_more_pose": {
      "node_id": "one_or_more_pose",
      "disambiguation_index": 0,
      "label": "one or more poses",
      "aliases": [
        "one or more poses"
      ],
      "types": [
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'one or more poses' refers to the distinct configurations or positions of the human body, particularly the upper limb, that can be combined with movements to form a gesture in the context of Human Device Interaction.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-9",
          "local_name": "one or more poses",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-one_or_more_pose-Mention-1"
        }
      ],
      "relevance": 0.57373046875
    },
    "Entity-hdgi__yaxisdirection": {
      "node_id": "hdgi__yaxisdirection",
      "disambiguation_index": 0,
      "label": "hdgi:yAxisDirection",
      "aliases": [
        "hdgi:yAxisDirection"
      ],
      "types": [
        "attribute",
        "direction",
        "concept",
        "enum",
        "data attribute",
        "axis direction",
        "directional reference"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:yAxisDirection refers to a predefined directional attribute within the HDGI ontology that specifies the vertical orientation of an axis, which can be either 'upward' or 'downward'.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "hdgi:yAxisDirection",
          "local_types": [
            "attribute",
            "direction",
            "concept",
            "enum",
            "data attribute",
            "axis direction",
            "directional reference"
          ],
          "iri": "Entity-hdgi__yaxisdirection-Mention-1"
        }
      ],
      "relevance": 0.5732421875
    },
    "Entity-it_referent": {
      "node_id": "it_referent",
      "disambiguation_index": 0,
      "label": "its referents",
      "aliases": [
        "its referents"
      ],
      "types": [
        "referent"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'its referents' refers to the specific effects or actions that a gesture is intended to convey or trigger in a gesture-based interaction system.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-2",
          "local_name": "its referents",
          "local_types": [
            "referent"
          ],
          "iri": "Entity-it_referent-Mention-1"
        }
      ],
      "relevance": 0.5732421875
    },
    "Entity-human-computer_interaction": {
      "node_id": "human-computer_interaction",
      "disambiguation_index": 0,
      "label": "Human-Computer Interaction",
      "aliases": [
        "Human-Computer Interaction",
        "Human Computer Interaction"
      ],
      "types": [
        "discipline",
        "field",
        "field of study"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Human-Computer Interaction is a multidisciplinary field that studies the design and use of computer technology, focusing particularly on the interfaces between people (users) and computers.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-2",
          "local_name": "Human-Computer Interaction",
          "local_types": [
            "discipline",
            "field of study",
            "field"
          ],
          "iri": "Entity-human-computer_interaction-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-2",
          "local_name": "Human Computer Interaction",
          "local_types": [
            "discipline",
            "field",
            "field of study"
          ],
          "iri": "Entity-human-computer_interaction-Mention-2"
        }
      ],
      "relevance": 0.57275390625
    },
    "Entity-an_impressive_amount_of_knowledge": {
      "node_id": "an_impressive_amount_of_knowledge",
      "disambiguation_index": 0,
      "label": "an impressive amount of knowledge",
      "aliases": [
        "an impressive amount of knowledge"
      ],
      "types": [
        "knowledge"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'an impressive amount of knowledge' refers to the extensive but disorganized information and insights gained from Gesture Elicitation Studies (GES) regarding user preferences and effective gesture vocabularies for human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-5",
          "local_name": "an impressive amount of knowledge",
          "local_types": [
            "knowledge"
          ],
          "iri": "Entity-an_impressive_amount_of_knowledge-Mention-1"
        }
      ],
      "relevance": 0.57275390625
    },
    "Entity-blind": {
      "node_id": "blind",
      "disambiguation_index": 0,
      "label": "blinds",
      "aliases": [
        "blinds"
      ],
      "types": [
        "product",
        "device",
        "home decor",
        "home appliance",
        "blinds"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "In this context, 'blinds' refers to a type of window covering that can be adjusted to control light and privacy, which is included in the study of gesture recognition for controlling devices like televisions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "blinds",
          "local_types": [
            "product",
            "device",
            "home decor",
            "home appliance",
            "blinds"
          ],
          "iri": "Entity-blind-Mention-1"
        }
      ],
      "relevance": 0.572265625
    },
    "Entity-concept": {
      "node_id": "concept",
      "disambiguation_index": 0,
      "label": "concepts",
      "aliases": [
        "concepts"
      ],
      "types": [
        "theoretical construct",
        "idea",
        "abstract idea"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'concepts' refers to the various ideas, features, and attributes associated with arm-based gestures that the ontology aims to systematically analyze and describe.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-2",
          "local_name": "concepts",
          "local_types": [
            "theoretical construct",
            "idea",
            "abstract idea"
          ],
          "iri": "Entity-concept-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-5",
          "local_name": "concepts",
          "local_types": [
            "idea",
            "theoretical construct"
          ],
          "iri": "Entity-concept-Mention-2"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "concepts",
          "local_types": [
            "theoretical construct"
          ],
          "iri": "Entity-concept-Mention-3"
        }
      ],
      "relevance": 0.572265625
    },
    "Entity-action": {
      "node_id": "action",
      "disambiguation_index": 0,
      "label": "action",
      "aliases": [
        "action",
        "actions"
      ],
      "types": [
        "process",
        "activity",
        "behavior"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'action' refers to the desired effect or outcome that a user aims to achieve through the performance of a specific gesture in a gesture-controlled interface.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-2",
          "local_name": "action",
          "local_types": [
            "activity",
            "process"
          ],
          "iri": "Entity-action-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "actions",
          "local_types": [
            "behavior",
            "activity"
          ],
          "iri": "Entity-action-Mention-2"
        }
      ],
      "relevance": 0.57177734375
    },
    "Entity-different_expectation": {
      "node_id": "different_expectation",
      "disambiguation_index": 0,
      "label": "different expectations",
      "aliases": [
        "different expectations"
      ],
      "types": [
        "expectation"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Different expectations refer to the varying anticipations users have regarding the interaction methods and gestures they should employ when using an interface, which can lead to confusion when these expectations do not align with the manufacturer's design choices.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-2",
          "local_name": "different expectations",
          "local_types": [
            "expectation"
          ],
          "iri": "Entity-different_expectation-Mention-1"
        }
      ],
      "relevance": 0.57080078125
    },
    "Entity-binary_or_a_few_choice": {
      "node_id": "binary_or_a_few_choice",
      "disambiguation_index": 0,
      "label": "binary or a few choices",
      "aliases": [
        "binary or a few choices"
      ],
      "types": [
        "choice"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'binary or a few choices' refers to the limited options available for gesture selection in gesture-based systems, where users are often restricted to a small set of predefined gestures determined by the system designers.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-4",
          "local_name": "binary or a few choices",
          "local_types": [
            "choice"
          ],
          "iri": "Entity-binary_or_a_few_choice-Mention-1"
        }
      ],
      "relevance": 0.5703125
    },
    "Entity-specific_property": {
      "node_id": "specific_property",
      "disambiguation_index": 0,
      "label": "specific property",
      "aliases": [
        "specific property"
      ],
      "types": [
        "property"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'specific property' refers to a defined characteristic or attribute of gestures that is subject to universal and existential class restrictions, ensuring that the range of the property is accurately asserted only for instances of that property within a specified class.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "specific property",
          "local_types": [
            "property"
          ],
          "iri": "Entity-specific_property-Mention-1"
        }
      ],
      "relevance": 0.5703125
    },
    "Entity-augmented_reality": {
      "node_id": "augmented_reality",
      "disambiguation_index": 0,
      "label": "Augmented Reality",
      "aliases": [
        "Augmented Reality",
        "Augmented Reality (AR)"
      ],
      "types": [
        "immersive technology",
        "technology",
        "concept",
        "virtual environment",
        "AR",
        "virtual experience"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Augmented Reality is a technology that overlays digital information and virtual objects onto the real world, enhancing the user's perception and interaction with their environment.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "Augmented Reality",
          "local_types": [
            "technology",
            "concept"
          ],
          "iri": "Entity-augmented_reality-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "Augmented Reality",
          "local_types": [
            "technology",
            "concept"
          ],
          "iri": "Entity-augmented_reality-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "Augmented Reality (AR)",
          "local_types": [
            "virtual environment",
            "AR",
            "technology",
            "virtual experience"
          ],
          "iri": "Entity-augmented_reality-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "Augmented Reality (AR)",
          "local_types": [
            "immersive technology",
            "technology",
            "virtual environment",
            "AR",
            "virtual experience"
          ],
          "iri": "Entity-augmented_reality-Mention-4"
        }
      ],
      "relevance": 0.56982421875
    },
    "Entity-hdgi__forearm": {
      "node_id": "hdgi__forearm",
      "disambiguation_index": 0,
      "label": "hdgi:Forearm",
      "aliases": [
        "hdgi:Forearm"
      ],
      "types": [
        "upper limb",
        "anatomy",
        "anatomical structure",
        "body part",
        "concept",
        "subclass",
        "model",
        "pose",
        "pose representation",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Forearm refers to a defined class within the ontology that represents the anatomical structure of the human forearm, serving as a fundamental component of the upper limb region in the context of human-device gesture interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "hdgi:Forearm",
          "local_types": [
            "upper limb",
            "anatomy",
            "anatomical structure",
            "body part",
            "class"
          ],
          "iri": "Entity-hdgi__forearm-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-5",
          "local_name": "hdgi:Forearm",
          "local_types": [
            "anatomical structure",
            "body part",
            "subclass",
            "model",
            "pose",
            "pose representation"
          ],
          "iri": "Entity-hdgi__forearm-Mention-2"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-2",
          "local_name": "hdgi:Forearm",
          "local_types": [
            "anatomy",
            "concept",
            "body part"
          ],
          "iri": "Entity-hdgi__forearm-Mention-3"
        }
      ],
      "relevance": 0.56982421875
    },
    "Entity-hdgi__timestamp": {
      "node_id": "hdgi__timestamp",
      "disambiguation_index": 0,
      "label": "hdgi:timestamp",
      "aliases": [
        "hdgi:timestamp difference",
        "hdgi:timestamp"
      ],
      "types": [
        "time reference",
        "attribute",
        "concept",
        "data type",
        "data attribute",
        "measurement",
        "entity",
        "timestamp",
        "time representation",
        "time measurement",
        "time"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:timestamp refers to a specific point in time associated with a pose in the HDGI ontology, indicating when a particular body part's position and rotation are recorded during a gesture.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "hdgi:timestamp",
          "local_types": [
            "time reference",
            "concept",
            "data type",
            "data attribute",
            "entity",
            "timestamp",
            "time representation",
            "time"
          ],
          "iri": "Entity-hdgi__timestamp-Mention-1"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-6",
          "local_name": "hdgi:timestamp",
          "local_types": [
            "attribute",
            "concept",
            "data type",
            "timestamp",
            "time measurement"
          ],
          "iri": "Entity-hdgi__timestamp-Mention-2"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-6",
          "local_name": "hdgi:timestamp difference",
          "local_types": [
            "measurement",
            "timestamp"
          ],
          "iri": "Entity-hdgi__timestamp-Mention-3"
        }
      ],
      "relevance": 0.56982421875
    },
    "Entity-their_other_hand": {
      "node_id": "their_other_hand",
      "disambiguation_index": 0,
      "label": "their other hand",
      "aliases": [
        "their other hand"
      ],
      "types": [
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their other hand' refers to the second hand of a user, which can be used to perform gestures or actions, such as tapping an icon, in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-3",
          "local_name": "their other hand",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-their_other_hand-Mention-1"
        }
      ],
      "relevance": 0.56982421875
    },
    "Entity-user_experience__ux_": {
      "node_id": "user_experience__ux_",
      "disambiguation_index": 0,
      "label": "User Experience (UX)",
      "aliases": [
        "User Experience (UX)",
        "user experience (UX)"
      ],
      "types": [
        "field of study",
        "user experience",
        "design principle",
        "concept",
        "design discipline",
        "UX",
        "design concept",
        "User Experience",
        "user-centered design",
        "experience",
        "field"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "User Experience (UX) refers to the overall experience and satisfaction a user has when interacting with a product, system, or service, encompassing aspects such as usability, accessibility, and pleasure in the interaction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-2",
          "local_name": "User Experience (UX)",
          "local_types": [
            "field of study",
            "user experience",
            "design principle",
            "concept",
            "design discipline",
            "UX",
            "User Experience",
            "field"
          ],
          "iri": "Entity-user_experience__ux_-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-2",
          "local_name": "user experience (UX)",
          "local_types": [
            "field of study",
            "design principle",
            "concept",
            "UX",
            "design concept",
            "user-centered design",
            "experience"
          ],
          "iri": "Entity-user_experience__ux_-Mention-2"
        }
      ],
      "relevance": 0.5693359375
    },
    "Entity-numeric_terminology": {
      "node_id": "numeric_terminology",
      "disambiguation_index": 0,
      "label": "numeric terminology",
      "aliases": [
        "numeric terminology"
      ],
      "types": [
        "language",
        "terminology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Numeric terminology refers to a system of numerical representations and definitions used in the context of gesture notation, which can be complex and difficult to interpret without a specific reference guide.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-10",
          "local_name": "numeric terminology",
          "local_types": [
            "language",
            "terminology"
          ],
          "iri": "Entity-numeric_terminology-Mention-1"
        }
      ],
      "relevance": 0.56884765625
    },
    "Entity-hdgi__zrotation": {
      "node_id": "hdgi__zrotation",
      "disambiguation_index": 0,
      "label": "hdgi:zRotation",
      "aliases": [
        "hdgi:zRotation"
      ],
      "types": [
        "rotation component",
        "attribute",
        "concept",
        "rotation axis",
        "data type",
        "data attribute",
        "rotation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:zRotation refers to the yaw component of the rotation of a pose in a 3D space, which can be represented using either Euler angles or quaternions in the context of gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "hdgi:zRotation",
          "local_types": [
            "rotation component",
            "attribute",
            "concept",
            "rotation axis",
            "data type",
            "data attribute",
            "rotation"
          ],
          "iri": "Entity-hdgi__zrotation-Mention-1"
        }
      ],
      "relevance": 0.56884765625
    },
    "Entity-the_capability_of_identifying_the_relationship": {
      "node_id": "the_capability_of_identifying_the_relationship",
      "disambiguation_index": 0,
      "label": "the capability of identifying the relationship",
      "aliases": [
        "the capability of identifying the relationship"
      ],
      "types": [
        "capability",
        "relationship"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The capability of identifying the relationship refers to the ability to understand and define the connections and meanings between various gestures beyond their predefined actions, facilitating a more nuanced and flexible approach to gesture recognition in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "the capability of identifying the relationship",
          "local_types": [
            "capability",
            "relationship"
          ],
          "iri": "Entity-the_capability_of_identifying_the_relationship-Mention-1"
        }
      ],
      "relevance": 0.56884765625
    },
    "Entity-rotation_": {
      "node_id": "rotation_",
      "disambiguation_index": 0,
      "label": "'rotation'",
      "aliases": [
        "'rotation'"
      ],
      "types": [
        "attribute"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'rotation' refers to the representation of the orientation of a pose in 3D space, which can be described using either Euler angles (yaw, pitch, roll) or quaternions, allowing for flexibility in modeling data from various gesture recognition systems.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-4",
          "local_name": "'rotation'",
          "local_types": [
            "attribute"
          ],
          "iri": "Entity-rotation_-Mention-1"
        }
      ],
      "relevance": 0.56884765625
    },
    "Entity-received_data": {
      "node_id": "received_data",
      "disambiguation_index": 0,
      "label": "received data",
      "aliases": [
        "received data"
      ],
      "types": [
        "data"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Received data refers to the information pertaining to the position and rotation of body parts captured during gesture recognition, which can be modeled using either Euler angles or quaternions in the context of the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "received data",
          "local_types": [
            "data"
          ],
          "iri": "Entity-received_data-Mention-1"
        }
      ],
      "relevance": 0.56884765625
    },
    "Entity-an_initial_step": {
      "node_id": "an_initial_step",
      "disambiguation_index": 0,
      "label": "an initial step",
      "aliases": [
        "an initial step"
      ],
      "types": [
        "step",
        "process"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "An initial step refers to the foundational action taken to develop a comprehensive knowledge base for human device gesture interactions, aimed at enhancing user experience.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-1-Sentence-2",
          "local_name": "an initial step",
          "local_types": [
            "step",
            "process"
          ],
          "iri": "Entity-an_initial_step-Mention-1"
        }
      ],
      "relevance": 0.56884765625
    },
    "Entity-semantic_sensor_network": {
      "node_id": "semantic_sensor_network",
      "disambiguation_index": 0,
      "label": "Semantic Sensor Network",
      "aliases": [
        "Semantic Sensor Network"
      ],
      "types": [
        "ontology",
        "framework"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The Semantic Sensor Network is an ontology and framework designed to facilitate the integration and interoperability of sensor data through semantic web technologies.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-10",
          "local_name": "Semantic Sensor Network",
          "local_types": [
            "ontology",
            "framework"
          ],
          "iri": "Entity-semantic_sensor_network-Mention-1"
        }
      ],
      "relevance": 0.568359375
    },
    "Entity-observed_property": {
      "node_id": "observed_property",
      "disambiguation_index": 0,
      "label": "observed properties",
      "aliases": [
        "observed properties"
      ],
      "types": [
        "attribute",
        "characteristic",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'observed properties' refers to the characteristics or features that sensors measure and report within the context of the Semantic Sensor Network (SSN) ontology.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-11",
          "local_name": "observed properties",
          "local_types": [
            "attribute",
            "characteristic",
            "property"
          ],
          "iri": "Entity-observed_property-Mention-1"
        }
      ],
      "relevance": 0.568359375
    },
    "Entity-different_sdks-systems": {
      "node_id": "different_sdks-systems",
      "disambiguation_index": 0,
      "label": "different SDKs-systems",
      "aliases": [
        "different SDKs-systems"
      ],
      "types": [
        "system",
        "SDK"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Different SDKs-systems refer to various software development kits and their associated systems that may implement distinct coordinate systems and data representations, leading to potential inconsistencies in gesture recognition and modeling.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-12",
          "local_name": "different SDKs-systems",
          "local_types": [
            "system",
            "SDK"
          ],
          "iri": "Entity-different_sdks-systems-Mention-1"
        }
      ],
      "relevance": 0.568359375
    },
    "Entity-palm_and_finger_position": {
      "node_id": "palm_and_finger_position",
      "disambiguation_index": 0,
      "label": "Palm and finger positions",
      "aliases": [
        "Palm and finger positions"
      ],
      "types": [
        "position",
        "anatomy",
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Palm and finger positions refer to the specific spatial orientations and placements of the palm and fingers of a hand, which are defined in relation to the wrist joint within a 3D coordinate system for the purpose of gesture recognition in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-9",
          "local_name": "Palm and finger positions",
          "local_types": [
            "position",
            "anatomy",
            "body part"
          ],
          "iri": "Entity-palm_and_finger_position-Mention-1"
        }
      ],
      "relevance": 0.56787109375
    },
    "Entity-khairunizam_et_al_.": {
      "node_id": "khairunizam_et_al_.",
      "disambiguation_index": 0,
      "label": "Khairunizam et al.",
      "aliases": [
        "Khairunizam",
        "Khairunizam et al."
      ],
      "types": [
        "author",
        "researcher",
        "authors"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Khairunizam et al. refers to a group of researchers who conducted a study focused on enhancing the recognition of arm gestures by computational systems, utilizing motion capture technology to analyze geometrical gestures.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-1",
          "local_name": "Khairunizam et al.",
          "local_types": [
            "author",
            "authors",
            "researcher"
          ],
          "iri": "Entity-khairunizam_et_al_.-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-1",
          "local_name": "Khairunizam",
          "local_types": [
            "author",
            "researcher"
          ],
          "iri": "Entity-khairunizam_et_al_.-Mention-2"
        }
      ],
      "relevance": 0.56689453125
    },
    "Entity-intrinsic_and_extrinsic_property": {
      "node_id": "intrinsic_and_extrinsic_property",
      "disambiguation_index": 0,
      "label": "intrinsic and extrinsic properties",
      "aliases": [
        "intrinsic and extrinsic properties"
      ],
      "types": [
        "property"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Intrinsic and extrinsic properties refer to the inherent characteristics and external factors associated with body-based contextual gestures in the context of gesture recognition and interaction design.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "intrinsic and extrinsic properties",
          "local_types": [
            "property"
          ],
          "iri": "Entity-intrinsic_and_extrinsic_property-Mention-1"
        }
      ],
      "relevance": 0.56640625
    },
    "Entity-the_face": {
      "node_id": "the_face",
      "disambiguation_index": 0,
      "label": "the face",
      "aliases": [
        "the face"
      ],
      "types": [
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The face refers to the front part of the human head, which is involved in gesture interactions that express user intentions and facilitate communication with devices or systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "the face",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-the_face-Mention-1"
        }
      ],
      "relevance": 0.56591796875
    },
    "Entity-ar": {
      "node_id": "ar",
      "disambiguation_index": 0,
      "label": "AR",
      "aliases": [
        "AR"
      ],
      "types": [
        "immersive technology",
        "abbreviation",
        "technology",
        "augmented reality",
        "field"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "AR refers to Augmented Reality, an immersive technology that enhances the real-world environment with digital information and interactive elements, particularly in the context of gesture-based human-computer interaction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-2",
          "local_name": "AR",
          "local_types": [
            "immersive technology",
            "abbreviation",
            "technology",
            "augmented reality",
            "field"
          ],
          "iri": "Entity-ar-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "AR",
          "local_types": [
            "technology",
            "field"
          ],
          "iri": "Entity-ar-Mention-2"
        }
      ],
      "relevance": 0.5654296875
    },
    "Entity-detailed_representation_of_the_hand": {
      "node_id": "detailed_representation_of_the_hand",
      "disambiguation_index": 0,
      "label": "detailed representation of the hand",
      "aliases": [
        "detailed representation of the hand",
        "a detailed representation of the hand"
      ],
      "types": [
        "hand",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'detailed representation of the hand' refers to a comprehensive and precise depiction of the hand's structure, movements, and gestures, which is essential for accurately modeling hand gestures in gesture-controlled interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "detailed representation of the hand",
          "local_types": [
            "representation",
            "hand"
          ],
          "iri": "Entity-detailed_representation_of_the_hand-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "a detailed representation of the hand",
          "local_types": [
            "representation",
            "hand"
          ],
          "iri": "Entity-detailed_representation_of_the_hand-Mention-2"
        }
      ],
      "relevance": 0.5654296875
    },
    "Entity-different_coordinate_system": {
      "node_id": "different_coordinate_system",
      "disambiguation_index": 0,
      "label": "different coordinate systems",
      "aliases": [
        "different coordinate systems"
      ],
      "types": [
        "coordinate system"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Different coordinate systems refer to the various frameworks used by different software development kits (SDKs) to define the spatial positioning and orientation of objects in 3D space, which can lead to inconsistencies in gesture recognition and representation across devices.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-12",
          "local_name": "different coordinate systems",
          "local_types": [
            "coordinate system"
          ],
          "iri": "Entity-different_coordinate_system-Mention-1"
        }
      ],
      "relevance": 0.56494140625
    },
    "Entity-pinch_their_thumb_and_index_finger_together": {
      "node_id": "pinch_their_thumb_and_index_finger_together",
      "disambiguation_index": 0,
      "label": "pinch their thumb and index finger together",
      "aliases": [
        "pinch their thumb and index finger together"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'pinch their thumb and index finger together' refers to a specific gesture used in the HoloLens 2 device, where the user performs this action to open the start menu while looking at an icon displayed near their wrist.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "pinch their thumb and index finger together",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-pinch_their_thumb_and_index_finger_together-Mention-1"
        }
      ],
      "relevance": 0.564453125
    },
    "Entity-infinite_set_of_concept__feature__attribute__and_relationship": {
      "node_id": "infinite_set_of_concept__feature__attribute__and_relationship",
      "disambiguation_index": 0,
      "label": "infinite set of concepts, features, attributes, and relationships",
      "aliases": [
        "infinite set of concepts, features, attributes, and relationships"
      ],
      "types": [
        "concept",
        "feature",
        "attribute",
        "relationship"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'infinite set of concepts, features, attributes, and relationships' refers to the vast and potentially limitless variety of elements that can be associated with arm-based gestures, which the authors of the paper choose not to model in their ontology.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-2",
          "local_name": "infinite set of concepts, features, attributes, and relationships",
          "local_types": [
            "concept",
            "feature",
            "attribute",
            "relationship"
          ],
          "iri": "Entity-infinite_set_of_concept__feature__attribute__and_relationship-Mention-1"
        }
      ],
      "relevance": 0.564453125
    },
    "Entity-the_movement_of_the_user__s_right_arm": {
      "node_id": "the_movement_of_the_user__s_right_arm",
      "disambiguation_index": 0,
      "label": "the movement of the user\u2019s right arm",
      "aliases": [
        "the movement of the user\u2019s right arm"
      ],
      "types": [
        "movement",
        "body part",
        "arm"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The movement of the user\u2019s right arm refers to the specific physical actions and positions of the right arm as captured and analyzed during the performance of arm gestures, particularly in the context of gesture recognition studies utilizing motion capture technology.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "the movement of the user\u2019s right arm",
          "local_types": [
            "movement",
            "body part",
            "arm"
          ],
          "iri": "Entity-the_movement_of_the_user__s_right_arm-Mention-1"
        }
      ],
      "relevance": 0.564453125
    },
    "Entity-potential_pose": {
      "node_id": "potential_pose",
      "disambiguation_index": 0,
      "label": "potential pose",
      "aliases": [
        "potential pose"
      ],
      "types": [
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A potential pose refers to a specific configuration or arrangement of a body part that can be realized in a gesture-controlled interface, serving as a foundational element in the modeling of static gestures within the Human Device Gesture Interaction Ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-3",
          "local_name": "potential pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-potential_pose-Mention-1"
        }
      ],
      "relevance": 0.564453125
    },
    "Entity-this_view": {
      "node_id": "this_view",
      "disambiguation_index": 0,
      "label": "this view",
      "aliases": [
        "this view"
      ],
      "types": [
        "concept"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This view refers to the established understanding of affordance in Human Computer Interaction and Design, which emphasizes the perceived and actual properties of objects that determine their potential uses by users.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-2",
          "local_name": "this view",
          "local_types": [
            "concept"
          ],
          "iri": "Entity-this_view-Mention-1"
        }
      ],
      "relevance": 0.56396484375
    },
    "Entity-example_model": {
      "node_id": "example_model",
      "disambiguation_index": 0,
      "label": "example models",
      "aliases": [
        "example models"
      ],
      "types": [
        "model",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'example models' refer to specific representations of the start and end poses of the right forearm and right palm in the context of gesture modeling within the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "example models",
          "local_types": [
            "model",
            "representation"
          ],
          "iri": "Entity-example_model-Mention-1"
        }
      ],
      "relevance": 0.5634765625
    },
    "Entity-hdgi__pose_class": {
      "node_id": "hdgi__pose_class",
      "disambiguation_index": 0,
      "label": "hdgi:Pose class",
      "aliases": [
        "hdgi:Pose class"
      ],
      "types": [
        "class"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The hdgi:Pose class defines the precise spatial configuration of a gesture in three-dimensional space by specifying its position and rotation, allowing for the representation of static gestures involving individual body parts.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-4",
          "local_name": "hdgi:Pose class",
          "local_types": [
            "class"
          ],
          "iri": "Entity-hdgi__pose_class-Mention-1"
        }
      ],
      "relevance": 0.5634765625
    },
    "Entity-user_experience__mbux_": {
      "node_id": "user_experience__mbux_",
      "disambiguation_index": 0,
      "label": "User Experience (MBUX)",
      "aliases": [
        "User Experience (MBUX)",
        "Mercedes-Benz\u2019 User Experience (MBUX)",
        "Mercedes-Benz\u2019 User Experience (MBUX) multimedia infotainment system"
      ],
      "types": [
        "infotainment system",
        "product",
        "technology",
        "system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "User Experience (MBUX) is a multimedia infotainment system developed by Mercedes-Benz that enhances user interaction through advanced touch and gesture controls.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "User Experience (MBUX)",
          "local_types": [
            "infotainment system",
            "product",
            "technology"
          ],
          "iri": "Entity-user_experience__mbux_-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "Mercedes-Benz\u2019 User Experience (MBUX)",
          "local_types": [
            "technology",
            "system"
          ],
          "iri": "Entity-user_experience__mbux_-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "Mercedes-Benz\u2019 User Experience (MBUX) multimedia infotainment system",
          "local_types": [
            "infotainment system",
            "product"
          ],
          "iri": "Entity-user_experience__mbux_-Mention-3"
        }
      ],
      "relevance": 0.56298828125
    },
    "Entity-desired_effect_of_an_action": {
      "node_id": "desired_effect_of_an_action",
      "disambiguation_index": 0,
      "label": "desired effect of an action",
      "aliases": [
        "the desired effect of an action",
        "desired effect of an action"
      ],
      "types": [
        "outcome",
        "action",
        "result",
        "effect"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'desired effect of an action' refers to the specific outcome or referent that a gesture is intended to achieve in the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "desired effect of an action",
          "local_types": [
            "outcome",
            "result"
          ],
          "iri": "Entity-desired_effect_of_an_action-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "the desired effect of an action",
          "local_types": [
            "action",
            "effect"
          ],
          "iri": "Entity-desired_effect_of_an_action-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-2",
          "local_name": "the desired effect of an action",
          "local_types": [
            "action",
            "effect"
          ],
          "iri": "Entity-desired_effect_of_an_action-Mention-3"
        }
      ],
      "relevance": 0.56298828125
    },
    "Entity-existing_knowledge": {
      "node_id": "existing_knowledge",
      "disambiguation_index": 0,
      "label": "existing knowledge",
      "aliases": [
        "existing knowledge"
      ],
      "types": [
        "knowledge"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Existing knowledge refers to the accumulated understanding and data derived from previous Gesture Elicitation Studies (GES) that can be utilized to inform and enhance the development of gesture vocabularies and their mappings to referents in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-4",
          "local_name": "existing knowledge",
          "local_types": [
            "knowledge"
          ],
          "iri": "Entity-existing_knowledge-Mention-1"
        }
      ],
      "relevance": 0.5625
    },
    "Entity-each_body_part": {
      "node_id": "each_body_part",
      "disambiguation_index": 0,
      "label": "Each body part",
      "aliases": [
        "each body part",
        "Each body part"
      ],
      "types": [
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Each body part refers to the individual anatomical segments of the human body that can be involved in a pose during gesture interactions, as defined within the context of the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-1",
          "local_name": "Each body part",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-each_body_part-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-3",
          "local_name": "each body part",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-each_body_part-Mention-2"
        }
      ],
      "relevance": 0.56201171875
    },
    "Entity-the_leap-motion_sdk": {
      "node_id": "the_leap-motion_sdk",
      "disambiguation_index": 0,
      "label": "the leap-motion SDK",
      "aliases": [
        "the leap-motion SDK"
      ],
      "types": [
        "software development kit",
        "SDK"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The leap-motion SDK is a software development kit designed for the Leap Motion controller, which enables precise hand and finger tracking in 3D space, utilizing a right-hand coordinate system for gesture recognition.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-14",
          "local_name": "the leap-motion SDK",
          "local_types": [
            "software development kit",
            "SDK"
          ],
          "iri": "Entity-the_leap-motion_sdk-Mention-1"
        }
      ],
      "relevance": 0.56201171875
    },
    "Entity-vr": {
      "node_id": "vr",
      "disambiguation_index": 0,
      "label": "VR",
      "aliases": [
        "VR"
      ],
      "types": [
        "immersive technology",
        "abbreviation",
        "technology",
        "virtual reality",
        "field"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "VR refers to Virtual Reality, an immersive technology that creates a simulated environment for users, enhancing Human-Computer Interaction through intuitive gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-2",
          "local_name": "VR",
          "local_types": [
            "immersive technology",
            "abbreviation",
            "technology",
            "virtual reality",
            "field"
          ],
          "iri": "Entity-vr-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "VR",
          "local_types": [
            "technology",
            "field"
          ],
          "iri": "Entity-vr-Mention-2"
        }
      ],
      "relevance": 0.56103515625
    },
    "Entity-interactive_system": {
      "node_id": "interactive_system",
      "disambiguation_index": 0,
      "label": "interactive systems",
      "aliases": [
        "interactive systems"
      ],
      "types": [
        "technology",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Interactive systems are technology-based platforms that enable user interaction through various input methods, facilitating communication and control between users and digital environments.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "interactive systems",
          "local_types": [
            "technology",
            "system"
          ],
          "iri": "Entity-interactive_system-Mention-1"
        }
      ],
      "relevance": 0.560546875
    },
    "Entity-a_referent": {
      "node_id": "a_referent",
      "disambiguation_index": 0,
      "label": "a referent",
      "aliases": [
        "a referent"
      ],
      "types": [
        "referent"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A referent is the desired effect of an action that a gesture signifies in the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-2",
          "local_name": "a referent",
          "local_types": [
            "referent"
          ],
          "iri": "Entity-a_referent-Mention-1"
        }
      ],
      "relevance": 0.56005859375
    },
    "Entity-a_reference_guide": {
      "node_id": "a_reference_guide",
      "disambiguation_index": 0,
      "label": "a reference guide",
      "aliases": [
        "a reference guide"
      ],
      "types": [
        "guide"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A reference guide refers to a structured document or resource that provides standardized definitions and instructions for designers to accurately interpret and implement numeric terminology related to gesture vocabularies in gestural interfaces.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-10",
          "local_name": "a reference guide",
          "local_types": [
            "guide"
          ],
          "iri": "Entity-a_reference_guide-Mention-1"
        }
      ],
      "relevance": 0.56005859375
    },
    "Entity-equivalent_class_and_property": {
      "node_id": "equivalent_class_and_property",
      "disambiguation_index": 0,
      "label": "equivalent classes and properties",
      "aliases": [
        "equivalent classes and properties"
      ],
      "types": [
        "classes",
        "properties"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'equivalent classes and properties' refers to the classes and properties defined in the HDGI ontology that correspond to similar concepts in external ontologies, facilitating interoperability and alignment between different gesture representation systems.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "equivalent classes and properties",
          "local_types": [
            "classes",
            "properties"
          ],
          "iri": "Entity-equivalent_class_and_property-Mention-1"
        }
      ],
      "relevance": 0.56005859375
    },
    "Entity-procedure": {
      "node_id": "procedure",
      "disambiguation_index": 0,
      "label": "procedures",
      "aliases": [
        "procedures"
      ],
      "types": [
        "methodology",
        "process",
        "procedure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the SSN ontology, 'procedures' refer to the systematic methods or processes involved in the operation and interaction of sensors and actuators within the framework of the Semantic Sensor Network.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-11",
          "local_name": "procedures",
          "local_types": [
            "methodology",
            "process",
            "procedure"
          ],
          "iri": "Entity-procedure-Mention-1"
        }
      ],
      "relevance": 0.5595703125
    },
    "Entity-user_context": {
      "node_id": "user_context",
      "disambiguation_index": 0,
      "label": "user context",
      "aliases": [
        "user context"
      ],
      "types": [
        "context",
        "user experience"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "User context refers to the specific circumstances, preferences, and characteristics of an individual user that influence their interactions and experiences with a system or device.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "user context",
          "local_types": [
            "context",
            "user experience"
          ],
          "iri": "Entity-user_context-Mention-1"
        }
      ],
      "relevance": 0.5595703125
    },
    "Entity-start_icon": {
      "node_id": "start_icon",
      "disambiguation_index": 0,
      "label": "start icon",
      "aliases": [
        "start icon",
        "the start icon"
      ],
      "types": [
        "UI element",
        "icon",
        "user interface element"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'start icon' refers to a graphical user interface element displayed on the Microsoft HoloLens 2, which users can interact with to access the start menu by performing a specific gesture.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "start icon",
          "local_types": [
            "UI element",
            "icon",
            "user interface element"
          ],
          "iri": "Entity-start_icon-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "the start icon",
          "local_types": [
            "icon"
          ],
          "iri": "Entity-start_icon-Mention-2"
        }
      ],
      "relevance": 0.55859375
    },
    "Entity-gesture_that_do_not_carry_a_referent": {
      "node_id": "gesture_that_do_not_carry_a_referent",
      "disambiguation_index": 0,
      "label": "gestures that do not carry a referent",
      "aliases": [
        "gestures that do not carry a referent"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gestures that do not carry a referent are hand movements or signals that lack a specific meaning or association with a particular action or function related to a device's affordance.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-3",
          "local_name": "gestures that do not carry a referent",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-gesture_that_do_not_carry_a_referent-Mention-1"
        }
      ],
      "relevance": 0.55859375
    },
    "Entity-hdgi__footpose": {
      "node_id": "hdgi__footpose",
      "disambiguation_index": 0,
      "label": "hdgi:FootPose",
      "aliases": [
        "hdgi:FootPose"
      ],
      "types": [
        "subclass",
        "pose representation",
        "pose"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:FootPose refers to a specific subclass of pose representation within the HDGI ontology, representing the static gesture or position of the foot in a 3D space.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-2-Sentence-4",
          "local_name": "hdgi:FootPose",
          "local_types": [
            "subclass",
            "pose representation",
            "pose"
          ],
          "iri": "Entity-hdgi__footpose-Mention-1"
        }
      ],
      "relevance": 0.55859375
    },
    "Entity-affordance": {
      "node_id": "affordance",
      "disambiguation_index": 0,
      "label": "affordance",
      "aliases": [
        "Affordance",
        "affordance",
        "affordances"
      ],
      "types": [
        "interaction design",
        "term",
        "theoretical term",
        "class",
        "feature",
        "design principle",
        "concept",
        "interaction capability",
        "interaction property",
        "design concept",
        "interaction concept",
        "affordance",
        "interaction potential",
        "theoretical framework",
        "theoretical construct",
        "human-computer interaction",
        "interaction"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Affordance is a concept in design and human-computer interaction that describes the properties of an object that suggest its possible uses to the user.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-1",
          "local_name": "affordance",
          "local_types": [
            "term",
            "theoretical term",
            "concept",
            "interaction property",
            "human-computer interaction"
          ],
          "iri": "Entity-affordance-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "affordance",
          "local_types": [
            "interaction concept",
            "design principle",
            "concept"
          ],
          "iri": "Entity-affordance-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-3",
          "local_name": "affordance",
          "local_types": [
            "affordance",
            "design principle",
            "concept",
            "interaction property"
          ],
          "iri": "Entity-affordance-Mention-3"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "affordance",
          "local_types": [
            "concept",
            "interaction property"
          ],
          "iri": "Entity-affordance-Mention-4"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "Affordance",
          "local_types": [
            "class",
            "concept"
          ],
          "iri": "Entity-affordance-Mention-5"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-8",
          "local_name": "affordance",
          "local_types": [
            "affordance",
            "interaction capability",
            "feature"
          ],
          "iri": "Entity-affordance-Mention-6"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-2",
          "local_name": "affordance",
          "local_types": [
            "concept",
            "interaction property"
          ],
          "iri": "Entity-affordance-Mention-7"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-5",
          "local_name": "affordance",
          "local_types": [
            "concept",
            "design principle"
          ],
          "iri": "Entity-affordance-Mention-8"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "affordance",
          "local_types": [
            "concept",
            "interaction property"
          ],
          "iri": "Entity-affordance-Mention-9"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-1",
          "local_name": "affordance",
          "local_types": [
            "concept",
            "interaction property"
          ],
          "iri": "Entity-affordance-Mention-10"
        },
        {
          "reference": "Section-1-Paragraph-2-Sentence-3",
          "local_name": "affordances",
          "local_types": [
            "interaction design",
            "affordance",
            "concept",
            "interaction property"
          ],
          "iri": "Entity-affordance-Mention-11"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "affordances",
          "local_types": [
            "interaction design",
            "design principle",
            "concept",
            "interaction potential",
            "affordance"
          ],
          "iri": "Entity-affordance-Mention-12"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "affordances",
          "local_types": [
            "interaction design",
            "concept",
            "interaction property",
            "affordance",
            "interaction"
          ],
          "iri": "Entity-affordance-Mention-13"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "affordances",
          "local_types": [
            "concept",
            "design principle"
          ],
          "iri": "Entity-affordance-Mention-14"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "affordances",
          "local_types": [
            "design concept",
            "interaction design"
          ],
          "iri": "Entity-affordance-Mention-15"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-2",
          "local_name": "affordances",
          "local_types": [
            "affordance",
            "interaction property",
            "concept",
            "interaction"
          ],
          "iri": "Entity-affordance-Mention-16"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-3",
          "local_name": "affordances",
          "local_types": [
            "theoretical framework",
            "concept"
          ],
          "iri": "Entity-affordance-Mention-17"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-5",
          "local_name": "affordances",
          "local_types": [
            "concept",
            "theoretical framework"
          ],
          "iri": "Entity-affordance-Mention-18"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-6",
          "local_name": "affordances",
          "local_types": [
            "theoretical construct",
            "concept"
          ],
          "iri": "Entity-affordance-Mention-19"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-1",
          "local_name": "affordances",
          "local_types": [
            "interaction design",
            "affordance",
            "design principle",
            "concept"
          ],
          "iri": "Entity-affordance-Mention-20"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-7",
          "local_name": "affordances",
          "local_types": [
            "affordance",
            "concept",
            "feature"
          ],
          "iri": "Entity-affordance-Mention-21"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-1",
          "local_name": "affordances",
          "local_types": [
            "design principle",
            "concept",
            "interaction property"
          ],
          "iri": "Entity-affordance-Mention-22"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "affordances",
          "local_types": [
            "interaction design",
            "design principle",
            "concept",
            "interaction property"
          ],
          "iri": "Entity-affordance-Mention-23"
        }
      ],
      "relevance": 0.55810546875
    },
    "Entity-size": {
      "node_id": "size",
      "disambiguation_index": 0,
      "label": "size",
      "aliases": [
        "size"
      ],
      "types": [
        "measurement",
        "dimension"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention 'size' refers to the physical dimensions or scale of hand gestures, which have not been accounted for in the discussed gesture recognition approaches.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-11",
          "local_name": "size",
          "local_types": [
            "measurement",
            "dimension"
          ],
          "iri": "Entity-size-Mention-1"
        }
      ],
      "relevance": 0.55810546875
    },
    "Entity-hdgi__xrotation": {
      "node_id": "hdgi__xrotation",
      "disambiguation_index": 0,
      "label": "hdgi:xRotation",
      "aliases": [
        "hdgi:xRotation"
      ],
      "types": [
        "rotation component",
        "attribute",
        "concept",
        "rotation axis",
        "data type",
        "data attribute",
        "rotation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:xRotation refers to the roll component of a rotation in a 3D pose representation, which can be modeled using Euler angles or quaternions within the HDGI ontology for gesture interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "hdgi:xRotation",
          "local_types": [
            "rotation component",
            "attribute",
            "concept",
            "rotation axis",
            "data type",
            "data attribute",
            "rotation"
          ],
          "iri": "Entity-hdgi__xrotation-Mention-1"
        }
      ],
      "relevance": 0.55810546875
    },
    "Entity-the_thing": {
      "node_id": "the_thing",
      "disambiguation_index": 0,
      "label": "the thing",
      "aliases": [
        "the thing"
      ],
      "types": [
        "object"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of Human-Computer Interaction, 'the thing' refers to an object or device whose perceived and actual properties define the possible ways it can be utilized by users.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-1",
          "local_name": "the thing",
          "local_types": [
            "object"
          ],
          "iri": "Entity-the_thing-Mention-1"
        }
      ],
      "relevance": 0.55810546875
    },
    "Entity-the_start_pose": {
      "node_id": "the_start_pose",
      "disambiguation_index": 0,
      "label": "the start pose",
      "aliases": [
        "the start pose"
      ],
      "types": [
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The start pose refers to the initial static position of a body part, such as the right forearm or palm, in a gesture sequence, which is modeled within the context of the HDGI ontology for human-device interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "the start pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-the_start_pose-Mention-1"
        }
      ],
      "relevance": 0.55712890625
    },
    "Entity-immersive_technology": {
      "node_id": "immersive_technology",
      "disambiguation_index": 0,
      "label": "immersive technologies",
      "aliases": [
        "immersive technologies"
      ],
      "types": [
        "technology",
        "innovation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Immersive technologies refer to digital tools and systems that create a simulated environment, enhancing user experience through interactive and engaging interfaces, often utilizing augmented reality (AR) and virtual reality (VR).",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-2",
          "local_name": "immersive technologies",
          "local_types": [
            "technology",
            "innovation"
          ],
          "iri": "Entity-immersive_technology-Mention-1"
        }
      ],
      "relevance": 0.556640625
    },
    "Entity-service": {
      "node_id": "service",
      "disambiguation_index": 0,
      "label": "Services",
      "aliases": [
        "Services",
        "service"
      ],
      "types": [
        "technology",
        "service",
        "software",
        "third party service",
        "software service"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Services refers to third-party software services that facilitate the integration of predefined SPARQL endpoints with RESTful APIs for gesture recognition applications.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-3",
          "local_name": "Services",
          "local_types": [
            "software",
            "third party service",
            "software service",
            "service"
          ],
          "iri": "Entity-service-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-4",
          "local_name": "service",
          "local_types": [
            "software",
            "technology"
          ],
          "iri": "Entity-service-Mention-2"
        }
      ],
      "relevance": 0.5556640625
    },
    "Entity-xrotation": {
      "node_id": "xrotation",
      "disambiguation_index": 0,
      "label": "xRotation",
      "aliases": [
        "xRotation"
      ],
      "types": [
        "rotation attribute",
        "spatial attribute"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "xRotation refers to the roll angle component of a rotation representation in a 3D space, specifically modeled as part of the hdgi:Rotation attribute in the context of human device gesture interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "xRotation",
          "local_types": [
            "rotation attribute",
            "spatial attribute"
          ],
          "iri": "Entity-xrotation-Mention-1"
        }
      ],
      "relevance": 0.5546875
    },
    "Entity-their_own_private_cloud": {
      "node_id": "their_own_private_cloud",
      "disambiguation_index": 0,
      "label": "their own private cloud",
      "aliases": [
        "their own private cloud"
      ],
      "types": [
        "cloud",
        "private cloud"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'their own private cloud' refers to a customizable and secure cloud computing environment that users can deploy independently to host and manage their services, applications, and data, particularly in the context of integrating gesture recognition software with the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-4",
          "local_name": "their own private cloud",
          "local_types": [
            "cloud",
            "private cloud"
          ],
          "iri": "Entity-their_own_private_cloud-Mention-1"
        }
      ],
      "relevance": 0.55419921875
    },
    "Entity-maier_et_al_.": {
      "node_id": "maier_et_al_.",
      "disambiguation_index": 0,
      "label": "Maier et al.",
      "aliases": [
        "Maier et al."
      ],
      "types": [
        "author",
        "researcher",
        "person"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Maier et al. refers to a group of researchers who define affordances as the potential uses of a device in the context of Human Computer Interaction and Design.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-3",
          "local_name": "Maier et al.",
          "local_types": [
            "author",
            "researcher",
            "person"
          ],
          "iri": "Entity-maier_et_al_.-Mention-1"
        }
      ],
      "relevance": 0.5537109375
    },
    "Entity-rotation_change": {
      "node_id": "rotation_change",
      "disambiguation_index": 0,
      "label": "rotation change",
      "aliases": [
        "rotation change"
      ],
      "types": [
        "rotation",
        "action",
        "change"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'rotation change' refers to a specific type of movement in the context of gesture-controlled interfaces, indicating a single, distinct alteration in the orientation of a body part, which is considered atomic and is part of the broader classification of dynamic gestures.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-5",
          "local_name": "rotation change",
          "local_types": [
            "rotation",
            "action",
            "change"
          ],
          "iri": "Entity-rotation_change-Mention-1"
        }
      ],
      "relevance": 0.5537109375
    },
    "Entity-hdgi__zaxisdirection": {
      "node_id": "hdgi__zaxisdirection",
      "disambiguation_index": 0,
      "label": "hdgi:zAxisDirection",
      "aliases": [
        "hdgi:zAxisDirection"
      ],
      "types": [
        "attribute",
        "direction",
        "concept",
        "enum",
        "data attribute",
        "axis direction",
        "directional reference"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:zAxisDirection refers to a predefined directional attribute within the HDGI ontology that specifies the orientation of the z-axis in a local coordinate system, with possible values of 'outward' or 'inward'.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "hdgi:zAxisDirection",
          "local_types": [
            "attribute",
            "direction",
            "concept",
            "enum",
            "data attribute",
            "axis direction",
            "directional reference"
          ],
          "iri": "Entity-hdgi__zaxisdirection-Mention-1"
        }
      ],
      "relevance": 0.55322265625
    },
    "Entity-their_scope": {
      "node_id": "their_scope",
      "disambiguation_index": 0,
      "label": "their scope",
      "aliases": [
        "their scope"
      ],
      "types": [
        "scope"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their scope' refers to the limited range and specific applications of existing gesture vocabularies in gesture-based systems, which restricts their usability and effectiveness in diverse contexts.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-4",
          "local_name": "their scope",
          "local_types": [
            "scope"
          ],
          "iri": "Entity-their_scope-Mention-1"
        }
      ],
      "relevance": 0.55322265625
    },
    "Entity-automated_system": {
      "node_id": "automated_system",
      "disambiguation_index": 0,
      "label": "automated systems",
      "aliases": [
        "automated systems"
      ],
      "types": [
        "technology",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Automated systems are technology-driven frameworks designed to perform tasks or processes with minimal human intervention, often utilizing algorithms and data to enhance efficiency and accuracy.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "automated systems",
          "local_types": [
            "technology",
            "system"
          ],
          "iri": "Entity-automated_system-Mention-1"
        }
      ],
      "relevance": 0.552734375
    },
    "Entity-observation": {
      "node_id": "observation",
      "disambiguation_index": 0,
      "label": "Observation",
      "aliases": [
        "Observation",
        "observations"
      ],
      "types": [
        "concept",
        "data type",
        "observation",
        "measurement",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the Semantic Sensor Network (SSN) ontology, 'Observation' refers to a fundamental component that represents the data collected by sensors, which is essential for understanding the interactions and behaviors of devices within the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-10",
          "local_name": "Observation",
          "local_types": [
            "data type",
            "concept"
          ],
          "iri": "Entity-observation-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-11",
          "local_name": "observations",
          "local_types": [
            "observation",
            "measurement",
            "data"
          ],
          "iri": "Entity-observation-Mention-2"
        }
      ],
      "relevance": 0.552734375
    },
    "Entity-a_hdgi__pose": {
      "node_id": "a_hdgi__pose",
      "disambiguation_index": 0,
      "label": "A hdgi:Pose",
      "aliases": [
        "A hdgi:Pose"
      ],
      "types": [
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A hdgi:Pose is a representation of a static gesture that involves a single body part at a specific point in time, characterized by its position and rotation in a 3D space, and includes a timestamp for temporal context.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-2-Sentence-3",
          "local_name": "A hdgi:Pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-a_hdgi__pose-Mention-1"
        }
      ],
      "relevance": 0.552734375
    },
    "Entity-semantic_sensor_network__ssn_": {
      "node_id": "semantic_sensor_network__ssn_",
      "disambiguation_index": 0,
      "label": "Semantic Sensor Network (SSN)",
      "aliases": [
        "SSN",
        "Semantic Sensor Network (SSN)"
      ],
      "types": [
        "ontology",
        "concept",
        "framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The Semantic Sensor Network (SSN) is an ontology and framework designed for modeling and representing sensor data and observations in a semantic web context.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-10",
          "local_name": "Semantic Sensor Network (SSN)",
          "local_types": [
            "ontology",
            "framework"
          ],
          "iri": "Entity-semantic_sensor_network__ssn_-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-10",
          "local_name": "SSN",
          "local_types": [
            "ontology",
            "concept"
          ],
          "iri": "Entity-semantic_sensor_network__ssn_-Mention-2"
        }
      ],
      "relevance": 0.55224609375
    },
    "Entity-an_example_of_a_pose_modeling": {
      "node_id": "an_example_of_a_pose_modeling",
      "disambiguation_index": 0,
      "label": "an example of a pose modeling",
      "aliases": [
        "an example of a pose modeling"
      ],
      "types": [
        "example",
        "pose modeling"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "An example of a pose modeling refers to a specific representation of the static gestures involved in the 'Right Hand Swipe Left' action, detailing the start and end poses of the right forearm and palm within the context of the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-1",
          "local_name": "an example of a pose modeling",
          "local_types": [
            "example",
            "pose modeling"
          ],
          "iri": "Entity-an_example_of_a_pose_modeling-Mention-1"
        }
      ],
      "relevance": 0.55224609375
    },
    "Entity-internet_of_thing": {
      "node_id": "internet_of_thing",
      "disambiguation_index": 0,
      "label": "Internet of Things",
      "aliases": [
        "IoT",
        "Internet of Things",
        "Internet of Things (IoT)"
      ],
      "types": [
        "network",
        "technology",
        "concept",
        "system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The Internet of Things (IoT) refers to the network of interconnected devices and systems that communicate and exchange data over the internet, enabling automation and enhanced functionality in various applications.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "Internet of Things",
          "local_types": [
            "technology",
            "concept"
          ],
          "iri": "Entity-internet_of_thing-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "IoT",
          "local_types": [
            "technology",
            "concept"
          ],
          "iri": "Entity-internet_of_thing-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "Internet of Things (IoT)",
          "local_types": [
            "system",
            "technology",
            "network"
          ],
          "iri": "Entity-internet_of_thing-Mention-3"
        }
      ],
      "relevance": 0.5517578125
    },
    "Entity-dynamic_gesture": {
      "node_id": "dynamic_gesture",
      "disambiguation_index": 0,
      "label": "dynamic gestures",
      "aliases": [
        "dynamic gesture",
        "static and dynamic gestures",
        "dynamic gestures"
      ],
      "types": [
        "atomic gesture",
        "movement type",
        "gesture type",
        "gesture",
        "action",
        "movement",
        "type"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Dynamic gestures are a type of gesture characterized by a specific start and end pose, involving a single body part and an atomic movement, distinguishing them from static gestures.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "dynamic gestures",
          "local_types": [
            "gesture type",
            "gesture",
            "atomic gesture",
            "type"
          ],
          "iri": "Entity-dynamic_gesture-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "dynamic gesture",
          "local_types": [
            "gesture",
            "movement"
          ],
          "iri": "Entity-dynamic_gesture-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-1",
          "local_name": "dynamic gestures",
          "local_types": [
            "gesture type"
          ],
          "iri": "Entity-dynamic_gesture-Mention-3"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-1",
          "local_name": "dynamic gestures",
          "local_types": [
            "gesture",
            "action",
            "movement type"
          ],
          "iri": "Entity-dynamic_gesture-Mention-4"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "static and dynamic gestures",
          "local_types": [
            "gesture",
            "type",
            "gesture type"
          ],
          "iri": "Entity-dynamic_gesture-Mention-5"
        }
      ],
      "relevance": 0.5517578125
    },
    "Entity-hdgi__xaxisdirection": {
      "node_id": "hdgi__xaxisdirection",
      "disambiguation_index": 0,
      "label": "hdgi:xAxisDirection",
      "aliases": [
        "hdgi:xAxisDirection"
      ],
      "types": [
        "attribute",
        "direction",
        "concept",
        "enum",
        "data attribute",
        "axis direction",
        "directional reference"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:xAxisDirection refers to a predefined directional attribute in the HDGI ontology that specifies the orientation of the x-axis in a local coordinate system, which can be either 'leftward' or 'rightward'.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "hdgi:xAxisDirection",
          "local_types": [
            "attribute",
            "direction",
            "concept",
            "enum",
            "data attribute",
            "axis direction",
            "directional reference"
          ],
          "iri": "Entity-hdgi__xaxisdirection-Mention-1"
        }
      ],
      "relevance": 0.5517578125
    },
    "Entity-a_swipe_gesture_": {
      "node_id": "a_swipe_gesture_",
      "disambiguation_index": 0,
      "label": "a 'swipe gesture'",
      "aliases": [
        "a 'swipe gesture'"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A 'swipe gesture' refers to a specific type of dynamic gesture characterized by a movement of a body part, such as the right hand, that transitions from one pose to another, exemplified by the action of swiping left with the right hand.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-1",
          "local_name": "a 'swipe gesture'",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-a_swipe_gesture_-Mention-1"
        }
      ],
      "relevance": 0.5517578125
    },
    "Entity-ar_and_vr": {
      "node_id": "ar_and_vr",
      "disambiguation_index": 0,
      "label": "AR and VR",
      "aliases": [
        "AR and VR"
      ],
      "types": [
        "technology",
        "immersive technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "AR and VR refer to augmented reality and virtual reality technologies that create immersive digital experiences by overlaying or simulating environments and interactions.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-2",
          "local_name": "AR and VR",
          "local_types": [
            "technology",
            "immersive technology"
          ],
          "iri": "Entity-ar_and_vr-Mention-1"
        }
      ],
      "relevance": 0.55029296875
    },
    "Entity-user__s_right_arm": {
      "node_id": "user__s_right_arm",
      "disambiguation_index": 0,
      "label": "user\u2019s right arm",
      "aliases": [
        "user\u2019s right arm"
      ],
      "types": [
        "anatomy",
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention 'user\u2019s right arm' refers to the right upper limb of a human being, specifically in the context of capturing its movements during arm gesture recognition using motion capture technology.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "user\u2019s right arm",
          "local_types": [
            "anatomy",
            "body part"
          ],
          "iri": "Entity-user__s_right_arm-Mention-1"
        }
      ],
      "relevance": 0.55029296875
    },
    "Entity-a_set_of_predefined_sparql_endpoint": {
      "node_id": "a_set_of_predefined_sparql_endpoint",
      "disambiguation_index": 0,
      "label": "a set of predefined SPARQL endpoints",
      "aliases": [
        "a set of predefined SPARQL endpoints"
      ],
      "types": [
        "endpoint",
        "SPARQL"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A set of predefined SPARQL endpoints refers to a collection of established query interfaces that utilize the SPARQL query language, designed to facilitate the retrieval and manipulation of data from the HDGI ontology through RESTful APIs for easier integration with third-party software and services.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-3",
          "local_name": "a set of predefined SPARQL endpoints",
          "local_types": [
            "endpoint",
            "SPARQL"
          ],
          "iri": "Entity-a_set_of_predefined_sparql_endpoint-Mention-1"
        }
      ],
      "relevance": 0.55029296875
    },
    "Entity-turtle": {
      "node_id": "turtle",
      "disambiguation_index": 0,
      "label": "Turtle",
      "aliases": [
        "Turtle"
      ],
      "types": [
        "syntax",
        "format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'Turtle' refers to a syntax used for expressing classes and properties in the OWL2 modeling framework.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-6",
          "local_name": "Turtle",
          "local_types": [
            "syntax",
            "format"
          ],
          "iri": "Entity-turtle-Mention-1"
        }
      ],
      "relevance": 0.5498046875
    },
    "Entity-bmw__s_idrive_infotainment_system": {
      "node_id": "bmw__s_idrive_infotainment_system",
      "disambiguation_index": 0,
      "label": "BMW\u2019s iDrive infotainment system",
      "aliases": [
        "BMW\u2019s iDrive infotainment system"
      ],
      "types": [
        "infotainment system",
        "product",
        "technology",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "BMW\u2019s iDrive infotainment system is an integrated multimedia interface that allows users to control various vehicle functions, including navigation, communication, and entertainment, through a combination of touchscreen and physical controls.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "BMW\u2019s iDrive infotainment system",
          "local_types": [
            "infotainment system",
            "product",
            "technology",
            "system"
          ],
          "iri": "Entity-bmw__s_idrive_infotainment_system-Mention-1"
        }
      ],
      "relevance": 0.5498046875
    },
    "Entity-a_particular_affordance_of_a_device": {
      "node_id": "a_particular_affordance_of_a_device",
      "disambiguation_index": 0,
      "label": "a particular affordance of a device",
      "aliases": [
        "a particular affordance of a device"
      ],
      "types": [
        "affordance",
        "device"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A particular affordance of a device refers to a specific capability or function that a device offers to users, which can be activated or utilized through gestures that have a meaningful relationship to that function.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-3",
          "local_name": "a particular affordance of a device",
          "local_types": [
            "affordance",
            "device"
          ],
          "iri": "Entity-a_particular_affordance_of_a_device-Mention-1"
        }
      ],
      "relevance": 0.5498046875
    },
    "Entity-affordance_of_answering_a_call_in_a_car": {
      "node_id": "affordance_of_answering_a_call_in_a_car",
      "disambiguation_index": 0,
      "label": "affordance of answering a call in a car",
      "aliases": [
        "the affordance of answering a call in a car",
        "affordance of answering a call in a car"
      ],
      "types": [
        "context",
        "action",
        "affordance"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The affordance of answering a call in a car refers to the capability or feature of a vehicle's interface that allows users to interactively accept phone calls through specific gestures, enhancing user experience and accessibility in automotive environments.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "affordance of answering a call in a car",
          "local_types": [
            "affordance",
            "action"
          ],
          "iri": "Entity-affordance_of_answering_a_call_in_a_car-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "the affordance of answering a call in a car",
          "local_types": [
            "affordance",
            "action",
            "context"
          ],
          "iri": "Entity-affordance_of_answering_a_call_in_a_car-Mention-2"
        }
      ],
      "relevance": 0.54931640625
    },
    "Entity-usability": {
      "node_id": "usability",
      "disambiguation_index": 0,
      "label": "usability",
      "aliases": [
        "usability"
      ],
      "types": [
        "user experience",
        "design principle"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Usability refers to the ease of use and effectiveness of a product or system, particularly in terms of how well it meets the needs and expectations of its users.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-6",
          "local_name": "usability",
          "local_types": [
            "user experience",
            "design principle"
          ],
          "iri": "Entity-usability-Mention-1"
        }
      ],
      "relevance": 0.54931640625
    },
    "Entity-further_body_part": {
      "node_id": "further_body_part",
      "disambiguation_index": 0,
      "label": "further body parts",
      "aliases": [
        "further body parts"
      ],
      "types": [
        "body part",
        "anatomy"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'further body parts' refers to additional anatomical components beyond the defined upper limb region in the hdgi:BodyPart class, which are intended to be represented in the ontology for the purpose of describing new poses in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "further body parts",
          "local_types": [
            "body part",
            "anatomy"
          ],
          "iri": "Entity-further_body_part-Mention-1"
        }
      ],
      "relevance": 0.54931640625
    },
    "Entity-one_or_more_pose_(1)": {
      "node_id": "one_or_more_pose_(1)",
      "disambiguation_index": 1,
      "label": "one or more poses",
      "aliases": [
        "one or more poses"
      ],
      "types": [
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'one or more poses' refers to the capability of a hdgi:Pose class in the HDGI ontology to encompass multiple distinct poses, each representing a specific static gesture involving a single body part at a given time.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-2-Sentence-2",
          "local_name": "one or more poses",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-one_or_more_pose_(1)-Mention-1"
        }
      ],
      "relevance": 0.54931640625
    },
    "Entity-tv": {
      "node_id": "tv",
      "disambiguation_index": 0,
      "label": "TV",
      "aliases": [
        "TV"
      ],
      "types": [
        "electronic device",
        "electronics",
        "device",
        "product"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "In this context, 'TV' refers to a television set that is used as a device in the experiment to recognize and interpret hand gestures for controlling its functions.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "TV",
          "local_types": [
            "electronic device",
            "electronics",
            "device",
            "product"
          ],
          "iri": "Entity-tv-Mention-1"
        }
      ],
      "relevance": 0.548828125
    },
    "Entity-section_2": {
      "node_id": "section_2",
      "disambiguation_index": 0,
      "label": "Section 2",
      "aliases": [
        "Section 2"
      ],
      "types": [
        "section",
        "part of paper",
        "part of a document"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Section 2 refers to a part of the paper where existing approaches to address the problem of ubiquitousness in human-device gesture interactions are discussed.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-2",
          "local_name": "Section 2",
          "local_types": [
            "section",
            "part of paper",
            "part of a document"
          ],
          "iri": "Entity-section_2-Mention-1"
        }
      ],
      "relevance": 0.548828125
    },
    "Entity-right_hand": {
      "node_id": "right_hand",
      "disambiguation_index": 0,
      "label": "right hand",
      "aliases": [
        "right hand",
        "the right hand"
      ],
      "types": [
        "body part",
        "human anatomy"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'right hand' refers to the human anatomical body part used in the context of performing gestures, specifically in this case, a dynamic gesture known as a 'swipe gesture'.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-1",
          "local_name": "right hand",
          "local_types": [
            "body part",
            "human anatomy"
          ],
          "iri": "Entity-right_hand-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-1",
          "local_name": "the right hand",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-right_hand-Mention-2"
        }
      ],
      "relevance": 0.54833984375
    },
    "Entity-upper_arm_position": {
      "node_id": "upper_arm_position",
      "disambiguation_index": 0,
      "label": "upper arm positions",
      "aliases": [
        "upper arm positions"
      ],
      "types": [
        "anatomy",
        "position",
        "body part",
        "anatomical position"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Upper arm positions refer to the specific spatial orientations and placements of the upper arm in relation to the shoulder joint, as defined within the context of gesture modeling in the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-7",
          "local_name": "upper arm positions",
          "local_types": [
            "anatomy",
            "position",
            "body part",
            "anatomical position"
          ],
          "iri": "Entity-upper_arm_position-Mention-1"
        }
      ],
      "relevance": 0.54736328125
    },
    "Entity-bloom__gesture": {
      "node_id": "bloom__gesture",
      "disambiguation_index": 0,
      "label": "'bloom' gesture",
      "aliases": [
        "'bloom' gesture"
      ],
      "types": [
        "gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The 'bloom' gesture refers to a specific hand movement used in the Microsoft HoloLens to open the 'start' menu, exemplifying a gesture-based interaction in augmented reality systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-1",
          "local_name": "'bloom' gesture",
          "local_types": [
            "gesture"
          ],
          "iri": "Entity-bloom__gesture-Mention-1"
        }
      ],
      "relevance": 0.54736328125
    },
    "Entity-zposition_value": {
      "node_id": "zposition_value",
      "disambiguation_index": 0,
      "label": "zPosition values",
      "aliases": [
        "zPosition values"
      ],
      "types": [
        "coordinate"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "zPosition values refer to the coordinate values that represent the position along the z-axis in a 3D space, which are part of the hdgi:Position class in the context of modeling human gestures and poses within the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-10",
          "local_name": "zPosition values",
          "local_types": [
            "coordinate"
          ],
          "iri": "Entity-zposition_value-Mention-1"
        }
      ],
      "relevance": 0.54736328125
    },
    "Entity-hdgi__hasposition": {
      "node_id": "hdgi__hasposition",
      "disambiguation_index": 0,
      "label": "hdgi:hasPosition",
      "aliases": [
        "hdgi:hasPosition"
      ],
      "types": [
        "relationship",
        "ontology",
        "mapping",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:hasPosition is a property in the HDGI ontology that defines the spatial position of a pose in a 3D coordinate system, linking a specific pose to its corresponding x, y, and z position values.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-5",
          "local_name": "hdgi:hasPosition",
          "local_types": [
            "relationship",
            "ontology",
            "mapping",
            "property"
          ],
          "iri": "Entity-hdgi__hasposition-Mention-1"
        }
      ],
      "relevance": 0.546875
    },
    "Entity-apis": {
      "node_id": "apis",
      "disambiguation_index": 0,
      "label": "APIs",
      "aliases": [
        "APIs",
        "API"
      ],
      "types": [
        "application programming interface",
        "technology",
        "software",
        "software component",
        "interface",
        "API",
        "software interface"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "APIs, or Application Programming Interfaces, are sets of rules and protocols that allow different software applications to communicate and interact with each other.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-2",
          "local_name": "APIs",
          "local_types": [
            "software component",
            "interface",
            "technology",
            "software interface"
          ],
          "iri": "Entity-apis-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "API",
          "local_types": [
            "application programming interface",
            "technology",
            "software",
            "interface",
            "software interface"
          ],
          "iri": "Entity-apis-Mention-2"
        },
        {
          "reference": "Section-10-Paragraph-5-Sentence-1",
          "local_name": "API",
          "local_types": [
            "software component",
            "API",
            "application programming interface"
          ],
          "iri": "Entity-apis-Mention-3"
        }
      ],
      "relevance": 0.546875
    },
    "Entity-sensor__observation__sample__and_actuator": {
      "node_id": "sensor__observation__sample__and_actuator",
      "disambiguation_index": 0,
      "label": "Sensor, Observation, Sample, and Actuator",
      "aliases": [
        "Sensor, Observation, Sample, and Actuator"
      ],
      "types": [
        "components"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'Sensor, Observation, Sample, and Actuator' refers to a core ontology that underpins the Semantic Sensor Network (SSN) ontology, which describes the functionalities and relationships of sensors, their observations, the samples they collect, and the actuators that respond to those observations in the context of the Internet of Things.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-10",
          "local_name": "Sensor, Observation, Sample, and Actuator",
          "local_types": [
            "components"
          ],
          "iri": "Entity-sensor__observation__sample__and_actuator-Mention-1"
        }
      ],
      "relevance": 0.546875
    },
    "Entity-microsoft_hololens": {
      "node_id": "microsoft_hololens",
      "disambiguation_index": 0,
      "label": "Microsoft HoloLens",
      "aliases": [
        "HoloLens 2",
        "Microsoft HoloLens",
        "Microsoft HoloLens 2"
      ],
      "types": [
        "product",
        "technology",
        "mixed reality device",
        "augmented reality headset",
        "augmented reality",
        "device",
        "hardware",
        "system",
        "augmented reality device"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Microsoft HoloLens is a mixed reality headset developed by Microsoft that enables users to interact with digital content in a real-world environment through augmented reality technology.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-1",
          "local_name": "Microsoft HoloLens",
          "local_types": [
            "product",
            "technology",
            "device",
            "augmented reality",
            "augmented reality device"
          ],
          "iri": "Entity-microsoft_hololens-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "HoloLens 2",
          "local_types": [
            "product",
            "technology",
            "device",
            "augmented reality",
            "augmented reality headset",
            "augmented reality device"
          ],
          "iri": "Entity-microsoft_hololens-Mention-2"
        },
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "Microsoft HoloLens 2",
          "local_types": [
            "product",
            "technology",
            "mixed reality device",
            "hardware",
            "device",
            "augmented reality",
            "augmented reality headset",
            "system",
            "augmented reality device"
          ],
          "iri": "Entity-microsoft_hololens-Mention-3"
        },
        {
          "reference": "Section-11-Paragraph-4-Sentence-3",
          "local_name": "Microsoft HoloLens 2",
          "local_types": [
            "device",
            "product",
            "augmented reality headset",
            "augmented reality device"
          ],
          "iri": "Entity-microsoft_hololens-Mention-4"
        }
      ],
      "relevance": 0.54638671875
    },
    "Entity-semantic_web_standard": {
      "node_id": "semantic_web_standard",
      "disambiguation_index": 0,
      "label": "Semantic Web standards",
      "aliases": [
        "Semantic Web standards"
      ],
      "types": [
        "technology standard",
        "web technology",
        "standard",
        "framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Semantic Web standards are a set of specifications and technologies designed to enable the sharing and reuse of data across different applications on the web, facilitating interoperability and machine understanding.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-2",
          "local_name": "Semantic Web standards",
          "local_types": [
            "technology standard",
            "web technology",
            "standard",
            "framework"
          ],
          "iri": "Entity-semantic_web_standard-Mention-1"
        }
      ],
      "relevance": 0.54638671875
    },
    "Entity-haslocalcoordinatesystem": {
      "node_id": "haslocalcoordinatesystem",
      "disambiguation_index": 0,
      "label": "hasLocalCoordinateSystem",
      "aliases": [
        "hasLocalCoordinateSystem"
      ],
      "types": [
        "data structure",
        "mapping",
        "identifier"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The entity 'hasLocalCoordinateSystem' refers to an object property in the HDGI ontology that establishes a relationship between a position in 3D space and its corresponding local coordinate system, ensuring that the position values are interpreted correctly relative to the defined axes of that system.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-4",
          "local_name": "hasLocalCoordinateSystem",
          "local_types": [
            "data structure",
            "mapping",
            "identifier"
          ],
          "iri": "Entity-haslocalcoordinatesystem-Mention-1"
        }
      ],
      "relevance": 0.54638671875
    },
    "Entity-physical_movement_of_the_face__limb__or_body": {
      "node_id": "physical_movement_of_the_face__limb__or_body",
      "disambiguation_index": 0,
      "label": "physical movements of the face, limbs, or body",
      "aliases": [
        "physical movements of the face, limbs, or body"
      ],
      "types": [
        "interaction method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Physical movements of the face, limbs, or body refer to the various gestures and motions that individuals use to communicate, express emotions, or interact with their environment.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "physical movements of the face, limbs, or body",
          "local_types": [
            "interaction method"
          ],
          "iri": "Entity-physical_movement_of_the_face__limb__or_body-Mention-1"
        }
      ],
      "relevance": 0.544921875
    },
    "Entity-arm_class": {
      "node_id": "arm_class",
      "disambiguation_index": 0,
      "label": "Arm class",
      "aliases": [
        "Arm class"
      ],
      "types": [
        "anatomical structure",
        "class",
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The Arm class refers to a classification in the Foundational Model of Anatomy (FMA) that represents the anatomical structure of the human arm, specifically corresponding to the hdgi:UpperArm class in the context of gesture modeling for Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "Arm class",
          "local_types": [
            "anatomical structure",
            "class",
            "body part"
          ],
          "iri": "Entity-arm_class-Mention-1"
        }
      ],
      "relevance": 0.544921875
    },
    "Entity-the_term_affordance": {
      "node_id": "the_term_affordance",
      "disambiguation_index": 0,
      "label": "the term affordance",
      "aliases": [
        "an affordance",
        "the term affordance",
        "the affordance"
      ],
      "types": [
        "term",
        "concept"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'affordance' refers to the perceived and actual properties of an object that determine the possible uses or actions that can be performed with it, particularly in the context of Human-Computer Interaction and design.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-1",
          "local_name": "the term affordance",
          "local_types": [
            "term",
            "concept"
          ],
          "iri": "Entity-the_term_affordance-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-5",
          "local_name": "the affordance",
          "local_types": [
            "concept"
          ],
          "iri": "Entity-the_term_affordance-Mention-2"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-6",
          "local_name": "an affordance",
          "local_types": [
            "concept"
          ],
          "iri": "Entity-the_term_affordance-Mention-3"
        }
      ],
      "relevance": 0.54443359375
    },
    "Entity-motion_capture": {
      "node_id": "motion_capture",
      "disambiguation_index": 0,
      "label": "motion capture",
      "aliases": [
        "motion capture"
      ],
      "types": [
        "technology",
        "method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Motion capture is a technology and method used to record the movement of objects or people, often for the purpose of creating realistic animations in film, video games, and virtual reality.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "motion capture",
          "local_types": [
            "technology",
            "method"
          ],
          "iri": "Entity-motion_capture-Mention-1"
        }
      ],
      "relevance": 0.5439453125
    },
    "Entity-other_body_part": {
      "node_id": "other_body_part",
      "disambiguation_index": 0,
      "label": "other body parts",
      "aliases": [
        "other body parts"
      ],
      "types": [
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'other body parts' refers to the various anatomical regions of the human body beyond the upper limbs, which can be involved in gesture-based interactions and are considered for the extensibility of gesture ontologies.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "other body parts",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-other_body_part-Mention-1"
        }
      ],
      "relevance": 0.5439453125
    },
    "Entity-one_manufacturer": {
      "node_id": "one_manufacturer",
      "disambiguation_index": 0,
      "label": "one manufacturer",
      "aliases": [
        "one manufacturer"
      ],
      "types": [
        "manufacturer"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of the HDGI ontology, 'one manufacturer' refers to a single entity responsible for producing a device, which is modeled as having a unique relationship with that device, indicating that each device can only be associated with one specific manufacturer.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-3-Sentence-2",
          "local_name": "one manufacturer",
          "local_types": [
            "manufacturer"
          ],
          "iri": "Entity-one_manufacturer-Mention-1"
        }
      ],
      "relevance": 0.54345703125
    },
    "Entity-ssn_ontology": {
      "node_id": "ssn_ontology",
      "disambiguation_index": 0,
      "label": "SSN ontology",
      "aliases": [
        "SSN ontology",
        "The SSN ontology"
      ],
      "types": [
        "ontology",
        "framework"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The SSN ontology is a formal representation framework that defines concepts and relationships related to sensors, observations, and their associated properties in the context of the Semantic Web.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-11",
          "local_name": "SSN ontology",
          "local_types": [
            "ontology",
            "framework"
          ],
          "iri": "Entity-ssn_ontology-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-11",
          "local_name": "The SSN ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-ssn_ontology-Mention-2"
        }
      ],
      "relevance": 0.54296875
    },
    "Entity-further_experiment": {
      "node_id": "further_experiment",
      "disambiguation_index": 0,
      "label": "further experiments",
      "aliases": [
        "further experiments"
      ],
      "types": [
        "experiment"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Further experiments refer to additional research activities aimed at testing and validating the proposed gestural interaction taxonomy and notation method with a larger set of commands to assess their effectiveness and adaptability.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-9",
          "local_name": "further experiments",
          "local_types": [
            "experiment"
          ],
          "iri": "Entity-further_experiment-Mention-1"
        }
      ],
      "relevance": 0.54296875
    },
    "Entity-user_experience": {
      "node_id": "user_experience",
      "disambiguation_index": 0,
      "label": "user experience",
      "aliases": [
        "user experience",
        "User Experience"
      ],
      "types": [
        "concept",
        "user satisfaction",
        "design goal",
        "experience",
        "field"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "User experience refers to the overall satisfaction and effectiveness of a user's interaction with a product, system, or service, encompassing aspects of usability, accessibility, and emotional response.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-2",
          "local_name": "user experience",
          "local_types": [
            "concept",
            "field"
          ],
          "iri": "Entity-user_experience-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "User Experience",
          "local_types": [
            "concept",
            "field"
          ],
          "iri": "Entity-user_experience-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-2",
          "local_name": "User Experience",
          "local_types": [
            "concept",
            "field"
          ],
          "iri": "Entity-user_experience-Mention-3"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-2",
          "local_name": "user experience",
          "local_types": [
            "user satisfaction",
            "design goal",
            "experience"
          ],
          "iri": "Entity-user_experience-Mention-4"
        }
      ],
      "relevance": 0.5419921875
    },
    "Entity-answering_a_call": {
      "node_id": "answering_a_call",
      "disambiguation_index": 0,
      "label": "answering a call",
      "aliases": [
        "answering a call"
      ],
      "types": [
        "action",
        "communication task"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'answering a call' refers to the action of using a specific gesture to accept an incoming phone call within the context of gesture-controlled interfaces in vehicles.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "answering a call",
          "local_types": [
            "action",
            "communication task"
          ],
          "iri": "Entity-answering_a_call-Mention-1"
        }
      ],
      "relevance": 0.541015625
    },
    "Entity-feature_of_interest": {
      "node_id": "feature_of_interest",
      "disambiguation_index": 0,
      "label": "features of interest",
      "aliases": [
        "features of interest"
      ],
      "types": [
        "attribute",
        "characteristic",
        "feature"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'features of interest' refers to the specific properties or characteristics that are observed and studied within the context of sensor data and their interactions in the Semantic Sensor Network (SSN) ontology.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-11",
          "local_name": "features of interest",
          "local_types": [
            "attribute",
            "characteristic",
            "feature"
          ],
          "iri": "Entity-feature_of_interest-Mention-1"
        }
      ],
      "relevance": 0.541015625
    },
    "Entity-ux": {
      "node_id": "ux",
      "disambiguation_index": 0,
      "label": "UX",
      "aliases": [
        "UX"
      ],
      "types": [
        "user experience",
        "concept",
        "abbreviation"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "UX refers to user experience, which encompasses the overall experience and satisfaction a user has when interacting with a product, system, or service.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-2",
          "local_name": "UX",
          "local_types": [
            "user experience",
            "concept",
            "abbreviation"
          ],
          "iri": "Entity-ux-Mention-1"
        }
      ],
      "relevance": 0.54052734375
    },
    "Entity-restful_apis": {
      "node_id": "restful_apis",
      "disambiguation_index": 0,
      "label": "RESTful APIs",
      "aliases": [
        "RESTful APIs"
      ],
      "types": [
        "application programming interface",
        "technology",
        "web standard",
        "web service",
        "RESTful",
        "interface",
        "API"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "RESTful APIs are application programming interfaces that adhere to the principles of Representational State Transfer (REST), allowing for interaction with web services through standard HTTP methods.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-3",
          "local_name": "RESTful APIs",
          "local_types": [
            "application programming interface",
            "technology",
            "web standard",
            "web service",
            "RESTful",
            "interface",
            "API"
          ],
          "iri": "Entity-restful_apis-Mention-1"
        }
      ],
      "relevance": 0.54052734375
    },
    "Entity-the_problem_of_having_different_origin_point": {
      "node_id": "the_problem_of_having_different_origin_point",
      "disambiguation_index": 0,
      "label": "the problem of having different origin points",
      "aliases": [
        "the problem of having different origin points"
      ],
      "types": [
        "problem"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The problem of having different origin points refers to the challenges arising from variations in coordinate systems used by different gesture recognition devices, which can lead to inconsistencies in the interpretation of gesture positions and movements.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-6",
          "local_name": "the problem of having different origin points",
          "local_types": [
            "problem"
          ],
          "iri": "Entity-the_problem_of_having_different_origin_point-Mention-1"
        }
      ],
      "relevance": 0.5400390625
    },
    "Entity-semantic_web": {
      "node_id": "semantic_web",
      "disambiguation_index": 0,
      "label": "Semantic Web",
      "aliases": [
        "Semantic Web"
      ],
      "types": [
        "technology",
        "concept"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The Semantic Web is a framework for representing and sharing data on the internet in a way that enables machines to understand and process the information, utilizing standards such as RDF, RDFS, and OWL.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-2",
          "local_name": "Semantic Web",
          "local_types": [
            "technology",
            "concept"
          ],
          "iri": "Entity-semantic_web-Mention-1"
        }
      ],
      "relevance": 0.53955078125
    },
    "Entity-2020": {
      "node_id": "2020",
      "disambiguation_index": 0,
      "label": "2020",
      "aliases": [
        "2020"
      ],
      "types": [
        "year",
        "date"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The mention '2020' refers to the year in which a review by Villarreal Narvaez et al. was conducted, highlighting the ongoing challenges and future needs in the field of gesture recognition.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "2020",
          "local_types": [
            "year",
            "date"
          ],
          "iri": "Entity-2020-Mention-1"
        }
      ],
      "relevance": 0.53955078125
    },
    "Entity-a_new_namespace": {
      "node_id": "a_new_namespace",
      "disambiguation_index": 0,
      "label": "a new namespace",
      "aliases": [
        "a new namespace"
      ],
      "types": [
        "namespace"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A new namespace refers to the unique identifier 'https://w3id.org/hdgi' created for the HDGI ontology, which allows for the independent definition of classes used in the ontology without reliance on external ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "a new namespace",
          "local_types": [
            "namespace"
          ],
          "iri": "Entity-a_new_namespace-Mention-1"
        }
      ],
      "relevance": 0.53955078125
    },
    "Entity-eight_atomic_gesture": {
      "node_id": "eight_atomic_gesture",
      "disambiguation_index": 0,
      "label": "eight atomic gestures",
      "aliases": [
        "eight atomic gestures"
      ],
      "types": [
        "gesture",
        "atomic gesture"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'eight atomic gestures' refers to the individual, fundamental movements that collectively comprise the dynamic gesture known as 'right hand swipe left', each characterized by a specific body part, start pose, end pose, and movement.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-2",
          "local_name": "eight atomic gestures",
          "local_types": [
            "gesture",
            "atomic gesture"
          ],
          "iri": "Entity-eight_atomic_gesture-Mention-1"
        }
      ],
      "relevance": 0.53955078125
    },
    "Entity-right": {
      "node_id": "right",
      "disambiguation_index": 0,
      "label": "right",
      "aliases": [
        "right"
      ],
      "types": [
        "direction",
        "spatial reference"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the paper, 'right' refers to the classification of fingers as either left or right entities, specifically indicating the right hand's fingers in the modeling of human upper limb gestures.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "right",
          "local_types": [
            "direction",
            "spatial reference"
          ],
          "iri": "Entity-right-Mention-1"
        }
      ],
      "relevance": 0.5390625
    },
    "Entity-a_majority_of_them": {
      "node_id": "a_majority_of_them",
      "disambiguation_index": 0,
      "label": "a majority of them",
      "aliases": [
        "a majority of them"
      ],
      "types": [
        "group"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'a majority of them' refers to the numerous gesture vocabularies defined in Gesture Elicitation Studies (GES) that are constrained in their applicability and intended uses.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-4",
          "local_name": "a majority of them",
          "local_types": [
            "group"
          ],
          "iri": "Entity-a_majority_of_them-Mention-1"
        }
      ],
      "relevance": 0.5390625
    },
    "Entity-left_and_right_entity": {
      "node_id": "left_and_right_entity",
      "disambiguation_index": 0,
      "label": "left and right entities",
      "aliases": [
        "left and right entities"
      ],
      "types": [
        "entity",
        "direction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'left and right entities' refers to the classification of individual fingers of the human hand into two distinct categories based on their lateral position, specifically the fingers on the left hand and the fingers on the right hand, within the context of modeling gestures in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "left and right entities",
          "local_types": [
            "entity",
            "direction"
          ],
          "iri": "Entity-left_and_right_entity-Mention-1"
        }
      ],
      "relevance": 0.5390625
    },
    "Entity-a_pose": {
      "node_id": "a_pose",
      "disambiguation_index": 0,
      "label": "a pose",
      "aliases": [
        "a pose"
      ],
      "types": [
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A pose refers to a specific static configuration of a body part in a 3D space, characterized by its position and rotation, and is a fundamental component in modeling gestures within the Human Device Gesture Interaction ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-1",
          "local_name": "a pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-a_pose-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-4",
          "local_name": "a pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-a_pose-Mention-2"
        }
      ],
      "relevance": 0.5390625
    },
    "Entity-wobbrock_et_al_.": {
      "node_id": "wobbrock_et_al_.",
      "disambiguation_index": 0,
      "label": "Wobbrock et al.",
      "aliases": [
        "Wobbrock et al."
      ],
      "types": [
        "author",
        "researcher"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Wobbrock et al. refers to a group of researchers led by Jacob Wobbrock, known for their contributions to human-computer interaction and user interface design.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "Wobbrock et al.",
          "local_types": [
            "author",
            "researcher"
          ],
          "iri": "Entity-wobbrock_et_al_.-Mention-1"
        }
      ],
      "relevance": 0.53759765625
    },
    "Entity-menu_item": {
      "node_id": "menu_item",
      "disambiguation_index": 0,
      "label": "menu items",
      "aliases": [
        "menu items"
      ],
      "types": [
        "input method",
        "interface element"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Menu items are selectable options presented in a user interface that allow users to perform actions or navigate through a system.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-1",
          "local_name": "menu items",
          "local_types": [
            "input method",
            "interface element"
          ],
          "iri": "Entity-menu_item-Mention-1"
        }
      ],
      "relevance": 0.53759765625
    },
    "Entity-user_study": {
      "node_id": "user_study",
      "disambiguation_index": 0,
      "label": "user studies",
      "aliases": [
        "user studies"
      ],
      "types": [
        "evaluation method",
        "research method",
        "evaluation technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "User studies are research methods that involve observing and analyzing the behavior, preferences, and experiences of users to evaluate and improve products, systems, or interfaces.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-1",
          "local_name": "user studies",
          "local_types": [
            "evaluation method",
            "research method",
            "evaluation technique"
          ],
          "iri": "Entity-user_study-Mention-1"
        }
      ],
      "relevance": 0.53759765625
    },
    "Entity-hdgi__legpose": {
      "node_id": "hdgi__legpose",
      "disambiguation_index": 0,
      "label": "hdgi:LegPose",
      "aliases": [
        "hdgi:LegPose"
      ],
      "types": [
        "subclass",
        "pose representation",
        "pose"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:LegPose refers to a specific subclass of pose representation within the HDGI ontology, representing the static gesture or position of a leg in a 3D space.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-2-Sentence-4",
          "local_name": "hdgi:LegPose",
          "local_types": [
            "subclass",
            "pose representation",
            "pose"
          ],
          "iri": "Entity-hdgi__legpose-Mention-1"
        }
      ],
      "relevance": 0.53759765625
    },
    "Entity-a_user__s_wrist": {
      "node_id": "a_user__s_wrist",
      "disambiguation_index": 0,
      "label": "a user\u2019s wrist",
      "aliases": [
        "a user\u2019s wrist"
      ],
      "types": [
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "a user\u2019s wrist refers to the joint connecting the hand to the forearm, allowing for the movement and flexibility of the hand.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "a user\u2019s wrist",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-a_user__s_wrist-Mention-1"
        }
      ],
      "relevance": 0.53662109375
    },
    "Entity-their_hand": {
      "node_id": "their_hand",
      "disambiguation_index": 0,
      "label": "their hand",
      "aliases": [
        "their hand"
      ],
      "types": [
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention 'their hand' refers to the user's hand, specifically the physical limb used to perform gestures in the context of interacting with the HoloLens 2 device.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "their hand",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-their_hand-Mention-1"
        }
      ],
      "relevance": 0.53662109375
    },
    "Entity-arm_movement": {
      "node_id": "arm_movement",
      "disambiguation_index": 0,
      "label": "arm movements",
      "aliases": [
        "arm gesture",
        "arm movements",
        "arm gestures"
      ],
      "types": [
        "physical action",
        "concept",
        "gesture",
        "action",
        "movement",
        "arm"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Arm movements refer to the physical actions or gestures involving the motion of the arms, often used for communication or interaction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-1",
          "local_name": "arm movements",
          "local_types": [
            "physical action",
            "gesture",
            "movement",
            "arm"
          ],
          "iri": "Entity-arm_movement-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-2",
          "local_name": "arm gestures",
          "local_types": [
            "physical action",
            "action",
            "gesture",
            "concept"
          ],
          "iri": "Entity-arm_movement-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "arm gesture",
          "local_types": [
            "gesture",
            "physical action"
          ],
          "iri": "Entity-arm_movement-Mention-3"
        }
      ],
      "relevance": 0.53662109375
    },
    "Entity-thing": {
      "node_id": "thing",
      "disambiguation_index": 0,
      "label": "thing",
      "aliases": [
        "thing"
      ],
      "types": [
        "object",
        "entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'thing' refers to an object or entity whose perceived and actual properties define its potential uses in the context of Human-Computer Interaction.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-1",
          "local_name": "thing",
          "local_types": [
            "object",
            "entity"
          ],
          "iri": "Entity-thing-Mention-1"
        }
      ],
      "relevance": 0.53662109375
    },
    "Entity-relevant_class": {
      "node_id": "relevant_class",
      "disambiguation_index": 0,
      "label": "relevant classes",
      "aliases": [
        "relevant classes",
        "relevant classes for HDI"
      ],
      "types": [
        "HDI",
        "category",
        "class",
        "classification"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'relevant classes' refers to specific categories of biological concepts from the Foundational Model of Anatomy (FMA) that are pertinent to Human Device Interaction (HDI), focusing on the upper limb region and its associated body parts.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "relevant classes",
          "local_types": [
            "classification",
            "category"
          ],
          "iri": "Entity-relevant_class-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "relevant classes for HDI",
          "local_types": [
            "class",
            "HDI"
          ],
          "iri": "Entity-relevant_class-Mention-2"
        }
      ],
      "relevance": 0.53564453125
    },
    "Entity-car": {
      "node_id": "car",
      "disambiguation_index": 0,
      "label": "car",
      "aliases": [
        "car"
      ],
      "types": [
        "transportation",
        "vehicle"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'car' refers to a modern automobile, which is a type of vehicle designed for the transportation of passengers and is increasingly integrated with gesture-controlled interfaces for enhanced user interaction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-3",
          "local_name": "car",
          "local_types": [
            "vehicle",
            "transportation"
          ],
          "iri": "Entity-car-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "car",
          "local_types": [
            "transportation",
            "vehicle"
          ],
          "iri": "Entity-car-Mention-2"
        }
      ],
      "relevance": 0.53515625
    },
    "Entity-virtual_reality": {
      "node_id": "virtual_reality",
      "disambiguation_index": 0,
      "label": "Virtual Reality",
      "aliases": [
        "Virtual Reality (VR)",
        "Virtual Reality"
      ],
      "types": [
        "immersive technology",
        "technology",
        "concept",
        "virtual environment",
        "virtual experience",
        "VR"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Virtual Reality is a technology that creates a simulated environment, allowing users to interact with a computer-generated 3D space as if they were physically present in it.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "Virtual Reality",
          "local_types": [
            "technology",
            "concept"
          ],
          "iri": "Entity-virtual_reality-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "Virtual Reality",
          "local_types": [
            "technology",
            "concept"
          ],
          "iri": "Entity-virtual_reality-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "Virtual Reality (VR)",
          "local_types": [
            "virtual environment",
            "technology",
            "virtual experience",
            "VR"
          ],
          "iri": "Entity-virtual_reality-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "Virtual Reality (VR)",
          "local_types": [
            "immersive technology",
            "technology",
            "virtual environment",
            "virtual experience",
            "VR"
          ],
          "iri": "Entity-virtual_reality-Mention-4"
        }
      ],
      "relevance": 0.53369140625
    },
    "Entity-fma": {
      "node_id": "fma",
      "disambiguation_index": 0,
      "label": "FMA",
      "aliases": [
        "FMA"
      ],
      "types": [
        "biological concept",
        "ontology",
        "biomedical resource",
        "medical resource",
        "database"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "FMA refers to the Foundational Model of Anatomy, an ontology that provides a structured representation of anatomical concepts and relationships, which is utilized in the context of modeling body parts for human-device interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "FMA",
          "local_types": [
            "biomedical resource",
            "biological concept",
            "ontology",
            "database"
          ],
          "iri": "Entity-fma-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "FMA",
          "local_types": [
            "ontology",
            "database"
          ],
          "iri": "Entity-fma-Mention-2"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "FMA",
          "local_types": [
            "medical resource",
            "ontology",
            "database"
          ],
          "iri": "Entity-fma-Mention-3"
        }
      ],
      "relevance": 0.53369140625
    },
    "Entity-semantic_web_standard__rdf__rdfs__and_owl2_": {
      "node_id": "semantic_web_standard__rdf__rdfs__and_owl2_",
      "disambiguation_index": 0,
      "label": "Semantic Web standards (RDF, RDFS, and OWL2)",
      "aliases": [
        "Semantic Web standards (RDF, RDFS, and OWL2)"
      ],
      "types": [
        "standard",
        "Semantic Web"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Semantic Web standards (RDF, RDFS, and OWL2) refer to a set of specifications and technologies designed to facilitate the sharing and integration of data across different systems on the web, enabling machines to understand and process information in a meaningful way.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-2",
          "local_name": "Semantic Web standards (RDF, RDFS, and OWL2)",
          "local_types": [
            "standard",
            "Semantic Web"
          ],
          "iri": "Entity-semantic_web_standard__rdf__rdfs__and_owl2_-Mention-1"
        }
      ],
      "relevance": 0.53369140625
    },
    "Entity-mixed_reality": {
      "node_id": "mixed_reality",
      "disambiguation_index": 0,
      "label": "Mixed Reality",
      "aliases": [
        "Mixed Reality"
      ],
      "types": [
        "virtual environment",
        "technology",
        "concept",
        "field"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Mixed Reality is a technology that combines elements of both virtual reality and augmented reality to create immersive environments where physical and digital objects coexist and interact in real-time.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-3",
          "local_name": "Mixed Reality",
          "local_types": [
            "virtual environment",
            "technology",
            "concept",
            "field"
          ],
          "iri": "Entity-mixed_reality-Mention-1"
        }
      ],
      "relevance": 0.533203125
    },
    "Entity-user_intent": {
      "node_id": "user_intent",
      "disambiguation_index": 0,
      "label": "user intent",
      "aliases": [
        "user intent"
      ],
      "types": [
        "intent"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "User intent refers to the underlying goal or purpose that a user aims to achieve through their actions or interactions with a system or interface.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-4",
          "local_name": "user intent",
          "local_types": [
            "intent"
          ],
          "iri": "Entity-user_intent-Mention-1"
        }
      ],
      "relevance": 0.53271484375
    },
    "Entity-start_menu": {
      "node_id": "start_menu",
      "disambiguation_index": 0,
      "label": "start menu",
      "aliases": [
        "start menu",
        "the start menu"
      ],
      "types": [
        "UI element",
        "menu",
        "user interface element"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The start menu is a graphical user interface element that provides access to various applications, settings, and features on a computer or device.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "start menu",
          "local_types": [
            "UI element",
            "menu",
            "user interface element"
          ],
          "iri": "Entity-start_menu-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "the start menu",
          "local_types": [
            "menu"
          ],
          "iri": "Entity-start_menu-Mention-2"
        }
      ],
      "relevance": 0.5322265625
    },
    "Entity-region_of_hand_": {
      "node_id": "region_of_hand_",
      "disambiguation_index": 0,
      "label": "'Region of hand'",
      "aliases": [
        "'Region of hand'"
      ],
      "types": [
        "region",
        "anatomy"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The 'Region of hand' refers to the anatomical classification within the Foundational Model of Anatomy (FMA) that encompasses the various parts of the human hand, including individual fingers and their subdivisions, which are relevant for modeling gestures in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "'Region of hand'",
          "local_types": [
            "region",
            "anatomy"
          ],
          "iri": "Entity-region_of_hand_-Mention-1"
        }
      ],
      "relevance": 0.5322265625
    },
    "Entity-code": {
      "node_id": "code",
      "disambiguation_index": 0,
      "label": "code",
      "aliases": [
        "code"
      ],
      "types": [
        "software",
        "resource"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'code' refers to the software and data associated with the HDGI ontology, which is made publicly available on GitHub for community contributions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "code",
          "local_types": [
            "software",
            "resource"
          ],
          "iri": "Entity-code-Mention-1"
        }
      ],
      "relevance": 0.53173828125
    },
    "Entity-it_own_namespace": {
      "node_id": "it_own_namespace",
      "disambiguation_index": 0,
      "label": "its own namespace",
      "aliases": [
        "its own namespace"
      ],
      "types": [
        "namespace"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'its own namespace' refers to the unique identifier space created for the HDGI ontology, specifically the URL https://w3id.org/hdgi, which allows the ontology's classes and relationships to be defined independently from external ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "its own namespace",
          "local_types": [
            "namespace"
          ],
          "iri": "Entity-it_own_namespace-Mention-1"
        }
      ],
      "relevance": 0.53173828125
    },
    "Entity-instance_of_that_property": {
      "node_id": "instance_of_that_property",
      "disambiguation_index": 0,
      "label": "instances of that property",
      "aliases": [
        "instances of that property"
      ],
      "types": [
        "instance"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Instances of that property refer to specific occurrences or examples of a defined property within the context of the HDGI ontology, which utilizes guarded local restrictions to assert the range of properties based on the class of the subject.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "instances of that property",
          "local_types": [
            "instance"
          ],
          "iri": "Entity-instance_of_that_property-Mention-1"
        }
      ],
      "relevance": 0.53125
    },
    "Entity-hdgi__position_class": {
      "node_id": "hdgi__position_class",
      "disambiguation_index": 0,
      "label": "hdgi:Position class",
      "aliases": [
        "hdgi:Position class"
      ],
      "types": [
        "class"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The hdgi:Position class defines the local coordinate system for representing the spatial placement of body parts in a gesture, specifying the x, y, and z position values relative to a defined origin.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-10",
          "local_name": "hdgi:Position class",
          "local_types": [
            "class"
          ],
          "iri": "Entity-hdgi__position_class-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-15",
          "local_name": "hdgi:Position class",
          "local_types": [
            "class"
          ],
          "iri": "Entity-hdgi__position_class-Mention-2"
        }
      ],
      "relevance": 0.53125
    },
    "Entity-the_z-axis": {
      "node_id": "the_z-axis",
      "disambiguation_index": 0,
      "label": "the Z-axis",
      "aliases": [
        "the Z-axis"
      ],
      "types": [
        "axis"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The Z-axis refers to one of the three axes in a 3D coordinate system, specifically indicating depth or distance from the viewer, with its direction defined differently in various gesture recognition systems, such as pointing inward in the leap-motion SDK.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-14",
          "local_name": "the Z-axis",
          "local_types": [
            "axis"
          ],
          "iri": "Entity-the_z-axis-Mention-1"
        }
      ],
      "relevance": 0.53125
    },
    "Entity-the_experiment": {
      "node_id": "the_experiment",
      "disambiguation_index": 0,
      "label": "the experiment",
      "aliases": [
        "the experiment"
      ],
      "types": [
        "experiment"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The experiment refers to a study that involved the use of 6 commands and 43 gestures specifically designed for controlling a TV and blinds, aimed at evaluating the effectiveness of a gestural interaction taxonomy and notation method.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "the experiment",
          "local_types": [
            "experiment"
          ],
          "iri": "Entity-the_experiment-Mention-1"
        }
      ],
      "relevance": 0.53076171875
    },
    "Entity-the_relevant_code": {
      "node_id": "the_relevant_code",
      "disambiguation_index": 0,
      "label": "the relevant code",
      "aliases": [
        "the relevant code"
      ],
      "types": [
        "code"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The relevant code refers to the software implementation and associated data of the HDGI ontology, which is made publicly accessible on GitHub for community collaboration and contribution.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "the relevant code",
          "local_types": [
            "code"
          ],
          "iri": "Entity-the_relevant_code-Mention-1"
        }
      ],
      "relevance": 0.53076171875
    },
    "Entity-individual_body_part": {
      "node_id": "individual_body_part",
      "disambiguation_index": 0,
      "label": "individual body parts",
      "aliases": [
        "individual body parts"
      ],
      "types": [
        "body part"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Individual body parts refer to the distinct anatomical segments of the human body that can be involved in gestures, allowing for the separate capture and description of movements and poses in the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "individual body parts",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-individual_body_part-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-3",
          "local_name": "individual body parts",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-individual_body_part-Mention-2"
        }
      ],
      "relevance": 0.53076171875
    },
    "Entity-ontology": {
      "node_id": "ontology",
      "disambiguation_index": 0,
      "label": "ontology",
      "aliases": [
        "ontology",
        "ontologies"
      ],
      "types": [
        "resource",
        "formal model",
        "framework",
        "conceptual framework",
        "theoretical model",
        "field of study",
        "data structure",
        "ontology",
        "concept",
        "model",
        "formal representation",
        "conceptual model",
        "knowledge structure",
        "knowledge representation",
        "formal system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Ontology is a formal representation of a set of concepts within a domain and the relationships between those concepts, used to facilitate understanding and communication in knowledge representation.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-1",
          "local_name": "ontology",
          "local_types": [
            "conceptual framework",
            "concept",
            "knowledge representation",
            "field of study"
          ],
          "iri": "Entity-ontology-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "ontology",
          "local_types": [
            "formal model",
            "ontology",
            "concept",
            "formal representation",
            "conceptual model",
            "knowledge structure",
            "knowledge representation"
          ],
          "iri": "Entity-ontology-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-2-Sentence-2",
          "local_name": "ontology",
          "local_types": [
            "concept",
            "data structure"
          ],
          "iri": "Entity-ontology-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-1",
          "local_name": "ontology",
          "local_types": [
            "knowledge representation",
            "conceptual framework"
          ],
          "iri": "Entity-ontology-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-2",
          "local_name": "ontology",
          "local_types": [
            "knowledge representation",
            "data structure"
          ],
          "iri": "Entity-ontology-Mention-5"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "ontology",
          "local_types": [
            "knowledge representation",
            "formal system"
          ],
          "iri": "Entity-ontology-Mention-6"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-1",
          "local_name": "ontologies",
          "local_types": [
            "framework",
            "data structure",
            "ontology",
            "model",
            "knowledge representation",
            "formal system"
          ],
          "iri": "Entity-ontology-Mention-7"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "ontology",
          "local_types": [
            "conceptual framework",
            "theoretical model"
          ],
          "iri": "Entity-ontology-Mention-8"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-4",
          "local_name": "ontology",
          "local_types": [
            "concept",
            "knowledge representation"
          ],
          "iri": "Entity-ontology-Mention-9"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-1",
          "local_name": "ontology",
          "local_types": [
            "model",
            "conceptual framework",
            "knowledge representation",
            "framework"
          ],
          "iri": "Entity-ontology-Mention-10"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "ontology",
          "local_types": [
            "conceptual framework",
            "knowledge representation"
          ],
          "iri": "Entity-ontology-Mention-11"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-5",
          "local_name": "ontologies",
          "local_types": [
            "knowledge representation",
            "data structure"
          ],
          "iri": "Entity-ontology-Mention-12"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "ontology",
          "local_types": [
            "conceptual framework",
            "knowledge representation"
          ],
          "iri": "Entity-ontology-Mention-13"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "ontology",
          "local_types": [
            "conceptual model",
            "framework"
          ],
          "iri": "Entity-ontology-Mention-14"
        },
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "ontology",
          "local_types": [
            "conceptual model",
            "knowledge representation",
            "formal system"
          ],
          "iri": "Entity-ontology-Mention-15"
        },
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "ontology",
          "local_types": [
            "conceptual model",
            "ontology",
            "resource"
          ],
          "iri": "Entity-ontology-Mention-16"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-3",
          "local_name": "ontology",
          "local_types": [
            "conceptual framework",
            "knowledge representation"
          ],
          "iri": "Entity-ontology-Mention-17"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "ontology",
          "local_types": [
            "concept",
            "framework"
          ],
          "iri": "Entity-ontology-Mention-18"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-8",
          "local_name": "ontology",
          "local_types": [
            "conceptual model",
            "knowledge representation"
          ],
          "iri": "Entity-ontology-Mention-19"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-9",
          "local_name": "ontologies",
          "local_types": [
            "data structure",
            "knowledge representation",
            "ontology"
          ],
          "iri": "Entity-ontology-Mention-20"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "ontology",
          "local_types": [
            "ontology",
            "knowledge representation",
            "conceptual framework"
          ],
          "iri": "Entity-ontology-Mention-21"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "ontology",
          "local_types": [
            "conceptual framework",
            "knowledge representation"
          ],
          "iri": "Entity-ontology-Mention-22"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-1",
          "local_name": "ontology",
          "local_types": [
            "data structure",
            "knowledge representation",
            "conceptual framework"
          ],
          "iri": "Entity-ontology-Mention-23"
        },
        {
          "reference": "Section-11-Paragraph-2-Sentence-1",
          "local_name": "ontology",
          "local_types": [
            "knowledge representation",
            "conceptual framework"
          ],
          "iri": "Entity-ontology-Mention-24"
        }
      ],
      "relevance": 0.5302734375
    },
    "Entity-community": {
      "node_id": "community",
      "disambiguation_index": 0,
      "label": "community",
      "aliases": [
        "community",
        "the community"
      ],
      "types": [
        "community",
        "collaborative network",
        "group"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'community' refers to a collaborative network of individuals and contributors who can access and participate in the development and enhancement of the HDGI ontology and its associated resources on GitHub.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "community",
          "local_types": [
            "collaborative network",
            "group"
          ],
          "iri": "Entity-community-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "the community",
          "local_types": [
            "community"
          ],
          "iri": "Entity-community-Mention-2"
        }
      ],
      "relevance": 0.5302734375
    },
    "Entity-ontology_design_pattern_initiative": {
      "node_id": "ontology_design_pattern_initiative",
      "disambiguation_index": 0,
      "label": "ontology design pattern initiative",
      "aliases": [
        "the ontology design pattern initiative",
        "ontology design pattern initiative"
      ],
      "types": [
        "organization",
        "initiative",
        "community"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The ontology design pattern initiative is a collaborative effort aimed at developing, sharing, and promoting reusable ontology design patterns to enhance the quality and interoperability of ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-4",
          "local_name": "ontology design pattern initiative",
          "local_types": [
            "organization",
            "initiative",
            "community"
          ],
          "iri": "Entity-ontology_design_pattern_initiative-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-4",
          "local_name": "the ontology design pattern initiative",
          "local_types": [
            "initiative"
          ],
          "iri": "Entity-ontology_design_pattern_initiative-Mention-2"
        }
      ],
      "relevance": 0.529296875
    },
    "Entity-sensor": {
      "node_id": "sensor",
      "disambiguation_index": 0,
      "label": "sensors",
      "aliases": [
        "sensors",
        "Sensor"
      ],
      "types": [
        "measurement instrument",
        "technology",
        "device",
        "sensor",
        "component"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Sensors are devices or instruments that detect and measure physical properties or changes in the environment, converting these measurements into signals that can be interpreted or recorded.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-4-Sentence-1",
          "local_name": "sensors",
          "local_types": [
            "device",
            "technology"
          ],
          "iri": "Entity-sensor-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-10",
          "local_name": "Sensor",
          "local_types": [
            "device",
            "component"
          ],
          "iri": "Entity-sensor-Mention-2"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-11",
          "local_name": "sensors",
          "local_types": [
            "measurement instrument",
            "device",
            "sensor"
          ],
          "iri": "Entity-sensor-Mention-3"
        }
      ],
      "relevance": 0.529296875
    },
    "Entity-the_same_referent": {
      "node_id": "the_same_referent",
      "disambiguation_index": 0,
      "label": "the same referent",
      "aliases": [
        "the same referent"
      ],
      "types": [
        "referent"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'the same referent' refers to the consistent effect or desired outcome associated with different gestures in gesture-based interactions, indicating that multiple gestures can signify the same action or intention.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "the same referent",
          "local_types": [
            "referent"
          ],
          "iri": "Entity-the_same_referent-Mention-1"
        }
      ],
      "relevance": 0.529296875
    },
    "Entity-sosa__sensor": {
      "node_id": "sosa__sensor",
      "disambiguation_index": 0,
      "label": "sosa:Sensor",
      "aliases": [
        "sosa:Sensor"
      ],
      "types": [
        "ontology class",
        "ontology",
        "concept",
        "ontology term",
        "entity",
        "sensor",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "sosa:Sensor refers to an ontology class that represents a device or entity capable of detecting and measuring physical properties or environmental conditions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-12",
          "local_name": "sosa:Sensor",
          "local_types": [
            "ontology class",
            "ontology",
            "concept",
            "ontology term",
            "entity",
            "sensor",
            "class"
          ],
          "iri": "Entity-sosa__sensor-Mention-1"
        }
      ],
      "relevance": 0.5283203125
    },
    "Entity-start_pose": {
      "node_id": "start_pose",
      "disambiguation_index": 0,
      "label": "start pose",
      "aliases": [
        "a start pose",
        "start pose"
      ],
      "types": [
        "pose",
        "position",
        "initial position"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'start pose' refers to the initial position of a body part in a dynamic gesture, which is defined as part of the gesture's structure in the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "start pose",
          "local_types": [
            "pose",
            "position",
            "initial position"
          ],
          "iri": "Entity-start_pose-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "start pose",
          "local_types": [
            "pose",
            "position"
          ],
          "iri": "Entity-start_pose-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "a start pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-start_pose-Mention-3"
        }
      ],
      "relevance": 0.5283203125
    },
    "Entity-web_service_interface": {
      "node_id": "web_service_interface",
      "disambiguation_index": 0,
      "label": "Web service interface",
      "aliases": [
        "Web service interface"
      ],
      "types": [
        "technology",
        "service",
        "software",
        "web technology",
        "software component",
        "interface"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A Web service interface is a standardized method that allows different software applications to communicate and interact over the internet using web protocols.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-2-Sentence-2",
          "local_name": "Web service interface",
          "local_types": [
            "technology",
            "service",
            "software",
            "web technology",
            "software component",
            "interface"
          ],
          "iri": "Entity-web_service_interface-Mention-1"
        }
      ],
      "relevance": 0.5283203125
    },
    "Entity-position_change": {
      "node_id": "position_change",
      "disambiguation_index": 0,
      "label": "position change",
      "aliases": [
        "position change"
      ],
      "types": [
        "action",
        "position",
        "change"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'position change' refers to a specific alteration in the spatial location of a body part during a gesture, which is considered an atomic component of a movement in the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-5",
          "local_name": "position change",
          "local_types": [
            "action",
            "position",
            "change"
          ],
          "iri": "Entity-position_change-Mention-1"
        }
      ],
      "relevance": 0.52685546875
    },
    "Entity-a_similar_study": {
      "node_id": "a_similar_study",
      "disambiguation_index": 0,
      "label": "a similar study",
      "aliases": [
        "a similar study"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'a similar study' refers to the research conducted by Khairunizam et al., which aimed to enhance the recognition of arm gestures by computational systems, focusing on geometrical gestures and utilizing motion capture technology.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-1",
          "local_name": "a similar study",
          "local_types": [
            "research"
          ],
          "iri": "Entity-a_similar_study-Mention-1"
        }
      ],
      "relevance": 0.52685546875
    },
    "Entity-their_research": {
      "node_id": "their_research",
      "disambiguation_index": 0,
      "label": "their research",
      "aliases": [
        "their research"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their research' refers to the study conducted by Khairunizam et al., which focuses on describing and recognizing arm gestures with higher accuracy using motion capture technology.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-2",
          "local_name": "their research",
          "local_types": [
            "research"
          ],
          "iri": "Entity-their_research-Mention-1"
        }
      ],
      "relevance": 0.52685546875
    },
    "Entity-a_tv": {
      "node_id": "a_tv",
      "disambiguation_index": 0,
      "label": "a TV",
      "aliases": [
        "a TV"
      ],
      "types": [
        "device",
        "TV"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A TV refers to a television set, an electronic device used for receiving and displaying broadcast signals, which in this context is involved in gesture-based interaction research focusing on command recognition.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "a TV",
          "local_types": [
            "device",
            "TV"
          ],
          "iri": "Entity-a_tv-Mention-1"
        }
      ],
      "relevance": 0.5263671875
    },
    "Entity-user_need": {
      "node_id": "user_need",
      "disambiguation_index": 0,
      "label": "user needs",
      "aliases": [
        "user needs"
      ],
      "types": [
        "user experience",
        "user requirement",
        "user",
        "needs"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "User needs refer to the specific requirements, preferences, and expectations of users that inform the design and functionality of products or services to enhance their overall experience.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-2",
          "local_name": "user needs",
          "local_types": [
            "user experience",
            "user requirement",
            "user",
            "needs"
          ],
          "iri": "Entity-user_need-Mention-1"
        }
      ],
      "relevance": 0.52587890625
    },
    "Entity-a_particular_actor": {
      "node_id": "a_particular_actor",
      "disambiguation_index": 0,
      "label": "a particular actor",
      "aliases": [
        "a particular actor"
      ],
      "types": [
        "actor"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of Human Device Interaction, 'a particular actor' refers to an individual user whose actions and manipulations are influenced by the context-dependent affordances of devices they interact with.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-6",
          "local_name": "a particular actor",
          "local_types": [
            "actor"
          ],
          "iri": "Entity-a_particular_actor-Mention-1"
        }
      ],
      "relevance": 0.52587890625
    },
    "Entity-a_search_query": {
      "node_id": "a_search_query",
      "disambiguation_index": 0,
      "label": "a search query",
      "aliases": [
        "a search query"
      ],
      "types": [
        "query"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A search query refers to a specific input or command entered by a user into a search engine or database, aimed at retrieving relevant information or data, such as gesture vocabularies for performing actions like answering a call in a car.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-3",
          "local_name": "a search query",
          "local_types": [
            "query"
          ],
          "iri": "Entity-a_search_query-Mention-1"
        }
      ],
      "relevance": 0.52490234375
    },
    "Entity-qualisys_motion_capture": {
      "node_id": "qualisys_motion_capture",
      "disambiguation_index": 0,
      "label": "Qualisys motion capture",
      "aliases": [
        "Qualisys motion capture"
      ],
      "types": [
        "motion capture",
        "technology",
        "motion capture system",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Qualisys motion capture refers to a motion capture system developed by Qualisys that utilizes advanced technology to track and analyze the movement of objects or individuals in three-dimensional space.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "Qualisys motion capture",
          "local_types": [
            "motion capture",
            "technology",
            "motion capture system",
            "system"
          ],
          "iri": "Entity-qualisys_motion_capture-Mention-1"
        }
      ],
      "relevance": 0.5244140625
    },
    "Entity-hdgi__yposition": {
      "node_id": "hdgi__yposition",
      "disambiguation_index": 0,
      "label": "hdgi:yPosition",
      "aliases": [
        "yPosition",
        "hdgi:yPosition"
      ],
      "types": [
        "spatial attribute",
        "attribute",
        "coordinate",
        "spatial coordinate",
        "concept",
        "data attribute",
        "spatial position",
        "position"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:yPosition refers to a spatial coordinate attribute within the HDGI ontology that specifies the vertical position of a body part in a defined local coordinate system.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-10",
          "local_name": "hdgi:yPosition",
          "local_types": [
            "position",
            "attribute",
            "coordinate"
          ],
          "iri": "Entity-hdgi__yposition-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-5",
          "local_name": "hdgi:yPosition",
          "local_types": [
            "attribute",
            "coordinate",
            "spatial coordinate",
            "concept",
            "data attribute",
            "spatial position",
            "position"
          ],
          "iri": "Entity-hdgi__yposition-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-10",
          "local_name": "yPosition",
          "local_types": [
            "coordinate",
            "spatial attribute"
          ],
          "iri": "Entity-hdgi__yposition-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-5",
          "local_name": "yPosition",
          "local_types": [
            "coordinate",
            "spatial attribute"
          ],
          "iri": "Entity-hdgi__yposition-Mention-4"
        }
      ],
      "relevance": 0.5244140625
    },
    "Entity-figure_3": {
      "node_id": "figure_3",
      "disambiguation_index": 0,
      "label": "Figure 3",
      "aliases": [
        "Figure 3"
      ],
      "types": [
        "reference",
        "visual representation",
        "illustration",
        "figure"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Figure 3 illustrates the relative positioning of various body parts in a 3D space as defined by the HDGI ontology, specifically highlighting the relationship of the hdgi:ForearmPose to the elbow joint.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-8",
          "local_name": "Figure 3",
          "local_types": [
            "reference",
            "illustration",
            "figure"
          ],
          "iri": "Entity-figure_3-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-8",
          "local_name": "Figure 3",
          "local_types": [
            "visual representation",
            "figure",
            "illustration"
          ],
          "iri": "Entity-figure_3-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-7",
          "local_name": "Figure 3",
          "local_types": [
            "figure",
            "illustration"
          ],
          "iri": "Entity-figure_3-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-9",
          "local_name": "Figure 3",
          "local_types": [
            "figure",
            "illustration"
          ],
          "iri": "Entity-figure_3-Mention-4"
        }
      ],
      "relevance": 0.5234375
    },
    "Entity-restful": {
      "node_id": "restful",
      "disambiguation_index": 0,
      "label": "RESTful",
      "aliases": [
        "RESTful"
      ],
      "types": [
        "architecture style"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "RESTful refers to an architectural style for designing networked applications that utilize HTTP requests to access and manipulate data, typically following the principles of Representational State Transfer (REST).",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "RESTful",
          "local_types": [
            "architecture style"
          ],
          "iri": "Entity-restful-Mention-1"
        }
      ],
      "relevance": 0.5234375
    },
    "Entity-interoperability": {
      "node_id": "interoperability",
      "disambiguation_index": 0,
      "label": "interoperability",
      "aliases": [
        "interoperability"
      ],
      "types": [
        "technology principle",
        "system property",
        "interoperability",
        "concept",
        "system capability"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Interoperability refers to the ability of different systems, devices, or applications to work together and exchange information effectively, regardless of their underlying technologies or platforms.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-2",
          "local_name": "interoperability",
          "local_types": [
            "system capability",
            "concept",
            "system property"
          ],
          "iri": "Entity-interoperability-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "interoperability",
          "local_types": [
            "technology principle",
            "interoperability",
            "concept",
            "system property"
          ],
          "iri": "Entity-interoperability-Mention-2"
        }
      ],
      "relevance": 0.52294921875
    },
    "Entity-hdgi__thumb": {
      "node_id": "hdgi__thumb",
      "disambiguation_index": 0,
      "label": "hdgi:Thumb",
      "aliases": [
        "hdgi:Thumb"
      ],
      "types": [
        "anatomical structure",
        "body part",
        "finger",
        "subclass",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:Thumb refers to the specific subclass of the hdgi:Finger class that represents the human thumb, which is part of the upper limb region and is mapped to the corresponding subclass in the Foundational Model of Anatomy.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "hdgi:Thumb",
          "local_types": [
            "anatomical structure",
            "body part",
            "finger",
            "subclass",
            "entity",
            "class"
          ],
          "iri": "Entity-hdgi__thumb-Mention-1"
        }
      ],
      "relevance": 0.52197265625
    },
    "Entity-few_study": {
      "node_id": "few_study",
      "disambiguation_index": 0,
      "label": "few studies",
      "aliases": [
        "few studies"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'few studies' refers to the limited number of research efforts that have focused on defining and formalizing the relationships between different gestures in the context of gesture recognition and interaction design.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "few studies",
          "local_types": [
            "research"
          ],
          "iri": "Entity-few_study-Mention-1"
        }
      ],
      "relevance": 0.52197265625
    },
    "Entity-hdgi__upperarm": {
      "node_id": "hdgi__upperarm",
      "disambiguation_index": 0,
      "label": "hdgi:UpperArm",
      "aliases": [
        "hdgi:UpperArm"
      ],
      "types": [
        "upper limb",
        "ontology",
        "anatomy",
        "anatomical structure",
        "body part",
        "concept",
        "subclass",
        "model",
        "pose",
        "pose representation",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "hdgi:UpperArm refers to a class in the HDGI ontology that represents the upper arm as a fundamental component of the human upper limb, equivalent to the Arm class in the Foundational Model of Anatomy (FMA).",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "hdgi:UpperArm",
          "local_types": [
            "upper limb",
            "anatomy",
            "anatomical structure",
            "body part",
            "class"
          ],
          "iri": "Entity-hdgi__upperarm-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "hdgi:UpperArm",
          "local_types": [
            "ontology",
            "class"
          ],
          "iri": "Entity-hdgi__upperarm-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-5",
          "local_name": "hdgi:UpperArm",
          "local_types": [
            "ontology",
            "anatomical structure",
            "body part",
            "subclass",
            "model",
            "pose",
            "pose representation",
            "class"
          ],
          "iri": "Entity-hdgi__upperarm-Mention-3"
        },
        {
          "reference": "Section-8-Paragraph-1-Sentence-2",
          "local_name": "hdgi:UpperArm",
          "local_types": [
            "anatomy",
            "concept",
            "body part"
          ],
          "iri": "Entity-hdgi__upperarm-Mention-4"
        }
      ],
      "relevance": 0.52099609375
    },
    "Entity-allen_time": {
      "node_id": "allen_time",
      "disambiguation_index": 0,
      "label": "Allen time",
      "aliases": [
        "Allen time"
      ],
      "types": [
        "temporal framework",
        "theoretical model",
        "concept",
        "temporal reference",
        "temporal logic"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Allen time refers to a temporal framework used in the ontology to sequence or coordinate gestures by mapping their movements and poses in a structured manner.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "Allen time",
          "local_types": [
            "temporal framework",
            "theoretical model",
            "concept",
            "temporal reference",
            "temporal logic"
          ],
          "iri": "Entity-allen_time-Mention-1"
        }
      ],
      "relevance": 0.52099609375
    },
    "Entity-upper_limb": {
      "node_id": "upper_limb",
      "disambiguation_index": 0,
      "label": "upper limbs",
      "aliases": [
        "upper limb",
        "human upper limbs",
        "upper limbs",
        "the upper limbs of the human body"
      ],
      "types": [
        "human body",
        "anatomy",
        "anatomical structure",
        "body part",
        "human anatomy",
        "anatomical part"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Upper limbs refer to the paired anatomical structures in the human body that include the arms, hands, and associated muscles and bones, primarily used for manipulation and interaction with the environment.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "upper limbs",
          "local_types": [
            "human body",
            "anatomy",
            "body part",
            "anatomical part"
          ],
          "iri": "Entity-upper_limb-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-1",
          "local_name": "upper limb",
          "local_types": [
            "anatomy",
            "body part"
          ],
          "iri": "Entity-upper_limb-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "upper limbs",
          "local_types": [
            "anatomy",
            "anatomical structure",
            "body part",
            "human anatomy"
          ],
          "iri": "Entity-upper_limb-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "the upper limbs of the human body",
          "local_types": [
            "body part",
            "human body"
          ],
          "iri": "Entity-upper_limb-Mention-4"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "human upper limbs",
          "local_types": [
            "anatomy",
            "body part"
          ],
          "iri": "Entity-upper_limb-Mention-5"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-2",
          "local_name": "human upper limbs",
          "local_types": [
            "anatomy",
            "body part"
          ],
          "iri": "Entity-upper_limb-Mention-6"
        }
      ],
      "relevance": 0.5205078125
    },
    "Entity-figure_3_-_point_a": {
      "node_id": "figure_3_-_point_a",
      "disambiguation_index": 0,
      "label": "Figure 3 - point A",
      "aliases": [
        "Figure 3 - point A"
      ],
      "types": [
        "figure",
        "reference"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Figure 3 - point A refers to the specific location in the HDGI ontology where the position of the upper arm is defined as being relative to the shoulder joint.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-7",
          "local_name": "Figure 3 - point A",
          "local_types": [
            "figure",
            "reference"
          ],
          "iri": "Entity-figure_3_-_point_a-Mention-1"
        }
      ],
      "relevance": 0.51953125
    },
    "Entity-sosa": {
      "node_id": "sosa",
      "disambiguation_index": 0,
      "label": "SOSA",
      "aliases": [
        "SOSA"
      ],
      "types": [
        "ontology",
        "concept",
        "framework"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "SOSA refers to the Sensor, Observation, Sample, and Actuator ontology, which serves as the foundational framework for the Semantic Sensor Network ontology, facilitating the description of sensors, their observations, and related properties.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-10",
          "local_name": "SOSA",
          "local_types": [
            "ontology",
            "framework"
          ],
          "iri": "Entity-sosa-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-9",
          "local_name": "SOSA",
          "local_types": [
            "ontology",
            "concept",
            "framework"
          ],
          "iri": "Entity-sosa-Mention-2"
        }
      ],
      "relevance": 0.51904296875
    },
    "Entity-human_behavior": {
      "node_id": "human_behavior",
      "disambiguation_index": 0,
      "label": "human behaviors",
      "aliases": [
        "human behaviors"
      ],
      "types": [
        "behavior",
        "action"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Human behaviors refer to the range of actions and reactions exhibited by individuals in response to internal or external stimuli.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-5",
          "local_name": "human behaviors",
          "local_types": [
            "behavior",
            "action"
          ],
          "iri": "Entity-human_behavior-Mention-1"
        }
      ],
      "relevance": 0.5185546875
    },
    "Entity-point_in_time": {
      "node_id": "point_in_time",
      "disambiguation_index": 0,
      "label": "point in time",
      "aliases": [
        "point in time"
      ],
      "types": [
        "temporal reference"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'point in time' refers to a specific moment at which a pose involving a body part is defined within the context of gesture recognition and human-device interaction.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-2",
          "local_name": "point in time",
          "local_types": [
            "temporal reference"
          ],
          "iri": "Entity-point_in_time-Mention-1"
        }
      ],
      "relevance": 0.51806640625
    },
    "Entity-global_domain_and_range_restriction": {
      "node_id": "global_domain_and_range_restriction",
      "disambiguation_index": 0,
      "label": "global domain and range restrictions",
      "aliases": [
        "global domain and range restrictions"
      ],
      "types": [
        "theoretical framework",
        "restriction",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Global domain and range restrictions refer to constraints applied to properties in an ontology that define the allowable classes for the subjects and objects of those properties, ensuring that the relationships between entities are clearly specified and aligned with external ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "global domain and range restrictions",
          "local_types": [
            "theoretical framework",
            "restriction",
            "concept"
          ],
          "iri": "Entity-global_domain_and_range_restriction-Mention-1"
        }
      ],
      "relevance": 0.517578125
    },
    "Entity-anyone_interested": {
      "node_id": "anyone_interested",
      "disambiguation_index": 0,
      "label": "anyone interested",
      "aliases": [
        "anyone interested"
      ],
      "types": [
        "individual"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'anyone interested' refers to individuals from the community who wish to contribute to the development and enhancement of the HDGI ontology and its associated resources available on GitHub.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "anyone interested",
          "local_types": [
            "individual"
          ],
          "iri": "Entity-anyone_interested-Mention-1"
        }
      ],
      "relevance": 0.5166015625
    },
    "Entity-forearmpose": {
      "node_id": "forearmpose",
      "disambiguation_index": 0,
      "label": "ForearmPose",
      "aliases": [
        "ForearmPose"
      ],
      "types": [
        "pose",
        "gesture"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "ForearmPose refers to a specific static gesture that represents the position and orientation of the forearm relative to the elbow joint within the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-8",
          "local_name": "ForearmPose",
          "local_types": [
            "pose",
            "gesture"
          ],
          "iri": "Entity-forearmpose-Mention-1"
        }
      ],
      "relevance": 0.51611328125
    },
    "Entity-ontology_engineering": {
      "node_id": "ontology_engineering",
      "disambiguation_index": 0,
      "label": "ontology engineering",
      "aliases": [
        "ontology engineering"
      ],
      "types": [
        "discipline",
        "research area",
        "ontology",
        "field"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Ontology engineering is a discipline that focuses on the design, development, and management of ontologies, which are formal representations of knowledge within a specific domain.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-1",
          "local_name": "ontology engineering",
          "local_types": [
            "discipline",
            "research area",
            "ontology",
            "field"
          ],
          "iri": "Entity-ontology_engineering-Mention-1"
        }
      ],
      "relevance": 0.51611328125
    },
    "Entity-point_a": {
      "node_id": "point_a",
      "disambiguation_index": 0,
      "label": "point A",
      "aliases": [
        "point A"
      ],
      "types": [
        "reference point",
        "marker"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "point A refers to the shoulder joint, which serves as the reference point for determining the relative positions of the upper arm in the context of gesture recognition.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-7",
          "local_name": "point A",
          "local_types": [
            "reference point",
            "marker"
          ],
          "iri": "Entity-point_a-Mention-1"
        }
      ],
      "relevance": 0.515625
    },
    "Entity-villarreal_narvaez": {
      "node_id": "villarreal_narvaez",
      "disambiguation_index": 0,
      "label": "Villarreal Narvaez",
      "aliases": [
        "Villarreal Narvaez et al.",
        "Villarreal Narvaez"
      ],
      "types": [
        "author",
        "researcher",
        "person"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Villarreal Narvaez is a researcher who co-authored a review in 2020 highlighting the ongoing challenges and future needs in gesture recognition and vocabulary interoperability.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "Villarreal Narvaez",
          "local_types": [
            "author",
            "researcher",
            "person"
          ],
          "iri": "Entity-villarreal_narvaez-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "Villarreal Narvaez et al.",
          "local_types": [
            "author",
            "researcher"
          ],
          "iri": "Entity-villarreal_narvaez-Mention-2"
        }
      ],
      "relevance": 0.5146484375
    },
    "Entity-central_location": {
      "node_id": "central_location",
      "disambiguation_index": 0,
      "label": "central location",
      "aliases": [
        "a central location",
        "central location"
      ],
      "types": [
        "location"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'central location' refers to a comprehensive repository or database that organizes and maps various gesture vocabularies to their corresponding functions, specifically for the purpose of answering calls in automotive systems.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "central location",
          "local_types": [
            "location"
          ],
          "iri": "Entity-central_location-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "a central location",
          "local_types": [
            "location"
          ],
          "iri": "Entity-central_location-Mention-2"
        }
      ],
      "relevance": 0.5146484375
    },
    "Entity-biological_concept": {
      "node_id": "biological_concept",
      "disambiguation_index": 0,
      "label": "biological concepts",
      "aliases": [
        "biological concepts"
      ],
      "types": [
        "biological entity",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'biological concepts' refers to the various anatomical and physiological classifications and structures defined in the Foundational Model of Anatomy (FMA), which are relevant to the modeling of human gestures in Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "biological concepts",
          "local_types": [
            "biological entity",
            "concept"
          ],
          "iri": "Entity-biological_concept-Mention-1"
        }
      ],
      "relevance": 0.5146484375
    },
    "Entity-eight_section_of_upper_limb_region": {
      "node_id": "eight_section_of_upper_limb_region",
      "disambiguation_index": 0,
      "label": "eight sections of upper limb region",
      "aliases": [
        "eight sections of upper limb region",
        "these eight sections of upper limb region"
      ],
      "types": [
        "upper limb",
        "anatomical structure",
        "anatomical region"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'eight sections of upper limb region' refer to the anatomical components of the human upper limb, specifically including the upper arm, forearm, palm, and individual fingers, which are utilized in gesture recognition and interaction within the context of Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-9",
          "local_name": "eight sections of upper limb region",
          "local_types": [
            "anatomical structure",
            "upper limb"
          ],
          "iri": "Entity-eight_section_of_upper_limb_region-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-9",
          "local_name": "these eight sections of upper limb region",
          "local_types": [
            "anatomical region",
            "upper limb"
          ],
          "iri": "Entity-eight_section_of_upper_limb_region-Mention-2"
        }
      ],
      "relevance": 0.51416015625
    },
    "Entity-separate_ontology_file": {
      "node_id": "separate_ontology_file",
      "disambiguation_index": 0,
      "label": "separate ontology files",
      "aliases": [
        "separate ontology files"
      ],
      "types": [
        "file",
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Separate ontology files refer to distinct files that contain alignments and mappings of the HDGI ontology to external ontologies, which are made available on GitHub for community use and contribution.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-9",
          "local_name": "separate ontology files",
          "local_types": [
            "file",
            "ontology"
          ],
          "iri": "Entity-separate_ontology_file-Mention-1"
        }
      ],
      "relevance": 0.51220703125
    },
    "Entity-existing_ontology": {
      "node_id": "existing_ontology",
      "disambiguation_index": 0,
      "label": "existing ontologies",
      "aliases": [
        "existing ontologies"
      ],
      "types": [
        "knowledge structure",
        "ontology",
        "framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Existing ontologies refer to established frameworks or structured representations of knowledge that define a set of concepts and the relationships between them, which are utilized for organizing information in a specific domain.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-5",
          "local_name": "existing ontologies",
          "local_types": [
            "knowledge structure",
            "ontology",
            "framework"
          ],
          "iri": "Entity-existing_ontology-Mention-1"
        }
      ],
      "relevance": 0.51123046875
    },
    "Entity-owl2": {
      "node_id": "owl2",
      "disambiguation_index": 0,
      "label": "OWL2",
      "aliases": [
        "OWL2"
      ],
      "types": [
        "format",
        "standard",
        "ontology language",
        "Semantic Web standard",
        "ontology",
        "technology",
        "language",
        "semantic web technology",
        "data format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "OWL2 is a semantic web ontology language that extends the original OWL (Web Ontology Language) to provide greater expressiveness and support for complex ontological structures.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-2",
          "local_name": "OWL2",
          "local_types": [
            "format",
            "standard",
            "Semantic Web standard",
            "technology",
            "data format"
          ],
          "iri": "Entity-owl2-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-6",
          "local_name": "OWL2",
          "local_types": [
            "standard",
            "ontology language",
            "ontology",
            "language",
            "semantic web technology"
          ],
          "iri": "Entity-owl2-Mention-2"
        }
      ],
      "relevance": 0.5107421875
    },
    "Entity-their_focus": {
      "node_id": "their_focus",
      "disambiguation_index": 0,
      "label": "their focus",
      "aliases": [
        "their focus"
      ],
      "types": [
        "focus"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'their focus' refers to the primary emphasis of Khairunizam et al. on the recognition of geometrical gestures, specifically limited to a set of five geometrical shapes.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-4",
          "local_name": "their focus",
          "local_types": [
            "focus"
          ],
          "iri": "Entity-their_focus-Mention-1"
        }
      ],
      "relevance": 0.51025390625
    },
    "Entity-device_manufacturer": {
      "node_id": "device_manufacturer",
      "disambiguation_index": 0,
      "label": "device manufacturers",
      "aliases": [
        "device manufacturers"
      ],
      "types": [
        "industry stakeholder",
        "manufacturer",
        "user group",
        "user",
        "organisation",
        "profession"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Device manufacturers are organizations or companies that design, produce, and sell devices, typically in the technology or electronics sectors.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "device manufacturers",
          "local_types": [
            "industry stakeholder",
            "organisation",
            "manufacturer"
          ],
          "iri": "Entity-device_manufacturer-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-2-Sentence-1",
          "local_name": "device manufacturers",
          "local_types": [
            "user group",
            "user",
            "profession",
            "organisation"
          ],
          "iri": "Entity-device_manufacturer-Mention-2"
        }
      ],
      "relevance": 0.509765625
    },
    "Entity-sosa__observableproperty": {
      "node_id": "sosa__observableproperty",
      "disambiguation_index": 0,
      "label": "sosa:ObservableProperty",
      "aliases": [
        "sosa:ObservableProperty"
      ],
      "types": [
        "ontology class",
        "ontology",
        "property",
        "concept",
        "ontology term",
        "observable property",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "sosa:ObservableProperty is an ontology class that represents a property that can be observed or measured, typically used in the context of sensing and data collection.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-12",
          "local_name": "sosa:ObservableProperty",
          "local_types": [
            "ontology class",
            "ontology",
            "property",
            "concept",
            "ontology term",
            "observable property",
            "entity",
            "class"
          ],
          "iri": "Entity-sosa__observableproperty-Mention-1"
        }
      ],
      "relevance": 0.50927734375
    },
    "Entity-rightward_": {
      "node_id": "rightward_",
      "disambiguation_index": 0,
      "label": "'rightward'",
      "aliases": [
        "'rightward'"
      ],
      "types": [
        "direction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "'rightward' refers to a predefined directional axis in the hdgi:LocalCoordinateSystem, indicating movement or orientation towards the right side in a 3D space.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "'rightward'",
          "local_types": [
            "direction"
          ],
          "iri": "Entity-rightward_-Mention-1"
        }
      ],
      "relevance": 0.50927734375
    },
    "Entity-capability": {
      "node_id": "capability",
      "disambiguation_index": 0,
      "label": "capability",
      "aliases": [
        "capability"
      ],
      "types": [
        "ability",
        "potential"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'capability' refers to the potential of studies to identify and analyze the relationships between gestures beyond their predefined meanings and mappings.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "capability",
          "local_types": [
            "ability",
            "potential"
          ],
          "iri": "Entity-capability-Mention-1"
        }
      ],
      "relevance": 0.5087890625
    },
    "Entity-core_ontology_design_pattern": {
      "node_id": "core_ontology_design_pattern",
      "disambiguation_index": 0,
      "label": "core ontology design pattern",
      "aliases": [
        "core ontology design pattern"
      ],
      "types": [
        "ontology",
        "design pattern"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A core ontology design pattern is a reusable solution or template that provides a structured approach to modeling specific types of knowledge within an ontology, facilitating consistency and interoperability in semantic representations.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-4",
          "local_name": "core ontology design pattern",
          "local_types": [
            "ontology",
            "design pattern"
          ],
          "iri": "Entity-core_ontology_design_pattern-Mention-1"
        }
      ],
      "relevance": 0.5087890625
    },
    "Entity-api_client": {
      "node_id": "api_client",
      "disambiguation_index": 0,
      "label": "API clients",
      "aliases": [
        "API clients"
      ],
      "types": [
        "client",
        "product",
        "technology",
        "tool",
        "software",
        "application interface",
        "software component",
        "API",
        "application"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "API clients are software applications or components that interact with an application programming interface (API) to enable communication and data exchange between different software systems.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "API clients",
          "local_types": [
            "client",
            "product",
            "technology",
            "tool",
            "software",
            "application interface",
            "software component",
            "API",
            "application"
          ],
          "iri": "Entity-api_client-Mention-1"
        }
      ],
      "relevance": 0.50830078125
    },
    "Entity-smart_home": {
      "node_id": "smart_home",
      "disambiguation_index": 0,
      "label": "smart homes",
      "aliases": [
        "smart homes"
      ],
      "types": [
        "housing",
        "living environment",
        "residential technology",
        "building",
        "product",
        "automation",
        "technology",
        "home automation",
        "home",
        "system",
        "smart home"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Smart homes are residential environments equipped with advanced technology and automation systems that enhance convenience, security, and energy efficiency through interconnected devices.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "smart homes",
          "local_types": [
            "housing",
            "residential technology",
            "building",
            "automation",
            "technology",
            "home automation",
            "home"
          ],
          "iri": "Entity-smart_home-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "smart homes",
          "local_types": [
            "housing",
            "living environment",
            "product",
            "technology",
            "home",
            "system",
            "smart home"
          ],
          "iri": "Entity-smart_home-Mention-2"
        }
      ],
      "relevance": 0.50830078125
    },
    "Entity-system_designer": {
      "node_id": "system_designer",
      "disambiguation_index": 0,
      "label": "system designers",
      "aliases": [
        "system designers"
      ],
      "types": [
        "role",
        "profession"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "System designers are professionals who create and develop systems, often focusing on user interaction and experience, by defining functionalities and evaluating design choices.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-5-Sentence-1",
          "local_name": "system designers",
          "local_types": [
            "role",
            "profession"
          ],
          "iri": "Entity-system_designer-Mention-1"
        }
      ],
      "relevance": 0.50732421875
    },
    "Entity-those_author": {
      "node_id": "those_author",
      "disambiguation_index": 0,
      "label": "those authors",
      "aliases": [
        "those authors"
      ],
      "types": [
        "authors"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'those authors' refers to Scoditti et al., who proposed a gestural interaction taxonomy but did not establish mappings of existing gesture vocabularies with their semantic relationships.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-4",
          "local_name": "those authors",
          "local_types": [
            "authors"
          ],
          "iri": "Entity-those_author-Mention-1"
        }
      ],
      "relevance": 0.5068359375
    },
    "Entity-single_body_part": {
      "node_id": "single_body_part",
      "disambiguation_index": 0,
      "label": "single body part",
      "aliases": [
        "single body part",
        "a single body part"
      ],
      "types": [
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'single body part' refers to an individual anatomical segment, such as a hand or arm, that is involved in performing a specific gesture within the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "single body part",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-single_body_part-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "a single body part",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-single_body_part-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-3",
          "local_name": "a single body part",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-single_body_part-Mention-3"
        }
      ],
      "relevance": 0.50634765625
    },
    "Entity-javascript": {
      "node_id": "javascript",
      "disambiguation_index": 0,
      "label": "JavaScript",
      "aliases": [
        "JavaScript"
      ],
      "types": [
        "programming language",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "JavaScript is a high-level, dynamic programming language commonly used for creating interactive effects within web browsers.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-2",
          "local_name": "JavaScript",
          "local_types": [
            "programming language",
            "technology"
          ],
          "iri": "Entity-javascript-Mention-1"
        }
      ],
      "relevance": 0.505859375
    },
    "Entity-notation": {
      "node_id": "notation",
      "disambiguation_index": 0,
      "label": "notation",
      "aliases": [
        "notation"
      ],
      "types": [
        "symbolic representation",
        "methodology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Notation refers to a system of symbols and signs used to represent concepts, quantities, or instructions in a structured and standardized manner.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-10",
          "local_name": "notation",
          "local_types": [
            "symbolic representation",
            "methodology"
          ],
          "iri": "Entity-notation-Mention-1"
        }
      ],
      "relevance": 0.505859375
    },
    "Entity-left": {
      "node_id": "left",
      "disambiguation_index": 0,
      "label": "left",
      "aliases": [
        "left"
      ],
      "types": [
        "direction",
        "spatial reference"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the paper, 'left' refers to the left side of the human body, specifically indicating the left fingers as part of the classification of body parts in the upper limb region for gesture modeling.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "left",
          "local_types": [
            "direction",
            "spatial reference"
          ],
          "iri": "Entity-left-Mention-1"
        }
      ],
      "relevance": 0.50537109375
    },
    "Entity-right_palm": {
      "node_id": "right_palm",
      "disambiguation_index": 0,
      "label": "right palm",
      "aliases": [
        "right palm"
      ],
      "types": [
        "anatomy",
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'right palm' refers to the anatomical part of the human body located at the distal end of the right forearm, which is involved in gesture recognition and modeling within the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "right palm",
          "local_types": [
            "anatomy",
            "body part"
          ],
          "iri": "Entity-right_palm-Mention-1"
        }
      ],
      "relevance": 0.50537109375
    },
    "Entity-anyone_interested_to_join_a_a_contributor": {
      "node_id": "anyone_interested_to_join_a_a_contributor",
      "disambiguation_index": 0,
      "label": "anyone interested to join as a contributor",
      "aliases": [
        "anyone interested to join as a contributor"
      ],
      "types": [
        "contributor"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention 'anyone interested to join as a contributor' refers to individuals or entities who wish to participate in the development and enhancement of the HDGI ontology by contributing code, data, or other resources through the GitHub platform.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "anyone interested to join as a contributor",
          "local_types": [
            "contributor"
          ],
          "iri": "Entity-anyone_interested_to_join_a_a_contributor-Mention-1"
        }
      ],
      "relevance": 0.5048828125
    },
    "Entity-qualisys": {
      "node_id": "qualisys",
      "disambiguation_index": 0,
      "label": "Qualisys",
      "aliases": [
        "Qualisys"
      ],
      "types": [
        "company",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Qualisys is a company that specializes in motion capture technology, which is utilized in various studies to accurately track and analyze human movements, such as arm gestures.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "Qualisys",
          "local_types": [
            "company",
            "technology"
          ],
          "iri": "Entity-qualisys-Mention-1"
        }
      ],
      "relevance": 0.50390625
    },
    "Entity-api_documentation": {
      "node_id": "api_documentation",
      "disambiguation_index": 0,
      "label": "API documentation",
      "aliases": [
        "API documentation"
      ],
      "types": [
        "documentation",
        "API",
        "technical resource"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "API documentation is a technical resource that provides detailed information about how to use an application programming interface (API), including its endpoints, request and response formats, and usage examples.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-6",
          "local_name": "API documentation",
          "local_types": [
            "documentation",
            "API",
            "technical resource"
          ],
          "iri": "Entity-api_documentation-Mention-1"
        }
      ],
      "relevance": 0.50390625
    },
    "Entity-an_interesting_study": {
      "node_id": "an_interesting_study",
      "disambiguation_index": 0,
      "label": "an interesting study",
      "aliases": [
        "an interesting study"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'an interesting study' refers to research conducted by Khairunizam et al., which utilized Qualisys motion capture technology to analyze and recognize arm gestures, focusing on geometrical shapes and aiming to enhance the accuracy of gesture recognition.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-3",
          "local_name": "an interesting study",
          "local_types": [
            "research"
          ],
          "iri": "Entity-an_interesting_study-Mention-1"
        }
      ],
      "relevance": 0.50341796875
    },
    "Entity-foundational_model_of_anatomy": {
      "node_id": "foundational_model_of_anatomy",
      "disambiguation_index": 0,
      "label": "Foundational Model of Anatomy",
      "aliases": [
        "Foundational Model of Anatomy"
      ],
      "types": [
        "model",
        "ontology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The Foundational Model of Anatomy is a comprehensive ontology that provides a structured representation of human anatomical structures and their relationships, facilitating the integration and sharing of anatomical knowledge.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "Foundational Model of Anatomy",
          "local_types": [
            "model",
            "ontology"
          ],
          "iri": "Entity-foundational_model_of_anatomy-Mention-1"
        }
      ],
      "relevance": 0.5029296875
    },
    "Entity-personalization": {
      "node_id": "personalization",
      "disambiguation_index": 0,
      "label": "personalization",
      "aliases": [
        "personalization"
      ],
      "types": [
        "process",
        "customization"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Personalization is the process of tailoring products, services, or experiences to meet the specific preferences and needs of individual users or groups.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-3",
          "local_name": "personalization",
          "local_types": [
            "process",
            "customization"
          ],
          "iri": "Entity-personalization-Mention-1"
        }
      ],
      "relevance": 0.50244140625
    },
    "Entity-android": {
      "node_id": "android",
      "disambiguation_index": 0,
      "label": "Android",
      "aliases": [
        "Android"
      ],
      "types": [
        "operating system",
        "technology",
        "platform"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Android is a mobile operating system developed by Google, designed primarily for touchscreen devices such as smartphones and tablets.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-2",
          "local_name": "Android",
          "local_types": [
            "operating system",
            "technology",
            "platform"
          ],
          "iri": "Entity-android-Mention-1"
        }
      ],
      "relevance": 0.501953125
    },
    "Entity-restful_endpoint": {
      "node_id": "restful_endpoint",
      "disambiguation_index": 0,
      "label": "RESTful endpoints",
      "aliases": [
        "RESTful endpoints"
      ],
      "types": [
        "web service",
        "endpoint",
        "technology",
        "API endpoint"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "RESTful endpoints are specific URLs in a web service that adhere to the principles of Representational State Transfer (REST), allowing clients to interact with resources using standard HTTP methods.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "RESTful endpoints",
          "local_types": [
            "web service",
            "endpoint",
            "technology",
            "API endpoint"
          ],
          "iri": "Entity-restful_endpoint-Mention-1"
        }
      ],
      "relevance": 0.501953125
    },
    "Entity-villarreal-narvaez": {
      "node_id": "villarreal-narvaez",
      "disambiguation_index": 0,
      "label": "Villarreal-Narvaez",
      "aliases": [
        "Villarreal-Narvaez"
      ],
      "types": [
        "author",
        "researcher",
        "person"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Villarreal-Narvaez is an author and researcher who contributed to a survey paper highlighting that most gestures are performed using the upper limbs of the human body.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "Villarreal-Narvaez",
          "local_types": [
            "author",
            "researcher",
            "person"
          ],
          "iri": "Entity-villarreal-narvaez-Mention-1"
        }
      ],
      "relevance": 0.50146484375
    },
    "Entity-oculus_quest": {
      "node_id": "oculus_quest",
      "disambiguation_index": 0,
      "label": "Oculus Quest",
      "aliases": [
        "Oculus Quest"
      ],
      "types": [
        "product",
        "technology",
        "device",
        "hardware",
        "virtual reality headset"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Oculus Quest is a standalone virtual reality headset developed by Oculus, designed for immersive gaming and interactive experiences without the need for external sensors or a connected computer.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-4",
          "local_name": "Oculus Quest",
          "local_types": [
            "product",
            "technology",
            "device",
            "hardware",
            "virtual reality headset"
          ],
          "iri": "Entity-oculus_quest-Mention-1"
        }
      ],
      "relevance": 0.50048828125
    },
    "Entity-ontology_building": {
      "node_id": "ontology_building",
      "disambiguation_index": 0,
      "label": "ontology building",
      "aliases": [
        "ontology building"
      ],
      "types": [
        "methodology",
        "process",
        "research activity",
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Ontology building is the process of creating a structured framework that defines the relationships and categories of concepts within a specific domain, facilitating knowledge representation and sharing.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-1",
          "local_name": "ontology building",
          "local_types": [
            "methodology",
            "process",
            "research activity",
            "ontology"
          ],
          "iri": "Entity-ontology_building-Mention-1"
        }
      ],
      "relevance": 0.50048828125
    },
    "Entity-hdgi__yrotation": {
      "node_id": "hdgi__yrotation",
      "disambiguation_index": 0,
      "label": "hdgi:yRotation",
      "aliases": [
        "hdgi:yRotation"
      ],
      "types": [
        "rotation component",
        "attribute",
        "concept",
        "rotation axis",
        "data type",
        "data attribute",
        "rotation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "hdgi:yRotation refers to the pitch angle component of a pose's rotation in a 3D space, which can be represented using either Euler angles or quaternions within the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "hdgi:yRotation",
          "local_types": [
            "rotation component",
            "attribute",
            "concept",
            "rotation axis",
            "data type",
            "data attribute",
            "rotation"
          ],
          "iri": "Entity-hdgi__yrotation-Mention-1"
        }
      ],
      "relevance": 0.498291015625
    },
    "Entity-that_class_a_the_subject": {
      "node_id": "that_class_a_the_subject",
      "disambiguation_index": 0,
      "label": "that class as the subject",
      "aliases": [
        "that class as the subject"
      ],
      "types": [
        "class"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'that class as the subject' refers to a specific class within the HDGI ontology that is used to define the range of properties in a way that restricts their application to instances of that class, thereby facilitating the alignment of the ontology with external ontologies through guarded local restrictions.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "that class as the subject",
          "local_types": [
            "class"
          ],
          "iri": "Entity-that_class_a_the_subject-Mention-1"
        }
      ],
      "relevance": 0.498291015625
    },
    "Entity-end_pose": {
      "node_id": "end_pose",
      "disambiguation_index": 0,
      "label": "end pose",
      "aliases": [
        "the end pose",
        "an end pose",
        "end pose"
      ],
      "types": [
        "final position",
        "pose",
        "position"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'end pose' refers to the final position of a body part in a dynamic gesture, marking the conclusion of the gesture's movement within the context of human-device interactions.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "end pose",
          "local_types": [
            "final position",
            "pose",
            "position"
          ],
          "iri": "Entity-end_pose-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "end pose",
          "local_types": [
            "pose",
            "position"
          ],
          "iri": "Entity-end_pose-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "an end pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-end_pose-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "the end pose",
          "local_types": [
            "pose"
          ],
          "iri": "Entity-end_pose-Mention-4"
        }
      ],
      "relevance": 0.498046875
    },
    "Entity-wrist": {
      "node_id": "wrist",
      "disambiguation_index": 0,
      "label": "wrist",
      "aliases": [
        "wrist",
        "the wrist"
      ],
      "types": [
        "joint",
        "anatomy",
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The wrist is a joint in the human body that connects the hand to the forearm, allowing for a range of motion and flexibility.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "wrist",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-wrist-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-9",
          "local_name": "wrist",
          "local_types": [
            "joint",
            "anatomy",
            "body part"
          ],
          "iri": "Entity-wrist-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-6-Sentence-3",
          "local_name": "the wrist",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-wrist-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-9",
          "local_name": "the wrist",
          "local_types": [
            "body part",
            "anatomy"
          ],
          "iri": "Entity-wrist-Mention-4"
        }
      ],
      "relevance": 0.497802734375
    },
    "Entity-guarded_local_restriction": {
      "node_id": "guarded_local_restriction",
      "disambiguation_index": 0,
      "label": "guarded local restrictions",
      "aliases": [
        "guarded local restrictions"
      ],
      "types": [
        "rule",
        "constraint",
        "restriction",
        "concept",
        "theoretical framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Guarded local restrictions refer to a type of constraint in ontology design that applies universal and existential class restrictions to specific properties, ensuring that the range of those properties is asserted only for instances of a particular class, thereby enhancing alignment with external ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "guarded local restrictions",
          "local_types": [
            "theoretical framework",
            "restriction",
            "concept"
          ],
          "iri": "Entity-guarded_local_restriction-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-8",
          "local_name": "guarded local restrictions",
          "local_types": [
            "rule",
            "restriction",
            "constraint"
          ],
          "iri": "Entity-guarded_local_restriction-Mention-2"
        }
      ],
      "relevance": 0.496826171875
    },
    "Entity-fma_class_definition": {
      "node_id": "fma_class_definition",
      "disambiguation_index": 0,
      "label": "FMA class definitions",
      "aliases": [
        "FMA class definitions and structures",
        "FMA class definitions"
      ],
      "types": [
        "definition",
        "taxonomy",
        "classification",
        "structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "FMA class definitions refer to the established categories and structures within the Foundational Model of Anatomy ontology that are utilized to define anatomical concepts relevant to human body parts, particularly in the context of modeling gestures for Human Device Interactions.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "FMA class definitions",
          "local_types": [
            "classification",
            "taxonomy"
          ],
          "iri": "Entity-fma_class_definition-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "FMA class definitions and structures",
          "local_types": [
            "definition",
            "structure"
          ],
          "iri": "Entity-fma_class_definition-Mention-2"
        }
      ],
      "relevance": 0.496337890625
    },
    "Entity-actor": {
      "node_id": "actor",
      "disambiguation_index": 0,
      "label": "actor",
      "aliases": [
        "actor"
      ],
      "types": [
        "individual",
        "entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'actor' refers to an individual user who interacts with a device, influencing the interpretation of affordances based on their specific context and actions.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-6",
          "local_name": "actor",
          "local_types": [
            "individual",
            "entity"
          ],
          "iri": "Entity-actor-Mention-1"
        }
      ],
      "relevance": 0.496337890625
    },
    "Entity-the_perceived_and_actual_property_of_the_thing": {
      "node_id": "the_perceived_and_actual_property_of_the_thing",
      "disambiguation_index": 0,
      "label": "the perceived and actual properties of the thing",
      "aliases": [
        "the perceived and actual properties of the thing"
      ],
      "types": [
        "properties"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'the perceived and actual properties of the thing' refers to the concept of affordance, which encompasses the characteristics of an object that inform users about its potential uses and interactions within a given context.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-1",
          "local_name": "the perceived and actual properties of the thing",
          "local_types": [
            "properties"
          ],
          "iri": "Entity-the_perceived_and_actual_property_of_the_thing-Mention-1"
        }
      ],
      "relevance": 0.495849609375
    },
    "Entity-automated_reasoning": {
      "node_id": "automated_reasoning",
      "disambiguation_index": 0,
      "label": "automated reasoning",
      "aliases": [
        "automated reasoning"
      ],
      "types": [
        "process",
        "computational logic",
        "artificial intelligence",
        "reasoning"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Automated reasoning is a field of artificial intelligence and computational logic that focuses on the development of algorithms and systems capable of deriving conclusions from a set of premises using formal reasoning techniques.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-5",
          "local_name": "automated reasoning",
          "local_types": [
            "process",
            "computational logic",
            "artificial intelligence",
            "reasoning"
          ],
          "iri": "Entity-automated_reasoning-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-2",
          "local_name": "automated reasoning",
          "local_types": [
            "artificial intelligence",
            "reasoning"
          ],
          "iri": "Entity-automated_reasoning-Mention-2"
        }
      ],
      "relevance": 0.49560546875
    },
    "Entity-java_version_1.9_or_higher": {
      "node_id": "java_version_1.9_or_higher",
      "disambiguation_index": 0,
      "label": "Java version 1.9 or higher",
      "aliases": [
        "Java version 1.9 or higher"
      ],
      "types": [
        "software",
        "programming language",
        "Java"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Java version 1.9 or higher refers to a specific version of the Java programming language and runtime environment that is required to run the web application developed in the context of the HDGI ontology project.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-3",
          "local_name": "Java version 1.9 or higher",
          "local_types": [
            "software",
            "programming language",
            "Java"
          ],
          "iri": "Entity-java_version_1.9_or_higher-Mention-1"
        }
      ],
      "relevance": 0.495361328125
    },
    "Entity-end_user": {
      "node_id": "end_user",
      "disambiguation_index": 0,
      "label": "end users",
      "aliases": [
        "end users"
      ],
      "types": [
        "user group",
        "user",
        "stakeholder"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "End users are individuals or groups who utilize a product, service, or system, often serving as the final consumers in a process.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-2",
          "local_name": "end users",
          "local_types": [
            "user group",
            "stakeholder"
          ],
          "iri": "Entity-end_user-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-5-Sentence-1",
          "local_name": "end users",
          "local_types": [
            "user",
            "stakeholder"
          ],
          "iri": "Entity-end_user-Mention-2"
        }
      ],
      "relevance": 0.493896484375
    },
    "Entity-customized_sparql_endpoint": {
      "node_id": "customized_sparql_endpoint",
      "disambiguation_index": 0,
      "label": "customized SPARQL endpoints",
      "aliases": [
        "customized SPARQL endpoints"
      ],
      "types": [
        "endpoint"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Customized SPARQL endpoints are tailored interfaces that allow users to query and interact with RDF data using the SPARQL query language, designed to meet specific requirements or preferences.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "customized SPARQL endpoints",
          "local_types": [
            "endpoint"
          ],
          "iri": "Entity-customized_sparql_endpoint-Mention-1"
        }
      ],
      "relevance": 0.493896484375
    },
    "Entity-upward_": {
      "node_id": "upward_",
      "disambiguation_index": 0,
      "label": "'upward'",
      "aliases": [
        "'upward'"
      ],
      "types": [
        "direction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "'upward' refers to a predefined directional axis in the hdgi:LocalCoordinateSystem, indicating the positive direction along the y-axis.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "'upward'",
          "local_types": [
            "direction"
          ],
          "iri": "Entity-upward_-Mention-1"
        }
      ],
      "relevance": 0.493896484375
    },
    "Entity-rotation": {
      "node_id": "rotation",
      "disambiguation_index": 0,
      "label": "rotation",
      "aliases": [
        "rotation"
      ],
      "types": [
        "attribute",
        "mathematical operation",
        "concept",
        "rotation",
        "transformation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the paper, 'rotation' refers to the representation of the orientation of a pose in 3D space, which can be described using either Euler angles (yaw, pitch, roll) or quaternions, allowing for flexibility in modeling data from various gesture recognition systems.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-16",
          "local_name": "rotation",
          "local_types": [
            "attribute",
            "mathematical operation",
            "concept",
            "rotation",
            "transformation"
          ],
          "iri": "Entity-rotation-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "rotation",
          "local_types": [
            "attribute"
          ],
          "iri": "Entity-rotation-Mention-2"
        }
      ],
      "relevance": 0.492431640625
    },
    "Entity-api_and_architecture_documentation": {
      "node_id": "api_and_architecture_documentation",
      "disambiguation_index": 0,
      "label": "API and architecture documentation",
      "aliases": [
        "API and architecture documentation"
      ],
      "types": [
        "documentation",
        "API"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "API and architecture documentation refers to written materials that provide detailed information about the application programming interfaces (APIs) and the underlying architecture of a software system, facilitating understanding and customization of the system.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "API and architecture documentation",
          "local_types": [
            "documentation",
            "API"
          ],
          "iri": "Entity-api_and_architecture_documentation-Mention-1"
        }
      ],
      "relevance": 0.492431640625
    },
    "Entity-leftward_": {
      "node_id": "leftward_",
      "disambiguation_index": 0,
      "label": "'leftward'",
      "aliases": [
        "'leftward'"
      ],
      "types": [
        "direction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "'leftward' refers to a predefined directional axis in the hdgi:LocalCoordinateSystem, indicating movement or orientation towards the left side in a 3D spatial context.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "'leftward'",
          "local_types": [
            "direction"
          ],
          "iri": "Entity-leftward_-Mention-1"
        }
      ],
      "relevance": 0.492431640625
    },
    "Entity-private_service": {
      "node_id": "private_service",
      "disambiguation_index": 0,
      "label": "private service",
      "aliases": [
        "private service"
      ],
      "types": [
        "software service",
        "service"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'private service' refers to a customizable web application that can be deployed in a private cloud environment, allowing users to define and manage their own SPARQL and RESTful endpoints for gesture recognition integration.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "private service",
          "local_types": [
            "software service",
            "service"
          ],
          "iri": "Entity-private_service-Mention-1"
        }
      ],
      "relevance": 0.4921875
    },
    "Entity-devicemanufacturer": {
      "node_id": "devicemanufacturer",
      "disambiguation_index": 0,
      "label": "DeviceManufacturer",
      "aliases": [
        "DeviceManufacturer"
      ],
      "types": [
        "entity",
        "concept",
        "organisation"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "DeviceManufacturer refers to an organization that produces and sells devices, often involving various models and technologies.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "DeviceManufacturer",
          "local_types": [
            "concept",
            "entity"
          ],
          "iri": "Entity-devicemanufacturer-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-2",
          "local_name": "DeviceManufacturer",
          "local_types": [
            "organisation",
            "entity"
          ],
          "iri": "Entity-devicemanufacturer-Mention-2"
        }
      ],
      "relevance": 0.490966796875
    },
    "Entity-api_client_stub": {
      "node_id": "api_client_stub",
      "disambiguation_index": 0,
      "label": "API client stubs",
      "aliases": [
        "API client stubs"
      ],
      "types": [
        "client",
        "SDK",
        "client stub",
        "code generation",
        "software component",
        "API"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "API client stubs are software components that provide a simplified interface for interacting with an API, typically generated automatically to facilitate easier integration in various programming languages.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-2",
          "local_name": "API client stubs",
          "local_types": [
            "client",
            "SDK",
            "client stub",
            "code generation",
            "software component",
            "API"
          ],
          "iri": "Entity-api_client_stub-Mention-1"
        }
      ],
      "relevance": 0.490966796875
    },
    "Entity-upper_limb_of_the_human_body": {
      "node_id": "upper_limb_of_the_human_body",
      "disambiguation_index": 0,
      "label": "upper limbs of the human body",
      "aliases": [
        "upper limbs of the human body",
        "the upper limbs of the human body"
      ],
      "types": [
        "human body",
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The upper limbs of the human body refer to the arms, including the shoulders, elbows, wrists, and hands, which are used for various functions such as manipulation and interaction with the environment.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "upper limbs of the human body",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-upper_limb_of_the_human_body-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "the upper limbs of the human body",
          "local_types": [
            "body part",
            "human body"
          ],
          "iri": "Entity-upper_limb_of_the_human_body-Mention-2"
        }
      ],
      "relevance": 0.490234375
    },
    "Entity-sample": {
      "node_id": "sample",
      "disambiguation_index": 0,
      "label": "Sample",
      "aliases": [
        "Sample",
        "samples"
      ],
      "types": [
        "data point",
        "specimen",
        "concept",
        "data type",
        "sample"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the Semantic Sensor Network ontology, 'Sample' refers to a fundamental component that represents a specific instance of data or observation collected by sensors.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-10",
          "local_name": "Sample",
          "local_types": [
            "data type",
            "concept"
          ],
          "iri": "Entity-sample-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-11",
          "local_name": "samples",
          "local_types": [
            "sample",
            "data point",
            "specimen"
          ],
          "iri": "Entity-sample-Mention-2"
        }
      ],
      "relevance": 0.48974609375
    },
    "Entity-foundational_model_of_anatomy__fma_": {
      "node_id": "foundational_model_of_anatomy__fma_",
      "disambiguation_index": 0,
      "label": "Foundational Model of Anatomy (FMA)",
      "aliases": [
        "Foundational Model of Anatomy (FMA) ontology",
        "Foundational Model of Anatomy (FMA)"
      ],
      "types": [
        "model",
        "ontology",
        "anatomical model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The Foundational Model of Anatomy (FMA) is a comprehensive ontology that provides a structured representation of human anatomy, including concepts and relationships among anatomical entities.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "Foundational Model of Anatomy (FMA)",
          "local_types": [
            "model",
            "ontology",
            "anatomical model"
          ],
          "iri": "Entity-foundational_model_of_anatomy__fma_-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "Foundational Model of Anatomy (FMA) ontology",
          "local_types": [
            "ontology",
            "model"
          ],
          "iri": "Entity-foundational_model_of_anatomy__fma_-Mention-2"
        }
      ],
      "relevance": 0.48876953125
    },
    "Entity-holistic_posture": {
      "node_id": "holistic_posture",
      "disambiguation_index": 0,
      "label": "holistic posture",
      "aliases": [
        "holistic posture",
        "the holistic posture of the human body",
        "holistic posture of the human body"
      ],
      "types": [
        "posture",
        "physical state",
        "body position",
        "human body"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'holistic posture' refers to the overall positioning and alignment of the human body as a whole, rather than focusing on specific details such as finger movements or hand gestures.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "holistic posture",
          "local_types": [
            "posture",
            "physical state",
            "body position"
          ],
          "iri": "Entity-holistic_posture-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "holistic posture of the human body",
          "local_types": [
            "posture",
            "human body"
          ],
          "iri": "Entity-holistic_posture-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "the holistic posture of the human body",
          "local_types": [
            "posture",
            "human body"
          ],
          "iri": "Entity-holistic_posture-Mention-3"
        }
      ],
      "relevance": 0.488525390625
    },
    "Entity-norman": {
      "node_id": "norman",
      "disambiguation_index": 0,
      "label": "Norman",
      "aliases": [
        "Norman"
      ],
      "types": [
        "author",
        "person"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Norman refers to Don Norman, a prominent figure in the field of Human-Computer Interaction and design, known for his work on the concept of affordances in user interface design.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-1-Sentence-1",
          "local_name": "Norman",
          "local_types": [
            "author",
            "person"
          ],
          "iri": "Entity-norman-Mention-1"
        }
      ],
      "relevance": 0.48681640625
    },
    "Entity-outward_": {
      "node_id": "outward_",
      "disambiguation_index": 0,
      "label": "'outward'",
      "aliases": [
        "'outward'"
      ],
      "types": [
        "direction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "'outward' refers to a predefined directional axis in the hdgi:LocalCoordinateSystem, specifically indicating the positive direction along the z-axis.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "'outward'",
          "local_types": [
            "direction"
          ],
          "iri": "Entity-outward_-Mention-1"
        }
      ],
      "relevance": 0.48681640625
    },
    "Entity-a_comprehensive_view_of_the_api": {
      "node_id": "a_comprehensive_view_of_the_api",
      "disambiguation_index": 0,
      "label": "a comprehensive view of the API",
      "aliases": [
        "a comprehensive view of the API"
      ],
      "types": [
        "view",
        "API"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A comprehensive view of the API refers to a detailed and user-friendly representation of the API's endpoint structures and functionalities, enabling users to understand and interact with the API in real-time.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-1",
          "local_name": "a comprehensive view of the API",
          "local_types": [
            "view",
            "API"
          ],
          "iri": "Entity-a_comprehensive_view_of_the_api-Mention-1"
        }
      ],
      "relevance": 0.486572265625
    },
    "Entity-web_application": {
      "node_id": "web_application",
      "disambiguation_index": 0,
      "label": "web application",
      "aliases": [
        "web application"
      ],
      "types": [
        "web-based software",
        "software",
        "software application",
        "application"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A web application is a software application that is accessed and interacted with through a web browser over a network, typically the Internet.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-3",
          "local_name": "web application",
          "local_types": [
            "software",
            "application"
          ],
          "iri": "Entity-web_application-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "web application",
          "local_types": [
            "web-based software",
            "software",
            "software application",
            "application"
          ],
          "iri": "Entity-web_application-Mention-2"
        }
      ],
      "relevance": 0.486083984375
    },
    "Entity-3d_space": {
      "node_id": "3d_space",
      "disambiguation_index": 0,
      "label": "3D space",
      "aliases": [
        "3D space"
      ],
      "types": [
        "space",
        "spatial dimension",
        "environment"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "3D space refers to a three-dimensional geometric environment characterized by width, height, and depth, where objects can be positioned and oriented.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-4",
          "local_name": "3D space",
          "local_types": [
            "space",
            "spatial dimension",
            "environment"
          ],
          "iri": "Entity-3d_space-Mention-1"
        }
      ],
      "relevance": 0.485107421875
    },
    "Entity-it_first_version": {
      "node_id": "it_first_version",
      "disambiguation_index": 0,
      "label": "its first version",
      "aliases": [
        "its first version"
      ],
      "types": [
        "version"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'its first version' refers to the initial iteration of the Microsoft HoloLens, which utilized a 'bloom' gesture to open its 'start' menu.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-1",
          "local_name": "its first version",
          "local_types": [
            "version"
          ],
          "iri": "Entity-it_first_version-Mention-1"
        }
      ],
      "relevance": 0.4833984375
    },
    "Entity-upper_arm": {
      "node_id": "upper_arm",
      "disambiguation_index": 0,
      "label": "upper arm",
      "aliases": [
        "upper arm"
      ],
      "types": [
        "gesture",
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The upper arm is the part of the human arm located between the shoulder and the elbow, serving as a key segment for various movements and gestures.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-2",
          "local_name": "upper arm",
          "local_types": [
            "body part",
            "gesture"
          ],
          "iri": "Entity-upper_arm-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-7",
          "local_name": "upper arm",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-upper_arm-Mention-2"
        }
      ],
      "relevance": 0.48291015625
    },
    "Entity-manufacturer__s_design_decision": {
      "node_id": "manufacturer__s_design_decision",
      "disambiguation_index": 0,
      "label": "manufacturer\u2019s design decision",
      "aliases": [
        "manufacturer\u2019s design decision"
      ],
      "types": [
        "design process",
        "decision making",
        "decision",
        "manufacturer"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A manufacturer\u2019s design decision refers to the choices and strategies made by a manufacturer regarding the aesthetic, functional, and technical aspects of a product's design.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "manufacturer\u2019s design decision",
          "local_types": [
            "design process",
            "decision making",
            "decision",
            "manufacturer"
          ],
          "iri": "Entity-manufacturer__s_design_decision-Mention-1"
        }
      ],
      "relevance": 0.482666015625
    },
    "Entity-palm": {
      "node_id": "palm",
      "disambiguation_index": 0,
      "label": "palm",
      "aliases": [
        "their palm",
        "palm",
        "Palm"
      ],
      "types": [
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'palm' refers to the inner surface of the hand, specifically the part that faces upward when a user holds their hand out while interacting with the HoloLens 2 device.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "palm",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-palm-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-9",
          "local_name": "Palm",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-palm-Mention-2"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-5",
          "local_name": "Palm",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-palm-Mention-3"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "Palm",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-palm-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-6-Sentence-2",
          "local_name": "their palm",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-palm-Mention-5"
        }
      ],
      "relevance": 0.482666015625
    },
    "Entity-design_decision": {
      "node_id": "design_decision",
      "disambiguation_index": 0,
      "label": "design decision",
      "aliases": [
        "design decision"
      ],
      "types": [
        "decision-making process",
        "design principle"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A design decision refers to a choice made during the design process that influences the functionality, aesthetics, or usability of a product or system.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "design decision",
          "local_types": [
            "decision-making process",
            "design principle"
          ],
          "iri": "Entity-design_decision-Mention-1"
        }
      ],
      "relevance": 0.4814453125
    },
    "Entity-axis_direction": {
      "node_id": "axis_direction",
      "disambiguation_index": 0,
      "label": "axis direction",
      "aliases": [
        "axis direction"
      ],
      "types": [
        "direction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'axis direction' refers to the predefined orientations of the axes in a local coordinate system, specifically indicating the possible directions for the x, y, and z axes, such as 'leftward' or 'rightward' for the x-axis, 'upward' or 'downward' for the y-axis, and 'outward' or 'inward' for the z-axis.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "axis direction",
          "local_types": [
            "direction"
          ],
          "iri": "Entity-axis_direction-Mention-1"
        }
      ],
      "relevance": 0.4814453125
    },
    "Entity-actuator": {
      "node_id": "actuator",
      "disambiguation_index": 0,
      "label": "Actuator",
      "aliases": [
        "Actuator",
        "actuators"
      ],
      "types": [
        "device",
        "control mechanism",
        "actuator",
        "component"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "An actuator is a device or component that converts a control signal into physical motion or action, often used in various systems to control mechanisms or processes.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-10",
          "local_name": "Actuator",
          "local_types": [
            "device",
            "component"
          ],
          "iri": "Entity-actuator-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-2-Sentence-11",
          "local_name": "actuators",
          "local_types": [
            "device",
            "control mechanism",
            "actuator"
          ],
          "iri": "Entity-actuator-Mention-2"
        }
      ],
      "relevance": 0.481201171875
    },
    "Entity-ontology_building_and_annotating": {
      "node_id": "ontology_building_and_annotating",
      "disambiguation_index": 0,
      "label": "ontology building and annotating",
      "aliases": [
        "ontology building and annotating"
      ],
      "types": [
        "process",
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Ontology building and annotating refers to the processes involved in creating and enriching ontologies by defining concepts, relationships, and attributes within a specific domain.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-1",
          "local_name": "ontology building and annotating",
          "local_types": [
            "process",
            "ontology"
          ],
          "iri": "Entity-ontology_building_and_annotating-Mention-1"
        }
      ],
      "relevance": 0.481201171875
    },
    "Entity-figure_3_-_point_b": {
      "node_id": "figure_3_-_point_b",
      "disambiguation_index": 0,
      "label": "Figure 3 - point B",
      "aliases": [
        "Figure 3 - point B"
      ],
      "types": [
        "figure",
        "point"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Figure 3 - point B refers to the specific position of a hdgi:ForearmPose in the context of the HDGI ontology, indicating that this position is defined relative to the elbow joint.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-8",
          "local_name": "Figure 3 - point B",
          "local_types": [
            "figure",
            "point"
          ],
          "iri": "Entity-figure_3_-_point_b-Mention-1"
        }
      ],
      "relevance": 0.47998046875
    },
    "Entity-rdf": {
      "node_id": "rdf",
      "disambiguation_index": 0,
      "label": "RDF",
      "aliases": [
        "RDF",
        "RDFS"
      ],
      "types": [
        "format",
        "standard",
        "Semantic Web standard",
        "technology",
        "data format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "RDF, or Resource Description Framework, is a standard model for data interchange on the web that facilitates the representation of information about resources in a structured way.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-2",
          "local_name": "RDF",
          "local_types": [
            "format",
            "standard",
            "Semantic Web standard",
            "technology",
            "data format"
          ],
          "iri": "Entity-rdf-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-2-Sentence-2",
          "local_name": "RDFS",
          "local_types": [
            "format",
            "standard",
            "Semantic Web standard",
            "technology",
            "data format"
          ],
          "iri": "Entity-rdf-Mention-2"
        }
      ],
      "relevance": 0.479736328125
    },
    "Entity-swift": {
      "node_id": "swift",
      "disambiguation_index": 0,
      "label": "Swift",
      "aliases": [
        "Swift"
      ],
      "types": [
        "programming language",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Swift refers to a programming language developed by Apple, primarily used for building applications for iOS, macOS, watchOS, and tvOS.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-2",
          "local_name": "Swift",
          "local_types": [
            "programming language",
            "technology"
          ],
          "iri": "Entity-swift-Mention-1"
        }
      ],
      "relevance": 0.479736328125
    },
    "Entity-universal_and_existential_class_restriction": {
      "node_id": "universal_and_existential_class_restriction",
      "disambiguation_index": 0,
      "label": "universal and existential class restrictions",
      "aliases": [
        "universal and existential class restrictions"
      ],
      "types": [
        "theoretical framework",
        "restriction",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Universal and existential class restrictions refer to a type of guarded local restrictions in ontology design that specify the range of a property based on the class of the subject, allowing for more precise alignment with external ontologies.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-7",
          "local_name": "universal and existential class restrictions",
          "local_types": [
            "theoretical framework",
            "restriction",
            "concept"
          ],
          "iri": "Entity-universal_and_existential_class_restriction-Mention-1"
        }
      ],
      "relevance": 0.47900390625
    },
    "Entity-referent": {
      "node_id": "referent",
      "disambiguation_index": 0,
      "label": "referent",
      "aliases": [
        "referent",
        "referents"
      ],
      "types": [
        "linguistic concept",
        "term",
        "action representation",
        "concept",
        "meaning",
        "entity",
        "linguistic term",
        "referent",
        "semantic entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A referent is a linguistic term that denotes the specific entity or concept that a word, phrase, or gesture represents or refers to in communication.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-1",
          "local_name": "referent",
          "local_types": [
            "concept",
            "linguistic term"
          ],
          "iri": "Entity-referent-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-3",
          "local_name": "referents",
          "local_types": [
            "linguistic concept",
            "semantic entity"
          ],
          "iri": "Entity-referent-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-5",
          "local_name": "referents",
          "local_types": [
            "concept",
            "entity"
          ],
          "iri": "Entity-referent-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-9-Sentence-2",
          "local_name": "referent",
          "local_types": [
            "referent",
            "term",
            "action representation",
            "concept"
          ],
          "iri": "Entity-referent-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-10-Sentence-2",
          "local_name": "referents",
          "local_types": [
            "concept",
            "entity"
          ],
          "iri": "Entity-referent-Mention-5"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-5",
          "local_name": "referents",
          "local_types": [
            "linguistic concept",
            "meaning"
          ],
          "iri": "Entity-referent-Mention-6"
        }
      ],
      "relevance": 0.47802734375
    },
    "Entity-automated_reasoning_task": {
      "node_id": "automated_reasoning_task",
      "disambiguation_index": 0,
      "label": "automated reasoning tasks",
      "aliases": [
        "automated reasoning tasks"
      ],
      "types": [
        "task",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Automated reasoning tasks are computational processes that involve the use of algorithms and formal logic to derive conclusions or make inferences from a set of premises or data.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-1-Sentence-3",
          "local_name": "automated reasoning tasks",
          "local_types": [
            "task",
            "process"
          ],
          "iri": "Entity-automated_reasoning_task-Mention-1"
        }
      ],
      "relevance": 0.477783203125
    },
    "Entity-left-hand_rule_coordinate_system": {
      "node_id": "left-hand_rule_coordinate_system",
      "disambiguation_index": 0,
      "label": "left-hand rule coordinate system",
      "aliases": [
        "left-hand rule coordinate system"
      ],
      "types": [
        "coordinate system",
        "mathematical concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A left-hand rule coordinate system is a type of coordinate system in which the orientation of the axes follows the left-hand rule, typically defining the direction of the axes based on the arrangement of the left hand with the thumb pointing along the primary axis.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-13",
          "local_name": "left-hand rule coordinate system",
          "local_types": [
            "coordinate system",
            "mathematical concept"
          ],
          "iri": "Entity-left-hand_rule_coordinate_system-Mention-1"
        }
      ],
      "relevance": 0.4775390625
    },
    "Entity-the_rotation_of_a_pose": {
      "node_id": "the_rotation_of_a_pose",
      "disambiguation_index": 0,
      "label": "The rotation of a pose",
      "aliases": [
        "The rotation of a pose"
      ],
      "types": [
        "concept",
        "pose"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The rotation of a pose refers to the orientation of a body part in a three-dimensional space, which can be represented using either Euler angles (yaw, pitch, roll) or quaternions, allowing for flexible modeling of static gestures in human-device interactions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-16",
          "local_name": "The rotation of a pose",
          "local_types": [
            "concept",
            "pose"
          ],
          "iri": "Entity-the_rotation_of_a_pose-Mention-1"
        }
      ],
      "relevance": 0.4775390625
    },
    "Entity-turtle_syntax": {
      "node_id": "turtle_syntax",
      "disambiguation_index": 0,
      "label": "Turtle syntax",
      "aliases": [
        "Turtle syntax"
      ],
      "types": [
        "format",
        "syntax",
        "data serialization format",
        "serialization format",
        "data serialization"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Turtle syntax is a textual syntax for expressing data in the Resource Description Framework (RDF) format, designed to be easy to read and write for humans while enabling the serialization of RDF graphs.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-6",
          "local_name": "Turtle syntax",
          "local_types": [
            "format",
            "syntax",
            "data serialization format",
            "serialization format",
            "data serialization"
          ],
          "iri": "Entity-turtle_syntax-Mention-1"
        }
      ],
      "relevance": 0.477294921875
    },
    "Entity-a_right-hand_rule": {
      "node_id": "a_right-hand_rule",
      "disambiguation_index": 0,
      "label": "a right-hand rule",
      "aliases": [
        "a right-hand rule"
      ],
      "types": [
        "rule"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A right-hand rule is a convention used in 3D coordinate systems where the orientation of the axes is defined such that if the thumb of the right hand points along the positive x-axis and the index finger points along the positive y-axis, then the middle finger, extended perpendicular to the other two, points along the positive z-axis.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-14",
          "local_name": "a right-hand rule",
          "local_types": [
            "rule"
          ],
          "iri": "Entity-a_right-hand_rule-Mention-1"
        }
      ],
      "relevance": 0.477294921875
    },
    "Entity-coordinate_system": {
      "node_id": "coordinate_system",
      "disambiguation_index": 0,
      "label": "coordinate systems",
      "aliases": [
        "coordinate systems"
      ],
      "types": [
        "mathematical concept",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Coordinate systems are mathematical frameworks used to define the position of points in space through a set of numerical values and reference axes.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-12",
          "local_name": "coordinate systems",
          "local_types": [
            "mathematical concept",
            "system"
          ],
          "iri": "Entity-coordinate_system-Mention-1"
        }
      ],
      "relevance": 0.47705078125
    },
    "Entity-unity3d11": {
      "node_id": "unity3d11",
      "disambiguation_index": 0,
      "label": "Unity3D11",
      "aliases": [
        "Unity3D11"
      ],
      "types": [
        "tool",
        "software",
        "game engine",
        "3D engine"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Unity3D11 is a game engine and 3D development platform that utilizes a left-hand rule coordinate system for modeling spatial positions and rotations in 3D space.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-13",
          "local_name": "Unity3D11",
          "local_types": [
            "tool",
            "software",
            "game engine",
            "3D engine"
          ],
          "iri": "Entity-unity3d11-Mention-1"
        }
      ],
      "relevance": 0.476318359375
    },
    "Entity-architecture_documentation": {
      "node_id": "architecture_documentation",
      "disambiguation_index": 0,
      "label": "architecture documentation",
      "aliases": [
        "architecture documentation"
      ],
      "types": [
        "documentation",
        "technical document"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Architecture documentation refers to a comprehensive set of documents that outline the structure, components, and interactions within a system or application, providing guidance for development, customization, and maintenance.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "architecture documentation",
          "local_types": [
            "documentation",
            "technical document"
          ],
          "iri": "Entity-architecture_documentation-Mention-1"
        }
      ],
      "relevance": 0.4755859375
    },
    "Entity-contributor": {
      "node_id": "contributor",
      "disambiguation_index": 0,
      "label": "contributor",
      "aliases": [
        "contributor"
      ],
      "types": [
        "participant",
        "individual",
        "role"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'contributor' refers to any individual or participant who engages with the GitHub community by contributing to the relevant code, data, and ontology associated with the HDGI project.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "contributor",
          "local_types": [
            "participant",
            "individual",
            "role"
          ],
          "iri": "Entity-contributor-Mention-1"
        }
      ],
      "relevance": 0.474365234375
    },
    "Entity-point_b": {
      "node_id": "point_b",
      "disambiguation_index": 0,
      "label": "point B",
      "aliases": [
        "point B"
      ],
      "types": [
        "reference point",
        "location"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Point B refers to the specific location in a 3D space where the position of a hdgi:ForearmPose is defined relative to the elbow joint.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-8",
          "local_name": "point B",
          "local_types": [
            "reference point",
            "location"
          ],
          "iri": "Entity-point_b-Mention-1"
        }
      ],
      "relevance": 0.474365234375
    },
    "Entity-designer_and_manufacturer": {
      "node_id": "designer_and_manufacturer",
      "disambiguation_index": 0,
      "label": "designers and manufacturers",
      "aliases": [
        "designers and manufacturers"
      ],
      "types": [
        "designer",
        "manufacturer"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Designers and manufacturers are professionals and companies involved in the creation and production of products, encompassing both the conceptual design and the actual manufacturing processes.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-1",
          "local_name": "designers and manufacturers",
          "local_types": [
            "designer",
            "manufacturer"
          ],
          "iri": "Entity-designer_and_manufacturer-Mention-1"
        }
      ],
      "relevance": 0.472900390625
    },
    "Entity-ontological_framework": {
      "node_id": "ontological_framework",
      "disambiguation_index": 0,
      "label": "ontological framework",
      "aliases": [
        "ontological framework"
      ],
      "types": [
        "framework",
        "concept",
        "model",
        "theoretical framework",
        "philosophical concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "An ontological framework is a structured set of concepts and categories that defines the nature of existence and the relationships between entities within a particular domain of knowledge.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-5",
          "local_name": "ontological framework",
          "local_types": [
            "framework",
            "concept",
            "model",
            "theoretical framework",
            "philosophical concept"
          ],
          "iri": "Entity-ontological_framework-Mention-1"
        }
      ],
      "relevance": 0.46875
    },
    "Entity-reference_guide": {
      "node_id": "reference_guide",
      "disambiguation_index": 0,
      "label": "reference guide",
      "aliases": [
        "reference guide"
      ],
      "types": [
        "document",
        "guide",
        "manual"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A reference guide is a document that provides essential information, instructions, or guidelines on a specific subject to assist users in understanding or performing tasks effectively.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-10",
          "local_name": "reference guide",
          "local_types": [
            "document",
            "guide",
            "manual"
          ],
          "iri": "Entity-reference_guide-Mention-1"
        }
      ],
      "relevance": 0.46630859375
    },
    "Entity-geometrical_shape": {
      "node_id": "geometrical_shape",
      "disambiguation_index": 0,
      "label": "geometrical shapes",
      "aliases": [
        "geometrical shapes"
      ],
      "types": [
        "shape",
        "geometry"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Geometrical shapes are defined forms or figures in geometry, characterized by their specific properties and dimensions, such as circles, squares, triangles, and polygons.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-4",
          "local_name": "geometrical shapes",
          "local_types": [
            "shape",
            "geometry"
          ],
          "iri": "Entity-geometrical_shape-Mention-1"
        }
      ],
      "relevance": 0.46630859375
    },
    "Entity-complete_api_documentation": {
      "node_id": "complete_api_documentation",
      "disambiguation_index": 0,
      "label": "complete API documentation",
      "aliases": [
        "complete API documentation"
      ],
      "types": [
        "documentation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Complete API documentation refers to a comprehensive set of documents that provide detailed information about an application's programming interface, including its endpoints, request and response formats, authentication methods, and usage examples.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-6",
          "local_name": "complete API documentation",
          "local_types": [
            "documentation"
          ],
          "iri": "Entity-complete_api_documentation-Mention-1"
        }
      ],
      "relevance": 0.466064453125
    },
    "Entity-yrotation": {
      "node_id": "yrotation",
      "disambiguation_index": 0,
      "label": "yRotation",
      "aliases": [
        "yRotation"
      ],
      "types": [
        "rotation attribute",
        "spatial attribute"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "yRotation refers to a rotation attribute that represents the angular displacement around the vertical axis in a three-dimensional space, typically used in the context of spatial transformations.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "yRotation",
          "local_types": [
            "rotation attribute",
            "spatial attribute"
          ],
          "iri": "Entity-yrotation-Mention-1"
        }
      ],
      "relevance": 0.4658203125
    },
    "Entity-state_of_the_art": {
      "node_id": "state_of_the_art",
      "disambiguation_index": 0,
      "label": "state of the art",
      "aliases": [
        "state of the art"
      ],
      "types": [
        "state of the art",
        "current trends",
        "research status"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The term 'state of the art' refers to the highest level of development or advancement in a particular field, representing the most current and effective techniques, technologies, or methodologies available.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-1",
          "local_name": "state of the art",
          "local_types": [
            "state of the art",
            "current trends",
            "research status"
          ],
          "iri": "Entity-state_of_the_art-Mention-1"
        }
      ],
      "relevance": 0.465576171875
    },
    "Entity-linked_data": {
      "node_id": "linked_data",
      "disambiguation_index": 0,
      "label": "linked data",
      "aliases": [
        "linked data"
      ],
      "types": [
        "data",
        "information resource",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Linked data refers to a method of publishing structured data on the web in such a way that it can be interlinked and become more useful through semantic connections.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-3-Sentence-4",
          "local_name": "linked data",
          "local_types": [
            "data",
            "information resource",
            "data type"
          ],
          "iri": "Entity-linked_data-Mention-1"
        }
      ],
      "relevance": 0.46533203125
    },
    "Entity-designer_and_developer": {
      "node_id": "designer_and_developer",
      "disambiguation_index": 0,
      "label": "designers and developers",
      "aliases": [
        "designers and developers"
      ],
      "types": [
        "professionals"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Designers and developers are professionals who create and build visual and functional aspects of products, typically in the fields of technology and design.",
      "mentions": [
        {
          "reference": "Section-8-Paragraph-1-Sentence-3",
          "local_name": "designers and developers",
          "local_types": [
            "professionals"
          ],
          "iri": "Entity-designer_and_developer-Mention-1"
        }
      ],
      "relevance": 0.46484375
    },
    "Entity-proof-of-concept_implementation": {
      "node_id": "proof-of-concept_implementation",
      "disambiguation_index": 0,
      "label": "proof-of-concept implementation",
      "aliases": [
        "proof-of-concept implementation"
      ],
      "types": [
        "implementation",
        "demonstration"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A proof-of-concept implementation is a preliminary version of a system or product designed to demonstrate its feasibility and functionality, often used to validate concepts or ideas before full-scale development.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-2",
          "local_name": "proof-of-concept implementation",
          "local_types": [
            "implementation",
            "demonstration"
          ],
          "iri": "Entity-proof-of-concept_implementation-Mention-1"
        }
      ],
      "relevance": 0.46484375
    },
    "Entity-online_search_engine": {
      "node_id": "online_search_engine",
      "disambiguation_index": 0,
      "label": "online search engines",
      "aliases": [
        "search engines",
        "online search engines"
      ],
      "types": [
        "software",
        "information retrieval system",
        "technology",
        "search engine"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Online search engines are software applications designed to search for information on the internet by indexing and retrieving data from various web sources based on user queries.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-2",
          "local_name": "online search engines",
          "local_types": [
            "software",
            "information retrieval system",
            "search engine",
            "technology"
          ],
          "iri": "Entity-online_search_engine-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-7-Sentence-2",
          "local_name": "search engines",
          "local_types": [
            "technology"
          ],
          "iri": "Entity-online_search_engine-Mention-2"
        }
      ],
      "relevance": 0.464599609375
    },
    "Entity-namespace": {
      "node_id": "namespace",
      "disambiguation_index": 0,
      "label": "namespace",
      "aliases": [
        "namespace"
      ],
      "types": [
        "context",
        "identifier",
        "concept",
        "scope"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A namespace is a container that provides a way to group and distinguish identifiers, such as classes or variables, to avoid naming conflicts in programming and data representation.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-1",
          "local_name": "namespace",
          "local_types": [
            "concept",
            "identifier"
          ],
          "iri": "Entity-namespace-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-5",
          "local_name": "namespace",
          "local_types": [
            "context",
            "identifier",
            "concept",
            "scope"
          ],
          "iri": "Entity-namespace-Mention-2"
        }
      ],
      "relevance": 0.464599609375
    },
    "Entity-how-to__documentation": {
      "node_id": "how-to__documentation",
      "disambiguation_index": 0,
      "label": "'how-to' documentation",
      "aliases": [
        "'how-to' documentation"
      ],
      "types": [
        "documentation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "'How-to' documentation refers to instructional materials that guide users through the steps necessary to complete a specific task or achieve a particular goal.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-4",
          "local_name": "'how-to' documentation",
          "local_types": [
            "documentation"
          ],
          "iri": "Entity-how-to__documentation-Mention-1"
        }
      ],
      "relevance": 0.463134765625
    },
    "Entity-computer_game": {
      "node_id": "computer_game",
      "disambiguation_index": 0,
      "label": "computer games",
      "aliases": [
        "computer games"
      ],
      "types": [
        "game",
        "product",
        "entertainment",
        "gaming",
        "software"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Computer games are digital interactive entertainment software designed for play on computers or gaming consoles.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "computer games",
          "local_types": [
            "software",
            "game",
            "entertainment",
            "gaming"
          ],
          "iri": "Entity-computer_game-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "computer games",
          "local_types": [
            "software",
            "game",
            "entertainment",
            "product"
          ],
          "iri": "Entity-computer_game-Mention-2"
        }
      ],
      "relevance": 0.462646484375
    },
    "Entity-taxonomy": {
      "node_id": "taxonomy",
      "disambiguation_index": 0,
      "label": "taxonomies",
      "aliases": [
        "taxonomies",
        "taxonomy"
      ],
      "types": [
        "taxonomy",
        "framework",
        "methodology",
        "classification system",
        "organizational structure",
        "knowledge representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Taxonomies are structured frameworks or classification systems used to organize and categorize information, concepts, or entities based on shared characteristics or relationships.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-1",
          "local_name": "taxonomies",
          "local_types": [
            "classification system",
            "organizational structure",
            "taxonomy",
            "framework"
          ],
          "iri": "Entity-taxonomy-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-9",
          "local_name": "taxonomy",
          "local_types": [
            "classification system",
            "methodology"
          ],
          "iri": "Entity-taxonomy-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-1",
          "local_name": "taxonomies",
          "local_types": [
            "classification system",
            "taxonomy",
            "knowledge representation"
          ],
          "iri": "Entity-taxonomy-Mention-3"
        }
      ],
      "relevance": 0.462646484375
    },
    "Entity-the_cloud": {
      "node_id": "the_cloud",
      "disambiguation_index": 0,
      "label": "the Cloud",
      "aliases": [
        "the Cloud"
      ],
      "types": [
        "cloud",
        "environment"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The Cloud refers to a network of remote servers hosted on the Internet that store, manage, and process data, allowing for the deployment and accessibility of services such as the HDGI RESTful service.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-4-Sentence-2",
          "local_name": "the Cloud",
          "local_types": [
            "cloud",
            "environment"
          ],
          "iri": "Entity-the_cloud-Mention-1"
        }
      ],
      "relevance": 0.462646484375
    },
    "Entity-semantic_relationship": {
      "node_id": "semantic_relationship",
      "disambiguation_index": 0,
      "label": "semantic relationships",
      "aliases": [
        "semantic relationships"
      ],
      "types": [
        "relationship",
        "linguistic concept",
        "meaning connection"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Semantic relationships refer to the connections and associations between meanings of words or phrases in a linguistic context.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "semantic relationships",
          "local_types": [
            "relationship",
            "linguistic concept",
            "meaning connection"
          ],
          "iri": "Entity-semantic_relationship-Mention-1"
        }
      ],
      "relevance": 0.461669921875
    },
    "Entity-accuracy": {
      "node_id": "accuracy",
      "disambiguation_index": 0,
      "label": "accuracy",
      "aliases": [
        "accuracy"
      ],
      "types": [
        "measurement",
        "performance metric"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Accuracy is a measurement or performance metric that quantifies the degree of correctness or precision of a system's output compared to a standard or true value.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-4-Sentence-2",
          "local_name": "accuracy",
          "local_types": [
            "measurement",
            "performance metric"
          ],
          "iri": "Entity-accuracy-Mention-1"
        }
      ],
      "relevance": 0.46142578125
    },
    "Entity-downward_": {
      "node_id": "downward_",
      "disambiguation_index": 0,
      "label": "'downward'",
      "aliases": [
        "'downward'"
      ],
      "types": [
        "direction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "'downward' refers to a predefined directional axis in the hdgi:LocalCoordinateSystem, specifically indicating the negative direction along the y-axis.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "'downward'",
          "local_types": [
            "direction"
          ],
          "iri": "Entity-downward_-Mention-1"
        }
      ],
      "relevance": 0.459716796875
    },
    "Entity-python": {
      "node_id": "python",
      "disambiguation_index": 0,
      "label": "Python",
      "aliases": [
        "Python"
      ],
      "types": [
        "programming language",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Python is a high-level programming language known for its readability and versatility, widely used in various domains such as web development, data analysis, artificial intelligence, and more.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-2",
          "local_name": "Python",
          "local_types": [
            "programming language",
            "technology"
          ],
          "iri": "Entity-python-Mention-1"
        }
      ],
      "relevance": 0.458251953125
    },
    "Entity-manufacturer": {
      "node_id": "manufacturer",
      "disambiguation_index": 0,
      "label": "manufacturer",
      "aliases": [
        "manufacturer",
        "manufacturers"
      ],
      "types": [
        "manufacturer",
        "stakeholder",
        "company",
        "entity",
        "role",
        "organisation",
        "industry",
        "individual",
        "profession"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A manufacturer is an entity or organization that produces goods or products, typically through industrial processes, and is responsible for the design and quality of those products.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "manufacturer",
          "local_types": [
            "organisation",
            "entity"
          ],
          "iri": "Entity-manufacturer-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-1",
          "local_name": "manufacturers",
          "local_types": [
            "industry",
            "organisation",
            "manufacturer"
          ],
          "iri": "Entity-manufacturer-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "manufacturers",
          "local_types": [
            "company",
            "industry",
            "entity",
            "organisation"
          ],
          "iri": "Entity-manufacturer-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "manufacturers",
          "local_types": [
            "individual",
            "organisation",
            "profession"
          ],
          "iri": "Entity-manufacturer-Mention-4"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-3",
          "local_name": "manufacturers",
          "local_types": [
            "individual",
            "role",
            "profession",
            "organisation"
          ],
          "iri": "Entity-manufacturer-Mention-5"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "manufacturers",
          "local_types": [
            "stakeholder",
            "role",
            "organisation",
            "industry",
            "profession"
          ],
          "iri": "Entity-manufacturer-Mention-6"
        }
      ],
      "relevance": 0.456298828125
    },
    "Entity-listing_1.2": {
      "node_id": "listing_1.2",
      "disambiguation_index": 0,
      "label": "Listing 1.2",
      "aliases": [
        "Listing 1.2"
      ],
      "types": [
        "reference",
        "example",
        "figure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Listing 1.2 is an example illustrating the pose modeling associated with the gesture 'Right Hand Swipe Left', detailing the start and end poses of the right forearm and palm.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-1",
          "local_name": "Listing 1.2",
          "local_types": [
            "reference",
            "example",
            "figure"
          ],
          "iri": "Entity-listing_1.2-Mention-1"
        }
      ],
      "relevance": 0.45556640625
    },
    "Entity-inward_": {
      "node_id": "inward_",
      "disambiguation_index": 0,
      "label": "'inward'",
      "aliases": [
        "'inward'"
      ],
      "types": [
        "direction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "'inward' refers to a directional axis in the context of a local coordinate system, specifically indicating a direction that points towards the origin or center of the coordinate system.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-6",
          "local_name": "'inward'",
          "local_types": [
            "direction"
          ],
          "iri": "Entity-inward_-Mention-1"
        }
      ],
      "relevance": 0.45556640625
    },
    "Entity-shoulder_joint": {
      "node_id": "shoulder_joint",
      "disambiguation_index": 0,
      "label": "shoulder joint",
      "aliases": [
        "shoulder joint"
      ],
      "types": [
        "joint",
        "anatomy",
        "anatomical structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The shoulder joint is a ball-and-socket joint that connects the upper arm bone to the shoulder blade, allowing for a wide range of motion in the arm.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-7",
          "local_name": "shoulder joint",
          "local_types": [
            "joint",
            "anatomy",
            "anatomical structure"
          ],
          "iri": "Entity-shoulder_joint-Mention-1"
        }
      ],
      "relevance": 0.455078125
    },
    "Entity-real-time": {
      "node_id": "real-time",
      "disambiguation_index": 0,
      "label": "real-time",
      "aliases": [
        "real-time"
      ],
      "types": [
        "time aspect",
        "system performance",
        "time"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Real-time refers to the immediate processing and response to inputs or events as they occur, without significant delay.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-1",
          "local_name": "real-time",
          "local_types": [
            "time aspect",
            "system performance",
            "time"
          ],
          "iri": "Entity-real-time-Mention-1"
        }
      ],
      "relevance": 0.454345703125
    },
    "Entity-zrotation": {
      "node_id": "zrotation",
      "disambiguation_index": 0,
      "label": "zRotation",
      "aliases": [
        "zRotation"
      ],
      "types": [
        "rotation attribute",
        "spatial attribute"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "zRotation refers to a spatial attribute that represents the rotation around the z-axis in a three-dimensional coordinate system.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "zRotation",
          "local_types": [
            "rotation attribute",
            "spatial attribute"
          ],
          "iri": "Entity-zrotation-Mention-1"
        }
      ],
      "relevance": 0.4541015625
    },
    "Entity-extensibility": {
      "node_id": "extensibility",
      "disambiguation_index": 0,
      "label": "extensibility",
      "aliases": [
        "extensibility"
      ],
      "types": [
        "feature",
        "capability"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Extensibility refers to the capability of a system or software to accommodate additional features or functionalities without significant changes to its existing structure.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-4",
          "local_name": "extensibility",
          "local_types": [
            "feature",
            "capability"
          ],
          "iri": "Entity-extensibility-Mention-1"
        }
      ],
      "relevance": 0.45361328125
    },
    "Entity-human": {
      "node_id": "human",
      "disambiguation_index": 0,
      "label": "Human",
      "aliases": [
        "Human",
        "human"
      ],
      "types": [
        "concept",
        "class",
        "biological organism",
        "entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Human refers to a member of the species Homo sapiens, characterized as a biological organism with complex cognitive abilities and social structures.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-3-Sentence-2",
          "local_name": "Human",
          "local_types": [
            "class",
            "concept"
          ],
          "iri": "Entity-human-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-1-Sentence-4",
          "local_name": "human",
          "local_types": [
            "entity",
            "biological organism"
          ],
          "iri": "Entity-human-Mention-2"
        }
      ],
      "relevance": 0.452880859375
    },
    "Entity-human_s_upper_limb_region": {
      "node_id": "human_s_upper_limb_region",
      "disambiguation_index": 0,
      "label": "human's upper limb region",
      "aliases": [
        "human's upper limb region"
      ],
      "types": [
        "upper limb",
        "anatomy",
        "anatomical region",
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The human's upper limb region refers to the anatomical area of the body that includes the arms, shoulders, and associated structures, functioning in various movements and activities.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "human's upper limb region",
          "local_types": [
            "anatomy",
            "upper limb",
            "anatomical region",
            "body part"
          ],
          "iri": "Entity-human_s_upper_limb_region-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "human's upper limb region",
          "local_types": [
            "body part",
            "upper limb"
          ],
          "iri": "Entity-human_s_upper_limb_region-Mention-2"
        }
      ],
      "relevance": 0.452880859375
    },
    "Entity-the_permanent_url_service": {
      "node_id": "the_permanent_url_service",
      "disambiguation_index": 0,
      "label": "the permanent URL service",
      "aliases": [
        "the permanent URL service"
      ],
      "types": [
        "service",
        "URL"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The permanent URL service refers to the use of w3id.org, which provides a stable and persistent URL for accessing resources related to the HDGI ontology.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-3",
          "local_name": "the permanent URL service",
          "local_types": [
            "service",
            "URL"
          ],
          "iri": "Entity-the_permanent_url_service-Mention-1"
        }
      ],
      "relevance": 0.451416015625
    },
    "Entity-sparql_endpoint": {
      "node_id": "sparql_endpoint",
      "disambiguation_index": 0,
      "label": "SPARQL endpoints",
      "aliases": [
        "SPARQL endpoints"
      ],
      "types": [
        "query language endpoint",
        "endpoint",
        "technology",
        "web standard",
        "data access",
        "web service",
        "data access point",
        "API",
        "data access method",
        "query language",
        "SPARQL"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "SPARQL endpoints are web services that allow users to query and access data stored in RDF format using the SPARQL query language.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-3",
          "local_name": "SPARQL endpoints",
          "local_types": [
            "endpoint",
            "technology",
            "web standard",
            "data access",
            "API",
            "data access method",
            "query language",
            "SPARQL"
          ],
          "iri": "Entity-sparql_endpoint-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "SPARQL endpoints",
          "local_types": [
            "endpoint",
            "technology",
            "data access point",
            "web service",
            "query language endpoint",
            "API",
            "data access method",
            "query language",
            "SPARQL"
          ],
          "iri": "Entity-sparql_endpoint-Mention-2"
        }
      ],
      "relevance": 0.450927734375
    },
    "Entity-automobile": {
      "node_id": "automobile",
      "disambiguation_index": 0,
      "label": "automobiles",
      "aliases": [
        "automobiles"
      ],
      "types": [
        "transportation",
        "industry",
        "vehicle"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Automobiles are motor vehicles designed primarily for the transportation of passengers on roads.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "automobiles",
          "local_types": [
            "transportation",
            "industry",
            "vehicle"
          ],
          "iri": "Entity-automobile-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "automobiles",
          "local_types": [
            "transportation",
            "vehicle"
          ],
          "iri": "Entity-automobile-Mention-2"
        }
      ],
      "relevance": 0.45068359375
    },
    "Entity-local_coordinate_system": {
      "node_id": "local_coordinate_system",
      "disambiguation_index": 0,
      "label": "local coordinate system",
      "aliases": [
        "local coordinate system"
      ],
      "types": [
        "coordinate system",
        "mathematical concept",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A local coordinate system is a mathematical framework used to define the position of points in a specific, localized space, typically characterized by its own origin and axes, distinct from a global or absolute coordinate system.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-10",
          "local_name": "local coordinate system",
          "local_types": [
            "coordinate system",
            "mathematical concept",
            "system"
          ],
          "iri": "Entity-local_coordinate_system-Mention-1"
        }
      ],
      "relevance": 0.45068359375
    },
    "Entity-semantic_model": {
      "node_id": "semantic_model",
      "disambiguation_index": 0,
      "label": "semantic model",
      "aliases": [
        "semantic model"
      ],
      "types": [
        "model",
        "representation",
        "theoretical framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A semantic model is a theoretical framework or representation that captures the meaning and relationships of concepts within a specific domain, often used to analyze and interpret data or phenomena.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-7",
          "local_name": "semantic model",
          "local_types": [
            "model",
            "representation",
            "theoretical framework"
          ],
          "iri": "Entity-semantic_model-Mention-1"
        }
      ],
      "relevance": 0.4501953125
    },
    "Entity-upper_limb_region": {
      "node_id": "upper_limb_region",
      "disambiguation_index": 0,
      "label": "upper limb region",
      "aliases": [
        "upper-limb region",
        "'upper limb region'",
        "upper limb region",
        "the 'upper limb region'",
        "the human upper-limb region",
        "human upper-limb region"
      ],
      "types": [
        "upper limb",
        "region",
        "anatomy",
        "concept",
        "body part",
        "anatomical region"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The upper limb region refers to the anatomical area of the human body that includes the arms, shoulders, and hands, encompassing all structures from the shoulder joint to the fingertips.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "upper limb region",
          "local_types": [
            "anatomical region",
            "body part"
          ],
          "iri": "Entity-upper_limb_region-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "upper limb region",
          "local_types": [
            "concept",
            "body part",
            "anatomical region"
          ],
          "iri": "Entity-upper_limb_region-Mention-2"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-9",
          "local_name": "upper limb region",
          "local_types": [
            "anatomical region",
            "body part"
          ],
          "iri": "Entity-upper_limb_region-Mention-3"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "human upper-limb region",
          "local_types": [
            "anatomical region",
            "body part"
          ],
          "iri": "Entity-upper_limb_region-Mention-4"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "upper-limb region",
          "local_types": [
            "anatomy",
            "body part"
          ],
          "iri": "Entity-upper_limb_region-Mention-5"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "'upper limb region'",
          "local_types": [
            "region",
            "upper limb"
          ],
          "iri": "Entity-upper_limb_region-Mention-6"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-8",
          "local_name": "the 'upper limb region'",
          "local_types": [
            "anatomical region"
          ],
          "iri": "Entity-upper_limb_region-Mention-7"
        },
        {
          "reference": "Section-11-Paragraph-3-Sentence-1",
          "local_name": "the human upper-limb region",
          "local_types": [
            "body part"
          ],
          "iri": "Entity-upper_limb_region-Mention-8"
        }
      ],
      "relevance": 0.4482421875
    },
    "Entity-knowledge_base": {
      "node_id": "knowledge_base",
      "disambiguation_index": 0,
      "label": "knowledge base",
      "aliases": [
        "knowledge base"
      ],
      "types": [
        "data repository",
        "repository",
        "information system",
        "database"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A knowledge base is a structured repository of information that enables systems to store, retrieve, and manage knowledge, facilitating automated reasoning and decision-making.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "knowledge base",
          "local_types": [
            "data repository",
            "database",
            "information system"
          ],
          "iri": "Entity-knowledge_base-Mention-1"
        },
        {
          "reference": "Section-11-Paragraph-1-Sentence-2",
          "local_name": "knowledge base",
          "local_types": [
            "repository",
            "information system",
            "database"
          ],
          "iri": "Entity-knowledge_base-Mention-2"
        }
      ],
      "relevance": 0.4482421875
    },
    "Entity-sparql": {
      "node_id": "sparql",
      "disambiguation_index": 0,
      "label": "SPARQL",
      "aliases": [
        "SPARQL"
      ],
      "types": [
        "technology",
        "query language"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "SPARQL is a query language and protocol used for accessing and manipulating data stored in Resource Description Framework (RDF) format.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-3",
          "local_name": "SPARQL",
          "local_types": [
            "technology",
            "query language"
          ],
          "iri": "Entity-sparql-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-4-Sentence-5",
          "local_name": "SPARQL",
          "local_types": [
            "technology",
            "query language"
          ],
          "iri": "Entity-sparql-Mention-2"
        }
      ],
      "relevance": 0.447021484375
    },
    "Entity-search_query": {
      "node_id": "search_query",
      "disambiguation_index": 0,
      "label": "search query",
      "aliases": [
        "search query"
      ],
      "types": [
        "information retrieval",
        "query"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A search query is a specific request for information entered into a search engine or database, typically consisting of keywords or phrases that guide the retrieval of relevant data.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-3",
          "local_name": "search query",
          "local_types": [
            "information retrieval",
            "query"
          ],
          "iri": "Entity-search_query-Mention-1"
        }
      ],
      "relevance": 0.446533203125
    },
    "Entity-expressive_power": {
      "node_id": "expressive_power",
      "disambiguation_index": 0,
      "label": "expressive power",
      "aliases": [
        "expressive power"
      ],
      "types": [
        "concept",
        "attribute"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Expressive power refers to the ability of a formal system, such as a language or ontology, to represent a wide range of concepts and relationships effectively.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-5",
          "local_name": "expressive power",
          "local_types": [
            "concept",
            "attribute"
          ],
          "iri": "Entity-expressive_power-Mention-1"
        }
      ],
      "relevance": 0.44580078125
    },
    "Entity-opensource_project": {
      "node_id": "opensource_project",
      "disambiguation_index": 0,
      "label": "OpenSource project",
      "aliases": [
        "OpenSource project"
      ],
      "types": [
        "development model",
        "software project",
        "project",
        "software",
        "OpenSource"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "An OpenSource project is a collaborative software development initiative that allows users to access, modify, and distribute the source code freely, typically governed by a license that promotes transparency and community contributions.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-3",
          "local_name": "OpenSource project",
          "local_types": [
            "development model",
            "software project",
            "project",
            "software",
            "OpenSource"
          ],
          "iri": "Entity-opensource_project-Mention-1"
        }
      ],
      "relevance": 0.44580078125
    },
    "Entity-semantics": {
      "node_id": "semantics",
      "disambiguation_index": 0,
      "label": "semantics",
      "aliases": [
        "semantics"
      ],
      "types": [
        "linguistic concept",
        "meaning",
        "concept",
        "component"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Semantics refers to the study of meaning in language, encompassing the interpretation of words, phrases, and sentences within a given context.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-8-Sentence-1",
          "local_name": "semantics",
          "local_types": [
            "linguistic concept",
            "meaning",
            "concept"
          ],
          "iri": "Entity-semantics-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "semantics",
          "local_types": [
            "linguistic concept",
            "concept",
            "component"
          ],
          "iri": "Entity-semantics-Mention-2"
        },
        {
          "reference": "Section-9-Paragraph-4-Sentence-2",
          "local_name": "semantics",
          "local_types": [
            "meaning",
            "linguistic concept"
          ],
          "iri": "Entity-semantics-Mention-3"
        }
      ],
      "relevance": 0.4453125
    },
    "Entity-ubiquitousness": {
      "node_id": "ubiquitousness",
      "disambiguation_index": 0,
      "label": "ubiquitousness",
      "aliases": [
        "ubiquitousness"
      ],
      "types": [
        "phenomenon",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Ubiquitousness refers to the state or quality of being present everywhere or being widespread, often used to describe phenomena or concepts that are commonly encountered or pervasive in a particular context.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-4",
          "local_name": "ubiquitousness",
          "local_types": [
            "phenomenon",
            "concept"
          ],
          "iri": "Entity-ubiquitousness-Mention-1"
        }
      ],
      "relevance": 0.444091796875
    },
    "Entity-extrinsic_property": {
      "node_id": "extrinsic_property",
      "disambiguation_index": 0,
      "label": "extrinsic properties",
      "aliases": [
        "extrinsic properties"
      ],
      "types": [
        "attribute",
        "property",
        "characteristic"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Extrinsic properties refer to characteristics or attributes of an object or system that are determined by external factors or influences, rather than inherent qualities.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-3-Sentence-5",
          "local_name": "extrinsic properties",
          "local_types": [
            "attribute",
            "property",
            "characteristic"
          ],
          "iri": "Entity-extrinsic_property-Mention-1"
        }
      ],
      "relevance": 0.443359375
    },
    "Entity-z-axis": {
      "node_id": "z-axis",
      "disambiguation_index": 0,
      "label": "Z-axis",
      "aliases": [
        "Z-axis"
      ],
      "types": [
        "axis",
        "coordinate system",
        "mathematical concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The Z-axis is a line in a three-dimensional coordinate system that typically represents depth or height, perpendicular to both the X-axis and Y-axis.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-13",
          "local_name": "Z-axis",
          "local_types": [
            "axis",
            "mathematical concept"
          ],
          "iri": "Entity-z-axis-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-14",
          "local_name": "Z-axis",
          "local_types": [
            "coordinate system",
            "mathematical concept"
          ],
          "iri": "Entity-z-axis-Mention-2"
        }
      ],
      "relevance": 0.443359375
    },
    "Entity-euler_angle": {
      "node_id": "euler_angle",
      "disambiguation_index": 0,
      "label": "Euler angles",
      "aliases": [
        "Euler angles"
      ],
      "types": [
        "rotation representation",
        "angle",
        "mathematical concept",
        "mathematical representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Euler angles are a mathematical representation used to describe the orientation of a rigid body in three-dimensional space through three angles, typically referred to as roll, pitch, and yaw.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "Euler angles",
          "local_types": [
            "rotation representation",
            "angle",
            "mathematical concept",
            "mathematical representation"
          ],
          "iri": "Entity-euler_angle-Mention-1"
        }
      ],
      "relevance": 0.443115234375
    },
    "Entity-software_development_kit": {
      "node_id": "software_development_kit",
      "disambiguation_index": 0,
      "label": "Software Development Kits",
      "aliases": [
        "Software Development Kits"
      ],
      "types": [
        "tool",
        "software",
        "development tool",
        "software package"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Software Development Kits are collections of software tools and libraries that facilitate the development of applications for specific platforms or frameworks.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-1-Sentence-3",
          "local_name": "Software Development Kits",
          "local_types": [
            "tool",
            "software",
            "development tool",
            "software package"
          ],
          "iri": "Entity-software_development_kit-Mention-1"
        }
      ],
      "relevance": 0.44189453125
    },
    "Entity-best_practice": {
      "node_id": "best_practice",
      "disambiguation_index": 0,
      "label": "best practice",
      "aliases": [
        "best practice"
      ],
      "types": [
        "methodology",
        "guideline"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A best practice refers to a method or guideline that is recognized as the most effective way to achieve a desired outcome based on experience and research.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-5",
          "local_name": "best practice",
          "local_types": [
            "methodology",
            "guideline"
          ],
          "iri": "Entity-best_practice-Mention-1"
        }
      ],
      "relevance": 0.44140625
    },
    "Entity-human_body": {
      "node_id": "human_body",
      "disambiguation_index": 0,
      "label": "human body",
      "aliases": [
        "human body"
      ],
      "types": [
        "organism",
        "anatomy",
        "biological entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The human body is the physical structure of a human being, consisting of various systems, organs, and tissues that function together to sustain life.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "human body",
          "local_types": [
            "organism",
            "biological entity"
          ],
          "iri": "Entity-human_body-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-2",
          "local_name": "human body",
          "local_types": [
            "anatomy",
            "biological entity"
          ],
          "iri": "Entity-human_body-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-3",
          "local_name": "human body",
          "local_types": [
            "biological entity",
            "anatomy"
          ],
          "iri": "Entity-human_body-Mention-3"
        },
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "human body",
          "local_types": [
            "biological entity",
            "organism"
          ],
          "iri": "Entity-human_body-Mention-4"
        }
      ],
      "relevance": 0.440673828125
    },
    "Entity-system_reliability": {
      "node_id": "system_reliability",
      "disambiguation_index": 0,
      "label": "system reliability",
      "aliases": [
        "system reliability"
      ],
      "types": [
        "quality attribute",
        "performance metric",
        "reliability",
        "system quality"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "System reliability refers to the ability of a system to consistently perform its intended functions without failure over a specified period of time.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-10-Sentence-4",
          "local_name": "system reliability",
          "local_types": [
            "quality attribute",
            "performance metric",
            "reliability",
            "system quality"
          ],
          "iri": "Entity-system_reliability-Mention-1"
        }
      ],
      "relevance": 0.440673828125
    },
    "Entity-java": {
      "node_id": "java",
      "disambiguation_index": 0,
      "label": "Java",
      "aliases": [
        "Java"
      ],
      "types": [
        "software",
        "programming language",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Java is a high-level, class-based programming language and computing platform that is widely used for building applications and software.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-3",
          "local_name": "Java",
          "local_types": [
            "software",
            "programming language",
            "technology"
          ],
          "iri": "Entity-java-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-5-Sentence-2",
          "local_name": "Java",
          "local_types": [
            "programming language",
            "technology"
          ],
          "iri": "Entity-java-Mention-2"
        }
      ],
      "relevance": 0.4384765625
    },
    "Entity-future_work": {
      "node_id": "future_work",
      "disambiguation_index": 0,
      "label": "future work",
      "aliases": [
        "future work"
      ],
      "types": [
        "future work",
        "research direction",
        "project",
        "work"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Future work refers to planned or proposed research activities or projects that are intended to be undertaken after the current study or project is completed.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-6",
          "local_name": "future work",
          "local_types": [
            "future work",
            "research direction",
            "project",
            "work"
          ],
          "iri": "Entity-future_work-Mention-1"
        }
      ],
      "relevance": 0.438232421875
    },
    "Entity-yaw": {
      "node_id": "yaw",
      "disambiguation_index": 0,
      "label": "yaw",
      "aliases": [
        "yaw"
      ],
      "types": [
        "rotation",
        "rotation parameter",
        "angle"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Yaw is an angle that represents the rotation around the vertical axis (y-axis) in a three-dimensional space.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-17",
          "local_name": "yaw",
          "local_types": [
            "rotation",
            "rotation parameter",
            "angle"
          ],
          "iri": "Entity-yaw-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "yaw",
          "local_types": [
            "angle"
          ],
          "iri": "Entity-yaw-Mention-2"
        }
      ],
      "relevance": 0.436767578125
    },
    "Entity-github": {
      "node_id": "github",
      "disambiguation_index": 0,
      "label": "GitHub",
      "aliases": [
        "GitHub"
      ],
      "types": [
        "website",
        "platform",
        "code repository",
        "repository hosting service",
        "repository service",
        "repository"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "GitHub is a web-based platform that provides hosting for software development and version control using Git, allowing users to store, manage, and collaborate on code repositories.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-4",
          "local_name": "GitHub",
          "local_types": [
            "website",
            "repository",
            "repository service",
            "platform"
          ],
          "iri": "Entity-github-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-3-Sentence-9",
          "local_name": "GitHub",
          "local_types": [
            "website",
            "platform",
            "repository hosting service",
            "repository service",
            "repository"
          ],
          "iri": "Entity-github-Mention-2"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-3",
          "local_name": "GitHub",
          "local_types": [
            "code repository",
            "repository",
            "platform"
          ],
          "iri": "Entity-github-Mention-3"
        }
      ],
      "relevance": 0.436279296875
    },
    "Entity-experiment": {
      "node_id": "experiment",
      "disambiguation_index": 0,
      "label": "experiment",
      "aliases": [
        "experiments",
        "experiment"
      ],
      "types": [
        "study",
        "scientific investigation",
        "research method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "An experiment is a systematic and controlled procedure conducted to investigate hypotheses, test theories, or demonstrate known facts within a scientific context.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "experiment",
          "local_types": [
            "study",
            "research method"
          ],
          "iri": "Entity-experiment-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-9",
          "local_name": "experiments",
          "local_types": [
            "research method",
            "scientific investigation"
          ],
          "iri": "Entity-experiment-Mention-2"
        }
      ],
      "relevance": 0.436279296875
    },
    "Entity-formalization": {
      "node_id": "formalization",
      "disambiguation_index": 0,
      "label": "formalization",
      "aliases": [
        "formalization"
      ],
      "types": [
        "methodology",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Formalization refers to the process of defining and structuring concepts or methodologies in a precise and systematic manner, often using formal languages or frameworks.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "formalization",
          "local_types": [
            "methodology",
            "concept"
          ],
          "iri": "Entity-formalization-Mention-1"
        }
      ],
      "relevance": 0.435791015625
    },
    "Entity-swagger_codegen": {
      "node_id": "swagger_codegen",
      "disambiguation_index": 0,
      "label": "Swagger codegen",
      "aliases": [
        "Swagger codegen"
      ],
      "types": [
        "documentation",
        "Swagger",
        "tool",
        "software",
        "code generation",
        "software tool",
        "code generation tool",
        "API client generator"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Swagger Codegen is a software tool that automatically generates client libraries, server stubs, and API documentation from an OpenAPI Specification.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-6",
          "local_name": "Swagger codegen",
          "local_types": [
            "documentation",
            "Swagger",
            "tool",
            "software",
            "code generation",
            "software tool",
            "code generation tool",
            "API client generator"
          ],
          "iri": "Entity-swagger_codegen-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-5-Sentence-2",
          "local_name": "Swagger codegen",
          "local_types": [
            "documentation",
            "Swagger",
            "tool",
            "software",
            "software tool",
            "code generation tool",
            "API client generator"
          ],
          "iri": "Entity-swagger_codegen-Mention-2"
        }
      ],
      "relevance": 0.43505859375
    },
    "Entity-sosa__actuator": {
      "node_id": "sosa__actuator",
      "disambiguation_index": 0,
      "label": "sosa:Actuator",
      "aliases": [
        "sosa:Actuator"
      ],
      "types": [
        "actuator",
        "ontology class",
        "ontology",
        "concept",
        "ontology term",
        "entity",
        "class"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "sosa:Actuator refers to a conceptual entity within an ontology that represents a component capable of causing a change or action in a system.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-12",
          "local_name": "sosa:Actuator",
          "local_types": [
            "actuator",
            "ontology class",
            "ontology",
            "concept",
            "ontology term",
            "entity",
            "class"
          ],
          "iri": "Entity-sosa__actuator-Mention-1"
        }
      ],
      "relevance": 0.43408203125
    },
    "Entity-3d_rigid_body": {
      "node_id": "3d_rigid_body",
      "disambiguation_index": 0,
      "label": "3D rigid body",
      "aliases": [
        "3D rigid body"
      ],
      "types": [
        "3D model",
        "geometric object",
        "physical object",
        "object"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A 3D rigid body is a solid object in three-dimensional space that does not deform under the influence of forces and maintains a fixed shape and volume.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-17",
          "local_name": "3D rigid body",
          "local_types": [
            "3D model",
            "geometric object",
            "physical object",
            "object"
          ],
          "iri": "Entity-3d_rigid_body-Mention-1"
        }
      ],
      "relevance": 0.433349609375
    },
    "Entity-elbow_joint": {
      "node_id": "elbow_joint",
      "disambiguation_index": 0,
      "label": "elbow joint",
      "aliases": [
        "elbow joint"
      ],
      "types": [
        "joint",
        "anatomy",
        "anatomical structure"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The elbow joint is a hinge joint in the human body that connects the upper arm bone (humerus) to the two bones of the forearm (radius and ulna), allowing for flexion and extension of the arm.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-8",
          "local_name": "elbow joint",
          "local_types": [
            "joint",
            "anatomy",
            "anatomical structure"
          ],
          "iri": "Entity-elbow_joint-Mention-1"
        }
      ],
      "relevance": 0.43310546875
    },
    "Entity-timestamp": {
      "node_id": "timestamp",
      "disambiguation_index": 0,
      "label": "timestamp",
      "aliases": [
        "timestamp"
      ],
      "types": [
        "time representation",
        "attribute",
        "data attribute"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A timestamp is a data attribute that represents a specific point in time, often used to record when an event occurs.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "timestamp",
          "local_types": [
            "time representation",
            "attribute",
            "data attribute"
          ],
          "iri": "Entity-timestamp-Mention-1"
        }
      ],
      "relevance": 0.43310546875
    },
    "Entity-systematic_analysis": {
      "node_id": "systematic_analysis",
      "disambiguation_index": 0,
      "label": "systematic analysis",
      "aliases": [
        "systematic analysis"
      ],
      "types": [
        "methodology",
        "research approach"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Systematic analysis refers to a structured and methodical approach to examining and interpreting data or phenomena, often used in research to ensure comprehensive understanding and organization of information.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "systematic analysis",
          "local_types": [
            "methodology",
            "research approach"
          ],
          "iri": "Entity-systematic_analysis-Mention-1"
        }
      ],
      "relevance": 0.43115234375
    },
    "Entity-swagger_codegen_capability": {
      "node_id": "swagger_codegen_capability",
      "disambiguation_index": 0,
      "label": "Swagger codegen capabilities",
      "aliases": [
        "Swagger codegen capabilities"
      ],
      "types": [
        "tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Swagger codegen capabilities refer to the features and functionalities of the Swagger Codegen tool that allow for the automatic generation of client libraries, server stubs, and API documentation from an OpenAPI Specification.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-6",
          "local_name": "Swagger codegen capabilities",
          "local_types": [
            "tool"
          ],
          "iri": "Entity-swagger_codegen_capability-Mention-1"
        }
      ],
      "relevance": 0.4306640625
    },
    "Entity-syntax": {
      "node_id": "syntax",
      "disambiguation_index": 0,
      "label": "syntax",
      "aliases": [
        "syntax"
      ],
      "types": [
        "linguistic concept",
        "concept",
        "component"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Syntax is a linguistic concept that refers to the set of rules, principles, and processes that govern the structure of sentences in a given language, including the arrangement of words and phrases.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "syntax",
          "local_types": [
            "linguistic concept",
            "concept",
            "component"
          ],
          "iri": "Entity-syntax-Mention-1"
        }
      ],
      "relevance": 0.42822265625
    },
    "Entity-body_part": {
      "node_id": "body_part",
      "disambiguation_index": 0,
      "label": "body parts",
      "aliases": [
        "body parts",
        "body part"
      ],
      "types": [
        "biological entity",
        "anatomy",
        "anatomical entity",
        "anatomical structure",
        "body part",
        "human anatomy",
        "physical component",
        "biological structure",
        "physical entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Body parts refer to the various physical components or structures that make up the human body, including limbs, organs, and other anatomical features.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-5-Sentence-4",
          "local_name": "body parts",
          "local_types": [
            "anatomical structure",
            "human anatomy"
          ],
          "iri": "Entity-body_part-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "body parts",
          "local_types": [
            "physical component",
            "anatomy",
            "body part"
          ],
          "iri": "Entity-body_part-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "body parts",
          "local_types": [
            "anatomical entity",
            "biological structure"
          ],
          "iri": "Entity-body_part-Mention-3"
        },
        {
          "reference": "Section-5-Paragraph-2-Sentence-3",
          "local_name": "body part",
          "local_types": [
            "physical component",
            "anatomy",
            "body part"
          ],
          "iri": "Entity-body_part-Mention-4"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "body parts",
          "local_types": [
            "anatomical entity",
            "body part"
          ],
          "iri": "Entity-body_part-Mention-5"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "body parts",
          "local_types": [
            "anatomical structure"
          ],
          "iri": "Entity-body_part-Mention-6"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-1",
          "local_name": "body part",
          "local_types": [
            "anatomy",
            "biological entity",
            "anatomical structure",
            "body part"
          ],
          "iri": "Entity-body_part-Mention-7"
        },
        {
          "reference": "Section-7-Paragraph-1-Sentence-3",
          "local_name": "body part",
          "local_types": [
            "anatomical structure",
            "biological entity"
          ],
          "iri": "Entity-body_part-Mention-8"
        },
        {
          "reference": "Section-7-Paragraph-2-Sentence-3",
          "local_name": "body part",
          "local_types": [
            "physical component",
            "anatomical entity",
            "body part",
            "physical entity"
          ],
          "iri": "Entity-body_part-Mention-9"
        }
      ],
      "relevance": 0.427734375
    },
    "Entity-forearm": {
      "node_id": "forearm",
      "disambiguation_index": 0,
      "label": "forearm",
      "aliases": [
        "forearm"
      ],
      "types": [
        "body part",
        "gesture"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The forearm is the part of the human arm between the elbow and the wrist, consisting of two long bones, the radius and ulna, and is involved in various movements and gestures.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-3-Sentence-2",
          "local_name": "forearm",
          "local_types": [
            "body part",
            "gesture"
          ],
          "iri": "Entity-forearm-Mention-1"
        }
      ],
      "relevance": 0.427734375
    },
    "Entity-pitch": {
      "node_id": "pitch",
      "disambiguation_index": 0,
      "label": "pitch",
      "aliases": [
        "pitch"
      ],
      "types": [
        "rotation",
        "rotation parameter",
        "angle"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of 3D rigid body rotation, 'pitch' refers to the angle of rotation around the x-axis.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-17",
          "local_name": "pitch",
          "local_types": [
            "rotation",
            "rotation parameter",
            "angle"
          ],
          "iri": "Entity-pitch-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "pitch",
          "local_types": [
            "angle"
          ],
          "iri": "Entity-pitch-Mention-2"
        }
      ],
      "relevance": 0.427001953125
    },
    "Entity-opensource": {
      "node_id": "opensource",
      "disambiguation_index": 0,
      "label": "OpenSource",
      "aliases": [
        "OpenSource"
      ],
      "types": [
        "license",
        "software model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "OpenSource refers to a software development model and licensing approach that allows the source code of software to be freely accessed, modified, and distributed by anyone.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-3",
          "local_name": "OpenSource",
          "local_types": [
            "license",
            "software model"
          ],
          "iri": "Entity-opensource-Mention-1"
        }
      ],
      "relevance": 0.4208984375
    },
    "Entity-javascript__java__python__swift__android": {
      "node_id": "javascript__java__python__swift__android",
      "disambiguation_index": 0,
      "label": "JavaScript, Java, Python, Swift, Android",
      "aliases": [
        "JavaScript, Java, Python, Swift, Android"
      ],
      "types": [
        "programming language"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JavaScript, Java, Python, Swift, and Android are programming languages and platforms used for software development.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-5-Sentence-2",
          "local_name": "JavaScript, Java, Python, Swift, Android",
          "local_types": [
            "programming language"
          ],
          "iri": "Entity-javascript__java__python__swift__android-Mention-1"
        }
      ],
      "relevance": 0.4208984375
    },
    "Entity-researcher": {
      "node_id": "researcher",
      "disambiguation_index": 0,
      "label": "researchers",
      "aliases": [
        "researchers"
      ],
      "types": [
        "professionals",
        "researcher",
        "individuals",
        "stakeholder",
        "academic",
        "academics",
        "professional",
        "individual"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Researchers are individuals or professionals engaged in systematic investigation and study to establish facts and reach new conclusions in various fields of knowledge.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-2-Sentence-3",
          "local_name": "researchers",
          "local_types": [
            "individuals",
            "academics"
          ],
          "iri": "Entity-researcher-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-3-Sentence-4",
          "local_name": "researchers",
          "local_types": [
            "academic",
            "researcher",
            "individual"
          ],
          "iri": "Entity-researcher-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-1",
          "local_name": "researchers",
          "local_types": [
            "professionals",
            "researcher",
            "individuals"
          ],
          "iri": "Entity-researcher-Mention-3"
        },
        {
          "reference": "Section-3-Paragraph-2-Sentence-2",
          "local_name": "researchers",
          "local_types": [
            "professional",
            "stakeholder"
          ],
          "iri": "Entity-researcher-Mention-4"
        }
      ],
      "relevance": 0.4189453125
    },
    "Entity-roll": {
      "node_id": "roll",
      "disambiguation_index": 0,
      "label": "roll",
      "aliases": [
        "roll"
      ],
      "types": [
        "rotation",
        "rotation parameter",
        "angle"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of 3D rigid body rotation, 'roll' refers to the angle of rotation around the z-axis.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-17",
          "local_name": "roll",
          "local_types": [
            "rotation",
            "rotation parameter",
            "angle"
          ],
          "iri": "Entity-roll-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "roll",
          "local_types": [
            "angle"
          ],
          "iri": "Entity-roll-Mention-2"
        }
      ],
      "relevance": 0.418212890625
    },
    "Entity-time_stamp": {
      "node_id": "time_stamp",
      "disambiguation_index": 0,
      "label": "time stamp",
      "aliases": [
        "time stamp"
      ],
      "types": [
        "attribute",
        "metadata",
        "data attribute",
        "timestamp",
        "temporal marker"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A time stamp is a piece of data that indicates the specific time at which an event occurred or a record was created.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-2-Sentence-3",
          "local_name": "time stamp",
          "local_types": [
            "attribute",
            "metadata",
            "data attribute",
            "timestamp",
            "temporal marker"
          ],
          "iri": "Entity-time_stamp-Mention-1"
        }
      ],
      "relevance": 0.416259765625
    },
    "Entity-many_to_many": {
      "node_id": "many_to_many",
      "disambiguation_index": 0,
      "label": "many to many",
      "aliases": [
        "many to many"
      ],
      "types": [
        "cardinality type",
        "relationship type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A many to many relationship is a type of association in which multiple entities from one set can be related to multiple entities from another set.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-8",
          "local_name": "many to many",
          "local_types": [
            "cardinality type",
            "relationship type"
          ],
          "iri": "Entity-many_to_many-Mention-1"
        }
      ],
      "relevance": 0.415771484375
    },
    "Entity-research": {
      "node_id": "research",
      "disambiguation_index": 0,
      "label": "research",
      "aliases": [
        "research"
      ],
      "types": [
        "study",
        "academic work",
        "investigation",
        "academic study"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Research refers to a systematic investigation or study aimed at discovering and interpreting facts, principles, or theories in a particular field.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-8",
          "local_name": "research",
          "local_types": [
            "study",
            "academic work"
          ],
          "iri": "Entity-research-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-3-Sentence-1",
          "local_name": "research",
          "local_types": [
            "academic study",
            "investigation"
          ],
          "iri": "Entity-research-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-4-Sentence-2",
          "local_name": "research",
          "local_types": [
            "academic work",
            "study"
          ],
          "iri": "Entity-research-Mention-3"
        }
      ],
      "relevance": 0.4150390625
    },
    "Entity-two_different_way": {
      "node_id": "two_different_way",
      "disambiguation_index": 0,
      "label": "two different ways",
      "aliases": [
        "two different ways"
      ],
      "types": [
        "method"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'two different ways' refers to the two distinct methods of representing the rotation of a pose in 3D space, specifically using either Euler angles (yaw, pitch, roll) or quaternions.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-16",
          "local_name": "two different ways",
          "local_types": [
            "method"
          ],
          "iri": "Entity-two_different_way-Mention-1"
        }
      ],
      "relevance": 0.410888671875
    },
    "Entity-github_code_repository": {
      "node_id": "github_code_repository",
      "disambiguation_index": 0,
      "label": "GitHub code repository",
      "aliases": [
        "GitHub code repository"
      ],
      "types": [
        "version control",
        "repository",
        "code repository",
        "code"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A GitHub code repository is an online storage space hosted on GitHub where developers can store, manage, and collaborate on code projects using version control.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-3",
          "local_name": "GitHub code repository",
          "local_types": [
            "version control",
            "repository",
            "code repository",
            "code"
          ],
          "iri": "Entity-github_code_repository-Mention-1"
        }
      ],
      "relevance": 0.410400390625
    },
    "Entity-quaternion": {
      "node_id": "quaternion",
      "disambiguation_index": 0,
      "label": "quaternions",
      "aliases": [
        "quaternions"
      ],
      "types": [
        "rotation parameter",
        "mathematical concept",
        "mathematical representation",
        "rotation",
        "rotation representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Quaternions are a number system that extends complex numbers and are used to represent rotations in three-dimensional space.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-1-Sentence-17",
          "local_name": "quaternions",
          "local_types": [
            "rotation parameter",
            "mathematical concept",
            "mathematical representation",
            "rotation",
            "rotation representation"
          ],
          "iri": "Entity-quaternion-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-3",
          "local_name": "quaternions",
          "local_types": [
            "rotation representation",
            "mathematical representation"
          ],
          "iri": "Entity-quaternion-Mention-2"
        }
      ],
      "relevance": 0.407470703125
    },
    "Entity-author": {
      "node_id": "author",
      "disambiguation_index": 0,
      "label": "authors",
      "aliases": [
        "authors"
      ],
      "types": [
        "individuals",
        "researchers"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Authors are individuals or researchers who create written works, typically contributing to academic or literary fields.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-2-Sentence-4",
          "local_name": "authors",
          "local_types": [
            "individuals",
            "researchers"
          ],
          "iri": "Entity-author-Mention-1"
        }
      ],
      "relevance": 0.406982421875
    },
    "Entity-bmw": {
      "node_id": "bmw",
      "disambiguation_index": 0,
      "label": "BMW",
      "aliases": [
        "BMW"
      ],
      "types": [
        "company",
        "automobile manufacturer"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "BMW is a German multinational company that produces luxury vehicles and motorcycles, known for its innovative automotive technology and performance.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "BMW",
          "local_types": [
            "company",
            "automobile manufacturer"
          ],
          "iri": "Entity-bmw-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "BMW",
          "local_types": [
            "company",
            "automobile manufacturer"
          ],
          "iri": "Entity-bmw-Mention-2"
        }
      ],
      "relevance": 0.405517578125
    },
    "Entity-survey_paper": {
      "node_id": "survey_paper",
      "disambiguation_index": 0,
      "label": "survey paper",
      "aliases": [
        "survey paper"
      ],
      "types": [
        "academic work",
        "publication",
        "research document",
        "academic paper",
        "academic publication",
        "research publication"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A survey paper is an academic publication that provides a comprehensive overview and analysis of existing research on a specific topic, summarizing key findings and identifying trends in the literature.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-9-Sentence-3",
          "local_name": "survey paper",
          "local_types": [
            "academic work",
            "publication",
            "research document",
            "academic paper",
            "academic publication",
            "research publication"
          ],
          "iri": "Entity-survey_paper-Mention-1"
        }
      ],
      "relevance": 0.403564453125
    },
    "Entity-paper": {
      "node_id": "paper",
      "disambiguation_index": 0,
      "label": "paper",
      "aliases": [
        "paper"
      ],
      "types": [
        "research document",
        "academic work"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A paper is a written document that presents research findings, analyses, or theoretical discussions, typically in an academic or scholarly context.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-2-Sentence-1",
          "local_name": "paper",
          "local_types": [
            "research document",
            "academic work"
          ],
          "iri": "Entity-paper-Mention-1"
        }
      ],
      "relevance": 0.400390625
    },
    "Entity-cardinality": {
      "node_id": "cardinality",
      "disambiguation_index": 0,
      "label": "cardinality",
      "aliases": [
        "cardinality"
      ],
      "types": [
        "mathematical concept",
        "relation property"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Cardinality is a mathematical concept that describes the number of elements in a set or the relationship between the sizes of two sets, often expressed in terms of the possible associations between entities.",
      "mentions": [
        {
          "reference": "Section-9-Paragraph-2-Sentence-8",
          "local_name": "cardinality",
          "local_types": [
            "mathematical concept",
            "relation property"
          ],
          "iri": "Entity-cardinality-Mention-1"
        }
      ],
      "relevance": 0.3974609375
    },
    "Entity-w3id.org": {
      "node_id": "w3id.org",
      "disambiguation_index": 0,
      "label": "w3id.org",
      "aliases": [
        "w3id.org"
      ],
      "types": [
        "website",
        "permanent URL service",
        "URL",
        "service",
        "URL service"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "w3id.org is a website that provides a permanent URL service for creating stable and persistent links to digital resources.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-2-Sentence-3",
          "local_name": "w3id.org",
          "local_types": [
            "website",
            "permanent URL service",
            "URL",
            "service",
            "URL service"
          ],
          "iri": "Entity-w3id.org-Mention-1"
        }
      ],
      "relevance": 0.39501953125
    },
    "Entity-research_community": {
      "node_id": "research_community",
      "disambiguation_index": 0,
      "label": "research community",
      "aliases": [
        "research community"
      ],
      "types": [
        "community",
        "stakeholder",
        "academic",
        "scholarly group",
        "academic community"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The research community refers to a collective of scholars, scientists, and academics engaged in the pursuit of knowledge and advancement in various fields of study.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-2-Sentence-3",
          "local_name": "research community",
          "local_types": [
            "community",
            "stakeholder",
            "academic",
            "scholarly group",
            "academic community"
          ],
          "iri": "Entity-research_community-Mention-1"
        }
      ],
      "relevance": 0.394287109375
    },
    "Entity-mercedes-benz": {
      "node_id": "mercedes-benz",
      "disambiguation_index": 0,
      "label": "Mercedes-Benz",
      "aliases": [
        "Mercedes-Benz"
      ],
      "types": [
        "company",
        "automobile manufacturer"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Mercedes-Benz is a German luxury automobile manufacturer known for producing high-quality vehicles and advanced automotive technologies.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-7-Sentence-1",
          "local_name": "Mercedes-Benz",
          "local_types": [
            "company",
            "automobile manufacturer"
          ],
          "iri": "Entity-mercedes-benz-Mention-1"
        },
        {
          "reference": "Section-9-Paragraph-3-Sentence-1",
          "local_name": "Mercedes-Benz",
          "local_types": [
            "company",
            "automobile manufacturer"
          ],
          "iri": "Entity-mercedes-benz-Mention-2"
        }
      ],
      "relevance": 0.3935546875
    },
    "Entity-rationale": {
      "node_id": "rationale",
      "disambiguation_index": 0,
      "label": "rationale",
      "aliases": [
        "rationale"
      ],
      "types": [
        "justification",
        "reasoning"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Rationale refers to the underlying reasoning or justification for a particular decision, design, or action.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-11-Sentence-3",
          "local_name": "rationale",
          "local_types": [
            "justification",
            "reasoning"
          ],
          "iri": "Entity-rationale-Mention-1"
        }
      ],
      "relevance": 0.391357421875
    },
    "Entity-java_version_1.9": {
      "node_id": "java_version_1.9",
      "disambiguation_index": 0,
      "label": "Java version 1.9",
      "aliases": [
        "Java version 1.9"
      ],
      "types": [
        "software",
        "programming language",
        "software version"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Java version 1.9 refers to a specific release of the Java programming language and software platform, which is required as a prerequisite to run the web application discussed in the paper.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-3",
          "local_name": "Java version 1.9",
          "local_types": [
            "software",
            "programming language",
            "software version"
          ],
          "iri": "Entity-java_version_1.9-Mention-1"
        }
      ],
      "relevance": 0.39013671875
    },
    "Entity-private_cloud": {
      "node_id": "private_cloud",
      "disambiguation_index": 0,
      "label": "private cloud",
      "aliases": [
        "private cloud"
      ],
      "types": [
        "infrastructure",
        "cloud computing",
        "cloud"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A private cloud is a type of cloud computing environment that is exclusively used by a single organization, providing greater control over resources and security compared to public cloud services.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-4",
          "local_name": "private cloud",
          "local_types": [
            "infrastructure",
            "cloud computing",
            "cloud"
          ],
          "iri": "Entity-private_cloud-Mention-1"
        }
      ],
      "relevance": 0.382568359375
    },
    "Entity-apache_2.0": {
      "node_id": "apache_2.0",
      "disambiguation_index": 0,
      "label": "Apache 2.0",
      "aliases": [
        "Apache 2.0",
        "Apache 2.0 license"
      ],
      "types": [
        "software license",
        "legal document",
        "legal",
        "license"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Apache 2.0 is an open-source software license that allows users to use, modify, and distribute software while providing certain protections and requirements for contributors.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-3",
          "local_name": "Apache 2.0",
          "local_types": [
            "license"
          ],
          "iri": "Entity-apache_2.0-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-3-Sentence-3",
          "local_name": "Apache 2.0 license",
          "local_types": [
            "software license",
            "legal document",
            "legal",
            "license"
          ],
          "iri": "Entity-apache_2.0-Mention-2"
        }
      ],
      "relevance": 0.37939453125
    },
    "Entity-literature": {
      "node_id": "literature",
      "disambiguation_index": 0,
      "label": "literature",
      "aliases": [
        "literature"
      ],
      "types": [
        "published material",
        "academic work"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Literature refers to the body of written works, particularly those that are published and contribute to academic discourse and knowledge.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-3-Sentence-1",
          "local_name": "literature",
          "local_types": [
            "published material",
            "academic work"
          ],
          "iri": "Entity-literature-Mention-1"
        }
      ],
      "relevance": 0.371826171875
    },
    "Entity-apache_tomcat": {
      "node_id": "apache_tomcat",
      "disambiguation_index": 0,
      "label": "Apache Tomcat",
      "aliases": [
        "Apache Tomcat server",
        "Apache Tomcat"
      ],
      "types": [
        "software",
        "server",
        "technology",
        "web server"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Apache Tomcat is an open-source web server and servlet container that implements the Java Servlet and JavaServer Pages (JSP) specifications.",
      "mentions": [
        {
          "reference": "Section-10-Paragraph-4-Sentence-3",
          "local_name": "Apache Tomcat",
          "local_types": [
            "software",
            "server",
            "technology",
            "web server"
          ],
          "iri": "Entity-apache_tomcat-Mention-1"
        },
        {
          "reference": "Section-10-Paragraph-4-Sentence-3",
          "local_name": "Apache Tomcat server",
          "local_types": [
            "software",
            "server",
            "web server"
          ],
          "iri": "Entity-apache_tomcat-Mention-2"
        }
      ],
      "relevance": 0.369384765625
    },
    "Entity-previous_study": {
      "node_id": "previous_study",
      "disambiguation_index": 0,
      "label": "previous studies",
      "aliases": [
        "previous studies"
      ],
      "types": [
        "study",
        "research work",
        "academic literature"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "previous studies refer to earlier research works or academic literature that have been conducted on a specific topic.",
      "mentions": [
        {
          "reference": "Section-11-Paragraph-2-Sentence-1",
          "local_name": "previous studies",
          "local_types": [
            "study",
            "research work",
            "academic literature"
          ],
          "iri": "Entity-previous_study-Mention-1"
        }
      ],
      "relevance": 0.3662109375
    },
    "Entity-right_forearm": {
      "node_id": "right_forearm",
      "disambiguation_index": 0,
      "label": "right forearm",
      "aliases": [
        "the right forearm",
        "right forearm"
      ],
      "types": [
        "forearm",
        "anatomy",
        "body part"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The right forearm is the segment of the arm located between the elbow and the wrist on the right side of the body.",
      "mentions": [
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "right forearm",
          "local_types": [
            "anatomy",
            "body part"
          ],
          "iri": "Entity-right_forearm-Mention-1"
        },
        {
          "reference": "Section-7-Paragraph-3-Sentence-2",
          "local_name": "the right forearm",
          "local_types": [
            "body part",
            "forearm"
          ],
          "iri": "Entity-right_forearm-Mention-2"
        }
      ],
      "relevance": 0.35888671875
    }
  },
  "summary": "Gesture-controlled interfaces are becoming increasingly popular with the growing use of Internet of Things (IoT) systems. In particular, in automobiles, smart homes, computer games, and Augmented Reality (AR) / Virtual Reality (VR) applications, gestures have become prevalent due to their accessibility to everyone. Designers, producers, and vendors integrating gesture interfaces into their products have also increased in numbers, giving rise to a greater variation of standards in utilizing them. This variety can confuse a user who is accustomed to a set of conventional controls and has their own preferences. The only option for a user is to adjust to the system even when the provided gestures are not intuitive and contrary to a user\u2019s expectations.\n\nThis paper addresses the problem of the absence of a systematic analysis and description of gestures and develops an ontology which formally describes gestures used in Human Device Interactions (HDI). The presented ontology is based on Semantic Web standards (RDF, RDFS, and OWL2). It is capable of describing a human gesture semantically, along with relevant mappings to affordances and user/device contexts, in an extensible way.\n\nGesture-based systems are increasingly used in various applications like automobiles, smart homes, and AR/VR due to their accessibility. These systems rely on physical movements to convey user intentions, but most are designed based on manufacturer preferences, leading to a lack of user-centered design. Wobbrock et al. introduced the concept of 'guessability' in 2005, highlighting the need for users to succeed in gesture interactions without prior knowledge. Despite numerous Gesture Elicitation Studies (GES), redundant gesture vocabularies exist, necessitating a gesture ontology to link related gestures and their referents. Current sensors like Microsoft Kinect enable gesture recognition, but designers often impose their preferences, which can confuse users. For instance, different systems like BMW's iDrive and Mercedes-Benz's MBUX use similar gestures for different functions. A centralized mapping of gestures would enhance interoperability and user experience. This paper proposes a Human Device Gesture Interaction (HDGI) ontology to map upper limb gestures to device affordances, allowing systems to interpret gestures without pre-programming. The paper details the HDGI ontology's design, syntax, and tools for integration with devices like Leap Motion and Oculus Quest, aiming to improve gesture personalization and system reliability.\n\nNumerous studies focus on hand gesture recognition and its integration into gestural interfaces, primarily using predefined gestures. However, few have formalized the relationships between gestures. A 2020 review by Villarreal Narvaez et al. indicates that gesture recognition is still evolving, necessitating interoperability among gesture vocabularies. Researchers have proposed taxonomies, such as Scoditti et al.'s gestural interaction taxonomy, to standardize gesture definitions, but these do not map existing vocabularies semantically. Choi et al. developed a 3D hand gesture taxonomy, limited to 6 commands, highlighting the need for broader experimentation. Other studies, like Osumar et al.'s gesture ontology, focus on mid-air gestures but lack detail and accessibility. Khairunizam et al. aimed to improve recognition of arm gestures using motion capture, yet their framework is limited to geometrical shapes. In contrast, our ontology aims to model gestures with specific affordances, allowing for extensibility to new gestures and body parts, while incorporating existing ontologies where applicable.\n\nThe HDGI ontology models human upper limb gestures for device interaction, mapping gestures to affordances to help devices understand human interactions. It serves as a resource for manufacturers and developers to identify common gestures and their dynamics, promoting flexibility and extensibility without enforcing standards. A new namespace, https://w3id.org/hdgi, has been created for the ontology, which is available on GitHub for community contributions. The ontology consists of seven main classes, including Gesture, BodyPart, and Device, establishing key relationships. It uses OWL2 and Turtle syntax, with a focus on local restrictions to align with external ontologies, which are also provided in separate files on GitHub.\n\nGesture is categorized into static and dynamic types. A dynamic gesture includes one start pose, one end pose, an atomic movement, and involves a single body part. Multiple gestures can be defined in sequence using the object property hdgi:includesGesture. For example, the 'right hand swipe left' consists of eight atomic gestures, each with a body part, start pose, end pose, and movement. The ontology allows for extensibility with subclasses like hdgi:HandGesture and hdgi:ForearmGesture, though only hand, forearm, and upper arm gestures are detailed in HDGI.\n\nWe utilize and expand upon the Foundational Model of Anatomy (FMA) ontology to model human upper limb parts. The hdgi:BodyPart class is designed to be extensible for future body part representations. We focus on relevant FMA classes, defining hdgi:UpperArm, hdgi:Forearm, hdgi:Palm, and hdgi:Finger as key components of the upper limb. The hdgi:UpperArm corresponds to the Arm class in FMA, while the hdgi:Finger class is subdivided into individual fingers: hdgi:Thumb, hdgi:IndexFinger, hdgi:MiddleFinger, hdgi:RingFinger, and hdgi:LittleFinger, which are also categorized by left and right. A gesture is defined as a combination of poses and movements involving these upper limb sections.\n\nEach pose involves one body part and is defined in 3D space by its position and rotation, using relationships like hdgi:hasPosition and hdgi:hasRotation. The HDGI ontology standardizes relative positions to avoid inconsistencies across devices, with positions based on joints (e.g., upper arm relative to the shoulder). The hdgi:Position class describes local coordinate systems to address variations in SDKs, such as Unity3D and leap-motion. Rotation can be represented using either Euler angles or quaternions for flexibility. A hdgi:Pose represents a static gesture with a timestamp and can contain multiple poses, currently modeling hdgi:UpperArm, hdgi:Forearm, Palm, and individual Fingers. Examples illustrate the modeling of poses like 'Right Hand Swipe Left', detailing the use of body parts, positions, and rotations.\n\nThe hdgi:Movement class focuses on dynamic gestures, independent of hdgi:Pose. It includes a predefined set of movements for hdgi:UpperArm, hdgi:Forearm, Palm, and Finger, allowing for extensibility by designers and developers. The class is flexible, not tightly coupled with hdgi:Gesture, hdgi:Pose, or hdgi:BodyPart. Each hdgi:Movement is atomic, relating to a single position or rotation change, and has a specific hdgi:Duration derived from the timestamp difference between start and end hdgi:Pose.\n\nAffordance refers to the perceived and actual properties of a device that determine its potential uses, as defined by Norman and later adopted in Human Computer Interaction. Maier et al. describe affordances as the set of possible human behaviors a device allows, while Brown et al. emphasize their context-dependent nature. This necessitates modeling both affordance and context in Human Device Gesture Interactions (HDGI) to understand user intent. Users communicate necessary affordances through gestures, and an effective mapping of gestures to affordances can enhance user experience. For instance, if a user gestures towards Device B but intends to interact with Device A's affordance, automated reasoning can bridge the gap. The HDGI ontology models relationships between devices, affordances, and manufacturers, allowing for multiple gestures and affordances across devices. This modeling aids systems in identifying gesture semantics and performing affordance mapping through a knowledge base, enabling independent layers for gesture recognition and communication.\n\nOntology engineering involves not only building and annotating but also integrating and documenting ontologies. The HDGI ontology implementation features a RESTful API-driven HDGI-Mapping Service, allowing designers and developers to access a gesture repository for contemporary gestures and their mappings. Users can define and upload their own gesture vocabularies, promoting reuse and reducing redundancy in gestural interfaces. The project is open-source under the Apache 2.0 license, enabling contributions and private cloud deployment. The service includes a web application with Java and Apache Tomcat prerequisites, along with comprehensive API and architecture documentation. Future enhancements include integrating Swagger UI for real-time API exploration and Swagger codegen for generating client SDKs in various programming languages, facilitating easier integration into gesture recognition software.\n\nThis work presents the Human Device Gesture Interaction (HDGI) ontology, a model of human device gesture interactions that describes gestures related to human device interactions and maps them with corresponding affordances. This is an initial step towards building a comprehensive human device gesture interaction knowledge base with the ultimate purpose of bringing better user experience. The HDGI ontology can assist gesture recognition systems, designers, manufacturers, and developers to formally express gestures and to carry automated reasoning tasks based on relationships between gestures and device affordances.\n\nWhile developing the ontology, we extracted elements observed from existing gesture vocabularies defined in previous studies. We also present a Web service interface, the HDGI Mapping service, that can be integrated with existing gesture recognition systems.\n\nThe intention and scope of the HDGI ontology can be summarized as follows: first, to describe gestures related to human device interaction performed using the human upper-limb region; second, to map the relationship between affordances and a particular gesture based on the user context, allowing devices to understand different gestures that humans perform to interact with the same affordances; and third, to act as a dictionary and a repository for manufacturers, developers, and designers to identify commonly used gestures for certain affordances, specify formally what a certain gesture means, and introduce new gestures if necessary.\n\nAs future work, there are several possible extensions that can be made to the ontology by incorporating more gesture types such as facial gestures and head gestures. Furthermore, we are planning to release and deploy the HDGI RESTful service in the Cloud and release API clients to leading hand-gesture supported systems such as Microsoft HoloLens 2, Microsoft Kinect, and Soli. Since gesture interactions in Mixed Reality are becoming increasingly popular, we plan to conduct several gesture elicitation studies using Microsoft HoloLens 2, especially to map gesture interactions in Mixed Reality to the HDGI ontology.",
  "triples": [
    [
      "Entity-gesture-controlled_interface",
      "Predicate-are_becoming_popular_with",
      "Entity-internet_of_thing__iot__system"
    ],
    [
      "Entity-internet_of_thing",
      "Predicate-is_related_to",
      "Entity-internet_of_thing"
    ],
    [
      "Entity-internet_of_thing",
      "Predicate-is_a_type_of",
      "Entity-internet_of_thing"
    ],
    [
      "Entity-gesture",
      "Predicate-have_become_prevalent_in",
      "Entity-automobile"
    ],
    [
      "Entity-gesture",
      "Predicate-have_become_prevalent_in",
      "Entity-smart_home"
    ],
    [
      "Entity-gesture",
      "Predicate-have_become_prevalent_in",
      "Entity-computer_game"
    ],
    [
      "Entity-gesture",
      "Predicate-have_become_prevalent_in",
      "Entity-augmented_reality"
    ],
    [
      "Entity-gesture",
      "Predicate-have_become_prevalent_in",
      "Entity-virtual_reality"
    ],
    [
      "Entity-designer__producer__and_vendor",
      "Predicate-integrating",
      "Entity-gesture-controlled_interface"
    ],
    [
      "Entity-designer__producer__and_vendor",
      "Predicate-have_increased_in_numbers",
      "Entity-their_product"
    ],
    [
      "Entity-gesture-controlled_interface",
      "Predicate-utilizing",
      "Entity-standard"
    ],
    [
      "Entity-standard",
      "Predicate-giving_rise_to",
      "Entity-a_greater_variation_of_standard"
    ],
    [
      "Entity-this_variety",
      "Predicate-can_confuse",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-a_user_(1)",
      "Predicate-is_accustomed_to",
      "Entity-a_set_of_conventional_control"
    ],
    [
      "Entity-a_user_(1)",
      "Predicate-has",
      "Entity-their_own_preference"
    ],
    [
      "Entity-variety",
      "Predicate-can_confuse",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-user",
      "Predicate-adjusts_to",
      "Entity-the_system"
    ],
    [
      "Entity-the_provided_gesture",
      "Predicate-are_not_intuitive_and_contrary_to",
      "Entity-user__s_expectation"
    ],
    [
      "Entity-a_user_(2)",
      "Predicate-adjusts_to",
      "Entity-the_system"
    ],
    [
      "Entity-this_paper",
      "Predicate-addresses",
      "Entity-the_problem_of_the_absence_of_a_systematic_analysis_and_description_of_gesture"
    ],
    [
      "Entity-this_paper",
      "Predicate-develops",
      "Entity-an_ontology"
    ],
    [
      "Entity-ontology",
      "Predicate-describes",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-an_ontology",
      "Predicate-describes",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_based_on",
      "Entity-semantic_web_standard"
    ],
    [
      "Entity-semantic_web_standard",
      "Predicate-includes",
      "Entity-rdf"
    ],
    [
      "Entity-semantic_web_standard",
      "Predicate-includes",
      "Entity-owl2"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_based_on",
      "Entity-semantic_web_standard__rdf__rdfs__and_owl2_"
    ],
    [
      "Entity-human_gesture",
      "Predicate-describes",
      "Entity-affordance"
    ],
    [
      "Entity-human_gesture",
      "Predicate-describes",
      "Entity-userdevice_context"
    ],
    [
      "Entity-human_gesture",
      "Predicate-describes",
      "Entity-an_extensible_way"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-describes",
      "Entity-human_gesture"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-describes",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_capable_of_describing",
      "Entity-human_gesture"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-includes_mappings_to",
      "Entity-affordance"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-includes_mappings_to",
      "Entity-userdevice_context"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_described_in",
      "Entity-an_extensible_way"
    ],
    [
      "Entity-gesture-based_system",
      "Predicate-are_explored_as",
      "Entity-method_for_controlling_interactive_system"
    ],
    [
      "Entity-gesture-based_system",
      "Predicate-are_becoming",
      "Entity-method_for_controlling_interactive_system"
    ],
    [
      "Entity-gesture",
      "Predicate-have_become_prevalent_in",
      "Entity-modern_automobile"
    ],
    [
      "Entity-gesture_interaction",
      "Predicate-consist_of",
      "Entity-physical_movement"
    ],
    [
      "Entity-gesture_interaction",
      "Predicate-allow",
      "Entity-user"
    ],
    [
      "Entity-user",
      "Predicate-express",
      "Entity-interaction_intention"
    ],
    [
      "Entity-user",
      "Predicate-send_out",
      "Entity-interactive_information"
    ],
    [
      "Entity-interactive_information",
      "Predicate-sent_out_to",
      "Entity-device"
    ],
    [
      "Entity-interactive_information",
      "Predicate-sent_out_to",
      "Entity-system"
    ],
    [
      "Entity-gesture_interaction",
      "Predicate-consist_of",
      "Entity-physical_movement_of_the_face__limb__or_body"
    ],
    [
      "Entity-gesture",
      "Predicate-allow",
      "Entity-user"
    ],
    [
      "Entity-gestural_interface",
      "Predicate-are_built_based_on",
      "Entity-manufacturer__s_design_decision"
    ],
    [
      "Entity-wobbrock_et_al_.",
      "Predicate-emphasize_that",
      "Entity-the_concept_of_guessability_of_a_system_"
    ],
    [
      "Entity-user",
      "Predicate-must_be_met_with",
      "Entity-success"
    ],
    [
      "Entity-user__s_initial_attempt",
      "Predicate-involve",
      "Entity-gesture__typing_command__or_using_button_or_menu_item"
    ],
    [
      "Entity-wobbrock_et_al_.",
      "Predicate-introduce",
      "Entity-the_concept_of_guessability_of_a_system_"
    ],
    [
      "Entity-wobbrock_et_al_.",
      "Predicate-emphasize_that",
      "Entity-user__s_initial_attempt"
    ],
    [
      "Entity-user__s_initial_attempt",
      "Predicate-must_be_met_with",
      "Entity-success"
    ],
    [
      "Entity-user__s_lack_of_knowledge_of_the_relevant_symbol",
      "Predicate-is_related_to",
      "Entity-success"
    ],
    [
      "Entity-gesture_elicitation_study__ge_",
      "Predicate-enables",
      "Entity-end_user__preference_for_symbolic_input"
    ],
    [
      "Entity-gesture_elicitation_study__ge_",
      "Predicate-is_considered",
      "Entity-gesture_elicitation_study__ge_"
    ],
    [
      "Entity-gesture_elicitation_study__ge_",
      "Predicate-is_abbreviated_as",
      "Entity-ge"
    ],
    [
      "Entity-gesture_elicitation_study",
      "Predicate-is_considered_the_introduction_of",
      "Entity-gesture_elicitation_study__ge_"
    ],
    [
      "Entity-many_researcher",
      "Predicate-attempted_to_define",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-researcher",
      "Predicate-attempted_to_define",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-a_majority_of_them",
      "Predicate-are_limited_in",
      "Entity-their_scope"
    ],
    [
      "Entity-these_ge",
      "Predicate-has_resulted_in",
      "Entity-an_impressive_amount_of_knowledge"
    ],
    [
      "Entity-multiple_study",
      "Predicate-show",
      "Entity-best_gesture_"
    ],
    [
      "Entity-best_gesture_",
      "Predicate-refer_to",
      "Entity-the_same_referent"
    ],
    [
      "Entity-the_gestural_sign",
      "Predicate-refers_to",
      "Entity-desired_effect_of_an_action"
    ],
    [
      "Entity-the_gestural_sign",
      "Predicate-refers_to",
      "Entity-effect_of_a_gesture"
    ],
    [
      "Entity-redundant_gesture_vocabulary",
      "Predicate-are",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-are",
      "Entity-redundant_gesture_vocabulary"
    ],
    [
      "Entity-knowledge_of_ge",
      "Predicate-is_linked",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-are_defined_for",
      "Entity-similar_referent"
    ],
    [
      "Entity-a_lack_of_linked_data",
      "Predicate-has_resulted_in",
      "Entity-researcher"
    ],
    [
      "Entity-researcher",
      "Predicate-conducting",
      "Entity-new_ge"
    ],
    [
      "Entity-researcher",
      "Predicate-need",
      "Entity-gesture-referent_mapping"
    ],
    [
      "Entity-researcher",
      "Predicate-using",
      "Entity-existing_knowledge"
    ],
    [
      "Entity-researcher",
      "Predicate-conduct",
      "Entity-new_ge"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-is_capable_of_describing",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-can_describe",
      "Entity-related_referent"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-facilitates",
      "Entity-automated_reasoning"
    ],
    [
      "Entity-several_sensor",
      "Predicate-allow",
      "Entity-movement_recognition"
    ],
    [
      "Entity-several_sensor",
      "Predicate-allow",
      "Entity-posture_or_movement_recognition"
    ],
    [
      "Entity-microsoft_kinect",
      "Predicate-is_a_type_of",
      "Entity-sensor"
    ],
    [
      "Entity-developer",
      "Predicate-define_and_capture",
      "Entity-mid-air_gesture"
    ],
    [
      "Entity-mid-air_gesture",
      "Predicate-are_used_in",
      "Entity-various_application"
    ],
    [
      "Entity-microsoft_kinect",
      "Predicate-allows",
      "Entity-posture_or_movement_recognition"
    ],
    [
      "Entity-microsoft_kinect",
      "Predicate-allows",
      "Entity-movement_recognition"
    ],
    [
      "Entity-microsoft_kinect",
      "Predicate-allows",
      "Entity-mid-air_gesture"
    ],
    [
      "Entity-ar_and_vr",
      "Predicate-advancements_in",
      "Entity-gestural_interface"
    ],
    [
      "Entity-gestural_interface",
      "Predicate-use",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-all_these_system",
      "Predicate-have_the_capability_to_detect",
      "Entity-rich_gestural_input"
    ],
    [
      "Entity-system",
      "Predicate-have_the_capability_to_detect",
      "Entity-gestural_input"
    ],
    [
      "Entity-designer__producer__and_vendor",
      "Predicate-integrating",
      "Entity-their_product"
    ],
    [
      "Entity-gesture-controlled_interface",
      "Predicate-contributing_to",
      "Entity-a_surge_in_their_number"
    ],
    [
      "Entity-gesture-controlled_interface",
      "Predicate-causing",
      "Entity-greater_variation_in_way_of_utilizing_them"
    ],
    [
      "Entity-system_designer",
      "Predicate-define",
      "Entity-gesture"
    ],
    [
      "Entity-system_designer",
      "Predicate-evaluate",
      "Entity-small-scale_user_study"
    ],
    [
      "Entity-system_designer",
      "Predicate-teach",
      "Entity-end_user"
    ],
    [
      "Entity-system_designer",
      "Predicate-evaluate",
      "Entity-user_study"
    ],
    [
      "Entity-people",
      "Predicate-have",
      "Entity-different_expectation"
    ],
    [
      "Entity-interface",
      "Predicate-to_perform",
      "Entity-a_certain_task"
    ],
    [
      "Entity-this",
      "Predicate-is_problematic_because",
      "Entity-people"
    ],
    [
      "Entity-user",
      "Predicate-is_accustomed_to",
      "Entity-a_set_of_conventional_control"
    ],
    [
      "Entity-these_system",
      "Predicate-have",
      "Entity-binary_or_a_few_choice"
    ],
    [
      "Entity-these_system",
      "Predicate-have",
      "Entity-gesture_selection"
    ],
    [
      "Entity-manufacturer-defined_gesture",
      "Predicate-are",
      "Entity-undesirable_or_counter-intuitive"
    ],
    [
      "Entity-it_first_version",
      "Predicate-has",
      "Entity-bloom__gesture"
    ],
    [
      "Entity-bloom__gesture",
      "Predicate-opens",
      "Entity-start__menu"
    ],
    [
      "Entity-user",
      "Predicate-holds_out",
      "Entity-their_hand"
    ],
    [
      "Entity-start_icon",
      "Predicate-appears_near",
      "Entity-a_user__s_wrist"
    ],
    [
      "Entity-user",
      "Predicate-looks_at",
      "Entity-start_icon"
    ],
    [
      "Entity-user",
      "Predicate-opens",
      "Entity-start_menu"
    ],
    [
      "Entity-microsoft_hololens",
      "Predicate-requires",
      "Entity-user"
    ],
    [
      "Entity-their_hand",
      "Predicate-faces",
      "Entity-palm"
    ],
    [
      "Entity-their_other_hand",
      "Predicate-taps",
      "Entity-the_icon_that_appears_near_the_wrist"
    ],
    [
      "Entity-user",
      "Predicate-has_to_pinch",
      "Entity-start__menu"
    ],
    [
      "Entity-user",
      "Predicate-can_tap",
      "Entity-the_icon_that_appears_near_the_wrist"
    ],
    [
      "Entity-bmw",
      "Predicate-has",
      "Entity-idrive"
    ],
    [
      "Entity-idrive",
      "Predicate-expects",
      "Entity-user"
    ],
    [
      "Entity-mercedes-benz",
      "Predicate-has",
      "Entity-user_experience__mbux_"
    ],
    [
      "Entity-online_search_engine",
      "Predicate-do_not_provide",
      "Entity-gesture-related_semantics"
    ],
    [
      "Entity-search_query",
      "Predicate-retrieve",
      "Entity-gesture_to_answer_a_call_in_a_car"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-supported_by",
      "Entity-different_vendor"
    ],
    [
      "Entity-designer_and_developer_(1)",
      "Predicate-have_to_find",
      "Entity-individual_study"
    ],
    [
      "Entity-designer_and_developer_(1)",
      "Predicate-have_to_read_or_learn",
      "Entity-necessary_data"
    ],
    [
      "Entity-designer_and_developer_(1)",
      "Predicate-read_or_learn",
      "Entity-necessary_data"
    ],
    [
      "Entity-gesture",
      "Predicate-maps_to",
      "Entity-affordance_of_answering_a_call_in_a_car"
    ],
    [
      "Entity-designer",
      "Predicate-would_find_convenient",
      "Entity-central_location"
    ],
    [
      "Entity-developer",
      "Predicate-would_find_convenient",
      "Entity-central_location"
    ],
    [
      "Entity-designer",
      "Predicate-would_be_convenient_for",
      "Entity-affordance_of_answering_a_call_in_a_car"
    ],
    [
      "Entity-developer",
      "Predicate-would_be_convenient_for",
      "Entity-affordance_of_answering_a_call_in_a_car"
    ],
    [
      "Entity-inter-mapping",
      "Predicate-helps_to_bring",
      "Entity-interoperability_among_interface"
    ],
    [
      "Entity-interoperability_among_interface",
      "Predicate-increases",
      "Entity-user_experience__ux_"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "Predicate-will_help_to_bring",
      "Entity-interoperability_among_interface"
    ],
    [
      "Entity-semantics",
      "Predicate-helps_to_bring",
      "Entity-interoperability_among_interface"
    ],
    [
      "Entity-inter-mapping",
      "Predicate-will_help_to_bring",
      "Entity-interoperability_among_interface"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "Predicate-helps_to_bring",
      "Entity-interoperability_among_interface"
    ],
    [
      "Entity-our_approach",
      "Predicate-is_to_design",
      "Entity-an_ontology_(1)"
    ],
    [
      "Entity-an_ontology_(1)",
      "Predicate-maps_to",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-and_their_relationships_to",
      "Entity-system_(1)"
    ],
    [
      "Entity-an_ontology_(1)",
      "Predicate-to_understand_and_interpret",
      "Entity-user_gesture"
    ],
    [
      "Entity-an_ontology_(1)",
      "Predicate-maps",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-have_relationships_to",
      "Entity-system_(1)"
    ],
    [
      "Entity-user",
      "Predicate-shown",
      "Entity-desired_effect_of_an_action"
    ],
    [
      "Entity-desired_effect_of_an_action",
      "Predicate-called",
      "Entity-a_referent"
    ],
    [
      "Entity-user",
      "Predicate-shown",
      "Entity-their_preferred_gesture"
    ],
    [
      "Entity-user",
      "Predicate-are_shown",
      "Entity-desired_effect_of_an_action"
    ],
    [
      "Entity-desired_effect_of_an_action",
      "Predicate-is_called",
      "Entity-a_referent"
    ],
    [
      "Entity-a_referent",
      "Predicate-is_related_to",
      "Entity-their_preferred_gesture"
    ],
    [
      "Entity-villarreal-narvaez_et_al_.",
      "Predicate-show",
      "Entity-gesture"
    ],
    [
      "Entity-gesture",
      "Predicate-are_performed_using",
      "Entity-hand"
    ],
    [
      "Entity-hand",
      "Predicate-are_part_of",
      "Entity-upper_limb"
    ],
    [
      "Entity-upper_limb",
      "Predicate-are_part_of",
      "Entity-the_human_body"
    ],
    [
      "Entity-upper_limb",
      "Predicate-are",
      "Entity-hand"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-describes",
      "Entity-upper_limb_related_gesture"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-maps",
      "Entity-device_affordances"
    ],
    [
      "Entity-upper_limb_related_gesture",
      "Predicate-is_related_to",
      "Entity-upper_limb"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-is_designed_to_describe",
      "Entity-upper_limb_related_gesture"
    ],
    [
      "Entity-system",
      "Predicate-query",
      "Entity-this_ontology"
    ],
    [
      "Entity-gesture",
      "Predicate-recognizing",
      "Entity-it_referent"
    ],
    [
      "Entity-ontology",
      "Predicate-allows",
      "Entity-system"
    ],
    [
      "Entity-the_gesture",
      "Predicate-understands",
      "Entity-it_referent"
    ],
    [
      "Entity-personalization",
      "Predicate-helps",
      "Entity-personalization_of_gesture"
    ],
    [
      "Entity-personalization_of_gesture",
      "Predicate-is_for",
      "Entity-particular_set_of_user"
    ],
    [
      "Entity-personalization_of_gesture",
      "Predicate-helps",
      "Entity-user"
    ],
    [
      "Entity-a_user_(3)",
      "Predicate-does_not_have_to_memorize",
      "Entity-a_particular_gesture"
    ],
    [
      "Entity-system",
      "Predicate-improves",
      "Entity-system_reliability"
    ],
    [
      "Entity-a_user_(3)",
      "Predicate-improves",
      "Entity-system_reliability"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-describes",
      "Entity-sample_usage"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-describes",
      "Entity-state_of_the_art"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-describes",
      "Entity-this_area"
    ],
    [
      "Entity-existing_approach",
      "Predicate-addresses",
      "Entity-ubiquitousness_in_human-device_gesture_interaction"
    ],
    [
      "Entity-section_3",
      "Predicate-describes",
      "Entity-syntax"
    ],
    [
      "Entity-section_3",
      "Predicate-describes",
      "Entity-semantics"
    ],
    [
      "Entity-section_3",
      "Predicate-describes",
      "Entity-design"
    ],
    [
      "Entity-section_3",
      "Predicate-describes",
      "Entity-formalization"
    ],
    [
      "Entity-design",
      "Predicate-has",
      "Entity-rationale"
    ],
    [
      "Entity-design",
      "Predicate-has",
      "Entity-rationale_behind_such_a_design"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-is_part_of",
      "Entity-hdgi_v0.1"
    ],
    [
      "Entity-tool_for_mapping_hdgi_v0.1_to_leap_motion_and_the_oculus_quest_device",
      "Predicate-illustrate",
      "Entity-hdgi_v0.1"
    ],
    [
      "Entity-tool_for_mapping_hdgi_v0.1_to_leap_motion_and_the_oculus_quest_device",
      "Predicate-illustrate",
      "Entity-leap_motion"
    ],
    [
      "Entity-tool_for_mapping_hdgi_v0.1_to_leap_motion_and_the_oculus_quest_device",
      "Predicate-illustrate_(1)",
      "Entity-oculus_quest"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-serves_as",
      "Entity-expressive_power_of_our_ontology"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-provides",
      "Entity-developer_and_designer"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-provides",
      "Entity-a_tool_on_how_to_integrate_the_hdgi_ontology"
    ],
    [
      "Entity-evaluation",
      "Predicate-of",
      "Entity-expressive_power_of_our_ontology"
    ],
    [
      "Entity-knowledge_of_ge",
      "Predicate-has_resulted_in",
      "Entity-an_impressive_amount_of_knowledge"
    ],
    [
      "Entity-a_large_number_of_study",
      "Predicate-deals_with",
      "Entity-the_problem_of_hand_gesture_recognition"
    ],
    [
      "Entity-a_large_number_of_study",
      "Predicate-can_be_found_dealing_with",
      "Entity-gestural_interface"
    ],
    [
      "Entity-gesture",
      "Predicate-are_predefined_with",
      "Entity-their_meaning_and_action"
    ],
    [
      "Entity-the_study",
      "Predicate-explore",
      "Entity-the_capability_of_identifying_the_relationship"
    ],
    [
      "Entity-the_capability_of_identifying_the_relationship",
      "Predicate-identifies",
      "Entity-relationship"
    ],
    [
      "Entity-study",
      "Predicate-attempted_to_define_and_formalise",
      "Entity-relationship_between_each_gesture"
    ],
    [
      "Entity-few_study",
      "Predicate-attempted_to_define_and_formalise",
      "Entity-relationship_between_each_gesture"
    ],
    [
      "Entity-review_conducted_by_villarreal_narvaez_et_al_._in_2020",
      "Predicate-show",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-hand_gesture_recognition",
      "Predicate-indicates",
      "Entity-gesture-related_vocabulary"
    ],
    [
      "Entity-gesture-related_vocabulary",
      "Predicate-increases_the_need_for",
      "Entity-interoperability"
    ],
    [
      "Entity-the_study",
      "Predicate-attempted_to_define_and_formalise",
      "Entity-relationship_between_each_gesture"
    ],
    [
      "Entity-researcher",
      "Predicate-adopt",
      "Entity-one_approach"
    ],
    [
      "Entity-one_approach",
      "Predicate-enables",
      "Entity-designer_and_manufacturer"
    ],
    [
      "Entity-designer_and_manufacturer",
      "Predicate-use",
      "Entity-standard_definition"
    ],
    [
      "Entity-one_approach",
      "Predicate-define_(1)",
      "Entity-taxonomy"
    ],
    [
      "Entity-taxonomy",
      "Predicate-define_(1)",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-researcher",
      "Predicate-use",
      "Entity-standard_definition"
    ],
    [
      "Entity-researcher",
      "Predicate-adopted",
      "Entity-one_approach"
    ],
    [
      "Entity-scoditti_et_al_.",
      "Predicate-proposed",
      "Entity-gestural_interaction_taxonomy"
    ],
    [
      "Entity-gestural_interaction_taxonomy",
      "Predicate-guides",
      "Entity-designer_and_researcher"
    ],
    [
      "Entity-designer_and_researcher",
      "Predicate-need",
      "Entity-systematic_structure"
    ],
    [
      "Entity-systematic_structure",
      "Predicate-helps",
      "Entity-designer_and_researcher"
    ],
    [
      "Entity-designer_and_researcher",
      "Predicate-create",
      "Entity-appropriate_technique"
    ],
    [
      "Entity-appropriate_technique",
      "Predicate-address",
      "Entity-the_problem_at_hand"
    ],
    [
      "Entity-system-wide_consistent_language",
      "Predicate-introduce",
      "Entity-gesture"
    ],
    [
      "Entity-author",
      "Predicate-do_not_map",
      "Entity-existing_gesture_vocabulary"
    ],
    [
      "Entity-choi_et_al_.",
      "Predicate-developed",
      "Entity-3d_hand_gesture_taxonomy"
    ],
    [
      "Entity-3d_hand_gesture_taxonomy",
      "Predicate-includes",
      "Entity-notation_method"
    ],
    [
      "Entity-the_result_of_this_study",
      "Predicate-can_be_used_as",
      "Entity-a_guideline"
    ],
    [
      "Entity-a_guideline",
      "Predicate-to_organize",
      "Entity-hand_gesture"
    ],
    [
      "Entity-this_research",
      "Predicate-is_restricted_to",
      "Entity-6_command__43_gesture_"
    ],
    [
      "Entity-tv_and_blind",
      "Predicate-were_used_in",
      "Entity-the_experiment"
    ],
    [
      "Entity-further_experiment",
      "Predicate-are_necessary_to_see",
      "Entity-the_proposed_taxonomy_and_notation_method"
    ],
    [
      "Entity-further_experiment",
      "Predicate-are_necessary_to_see",
      "Entity-capability"
    ],
    [
      "Entity-this_notation",
      "Predicate-use",
      "Entity-numeric_terminology"
    ],
    [
      "Entity-designer",
      "Predicate-follow",
      "Entity-a_reference_guide"
    ],
    [
      "Entity-a_reference_guide",
      "Predicate-is_provided",
      "Entity-this_notation"
    ],
    [
      "Entity-hand_gesture",
      "Predicate-have_not_been_considered_in",
      "Entity-their_approach"
    ],
    [
      "Entity-size_or_speed_of_hand_gesture",
      "Predicate-have_not_been_considered_in",
      "Entity-their_approach"
    ],
    [
      "Entity-existing_research_using_ontology",
      "Predicate-uses",
      "Entity-ontology"
    ],
    [
      "Entity-existing_research_using_ontology",
      "Predicate-moves_beyond",
      "Entity-taxonomy"
    ],
    [
      "Entity-osumar_et_al_.",
      "Predicate-modelled",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-describes",
      "Entity-mid-air_gesture_of_the_human_body"
    ],
    [
      "Entity-microsoft_kinect-based_skeleton",
      "Predicate-is_based_on",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-aims_to_describe",
      "Entity-mid-air_gesture_of_the_human_body"
    ],
    [
      "Entity-their_ontology",
      "Predicate-focuses_on",
      "Entity-holistic_posture"
    ],
    [
      "Entity-their_ontology",
      "Predicate-misses",
      "Entity-detail_like_the_finger_pose_or_movement"
    ],
    [
      "Entity-their_ontology",
      "Predicate-misses",
      "Entity-detailed_representation_of_the_hand"
    ],
    [
      "Entity-an_ontology",
      "Predicate-prevents",
      "Entity-use_and_extensibility"
    ],
    [
      "Entity-an_ontology",
      "Predicate-is_not_openly_shared",
      "Entity-use_and_extensibility"
    ],
    [
      "Entity-sensor-independent_ontology",
      "Predicate-is_a_contribution_to",
      "Entity-gesture"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "Predicate-is_not_considered",
      "Entity-affordance"
    ],
    [
      "Entity-different_gesture",
      "Predicate-have_semantic_relationships_to",
      "Entity-affordance"
    ],
    [
      "Entity-sensor-independent_ontology",
      "Predicate-has",
      "Entity-intrinsic_and_extrinsic_property"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-focuses_on_capturing",
      "Entity-holistic_posture"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-misses",
      "Entity-detail_like_the_finger_pose_or_movement"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "Predicate-is_not_considered",
      "Entity-an_ontology"
    ],
    [
      "Entity-khairunizam_et_al_.",
      "Predicate-conducted",
      "Entity-a_similar_study"
    ],
    [
      "Entity-a_similar_study",
      "Predicate-addresses",
      "Entity-the_challenge_of_how_to_increase_the_knowledge_level_of_computational_system"
    ],
    [
      "Entity-computational_system",
      "Predicate-recognizing",
      "Entity-gestural_information"
    ],
    [
      "Entity-gestural_information",
      "Predicate-with_regard_to",
      "Entity-arm_movement"
    ],
    [
      "Entity-khairunizam_et_al_.",
      "Predicate-have_conducted",
      "Entity-a_similar_study"
    ],
    [
      "Entity-khairunizam_et_al_.",
      "Predicate-attempted_to_recognize",
      "Entity-gestural_information"
    ],
    [
      "Entity-their_research",
      "Predicate-describes",
      "Entity-knowledge_of_the_arm_gesture"
    ],
    [
      "Entity-their_research",
      "Predicate-recognizes",
      "Entity-arm_movement"
    ],
    [
      "Entity-their_research",
      "Predicate-attempted_to_recognize",
      "Entity-higher_accuracy"
    ],
    [
      "Entity-their_research",
      "Predicate-has_tried_to_describe",
      "Entity-knowledge_of_the_arm_gesture"
    ],
    [
      "Entity-qualisys_motion_capture",
      "Predicate-used_to_capture",
      "Entity-the_movement_of_the_user__s_right_arm"
    ],
    [
      "Entity-the_movement_of_the_user__s_right_arm",
      "Predicate-performed_during",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-qualisys_motion_capture",
      "Predicate-was_used_to_capture",
      "Entity-the_movement_of_the_user__s_right_arm"
    ],
    [
      "Entity-their_focus",
      "Predicate-was_mainly_on",
      "Entity-geometrical_gesture"
    ],
    [
      "Entity-gesture_set",
      "Predicate-was_limited_to",
      "Entity-5_geometrical_shape"
    ],
    [
      "Entity-their_ontological_framework",
      "Predicate-does_not_consider",
      "Entity-mapping_of_other_gesture"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "Predicate-carries",
      "Entity-similar_referent"
    ],
    [
      "Entity-khairunizam_et_al_.",
      "Predicate-tried_to_describe",
      "Entity-knowledge_of_the_arm_gesture"
    ],
    [
      "Entity-the_attempt_above",
      "Predicate-have_a_different_scope_compared_to",
      "Entity-an_ontology"
    ],
    [
      "Entity-our_focus",
      "Predicate-is_not_on",
      "Entity-modelling_the_infinite_set_of_concept__feature__attribute__and_relationship"
    ],
    [
      "Entity-arm-based_gesture",
      "Predicate-are_attached_to",
      "Entity-relationship"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent",
      "Predicate-does_not_consider",
      "Entity-a_particular_affordance_of_a_device"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "Predicate-do_not_carry",
      "Entity-a_particular_affordance_of_a_device"
    ],
    [
      "Entity-gesture",
      "Predicate-carry_a_referent_to",
      "Entity-a_particular_affordance_of_a_device"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent",
      "Predicate-do_not_consider",
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device"
    ],
    [
      "Entity-gesture",
      "Predicate-be_extended_to",
      "Entity-other_body_part"
    ],
    [
      "Entity-gesture",
      "Predicate-extend_beyond",
      "Entity-upper_limb_of_the_human_body"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_extensible_to_allow_the_addition_of",
      "Entity-emerging_gesture"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_extended_to",
      "Entity-other_body_part"
    ],
    [
      "Entity-existing_ontology",
      "Predicate-fit",
      "Entity-best_practice"
    ],
    [
      "Entity-ontology",
      "Predicate-provided_mappings_to",
      "Entity-concept_and_property_in_these_ontology"
    ],
    [
      "Entity-ontology",
      "Predicate-provided_mappings_to",
      "Entity-mapping_to_concept_and_property"
    ],
    [
      "Entity-best_practice",
      "Predicate-provides",
      "Entity-mapping_to_concept_and_property"
    ],
    [
      "Entity-the_study",
      "Predicate-attempted_to_define",
      "Entity-relationship_between_each_gesture"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-models",
      "Entity-the_pose_and_movement_of_human_upper_limb"
    ],
    [
      "Entity-upper_limb",
      "Predicate-are_used_to_interact_with",
      "Entity-device"
    ],
    [
      "Entity-this_ontology",
      "Predicate-describes",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "Predicate-are_performed_using",
      "Entity-human_s_upper_limb_region"
    ],
    [
      "Entity-affordance",
      "Predicate-maps_to",
      "Entity-human_gesture"
    ],
    [
      "Entity-device",
      "Predicate-facilitates",
      "Entity-automated_system"
    ],
    [
      "Entity-a_dictionary_for_manufacturer__designer__and_developer",
      "Predicate-acts_as",
      "Entity-dictionary"
    ],
    [
      "Entity-designer",
      "Predicate-search_and_identify",
      "Entity-commonly_used_gesture"
    ],
    [
      "Entity-manufacturer",
      "Predicate-search_and_identify",
      "Entity-commonly_used_gesture"
    ],
    [
      "Entity-developer",
      "Predicate-search_and_identify",
      "Entity-commonly_used_gesture"
    ],
    [
      "Entity-commonly_used_gesture",
      "Predicate-for",
      "Entity-certain_affordances"
    ],
    [
      "Entity-certain_affordances",
      "Predicate-understands",
      "Entity-the_shape_and_dynamic_of_a_certain_gesture"
    ],
    [
      "Entity-device_manufacturer",
      "Predicate-introduce",
      "Entity-new_gesture"
    ],
    [
      "Entity-designer",
      "Predicate-introduce",
      "Entity-new_gesture"
    ],
    [
      "Entity-this_ontology",
      "Predicate-maps",
      "Entity-affordance"
    ],
    [
      "Entity-this_ontology",
      "Predicate-introduces",
      "Entity-new_gesture"
    ],
    [
      "Entity-this_study",
      "Predicate-aims_to_define",
      "Entity-semantic_model_of_gesture"
    ],
    [
      "Entity-semantic_model_of_gesture",
      "Predicate-is_combined_with",
      "Entity-it_associated_knowledge"
    ],
    [
      "Entity-a_new_namespace_http__w3id.orghdgi",
      "Predicate-defined_with",
      "Entity-the_prefix_hdgi"
    ],
    [
      "Entity-a_new_namespace_http__w3id.orghdgi",
      "Predicate-used_for",
      "Entity-all_the_class_used_in_the_ontology"
    ],
    [
      "Entity-all_the_class_used_in_the_ontology",
      "Predicate-independent_of",
      "Entity-external_ontology"
    ],
    [
      "Entity-namespace_http__w3id.orghdgi",
      "Predicate-defined_as",
      "Entity-a_new_namespace_http__w3id.orghdgi"
    ],
    [
      "Entity-the_prefix_hdgi",
      "Predicate-used_for",
      "Entity-all_the_class_used_in_the_ontology"
    ],
    [
      "Entity-relevant_mapping",
      "Predicate-provided_to",
      "Entity-external_ontology"
    ],
    [
      "Entity-w3id.org",
      "Predicate-is_using",
      "Entity-the_permanent_url_service"
    ],
    [
      "Entity-w3id.org",
      "Predicate-used_as",
      "Entity-the_permanent_url_service"
    ],
    [
      "Entity-the_relevant_code__data__and_ontology",
      "Predicate-are_made_available_for",
      "Entity-community"
    ],
    [
      "Entity-community",
      "Predicate-allows",
      "Entity-anyone_interested_to_join_a_a_contributor"
    ],
    [
      "Entity-github",
      "Predicate-allows",
      "Entity-anyone_interested_to_join_a_a_contributor"
    ],
    [
      "Entity-class_and_property_of_the_hdgi_ontology",
      "Predicate-represent",
      "Entity-human_upper_limb_region_gesture"
    ],
    [
      "Entity-human_upper_limb_region_gesture",
      "Predicate-associated_with",
      "Entity-affordance"
    ],
    [
      "Entity-human_upper_limb_region_gesture",
      "Predicate-associated_with",
      "Entity-context"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-represent",
      "Entity-human_upper_limb_region_gesture"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-associates_with",
      "Entity-affordance"
    ],
    [
      "Entity-this_ontology",
      "Predicate-is_designed_around",
      "Entity-seven_main_class"
    ],
    [
      "Entity-seven_main_class",
      "Predicate-consists_of",
      "Entity-hdgi__gesture"
    ],
    [
      "Entity-seven_main_class",
      "Predicate-consists_of",
      "Entity-hdgi__bodypart"
    ],
    [
      "Entity-seven_main_class",
      "Predicate-consists_of",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-seven_main_class",
      "Predicate-consists_of",
      "Entity-hdgi__movement"
    ],
    [
      "Entity-seven_main_class",
      "Predicate-consists_of",
      "Entity-hdgi__affordance"
    ],
    [
      "Entity-seven_main_class",
      "Predicate-consists_of",
      "Entity-hdgi__device"
    ],
    [
      "Entity-seven_main_class",
      "Predicate-consists_of",
      "Entity-hdgi__human"
    ],
    [
      "Entity-seven_main_class",
      "Predicate-establishes_relationships_with",
      "Entity-hdgi__observer"
    ],
    [
      "Entity-seven_main_class",
      "Predicate-establishes_relationships_with",
      "Entity-hdgi__context"
    ],
    [
      "Entity-this_core_ontology_design_pattern",
      "Predicate-will_be_registered_in",
      "Entity-ontology_design_pattern_initiative"
    ],
    [
      "Entity-this_ontology",
      "Predicate-introduces",
      "Entity-all_class_and_relationship"
    ],
    [
      "Entity-this_ontology",
      "Predicate-has",
      "Entity-it_own_namespace"
    ],
    [
      "Entity-all_class_and_relationship",
      "Predicate-in",
      "Entity-it_own_namespace"
    ],
    [
      "Entity-equivalent_class_and_property",
      "Predicate-from",
      "Entity-external_ontology"
    ],
    [
      "Entity-class_and_property",
      "Predicate-are_expressed_in",
      "Entity-owl2"
    ],
    [
      "Entity-modelling",
      "Predicate-use",
      "Entity-turtle_syntax"
    ],
    [
      "Entity-property",
      "Predicate-have",
      "Entity-global_domain_and_range_restriction"
    ],
    [
      "Entity-property",
      "Predicate-have",
      "Entity-guarded_local_restriction"
    ],
    [
      "Entity-specific_property",
      "Predicate-has",
      "Entity-universal_and_existential_class_restriction"
    ],
    [
      "Entity-instance_of_that_property",
      "Predicate-have",
      "Entity-that_class_a_the_subject"
    ],
    [
      "Entity-specific_property",
      "Predicate-asserts",
      "Entity-range_of_the_property"
    ],
    [
      "Entity-the_alignment_of_the_ontology",
      "Predicate-helps",
      "Entity-ontology"
    ],
    [
      "Entity-the_alignment_of_the_ontology",
      "Predicate-helps_in",
      "Entity-external_ontology"
    ],
    [
      "Entity-the_alignment_of_the_ontology",
      "Predicate-helps",
      "Entity-guarded_local_restriction"
    ],
    [
      "Entity-alignment",
      "Predicate-to",
      "Entity-ontology"
    ],
    [
      "Entity-alignment",
      "Predicate-as",
      "Entity-separate_ontology_file"
    ],
    [
      "Entity-separate_ontology_file",
      "Predicate-in",
      "Entity-github"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-is_designed_around",
      "Entity-seven_main_class"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-introduces",
      "Entity-all_class_and_relationship"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-uses",
      "Entity-owl2"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-uses",
      "Entity-turtle_syntax"
    ],
    [
      "Entity-this_ontology",
      "Predicate-acts_as",
      "Entity-a_dictionary_for_manufacturer__designer__and_developer"
    ],
    [
      "Entity-this_ontology",
      "Predicate-facilitates",
      "Entity-automated_system"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-aligns_with",
      "Entity-external_ontology"
    ],
    [
      "Entity-hdgi__gesture",
      "Predicate-distinguishes",
      "Entity-dynamic_gesture"
    ],
    [
      "Entity-dynamic_gesture",
      "Predicate-consists_of",
      "Entity-start_hdgi__pose"
    ],
    [
      "Entity-dynamic_gesture",
      "Predicate-consists_of",
      "Entity-end_hdgi__pose"
    ],
    [
      "Entity-dynamic_gesture",
      "Predicate-consists_of",
      "Entity-atomic_hdgi__movement"
    ],
    [
      "Entity-dynamic_gesture",
      "Predicate-involves",
      "Entity-hdgi__bodypart"
    ],
    [
      "Entity-gesture",
      "Predicate-can_have",
      "Entity-multiple_pose"
    ],
    [
      "Entity-gesture",
      "Predicate-can_have",
      "Entity-movement_of_multiple_body_part"
    ],
    [
      "Entity-sequence_of_gesture",
      "Predicate-define_(1)",
      "Entity-sequence_of_gesture"
    ],
    [
      "Entity-an_ontology",
      "Predicate-is_designed_to_capture_and_describe",
      "Entity-individual_body_part"
    ],
    [
      "Entity-gesture",
      "Predicate-involves",
      "Entity-multiple_movement_and_pose_of_body_part"
    ],
    [
      "Entity-hdgi__includesgesture",
      "Predicate-aggregates",
      "Entity-hdgi__gesture"
    ],
    [
      "Entity-hdgi__gesture",
      "Predicate-maps_to",
      "Entity-allen_time"
    ],
    [
      "Entity-hdgi__gesture",
      "Predicate-aggregates",
      "Entity-hdgi__includesgesture"
    ],
    [
      "Entity-hdgi__includesgesture",
      "Predicate-captures",
      "Entity-individual_body_part"
    ],
    [
      "Entity-ontology",
      "Predicate-is_designed_to_capture_and_describe",
      "Entity-individual_body_part"
    ],
    [
      "Entity-gesture",
      "Predicate-can_be_described_using",
      "Entity-hdgi__includesgesture"
    ],
    [
      "Entity-hdgi__gesture",
      "Predicate-puts_in_sequence_or_concurrent",
      "Entity-allen_time"
    ],
    [
      "Entity-gesture",
      "Predicate-can_contain",
      "Entity-one_or_more_gesture"
    ],
    [
      "Entity-the_gesture",
      "Predicate-can_contain",
      "Entity-one_or_more_gesture"
    ],
    [
      "Entity-a_swipe_gesture_",
      "Predicate-performed_with",
      "Entity-right_hand"
    ],
    [
      "Entity-right_hand",
      "Predicate-performs",
      "Entity-a_swipe_gesture_"
    ],
    [
      "Entity-a_swipe_gesture_",
      "Predicate-illustrated_in",
      "Entity-listing_1.1"
    ],
    [
      "Entity-a_swipe_gesture_",
      "Predicate-illustrated_in",
      "Entity-figure_2"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "Predicate-performed_with",
      "Entity-right_hand"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "Predicate-illustrated_in",
      "Entity-listing_1.1"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "Predicate-illustrated_in",
      "Entity-figure_2"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "Predicate-consists_of",
      "Entity-eight_atomic_gesture"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "Predicate-consists_of",
      "Entity-atomic_gesture"
    ],
    [
      "Entity-atomic_gesture",
      "Predicate-are_shown",
      "Entity-figure_2"
    ],
    [
      "Entity-atomic_gesture",
      "Predicate-are_listed_in",
      "Entity-listing_1.1"
    ],
    [
      "Entity-atomic_gesture",
      "Predicate-includes",
      "Entity-single_body_part"
    ],
    [
      "Entity-atomic_gesture",
      "Predicate-includes",
      "Entity-start_pose"
    ],
    [
      "Entity-atomic_gesture",
      "Predicate-includes",
      "Entity-end_pose"
    ],
    [
      "Entity-atomic_gesture",
      "Predicate-includes",
      "Entity-a_movement"
    ],
    [
      "Entity-eight_atomic_gesture",
      "Predicate-includes",
      "Entity-single_body_part"
    ],
    [
      "Entity-eight_atomic_gesture",
      "Predicate-includes",
      "Entity-start_pose"
    ],
    [
      "Entity-eight_atomic_gesture",
      "Predicate-includes",
      "Entity-end_pose"
    ],
    [
      "Entity-eight_atomic_gesture",
      "Predicate-includes",
      "Entity-a_movement"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-added",
      "Entity-hdgi__handgesture"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-added",
      "Entity-hdgi__forearmgesture"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-added",
      "Entity-hdgi__facialgesture"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-added",
      "Entity-hdgi__leggesture"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-added",
      "Entity-hdgi__upperarmgesture"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-includes",
      "Entity-hdgi__handgesture"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-includes",
      "Entity-hdgi__forearmgesture"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-includes",
      "Entity-hdgi__facialgesture"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-includes",
      "Entity-hdgi__leggesture"
    ],
    [
      "Entity-gesture_subclass",
      "Predicate-includes",
      "Entity-hdgi__upperarmgesture"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "Predicate-are_modeled_in_detail_in",
      "Entity-hdgi"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "Predicate-modeled_in_detail",
      "Entity-hdgi"
    ],
    [
      "Entity-hdgi",
      "Predicate-models",
      "Entity-hand__forearm__and_upper_arm_gesture"
    ],
    [
      "Entity-foundational_model_of_anatomy__fma_",
      "Predicate-reuses_and_extends",
      "Entity-concept"
    ],
    [
      "Entity-foundational_model_of_anatomy__fma_",
      "Predicate-reuses_and_extends",
      "Entity-class"
    ],
    [
      "Entity-foundational_model_of_anatomy__fma_",
      "Predicate-models",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__bodypart_class",
      "Predicate-allows_representation_of",
      "Entity-further_body_part"
    ],
    [
      "Entity-further_body_part",
      "Predicate-describes",
      "Entity-new_pose"
    ],
    [
      "Entity-upper_limb_region",
      "Predicate-focuses_on",
      "Entity-human_s_upper_limb_region"
    ],
    [
      "Entity-fma",
      "Predicate-describes",
      "Entity-biological_concept"
    ],
    [
      "Entity-relevant_class",
      "Predicate-are_modeled_for",
      "Entity-hdi"
    ],
    [
      "Entity-hdgi__upperarm",
      "Predicate-is_a_building_block_of",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-hdgi__forearm",
      "Predicate-is_a_building_block_of",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-hdgi__palm",
      "Predicate-is_a_building_block_of",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-hdgi__finger",
      "Predicate-is_a_building_block_of",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-fma_class_definition",
      "Predicate-are_preserved_with",
      "Entity-fma_class_definition"
    ],
    [
      "Entity-hdgi__upperarm_class",
      "Predicate-is_an_equivalent_class_to",
      "Entity-arm_class"
    ],
    [
      "Entity-hdgi__upperarm",
      "Predicate-is_an_equivalent_class_to",
      "Entity-arm"
    ],
    [
      "Entity-arm_class",
      "Predicate-is_equivalent_to",
      "Entity-hdgi__upperarm_class"
    ],
    [
      "Entity-hdgi__upperarm",
      "Predicate-is_an_equivalent_class_to",
      "Entity-arm_class"
    ],
    [
      "Entity-hdgi__finger_class",
      "Predicate-is_divided_to_represent",
      "Entity-hdgi__thumb"
    ],
    [
      "Entity-hdgi__finger_class",
      "Predicate-is_divided_to_represent",
      "Entity-hdgi__indexfinger"
    ],
    [
      "Entity-hdgi__finger_class",
      "Predicate-is_divided_to_represent",
      "Entity-hdgi__middlefinger"
    ],
    [
      "Entity-hdgi__finger_class",
      "Predicate-is_divided_to_represent",
      "Entity-hdgi__ringfinger"
    ],
    [
      "Entity-hdgi__finger_class",
      "Predicate-is_divided_to_represent",
      "Entity-hdgi__littlefinger"
    ],
    [
      "Entity-hdgi__thumb",
      "Predicate-mapped_to",
      "Entity-region_of_hand_"
    ],
    [
      "Entity-hdgi__indexfinger",
      "Predicate-mapped_to",
      "Entity-region_of_hand_"
    ],
    [
      "Entity-hdgi__middlefinger",
      "Predicate-mapped_to",
      "Entity-region_of_hand_"
    ],
    [
      "Entity-hdgi__ringfinger",
      "Predicate-mapped_to",
      "Entity-region_of_hand_"
    ],
    [
      "Entity-hdgi__littlefinger",
      "Predicate-mapped_to",
      "Entity-region_of_hand_"
    ],
    [
      "Entity-hdgi__finger",
      "Predicate-mapped_to",
      "Entity-region_of_hand_"
    ],
    [
      "Entity-these_finger",
      "Predicate-are_divided_into",
      "Entity-left_and_right_entity"
    ],
    [
      "Entity-these_finger",
      "Predicate-are_further_divided_into",
      "Entity-left_and_right_entity"
    ],
    [
      "Entity-figure_3",
      "Predicate-depicts",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-upper_limb_region",
      "Predicate-includes",
      "Entity-eight_section_of_upper_limb_region"
    ],
    [
      "Entity-upper_limb_region",
      "Predicate-defined_as",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-hdgi__bodypart_class",
      "Predicate-is_defined_in",
      "Entity-foundational_model_of_anatomy__fma_"
    ],
    [
      "Entity-each_body_part",
      "Predicate-can_be_involved_in",
      "Entity-a_pose"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-hdgiinvolves",
      "Entity-hdgi__bodypart"
    ],
    [
      "Entity-a_pose",
      "Predicate-must_hdgiinvolves",
      "Entity-hdgi__bodypart"
    ],
    [
      "Entity-each_body_part",
      "Predicate-has",
      "Entity-potential_pose"
    ],
    [
      "Entity-body_part",
      "Predicate-corresponds_to",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__pose_class",
      "Predicate-describes",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__pose_class",
      "Predicate-models",
      "Entity-position"
    ],
    [
      "Entity-hdgi__pose_class",
      "Predicate-models",
      "Entity-rotation_"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-placed_in",
      "Entity-3d_space"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "Predicate-hasPosition",
      "Entity-xposition"
    ],
    [
      "Entity-this_ontology",
      "Predicate-considers",
      "Entity-relative_position"
    ],
    [
      "Entity-upper_arm_position",
      "Predicate-are_relative_to",
      "Entity-shoulder_joint"
    ],
    [
      "Entity-figure_3_-_point_a",
      "Predicate-refers_to",
      "Entity-upper_arm_position"
    ],
    [
      "Entity-hdgi__forearmpose",
      "Predicate-are_relative_to",
      "Entity-elbow_joint"
    ],
    [
      "Entity-figure_3_-_point_b",
      "Predicate-is_referenced_in",
      "Entity-figure_3"
    ],
    [
      "Entity-palm_and_finger_position",
      "Predicate-are_always_relative_to",
      "Entity-wrist"
    ],
    [
      "Entity-hdgi__position_class",
      "Predicate-describes",
      "Entity-local_coordinate_system"
    ],
    [
      "Entity-xposition",
      "Predicate-is_based_on",
      "Entity-local_coordinate_system"
    ],
    [
      "Entity-hdgi__yposition",
      "Predicate-is_based_on",
      "Entity-local_coordinate_system"
    ],
    [
      "Entity-zposition",
      "Predicate-is_based_on",
      "Entity-local_coordinate_system"
    ],
    [
      "Entity-zposition_value",
      "Predicate-are_based_on",
      "Entity-local_coordinate_system"
    ],
    [
      "Entity-hdgi__position",
      "Predicate-has",
      "Entity-hdgi__localcoordinatesystem"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "Predicate-has_range",
      "Entity-hdgi__localcoordinatesystem"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "Predicate-used_for",
      "Entity-hdgi__position"
    ],
    [
      "Entity-hdgi__position",
      "Predicate-hasLocalCoordinateSystem",
      "Entity-hdgi__localcoordinatesystem"
    ],
    [
      "Entity-different_sdks-systems",
      "Predicate-is_using",
      "Entity-different_coordinate_system"
    ],
    [
      "Entity-different_sdks-systems",
      "Predicate-is_using",
      "Entity-coordinate_system"
    ],
    [
      "Entity-unity3d11",
      "Predicate-is_using",
      "Entity-left-hand_rule_coordinate_system"
    ],
    [
      "Entity-z-axis",
      "Predicate-points_outwards_from",
      "Entity-user"
    ],
    [
      "Entity-leap-motion_sdk",
      "Predicate-use",
      "Entity-a_right-hand_rule"
    ],
    [
      "Entity-z-axis",
      "Predicate-is_pointed_inwards",
      "Entity-the_z-axis"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "Predicate-models",
      "Entity-hdgi__position"
    ],
    [
      "Entity-hdgi__localcoordinatesystem_class",
      "Predicate-models",
      "Entity-hdgi__position_class"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "Predicate-relationship_with",
      "Entity-hdgi__position"
    ],
    [
      "Entity-yaw",
      "Predicate-describes_the_rotation_of",
      "Entity-3d_rigid_body"
    ],
    [
      "Entity-pitch",
      "Predicate-describes_the_rotation_of",
      "Entity-3d_rigid_body"
    ],
    [
      "Entity-roll",
      "Predicate-describes_the_rotation_of",
      "Entity-3d_rigid_body"
    ],
    [
      "Entity-quaternion",
      "Predicate-used_by_some_systems",
      "Entity-3d_rigid_body"
    ],
    [
      "Entity-our_model",
      "Predicate-keeps",
      "Entity-support_for_both_of_these_representation"
    ],
    [
      "Entity-our_model",
      "Predicate-is_able_to_model",
      "Entity-data_received_from_different_manufacturers-devices"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-represent",
      "Entity-static_gesture"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-can_contain",
      "Entity-one_or_more_pose_(1)"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-is_similar_to",
      "Entity-hdgi__gesture_class"
    ],
    [
      "Entity-a_hdgi__pose",
      "Predicate-involves",
      "Entity-single_body_part"
    ],
    [
      "Entity-individual_body_part",
      "Predicate-can_be_modeled_separately",
      "Entity-individual_body_part"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-involves",
      "Entity-single_body_part"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-has",
      "Entity-time_stamp"
    ],
    [
      "Entity-several_possible_pose",
      "Predicate-added_as_subclasses",
      "Entity-hdgi__legpose"
    ],
    [
      "Entity-several_possible_pose",
      "Predicate-added_as_subclasses",
      "Entity-hdgi__footpose"
    ],
    [
      "Entity-hdgi__upperarm",
      "Predicate-models",
      "Entity-hdgi__upperarm"
    ],
    [
      "Entity-hdgi__forearm",
      "Predicate-models",
      "Entity-hdgi__forearm"
    ],
    [
      "Entity-hdgi__palm",
      "Predicate-models",
      "Entity-hdgi__palm"
    ],
    [
      "Entity-hdgi__finger",
      "Predicate-models",
      "Entity-each_individual_hdgi__finger_pose"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-added_as_subclasses",
      "Entity-hdgi__legpose"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-added_as_subclasses",
      "Entity-hdgi__footpose"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-models",
      "Entity-hdgi__upperarm"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-models",
      "Entity-hdgi__forearm"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-models",
      "Entity-hdgi__palm"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-models",
      "Entity-hdgi__finger"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-models",
      "Entity-each_individual_hdgi__finger_pose"
    ],
    [
      "Entity-listing_1.2",
      "Predicate-provides",
      "Entity-an_example_of_a_pose_modeling"
    ],
    [
      "Entity-pose_modeling",
      "Predicate-is_related_to",
      "Entity-gesture_right_hand_swipe_left_"
    ],
    [
      "Entity-example_model",
      "Predicate-models",
      "Entity-the_start_pose"
    ],
    [
      "Entity-example_model",
      "Predicate-models",
      "Entity-end_pose"
    ],
    [
      "Entity-the_start_pose",
      "Predicate-of",
      "Entity-right_forearm"
    ],
    [
      "Entity-end_pose",
      "Predicate-of",
      "Entity-the_right_palm"
    ],
    [
      "Entity-right_forearm",
      "Predicate-is_modeled_as",
      "Entity-the_start_pose"
    ],
    [
      "Entity-the_right_palm",
      "Predicate-is_modeled_as_(1)",
      "Entity-end_pose"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-used",
      "Entity-hdgi__bodypart"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-has",
      "Entity-hdgi__timestamp"
    ],
    [
      "Entity-hdgi__timestamp",
      "Predicate-has_a_maximum_of",
      "Entity-hdgi__position"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-has",
      "Entity-hdgi__rotation"
    ],
    [
      "Entity-hdgi__rotation",
      "Predicate-could_be_modeled_using",
      "Entity-euler_angle"
    ],
    [
      "Entity-hdgi__rotation",
      "Predicate-could_be_modeled_using",
      "Entity-hdgi__quaternion"
    ],
    [
      "Entity-hdgi__xrotation",
      "Predicate-is_a_type_of",
      "Entity-euler_angle"
    ],
    [
      "Entity-hdgi__yrotation",
      "Predicate-is_a_type_of",
      "Entity-euler_angle"
    ],
    [
      "Entity-hdgi__zrotation",
      "Predicate-is_a_type_of",
      "Entity-euler_angle"
    ],
    [
      "Entity-hdgi__rotation",
      "Predicate-could_be_modeled_using",
      "Entity-quaternion"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-used_only",
      "Entity-hdgi__bodypart"
    ],
    [
      "Entity-hdgi__pose",
      "Predicate-has_exactly_one",
      "Entity-hdgi__timestamp"
    ],
    [
      "Entity-listing_1.3",
      "Predicate-explains",
      "Entity-hdgi__position"
    ],
    [
      "Entity-listing_1.3",
      "Predicate-explains",
      "Entity-haslocalcoordinatesystem"
    ],
    [
      "Entity-hdgi__position",
      "Predicate-has",
      "Entity-xposition"
    ],
    [
      "Entity-hdgi__position",
      "Predicate-has",
      "Entity-hdgi__yposition"
    ],
    [
      "Entity-hdgi__position",
      "Predicate-has",
      "Entity-zposition"
    ],
    [
      "Entity-hdgi__position",
      "Predicate-has_a_maximum_of_one",
      "Entity-xposition"
    ],
    [
      "Entity-hdgi__position",
      "Predicate-has_a_maximum_of_one",
      "Entity-hdgi__yposition"
    ],
    [
      "Entity-hdgi__position",
      "Predicate-has_a_maximum_of_one",
      "Entity-zposition"
    ],
    [
      "Entity-hdgi__position",
      "Predicate-has_exactly_one",
      "Entity-hdgi__localcoordinatesystem"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "Predicate-has",
      "Entity-axis_direction"
    ],
    [
      "Entity-hdgi__xaxisdirection",
      "Predicate-is_either",
      "Entity-leftward_"
    ],
    [
      "Entity-hdgi__xaxisdirection",
      "Predicate-is_either",
      "Entity-rightward_"
    ],
    [
      "Entity-hdgi__yaxisdirection",
      "Predicate-is_either",
      "Entity-upward_"
    ],
    [
      "Entity-hdgi__yaxisdirection",
      "Predicate-is_either",
      "Entity-downward_"
    ],
    [
      "Entity-hdgi__zaxisdirection",
      "Predicate-is_either",
      "Entity-outward_"
    ],
    [
      "Entity-hdgi__zaxisdirection",
      "Predicate-is_either",
      "Entity-inward_"
    ],
    [
      "Entity-an_example_of_a_pose_modeling",
      "Predicate-models",
      "Entity-the_start_pose"
    ],
    [
      "Entity-an_example_of_a_pose_modeling",
      "Predicate-models",
      "Entity-end_pose"
    ],
    [
      "Entity-hdgi__movement_class",
      "Predicate-relates_to",
      "Entity-dynamic_gesture"
    ],
    [
      "Entity-hdgi__movement_class",
      "Predicate-has_no_relationship_to",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__movement",
      "Predicate-consists_of",
      "Entity-a_predefined_set_of_movement"
    ],
    [
      "Entity-a_predefined_set_of_movement",
      "Predicate-describes",
      "Entity-hdgi__upperarm"
    ],
    [
      "Entity-a_predefined_set_of_movement",
      "Predicate-describes",
      "Entity-hdgi__forearm"
    ],
    [
      "Entity-a_predefined_set_of_movement",
      "Predicate-describes",
      "Entity-hdgi__palm"
    ],
    [
      "Entity-a_predefined_set_of_movement",
      "Predicate-describes",
      "Entity-hdgi__finger"
    ],
    [
      "Entity-designer_and_developer",
      "Predicate-includes",
      "Entity-new_movement"
    ],
    [
      "Entity-each_hdgi__movement",
      "Predicate-is_related_to",
      "Entity-position_change"
    ],
    [
      "Entity-each_hdgi__movement",
      "Predicate-is_related_to",
      "Entity-rotation_change"
    ],
    [
      "Entity-each_hdgi__movement",
      "Predicate-must_have",
      "Entity-hdgi__duration"
    ],
    [
      "Entity-hdgi__timestamp",
      "Predicate-derived_from",
      "Entity-start_hdgi__pose"
    ],
    [
      "Entity-hdgi__timestamp",
      "Predicate-derived_from",
      "Entity-end_hdgi__pose"
    ],
    [
      "Entity-hdgi__timestamp",
      "Predicate-is_between",
      "Entity-start_hdgi__pose"
    ],
    [
      "Entity-hdgi__timestamp",
      "Predicate-is_between",
      "Entity-end_hdgi__pose"
    ],
    [
      "Entity-hdgi__duration",
      "Predicate-can_be_derived_from",
      "Entity-hdgi__timestamp"
    ],
    [
      "Entity-the_term_affordance",
      "Predicate-refers_to",
      "Entity-the_perceived_and_actual_property_of_the_thing"
    ],
    [
      "Entity-this_view",
      "Predicate-has_become_standard_in",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-this_view",
      "Predicate-has_become_standard_in",
      "Entity-design"
    ],
    [
      "Entity-maier_et_al_.",
      "Predicate-define_(1)",
      "Entity-affordance"
    ],
    [
      "Entity-affordance",
      "Predicate-to_be_potential_uses_of",
      "Entity-device"
    ],
    [
      "Entity-the_human",
      "Predicate-is_able_to_do_something_using",
      "Entity-the_device"
    ],
    [
      "Entity-device",
      "Predicate-might_allow",
      "Entity-human_behavior"
    ],
    [
      "Entity-device",
      "Predicate-might_allow",
      "Entity-potential_human_behavior"
    ],
    [
      "Entity-brown_et_al_.",
      "Predicate-conclude_that",
      "Entity-affordance"
    ],
    [
      "Entity-affordance",
      "Predicate-are",
      "Entity-context_dependent_action_or_manipulation_possibility"
    ],
    [
      "Entity-context_dependent_action_or_manipulation_possibility",
      "Predicate-from_the_point_of_view_of",
      "Entity-a_particular_actor"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-requires_modeling_of",
      "Entity-hdgi__affordance"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-requires_modeling_of",
      "Entity-hdgi__context"
    ],
    [
      "Entity-hdgi__context",
      "Predicate-includes",
      "Entity-hdgi__usercontext"
    ],
    [
      "Entity-hdgi__context",
      "Predicate-includes",
      "Entity-hdgi__devicecontext"
    ],
    [
      "Entity-user_s_choice_of_gesture",
      "Predicate-is_based_on",
      "Entity-context"
    ],
    [
      "Entity-system",
      "Predicate-understands",
      "Entity-user_specific_gesture_semantics"
    ],
    [
      "Entity-a_user_(1)",
      "Predicate-communicates",
      "Entity-affordance"
    ],
    [
      "Entity-the_gesture",
      "Predicate-supported_by",
      "Entity-a_device"
    ],
    [
      "Entity-user",
      "Predicate-communicates",
      "Entity-device"
    ],
    [
      "Entity-gesture",
      "Predicate-supported_by",
      "Entity-device"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "Predicate-integrates",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-gesture_recognition_system",
      "Predicate-cater_for",
      "Entity-user_need"
    ],
    [
      "Entity-gesture_recognition_system",
      "Predicate-increases",
      "Entity-user_experience__ux_"
    ],
    [
      "Entity-device_a",
      "Predicate-has",
      "Entity-affordance_x"
    ],
    [
      "Entity-device_b",
      "Predicate-has",
      "Entity-affordance_y"
    ],
    [
      "Entity-device_b",
      "Predicate-communicates",
      "Entity-device_a"
    ],
    [
      "Entity-device_b",
      "Predicate-detects",
      "Entity-user_intent"
    ],
    [
      "Entity-device_b",
      "Predicate-communicates",
      "Entity-user_intent"
    ],
    [
      "Entity-device_b",
      "Predicate-interacts_with",
      "Entity-affordance_x"
    ],
    [
      "Entity-device_a",
      "Predicate-receives",
      "Entity-user_intent"
    ],
    [
      "Entity-device_b",
      "Predicate-would_be_able_to_understand",
      "Entity-user_intent"
    ],
    [
      "Entity-user_intent",
      "Predicate-is_to_interact_with",
      "Entity-affordance_x"
    ],
    [
      "Entity-device_b",
      "Predicate-understands_(1)",
      "Entity-user_intent"
    ],
    [
      "Entity-the_term_affordance",
      "Predicate-should_be_mapped_to",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-the_term_affordance",
      "Predicate-should_be_mapped_to",
      "Entity-gesture"
    ],
    [
      "Entity-the_term_affordance",
      "Predicate-rather_than",
      "Entity-a_device"
    ],
    [
      "Entity-hdgi__affordance",
      "Predicate-supports",
      "Entity-hdgi__gesture"
    ],
    [
      "Entity-the_term_affordance",
      "Predicate-can_have",
      "Entity-supported_gesture"
    ],
    [
      "Entity-hdgi__device",
      "Predicate-hosts",
      "Entity-affordance"
    ],
    [
      "Entity-affordance",
      "Predicate-can_be_hosted_by",
      "Entity-device"
    ],
    [
      "Entity-hdgi__affordance",
      "Predicate-afforded_by",
      "Entity-hdgi__device"
    ],
    [
      "Entity-hdgi__device",
      "Predicate-has_cardinality_of",
      "Entity-many_to_many"
    ],
    [
      "Entity-hdgi__device",
      "Predicate-is_a_sub_class_of",
      "Entity-sosa__platform"
    ],
    [
      "Entity-sosa",
      "Predicate-is_the_core_of",
      "Entity-semantic_sensor_network__ssn_"
    ],
    [
      "Entity-sosa",
      "Predicate-is_a_lightweight_but_self-contained_core_ontology_which_itself_is_the_core_of",
      "Entity-semantic_sensor_network"
    ],
    [
      "Entity-sensor__observation__sample__and_actuator",
      "Predicate-is_part_of",
      "Entity-sosa"
    ],
    [
      "Entity-sosa",
      "Predicate-is_the_core_of",
      "Entity-semantic_sensor_network"
    ],
    [
      "Entity-ssn_ontology",
      "Predicate-describes",
      "Entity-sensor"
    ],
    [
      "Entity-ssn_ontology",
      "Predicate-describes",
      "Entity-observation"
    ],
    [
      "Entity-ssn_ontology",
      "Predicate-describes",
      "Entity-procedure"
    ],
    [
      "Entity-ssn_ontology",
      "Predicate-describes",
      "Entity-feature_of_interest"
    ],
    [
      "Entity-ssn_ontology",
      "Predicate-describes",
      "Entity-sample"
    ],
    [
      "Entity-ssn_ontology",
      "Predicate-describes",
      "Entity-observed_property"
    ],
    [
      "Entity-ssn_ontology",
      "Predicate-describes",
      "Entity-actuator"
    ],
    [
      "Entity-sosa__sensor",
      "Predicate-is_a_sub_class_of",
      "Entity-sosa__actuatableproperty"
    ],
    [
      "Entity-sosa__actuator",
      "Predicate-is_a_sub_class_of",
      "Entity-sosa__actuatableproperty"
    ],
    [
      "Entity-hdgi__actuatableaffordance",
      "Predicate-is_a_sub_class_of",
      "Entity-sosa__actuatableproperty"
    ],
    [
      "Entity-hdgi__observableaffordance",
      "Predicate-is_a_sub_class_of",
      "Entity-sosa__observableproperty"
    ],
    [
      "Entity-hdgi__device",
      "Predicate-models_the_relationship_between",
      "Entity-hdgi__devicemanufacturer"
    ],
    [
      "Entity-hdgi__device",
      "Predicate-hdgimanufacturedBy",
      "Entity-hdgi__devicemanufacturer"
    ],
    [
      "Entity-hdgi__device",
      "Predicate-manufactured_by",
      "Entity-devicemanufacturer"
    ],
    [
      "Entity-device",
      "Predicate-has",
      "Entity-one_manufacturer"
    ],
    [
      "Entity-listing_1.4",
      "Predicate-provides",
      "Entity-hdgi__affordance"
    ],
    [
      "Entity-listing_1.4",
      "Predicate-provides",
      "Entity-hdgi__device"
    ],
    [
      "Entity-listing_1.4",
      "Predicate-provides",
      "Entity-hdgi__context"
    ],
    [
      "Entity-this_ontology",
      "Predicate-is_one_of_the_major_contributions_in",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_ontology",
      "Predicate-helps",
      "Entity-system"
    ],
    [
      "Entity-system",
      "Predicate-identify",
      "Entity-the_semantics_of_these_gesture"
    ],
    [
      "Entity-system",
      "Predicate-to_perform",
      "Entity-affordance_mapping"
    ],
    [
      "Entity-affordance_mapping",
      "Predicate-is_through",
      "Entity-interconnected_knowledge_base"
    ],
    [
      "Entity-interconnected_knowledge_base",
      "Predicate-is_instead_of",
      "Entity-predefined_one_to_one_mapping"
    ],
    [
      "Entity-this_ontology",
      "Predicate-is",
      "Entity-one_of_the_major_contribution_in_this_ontology"
    ],
    [
      "Entity-affordance_mapping",
      "Predicate-is_done_through",
      "Entity-interconnected_knowledge_base"
    ],
    [
      "Entity-gesture_recognition_system",
      "Predicate-allows",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-gesture_recognition_system",
      "Predicate-run",
      "Entity-detection"
    ],
    [
      "Entity-gesture_recognition_system",
      "Predicate-run",
      "Entity-mapping"
    ],
    [
      "Entity-gesture_recognition_system",
      "Predicate-run",
      "Entity-communication"
    ],
    [
      "Entity-gesture_recognition_system",
      "Predicate-run_in",
      "Entity-independent_layer"
    ],
    [
      "Entity-gesture_recognition_system",
      "Predicate-run",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-ontology_building_and_annotating",
      "Predicate-is_part_of",
      "Entity-ontology_engineering"
    ],
    [
      "Entity-integration_and_documentation",
      "Predicate-is_part_of",
      "Entity-ontology_engineering"
    ],
    [
      "Entity-ontology_building",
      "Predicate-is_part_of",
      "Entity-ontology_engineering"
    ],
    [
      "Entity-annotating",
      "Predicate-is_part_of",
      "Entity-ontology_engineering"
    ],
    [
      "Entity-integration",
      "Predicate-is_part_of",
      "Entity-ontology_engineering"
    ],
    [
      "Entity-documentation",
      "Predicate-is_part_of",
      "Entity-ontology_engineering"
    ],
    [
      "Entity-figure_4",
      "Predicate-illustrate",
      "Entity-proof-of-concept_implementation"
    ],
    [
      "Entity-figure_4",
      "Predicate-illustrate",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-illustrates",
      "Entity-proof-of-concept_implementation"
    ],
    [
      "Entity-a_set_of_predefined_sparql_endpoint",
      "Predicate-wrapped_with",
      "Entity-restful_apis"
    ],
    [
      "Entity-restful_apis",
      "Predicate-make_easier_and_faster_the_integration_with",
      "Entity-third_party_software_development_kit_and_service"
    ],
    [
      "Entity-sparql_endpoint",
      "Predicate-wrapped_with",
      "Entity-restful_apis"
    ],
    [
      "Entity-integration",
      "Predicate-makes_easier",
      "Entity-third_party_software_development_kit_and_service"
    ],
    [
      "Entity-designer",
      "Predicate-can_refer_to",
      "Entity-hdgi-gesture_repository"
    ],
    [
      "Entity-device_manufacturer",
      "Predicate-can_refer_to",
      "Entity-hdgi-gesture_repository"
    ],
    [
      "Entity-developer",
      "Predicate-can_refer_to",
      "Entity-hdgi-gesture_repository"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "Predicate-to_find",
      "Entity-currently_available_and_contemporary_gesture"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "Predicate-to_find",
      "Entity-relevant_mapping_to_device_affordances"
    ],
    [
      "Entity-hdgi-mapping_service",
      "Predicate-is_a_type_of",
      "Entity-api-driven_restful_web_service"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "Predicate-contains",
      "Entity-currently_available_and_contemporary_gesture"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "Predicate-contains",
      "Entity-relevant_mapping_to_device_affordances"
    ],
    [
      "Entity-apis",
      "Predicate-allow",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-apis",
      "Predicate-maps",
      "Entity-gesture_repository"
    ],
    [
      "Entity-apis",
      "Predicate-upload",
      "Entity-gesture_repository"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-will_be_accessible_to",
      "Entity-the_research_community"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-will_be_accessible_to",
      "Entity-research_community"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-are_available_to",
      "Entity-the_research_community"
    ],
    [
      "Entity-redundant_gesture_vocabulary",
      "Predicate-help_to_reduce",
      "Entity-ubiquitousness"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-help_to_reduce",
      "Entity-ubiquitousness"
    ],
    [
      "Entity-existing_one",
      "Predicate-increase_the_reuse_of",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-will_help_to_reduce",
      "Entity-redundant_gesture_vocabulary"
    ],
    [
      "Entity-our_study",
      "Predicate-looked_at",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-our_study",
      "Predicate-mapped_into",
      "Entity-this_ontology"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-in",
      "Entity-the_current_literature"
    ],
    [
      "Entity-our_study",
      "Predicate-looked_at",
      "Entity-the_current_literature"
    ],
    [
      "Entity-hdgi-service_endpoint",
      "Predicate-query_about",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-hdgi-service",
      "Predicate-allows_using",
      "Entity-hdgi-service_endpoint"
    ],
    [
      "Entity-opensource_project",
      "Predicate-is_made_under",
      "Entity-apache_2.0"
    ],
    [
      "Entity-service",
      "Predicate-deployed_in",
      "Entity-private_cloud"
    ],
    [
      "Entity-this_service",
      "Predicate-deployed_in",
      "Entity-their_own_private_cloud"
    ],
    [
      "Entity-this_service",
      "Predicate-can_be_deployed_in",
      "Entity-their_own_private_cloud"
    ],
    [
      "Entity-this_service",
      "Predicate-allows_using",
      "Entity-hdgi-service_endpoint"
    ],
    [
      "Entity-sample_mapping_service",
      "Predicate-continues_the_integration_with",
      "Entity-gesture_recognition_software_tool"
    ],
    [
      "Entity-sample_mapping_service",
      "Predicate-is_a_type_of",
      "Entity-the_web_application"
    ],
    [
      "Entity-java_version_1.9_or_higher",
      "Predicate-is_a_prerequisite_to_run",
      "Entity-the_web_application_(1)"
    ],
    [
      "Entity-apache_tomcat",
      "Predicate-is_a_prerequisite_to_run",
      "Entity-the_web_application_(1)"
    ],
    [
      "Entity-the_web_application_(1)",
      "Predicate-requires",
      "Entity-java_version_1.9_or_higher"
    ],
    [
      "Entity-the_web_application_(1)",
      "Predicate-requires",
      "Entity-apache_tomcat"
    ],
    [
      "Entity-a_how-to__documentation",
      "Predicate-is_provided",
      "Entity-how-to__documentation"
    ],
    [
      "Entity-api_and_architecture_documentation",
      "Predicate-helps",
      "Entity-web_application"
    ],
    [
      "Entity-api_and_architecture_documentation",
      "Predicate-helps",
      "Entity-customized_sparql_endpoint"
    ],
    [
      "Entity-api_and_architecture_documentation",
      "Predicate-helps",
      "Entity-restful_endpoint"
    ],
    [
      "Entity-web_application",
      "Predicate-run_as",
      "Entity-private_service"
    ],
    [
      "Entity-customized_sparql_endpoint",
      "Predicate-can_be_made",
      "Entity-the_web_application"
    ],
    [
      "Entity-complete_api_documentation",
      "Predicate-can_be_found",
      "Entity-api_documentation"
    ],
    [
      "Entity-swagger_ui",
      "Predicate-integrating_to",
      "Entity-hdgi_web_app"
    ],
    [
      "Entity-swagger_codegen",
      "Predicate-integrating_to",
      "Entity-hdgi_web_app"
    ],
    [
      "Entity-swagger_codegen_capability",
      "Predicate-integrating_to",
      "Entity-hdgi_web_app"
    ],
    [
      "Entity-api_documentation",
      "Predicate-can_be_found",
      "Entity-complete_api_documentation"
    ],
    [
      "Entity-swagger_ui",
      "Predicate-is_being_integrated_with",
      "Entity-hdgi_web_app"
    ],
    [
      "Entity-swagger_codegen",
      "Predicate-is_being_integrated_with",
      "Entity-hdgi_web_app"
    ],
    [
      "Entity-user",
      "Predicate-get",
      "Entity-a_comprehensive_view_of_the_api"
    ],
    [
      "Entity-user",
      "Predicate-understands",
      "Entity-endpoint_structure"
    ],
    [
      "Entity-user",
      "Predicate-try",
      "Entity-it"
    ],
    [
      "Entity-user",
      "Predicate-can_get",
      "Entity-a_comprehensive_view_of_the_api"
    ],
    [
      "Entity-api_client_stub",
      "Predicate-make_the_integration_of",
      "Entity-gesture_recognition_softwareservices"
    ],
    [
      "Entity-api_client_stub",
      "Predicate-are_for",
      "Entity-gesture_recognition_softwareservices"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-presents",
      "Entity-human_device_gesture_interaction__hdgi_"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-describes",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "Predicate-maps_with",
      "Entity-corresponding_affordances"
    ],
    [
      "Entity-an_initial_step",
      "Predicate-towards_building",
      "Entity-human_device_gesture_interaction_knowledge_base"
    ],
    [
      "Entity-human_device_gesture_interaction_knowledge_base",
      "Predicate-has_purpose_of_bringing",
      "Entity-better_user_experience"
    ],
    [
      "Entity-knowledge_base",
      "Predicate-is_built_towards",
      "Entity-better_user_experience"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-can_assist",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-can_assist",
      "Entity-designer"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-can_assist",
      "Entity-manufacturer"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-can_assist",
      "Entity-developer"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-can_assist",
      "Entity-automated_reasoning_task"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "Predicate-are_based_on",
      "Entity-gesture"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "Predicate-are_based_on",
      "Entity-device_affordances"
    ],
    [
      "Entity-this_ontology",
      "Predicate-can_assist",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-this_ontology",
      "Predicate-can_assist",
      "Entity-designer"
    ],
    [
      "Entity-this_ontology",
      "Predicate-can_assist",
      "Entity-manufacturer"
    ],
    [
      "Entity-this_ontology",
      "Predicate-can_assist",
      "Entity-developer"
    ],
    [
      "Entity-this_ontology",
      "Predicate-allows",
      "Entity-device"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-helps_to_express",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-helps_to_carry_out",
      "Entity-automated_reasoning_task"
    ],
    [
      "Entity-ontology",
      "Predicate-developing",
      "Entity-element_observed_from_existing_gesture_vocabulary"
    ],
    [
      "Entity-element_observed_from_existing_gesture_vocabulary",
      "Predicate-extracted_from",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-gesture_vocabulary",
      "Predicate-is_defined_in",
      "Entity-previous_study"
    ],
    [
      "Entity-hdgi-mapping_service",
      "Predicate-can_be_integrated_with",
      "Entity-existing_gesture_recognition_system"
    ],
    [
      "Entity-hdgi-mapping_service",
      "Predicate-is_a_type_of",
      "Entity-web_service_interface"
    ],
    [
      "Entity-hdgi-mapping_service",
      "Predicate-integrated_with",
      "Entity-existing_gesture_recognition_system"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-describes",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-maps",
      "Entity-relationship_between_gesture_and_device_affordances"
    ],
    [
      "Entity-manufacturer__developer__and_designer",
      "Predicate-identify",
      "Entity-commonly_used_gesture_for_certain_affordances"
    ],
    [
      "Entity-manufacturer__developer__and_designer",
      "Predicate-introduce",
      "Entity-new_gesture"
    ],
    [
      "Entity-designer",
      "Predicate-identify",
      "Entity-commonly_used_gesture_for_certain_affordances"
    ],
    [
      "Entity-this_ontology",
      "Predicate-can_be_extended_by_incorporating",
      "Entity-gesture_type"
    ],
    [
      "Entity-gesture_type",
      "Predicate-includes",
      "Entity-facial_gesture"
    ],
    [
      "Entity-gesture_type",
      "Predicate-includes",
      "Entity-head_gesture"
    ],
    [
      "Entity-possible_extension",
      "Predicate-can_be_made",
      "Entity-this_ontology"
    ],
    [
      "Entity-gesture_type",
      "Predicate-incorporating",
      "Entity-facial_gesture"
    ],
    [
      "Entity-gesture_type",
      "Predicate-incorporating",
      "Entity-head_gesture"
    ],
    [
      "Entity-hdgi_restful_service",
      "Predicate-release_and_deploy_in",
      "Entity-the_cloud"
    ],
    [
      "Entity-api_client",
      "Predicate-release_to",
      "Entity-leading_hand-gesture_supported_system"
    ],
    [
      "Entity-leading_hand-gesture_supported_system",
      "Predicate-includes",
      "Entity-microsoft_hololens"
    ],
    [
      "Entity-leading_hand-gesture_supported_system",
      "Predicate-includes",
      "Entity-microsoft_kinect"
    ],
    [
      "Entity-leading_hand-gesture_supported_system",
      "Predicate-includes",
      "Entity-solo"
    ],
    [
      "Entity-api_client",
      "Predicate-to_leading_hand-gesture_supported_systems",
      "Entity-microsoft_hololens"
    ],
    [
      "Entity-api_client",
      "Predicate-to_leading_hand-gesture_supported_systems",
      "Entity-microsoft_kinect"
    ],
    [
      "Entity-api_client",
      "Predicate-to_leading_hand-gesture_supported_systems",
      "Entity-solo"
    ],
    [
      "Entity-gesture_elicitation_study",
      "Predicate-conduct_using",
      "Entity-microsoft_hololens"
    ],
    [
      "Entity-gesture_interaction_in_mixed_reality",
      "Predicate-maps_to",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-gesture_elicitation_study",
      "Predicate-maps",
      "Entity-gesture_interaction_in_mixed_reality"
    ],
    [
      "Entity-gesture_interaction_in_mixed_reality",
      "Predicate-maps_to",
      "Entity-this_ontology"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-describes_and_maps",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-describes_and_maps",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-this_ontology",
      "Predicate-describes",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents_a_systematic_analysis_and_ontology_for_formally_describing",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-hdgi",
      "Predicate-describes",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-describes_and_maps",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "Predicate-maps",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_formally_represented_by",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "Predicate-maps",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-describes",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-our_approach",
      "Predicate-describes",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "Predicate-hdgiincludesGesture",
      "Entity-hdgi__human"
    ],
    [
      "Entity-our_ontology",
      "Predicate-describes",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "Predicate-maps",
      "Entity-this_mapping"
    ],
    [
      "Entity-this_ontology",
      "Predicate-is_represented_by",
      "Entity-human_device_gesture_interaction__hdgi_"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-human_device_gesture_interaction__hdgi_"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-is_represented_by",
      "Entity-the_presented_ontology"
    ],
    [
      "Entity-our_approach",
      "Predicate-is_designed_to_facilitate",
      "Entity-human_device_gesture_interaction__hdgi_"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-is_a_specific_implementation_of",
      "Entity-our_ontology"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-facilitates",
      "Entity-this_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-is_a_formal_framework_for_describing_and_mapping_gestures_in_Human_Device_Gesture_Interaction_HDGI",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-this_ontology",
      "Predicate-refers_to",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_version_of",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-define_(1)",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_a_formal_representation_of",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-describes_and_maps_gestures_used_in",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-our_approach",
      "Predicate-describes",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_a_specific_implementation_of",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-describes",
      "Entity-this_mapping"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-this_ontology"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-is_a_specific_instance_of",
      "Entity-hdgi"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-is_a_formal_framework_for_describing_and_mapping_human_gestures_in_Human_Device_Interactions",
      "Entity-hdgi"
    ],
    [
      "Entity-this_ontology",
      "Predicate-is",
      "Entity-hdgi"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-hdgi"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_version_of",
      "Entity-hdgi"
    ],
    [
      "Entity-hdgi",
      "Predicate-facilitates",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_a_formal_representation_of",
      "Entity-hdgi"
    ],
    [
      "Entity-hdgi",
      "Predicate-facilitates_the_mapping_of_gestures_to_affordances",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-is_an_ontology_for",
      "Entity-hdgi"
    ],
    [
      "Entity-our_approach",
      "Predicate-describes",
      "Entity-hdgi"
    ],
    [
      "Entity-hdgi",
      "Predicate-represent",
      "Entity-hdgi__human"
    ],
    [
      "Entity-hdgi",
      "Predicate-is_a_specific_implementation_of",
      "Entity-our_ontology"
    ],
    [
      "Entity-hdgi",
      "Predicate-facilitates",
      "Entity-this_mapping"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_version_of",
      "Entity-human_device_gesture_interaction__hdgi_"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_version_of",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-hdgi_v0.1"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_version_of",
      "Entity-the_presented_ontology"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-is_a_version_of",
      "Entity-hdgi_v0.1"
    ],
    [
      "Entity-our_approach",
      "Predicate-is_a_version_of",
      "Entity-hdgi_v0.1"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_a_version_of",
      "Entity-hdgi_v0.1"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-describes",
      "Entity-this_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-facilitates_the_integration_and_interoperability_of_gesture_data_across_various_devices_and_applications_in_Human_Device_Interaction",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-this_ontology",
      "Predicate-facilitates_the_integration_and_interoperability_of_gesture_data_across_various_devices_and_applications_in_Human_Device_Interaction",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_version_of",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-facilitates_the_integration_and_interoperability_of_gesture_data_across_various_devices_and_applications_in_Human_Device_Interaction_(1)",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-hdgi_ontology_mapping",
      "Predicate-facilitates",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-our_approach",
      "Predicate-facilitates_the_mapping_of_gesture_vocabularies_through_HDGI_ontology_mappings",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-our_ontology",
      "Predicate-facilitates_the_integration_of_HDGI_ontology_mappings_with_our_ontology",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-hdgi_ontology_mapping",
      "Predicate-facilitates",
      "Entity-this_mapping"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_a_specific_instance_of",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-the_presented_ontology"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-enables",
      "Entity-this_mapping"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-maps",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-facilitates_the_mapping_of_gestures_to_affordances_within_the_HDGI_ontology",
      "Entity-gesture_representation"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-facilitates_the_mapping_of_gestures_to_affordances",
      "Entity-hdgi_ontology"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-is_modeled_within",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents_a_systematic_analysis_and_ontology_for_gesture_representation",
      "Entity-gesture_representation"
    ],
    [
      "Entity-hdgi",
      "Predicate-facilitates_the_mapping_of_gestures_to_affordances_within_the_HDGI_ontology",
      "Entity-gesture_representation"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_component_of",
      "Entity-gesture_representation"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-facilitates_the_mapping_of_gestures_to_affordances",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_modeled_as",
      "Entity-gesture_representation"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-facilitates_the_mapping_of_gestures_to_affordances_within_the_HDGI_ontology",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-facilitates",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-our_approach",
      "Predicate-is_modeled_as",
      "Entity-gesture_representation"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-models",
      "Entity-hdgi__human"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_modeled_as",
      "Entity-gesture_representation"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-facilitates",
      "Entity-this_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-facilitates",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-facilitates_the_mapping_of_human_gestures_to_device_affordances",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-this_ontology",
      "Predicate-maps_to",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_version_of",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-hdgi_ontology_mapping",
      "Predicate-facilitates_the_integration_and_interoperability_of_gesture_data_across_various_devices_and_applications_in_Human_Device_Interaction",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-facilitates_the_mapping_of_gestures_to_affordances",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-facilitates",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-our_approach",
      "Predicate-facilitates_the_mapping_of_human_gestures_to_device_affordances",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-hdgi_mapping",
      "Predicate-maps_to",
      "Entity-our_ontology"
    ],
    [
      "Entity-hdgi_mapping",
      "Predicate-facilitates",
      "Entity-this_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-is_a_specific_ontology_of_Human_Device_Gesture_Interaction",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-this_ontology",
      "Predicate-is_described_in",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-describes",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-our_approach",
      "Predicate-describes",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-our_ontology",
      "Predicate-describes",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-enables",
      "Entity-this_mapping"
    ],
    [
      "Entity-our_approach",
      "Predicate-describes",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-our_approach"
    ],
    [
      "Entity-our_approach",
      "Predicate-describes",
      "Entity-the_presented_ontology"
    ],
    [
      "Entity-our_approach",
      "Predicate-describes",
      "Entity-our_ontology"
    ],
    [
      "Entity-our_approach",
      "Predicate-facilitates",
      "Entity-this_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-is_a_component_of",
      "Entity-hdgi__human"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-is_a_class_within",
      "Entity-hdgi__human"
    ],
    [
      "Entity-this_ontology",
      "Predicate-is_a_class_within",
      "Entity-hdgi__human"
    ],
    [
      "Entity-this_paper",
      "Predicate-describes",
      "Entity-hdgi__human"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_version_of",
      "Entity-hdgi__human"
    ],
    [
      "Entity-hdgi_ontology_mapping",
      "Predicate-maps",
      "Entity-hdgi__human"
    ],
    [
      "Entity-hdgi__human",
      "Predicate-is_represented_by",
      "Entity-the_presented_ontology"
    ],
    [
      "Entity-hdgi__human",
      "Predicate-maps",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-is_involved_in",
      "Entity-hdgi__human"
    ],
    [
      "Entity-our_approach",
      "Predicate-describes",
      "Entity-hdgi__human"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_a_component_of",
      "Entity-hdgi__human"
    ],
    [
      "Entity-this_mapping",
      "Predicate-maps",
      "Entity-hdgi__human"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_a_specific_implementation_of",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-our_ontology"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_a_formal_representation_of",
      "Entity-the_presented_ontology"
    ],
    [
      "Entity-our_ontology",
      "Predicate-describes_the_process_of",
      "Entity-this_mapping"
    ],
    [
      "Entity-this_mapping",
      "Predicate-links",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-describes",
      "Entity-this_mapping"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "Predicate-are_a_subset_of",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-describes_and_maps",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-is_defined_within",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "Predicate-is_defined_in",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-hdgi",
      "Predicate-is_defined_in",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-describes_and_maps",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "Predicate-maps",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-maps",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "Predicate-maps",
      "Entity-gesture_representation"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "Predicate-maps",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-describes",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-our_approach",
      "Predicate-maps",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-hdgi__human",
      "Predicate-isPerformedBy",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-our_ontology",
      "Predicate-describes",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "Predicate-maps",
      "Entity-this_mapping"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-describes_and_maps",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-is_a_structured_representation_of",
      "Entity-human_device_gesture_interaction__hdgi_"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-is_a_formal_representation_of",
      "Entity-formalization_of_hdgi_v0.1"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-is_represented_by",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-formalization_of_hdgi_v0.1"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-is_a_formal_representation_of",
      "Entity-hdgi"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-is_a_structured_representation_of",
      "Entity-hdgi_v0.1"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-define_(1)",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-is_represented_by",
      "Entity-the_presented_ontology"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-describes",
      "Entity-gesture_representation"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-describes_and_maps",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-describes",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-our_approach",
      "Predicate-describes",
      "Entity-formalization_of_hdgi_v0.1"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-describes",
      "Entity-hdgi__human"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_a_formal_representation_of",
      "Entity-formalization_of_hdgi_v0.1"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-enables",
      "Entity-this_mapping"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-describes",
      "Entity-gesture_related_to_device_interaction"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-is_a_formal_representation_of",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "Predicate-map",
      "Entity-device_interaction"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-describes_and_maps",
      "Entity-device_interaction"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-describes_and_maps",
      "Entity-device_interaction"
    ],
    [
      "Entity-this_ontology",
      "Predicate-describes",
      "Entity-device_interaction"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents_a_systematic_analysis_and_ontology_for_formally_describing_gestures_used_in_Human_Device_Interactions_HDI",
      "Entity-device_interaction"
    ],
    [
      "Entity-hdgi",
      "Predicate-describes",
      "Entity-device_interaction"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-describes_and_maps",
      "Entity-device_interaction"
    ],
    [
      "Entity-hdgi_ontology_mapping",
      "Predicate-maps",
      "Entity-device_interaction"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-describes",
      "Entity-device_interaction"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-maps",
      "Entity-device_interaction"
    ],
    [
      "Entity-hdgi_mapping",
      "Predicate-maps",
      "Entity-device_interaction"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "Predicate-is_a_component_of",
      "Entity-device_interaction"
    ],
    [
      "Entity-our_approach",
      "Predicate-maps",
      "Entity-device_interaction"
    ],
    [
      "Entity-hdgi__human",
      "Predicate-represent",
      "Entity-device_interaction"
    ],
    [
      "Entity-our_ontology",
      "Predicate-describes",
      "Entity-device_interaction"
    ],
    [
      "Entity-this_mapping",
      "Predicate-enables",
      "Entity-device_interaction"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "Predicate-are_represented_by",
      "Entity-device_interaction"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "Predicate-describes_and_maps",
      "Entity-device_interaction"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-maps",
      "Entity-device_interaction"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-describes",
      "Entity-gesture_used_in_human_device_interaction__hdi_"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "Predicate-facilitates_the_understanding_and_interpretation_of_user_gestures_in_various_interactive_systems",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-hdgi_ontology",
      "Predicate-is_a_specific_implementation_of",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-is_a_specific_implementation_of",
      "Entity-this_ontology"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-hdgi",
      "Predicate-is_a_specific_implementation_of",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-hdgi_v0.1",
      "Predicate-is_a_version_of",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-facilitates_the_integration_and_interoperability_of_gesture_data_across_various_devices_and_applications_in_Human_Device_Interaction",
      "Entity-hdgi_ontology_mapping"
    ],
    [
      "Entity-the_presented_ontology",
      "Predicate-is_a_formal_representation_of",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-gesture_representation",
      "Predicate-facilitates_the_mapping_of_gestures_to_affordances",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-maps",
      "Entity-hdgi_mapping"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-facilitates",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-our_approach",
      "Predicate-is_based_on",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-describes",
      "Entity-hdgi__human"
    ],
    [
      "Entity-our_ontology",
      "Predicate-is_a_specific_implementation_of",
      "Entity-gesture_ontology"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-describes",
      "Entity-this_mapping"
    ],
    [
      "Entity-gesture_ontology",
      "Predicate-describes",
      "Entity-gesture_related_to_device_interaction"
    ]
  ],
  "triples_typing": [
    [
      "Entity-the_human_body",
      "skos:broader",
      "Entity-body"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-villarreal_narvaez",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-gesture-based_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-movement_of_multiple_body_part",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-existing_knowledge",
      "skos:broader",
      "Entity-knowledge"
    ],
    [
      "Entity-the_problem_of_hand_gesture_recognition",
      "skos:broader",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-gesture-controlled_interface",
      "skos:broader",
      "Entity-body-based_contextual_gesture"
    ],
    [
      "Entity-their_preferred_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-sample",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-api_client",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-hdgi__affordance",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-upper_limb_of_the_human_body"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-device_affordances",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-arm_class",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-method_for_controlling_interactive_system",
      "skos:broader",
      "Entity-interactive_system"
    ],
    [
      "Entity-a_particular_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-human_upper_limb_region_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__rotation",
      "skos:broader",
      "Entity-rotation"
    ],
    [
      "Entity-sosa__observableproperty",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-effect_of_a_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-5_geometrical_shape",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_set",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hand",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-necessary_affordances",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-gesture-controlled_interface",
      "skos:broader",
      "Entity-gesture-based_system"
    ],
    [
      "Entity-affordance_y",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-forearm",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-atomic_hdgi__movement",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-gestural_information",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-finger_pose",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-referent"
    ],
    [
      "Entity-microsoft_kinect",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-mid-air_gesture_of_the_human_body",
      "skos:broader",
      "Entity-human_body"
    ],
    [
      "Entity-effect_of_a_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-end_user",
      "skos:broader",
      "Entity-a_user_(2)"
    ],
    [
      "Entity-interactive_information",
      "skos:broader",
      "Entity-communication"
    ],
    [
      "Entity-owl2",
      "skos:broader",
      "Entity-standard"
    ],
    [
      "Entity-namespace",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-single_body_part",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-6_command__43_gesture_",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-a_user",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-forearm",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-gesture_subclass"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-gesture_subclass"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-a_tool_on_how_to_integrate_the_hdgi_ontology",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-emerging_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-ssn_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-customized_sparql_endpoint",
      "skos:broader",
      "Entity-endpoint"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-forearmpose",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-wrist",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-sosa__actuator",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-static_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-brown_et_al_.",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-the_shape_and_dynamic_of_a_certain_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-better_user_experience",
      "skos:broader",
      "Entity-user_experience"
    ],
    [
      "Entity-context_dependent_action_or_manipulation_possibility",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-gesture_representation"
    ],
    [
      "Entity-5_geometrical_shape",
      "skos:broader",
      "Entity-shape"
    ],
    [
      "Entity-an_impressive_amount_of_knowledge",
      "skos:broader",
      "Entity-knowledge"
    ],
    [
      "Entity-user_s_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-pinch_their_thumb_and_index_finger_together",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-element_observed_from_existing_gesture_vocabulary",
      "skos:broader",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-people",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-hdgi_ontology",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-augmented_reality",
      "skos:broader",
      "Entity-immersive_technology"
    ],
    [
      "Entity-universal_gesture_standard",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-data_received_from_different_manufacturers-devices",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-the_leap-motion_sdk",
      "skos:broader",
      "Entity-software_development_kit"
    ],
    [
      "Entity-gesture_type",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-internet_of_thing__iot__system",
      "skos:broader",
      "Entity-internet_of_thing"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hand_gesture_recognition",
      "skos:broader",
      "Entity-gesture_recognition_device"
    ],
    [
      "Entity-computational_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-device_a",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-user_s_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-user",
      "skos:broader",
      "Entity-people"
    ],
    [
      "Entity-automated_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-gesture-related_vocabulary",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gestural_interface",
      "skos:broader",
      "Entity-interface"
    ],
    [
      "Entity-this_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-human_gesture",
      "skos:broader",
      "Entity-human_behavior"
    ],
    [
      "Entity-time_stamp",
      "skos:broader",
      "Entity-timestamp"
    ],
    [
      "Entity-relationship",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-universal_gesture_standard",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-their_meaning_and_action",
      "skos:broader",
      "Entity-meaning"
    ],
    [
      "Entity-forearmpose",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_a",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-affordance_of_answering_a_call_in_a_car",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-fma_class_definition",
      "skos:broader",
      "Entity-taxonomy"
    ],
    [
      "Entity-forearmpose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-the_rotation_of_a_pose",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-affordances_of_a_device",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-arm-based_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__thumb",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-eight_atomic_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_type",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__actuatableaffordance",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-swagger_ui",
      "skos:broader",
      "Entity-api_documentation"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-few_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-hand-gesture_supported_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-hdgi__movement",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-gesture_type"
    ],
    [
      "Entity-interactive_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-new_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-hdgi__observer",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi",
      "skos:broader",
      "Entity-standard"
    ],
    [
      "Entity-potential_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-manufacturer-defined_gesture",
      "skos:broader",
      "Entity-design_decision"
    ],
    [
      "Entity-ar_and_vr",
      "skos:broader",
      "Entity-immersive_technology"
    ],
    [
      "Entity-movement",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-desired_effect_of_an_action",
      "skos:broader",
      "Entity-effect"
    ],
    [
      "Entity-necessary_affordances",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-commonly_used_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-mid-air_gesture",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-observed_property",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-best_gesture_",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-their_touchscreen",
      "skos:broader",
      "Entity-touchscreen"
    ],
    [
      "Entity-their_own_private_cloud",
      "skos:broader",
      "Entity-cloud"
    ],
    [
      "Entity-a_user_(3)",
      "skos:broader",
      "Entity-a_user_(2)"
    ],
    [
      "Entity-hdgi__bodypart",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-their_touchscreen",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-mid-air_gesture_of_the_human_body",
      "skos:broader",
      "Entity-the_human_body"
    ],
    [
      "Entity-the_face",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-modelling_the_infinite_set_of_concept__feature__attribute__and_relationship",
      "skos:broader",
      "Entity-feature"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hand",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-arm-based_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-certain_affordances",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-eight_atomic_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_to_answer_a_call_in_a_car",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-the_movement_of_the_user__s_right_arm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-api_client",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-user",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-the_shape_and_dynamic_of_a_certain_gesture",
      "skos:broader",
      "Entity-shape"
    ],
    [
      "Entity-gestural_sign",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hand",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-each_individual_hdgi__finger_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-size_or_speed_of_hand_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-villarreal-narvaez_et_al_.",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-human_device_interaction"
    ],
    [
      "Entity-forearmpose",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-upper_limb_related_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-predefined_mapping_of_a_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-api_client",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-hdgi_web_app",
      "skos:broader",
      "Entity-web_application"
    ],
    [
      "Entity-existing_gesture_recognition_system",
      "skos:broader",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-hdgi__position",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__hasposition",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__actuatableaffordance",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-sample_usage",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-mid-air_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-the_pose_and_movement_of_human_upper_limb",
      "skos:broader",
      "Entity-human_s_upper_limb_region"
    ],
    [
      "Entity-sosa__platform",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-forearmpose",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-designer_and_researcher",
      "skos:broader",
      "Entity-designer"
    ],
    [
      "Entity-it",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-microsoft_kinect",
      "skos:broader",
      "Entity-sensor"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-observation",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-api_and_architecture_documentation",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-affordance_of_answering_a_call_in_a_car",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-user_experience__ux_",
      "skos:broader",
      "Entity-ux"
    ],
    [
      "Entity-relevant_mapping_to_device_affordances",
      "skos:broader",
      "Entity-affordances_of_a_device"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-pose_modeling"
    ],
    [
      "Entity-human_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-effect_of_a_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-upper_arm_position",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-gesture-controlled_interface",
      "skos:broader",
      "Entity-interface"
    ],
    [
      "Entity-the_movement_of_the_user__s_right_arm",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-gesture_a",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-the_problem_of_hand_gesture_recognition",
      "skos:broader",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-hdgi__actuatableaffordance",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-other_body_part",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__hasposition",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-upper_limb_related_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-computational_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-swagger_ui",
      "skos:broader",
      "Entity-documentation"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-forearm",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-communication"
    ],
    [
      "Entity-better_user_experience",
      "skos:broader",
      "Entity-ux"
    ],
    [
      "Entity-gesture_selection",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-affordance",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-internet_of_thing",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-atomic_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-leap-motion_sdk",
      "skos:broader",
      "Entity-gesture_recognition_software_tool"
    ],
    [
      "Entity-arm-based_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-the_provided_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-relevant_mapping_to_device_affordances",
      "skos:broader",
      "Entity-a_particular_affordance_of_a_device"
    ],
    [
      "Entity-finger_pose",
      "skos:broader",
      "Entity-finger"
    ],
    [
      "Entity-the_pose_and_movement_of_human_upper_limb",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-affordance_mapping",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__position",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-human_behavior"
    ],
    [
      "Entity-ge",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-arm-based_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-eight_atomic_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_pose_and_movement_of_human_upper_limb",
      "skos:broader",
      "Entity-upper_limb_of_the_human_body"
    ],
    [
      "Entity-certain_affordances",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-small-scale_user_study",
      "skos:broader",
      "Entity-study"
    ],
    [
      "Entity-answering_a_call",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-hdgi__yposition",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-one_or_more_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-sosa__platform",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-best_gesture_",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-user_s_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-oculus_quest",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-swagger_codegen_capability",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-sequence_of_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-affordance_mapping",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-it_referent",
      "skos:broader",
      "Entity-referent"
    ],
    [
      "Entity-context_dependent_action_or_manipulation_possibility",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-infinite_set_of_concept__feature__attribute__and_relationship",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-microsoft_hololens",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-universal_gesture_standard",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-ontology_building",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-user_experience__mbux_",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-bloom__gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-that_class_a_the_subject",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-hdgi__bodypart_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-hdgi__context",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-best_gesture_",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_start_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-semantic_model_of_gesture",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-cardinality_of_many_to_many",
      "skos:broader",
      "Entity-cardinality"
    ],
    [
      "Entity-khairunizam_et_al_.",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-these_ge",
      "skos:broader",
      "Entity-ge"
    ],
    [
      "Entity-gesture_interaction",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-upper_arm_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-sosa__actuatableproperty",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-human_device_gesture_interaction_knowledge_base",
      "skos:broader",
      "Entity-knowledge_base"
    ],
    [
      "Entity-size_or_speed_of_hand_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-the_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-riener_et_al_.",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-ontological_framework",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-the_permanent_url_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-conventional_control",
      "skos:broader",
      "Entity-user_experience__ux_"
    ],
    [
      "Entity-z-axis",
      "skos:broader",
      "Entity-coordinate_system"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-leap_motion",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-mixed_reality",
      "skos:broader",
      "Entity-virtual_reality"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-tool_for_mapping_hdgi_v0.1_to_leap_motion_and_the_oculus_quest_device",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-a_user_(2)",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-hdgi_restful_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-hdgi__duration",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-extrinsic_property",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-gestural_interaction_taxonomy",
      "skos:broader",
      "Entity-gestural_input"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-blind",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-finger",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-modern_automobile",
      "skos:broader",
      "Entity-automobile"
    ],
    [
      "Entity-instance_of_that_property",
      "skos:broader",
      "Entity-instance"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-a_certain_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-semantic_sensor_network__ssn_",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-ux",
      "skos:broader",
      "Entity-user_experience"
    ],
    [
      "Entity-expectation",
      "skos:broader",
      "Entity-ux"
    ],
    [
      "Entity-upper_limb_of_the_human_body",
      "skos:broader",
      "Entity-human_body"
    ],
    [
      "Entity-existing_gesture_vocabulary",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-potential_human_behavior",
      "skos:broader",
      "Entity-human_behavior"
    ],
    [
      "Entity-geometrical_shape",
      "skos:broader",
      "Entity-shape"
    ],
    [
      "Entity-hdgi__device",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-leap-motion_sdk",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-hdgi__indexfinger",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-a_tool_on_how_to_integrate_the_hdgi_ontology",
      "skos:broader",
      "Entity-integration"
    ],
    [
      "Entity-manufacturer-defined_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-right_palm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-bmw__s_idrive_infotainment_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-swagger_ui",
      "skos:broader",
      "Entity-complete_api_documentation"
    ],
    [
      "Entity-the_right_palm",
      "skos:broader",
      "Entity-palm"
    ],
    [
      "Entity-human_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-hdgi__observableaffordance",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-data_received_from_different_manufacturers-devices",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-systematic_analysis_and_description_of_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-previous_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-hdgi_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hand",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-one_or_more_pose_(1)",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_selection",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-existing_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-knowledge_of_the_arm_gesture",
      "skos:broader",
      "Entity-knowledge"
    ],
    [
      "Entity-a_set_of_predefined_sparql_endpoint",
      "skos:broader",
      "Entity-sparql"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-desired_effect_of_an_action",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-a_user__s_wrist",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-upper_limb"
    ],
    [
      "Entity-hdgi__legpose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-their_product",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-the_experiment",
      "skos:broader",
      "Entity-experiment"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-solo",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-qualisys_motion_capture",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-concept_and_property_in_these_ontology",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-future_work_(1)",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-forearmpose",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-zposition",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__footpose",
      "skos:broader",
      "Entity-pose_modeling"
    ],
    [
      "Entity-affordance_x",
      "skos:broader",
      "Entity-feature"
    ],
    [
      "Entity-a_swipe_gesture_",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-an_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-a_predefined_set_of_movement",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-their_preferred_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-bloom__gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-existing_gesture_recognition_system",
      "skos:broader",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-the_same_referent",
      "skos:broader",
      "Entity-referent"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-microsoft_hololens",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-choi_et_al_.",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-hdgi_ontology",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-apis",
      "skos:broader",
      "Entity-interface"
    ],
    [
      "Entity-hdgi__includesgesture",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-microsoft_hololens",
      "skos:broader",
      "Entity-ar"
    ],
    [
      "Entity-user_experience__mbux_",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-knowledge_of_the_arm_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-pinch_their_thumb_and_index_finger_together",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-user_need",
      "skos:broader",
      "Entity-user_experience__ux_"
    ],
    [
      "Entity-gesture_a",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-sosa__observableproperty",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-end_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-universal_gesture_standard",
      "skos:broader",
      "Entity-standard"
    ],
    [
      "Entity-leap-motion_sdk",
      "skos:broader",
      "Entity-software_development_kit"
    ],
    [
      "Entity-their_meaning_and_action",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-gestural_information",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-a_swipe_gesture_",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-sparql_endpoint",
      "skos:broader",
      "Entity-sparql"
    ],
    [
      "Entity-hdgi__xrotation",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-multiple_movement_and_pose_of_body_part",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-gesture_subclass"
    ],
    [
      "Entity-gesture-controlled_interface",
      "skos:broader",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-corresponding_affordances",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-finger_pose",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-upper_arm",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture-related_vocabulary",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__includesgesture",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-the_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-device_interaction",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-human_device_interaction__hdi_",
      "skos:broader",
      "Entity-hdi"
    ],
    [
      "Entity-hdgi__devicecontext",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-sosa__sensor",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-semantics",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-sosa__observableproperty",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-human",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-http__w3id.orghdgi",
      "skos:broader",
      "Entity-namespace"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-pose_and-or_movement",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-gesture_elicitation_study",
      "skos:broader",
      "Entity-study"
    ],
    [
      "Entity-knowledge_of_the_arm_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-infinite_set_of_concept__feature__attribute__and_relationship",
      "skos:broader",
      "Entity-feature"
    ],
    [
      "Entity-interoperability",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-a_lack_of_linked_data",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_elicitation_study",
      "skos:broader",
      "Entity-gesture_elicitation_study__ge_"
    ],
    [
      "Entity-attribute",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-corresponding_affordances",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-sosa__actuator",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-the_shape_and_dynamic_of_a_certain_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-xposition",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-user_need",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-best_gesture_",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-start_hdgi__pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__hasrotation",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-systematic_analysis_and_description_of_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-finger_pose",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-bmw__s_idrive_infotainment_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-rotation",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-movement_recognition",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-palm_and_finger_position",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__devicemanufacturer",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-unity3d11",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-commonly_used_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-variety",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-sosa__observableproperty",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__yrotation",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-the_rotation_of_a_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-6_command__43_gesture_",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-particular_set_of_user",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-ux",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-use_and_extensibility",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-the_shape_and_dynamic_of_a_certain_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-size_or_speed_of_hand_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-maier_et_al_.",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-device_manufacturer",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-microsoft_hololens",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-gesture_to_answer_a_call_in_a_car",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-hdgi__supportsgesture",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-solo",
      "skos:broader",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-scoditti_et_al_.",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-qualisys_motion_capture",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-api_documentation",
      "skos:broader",
      "Entity-documentation"
    ],
    [
      "Entity-hdgi__indexfinger",
      "skos:broader",
      "Entity-finger"
    ],
    [
      "Entity-a_swipe_gesture_",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-end_user",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-hdgi__actuatableaffordance",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-sosa__actuator",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-villarreal-narvaez_et_al_.",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-an_arm_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-icon",
      "skos:broader",
      "Entity-symbol"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-leap-motion_sdk",
      "skos:broader",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-human_device_interaction",
      "skos:broader",
      "Entity-user_experience__ux_"
    ],
    [
      "Entity-namespace_http__w3id.orghdgi",
      "skos:broader",
      "Entity-namespace"
    ],
    [
      "Entity-device_affordances",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-a_swipe_gesture_",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-personalization_of_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-user_context",
      "skos:broader",
      "Entity-user_experience__ux_"
    ],
    [
      "Entity-end_hdgi__pose",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-web_application",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-hdgi__thumb",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-knowledge_of_the_arm_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-a_hdgi__pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-human_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-the_challenge_of_how_to_increase_the_knowledge_level_of_computational_system",
      "skos:broader",
      "Entity-computational_system"
    ],
    [
      "Entity-sparql_endpoint",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-different_gesture"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-gesture_selection",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-an_interesting_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-property",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-multiple_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-upper_arm",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-knowledge_of_the_arm_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-human_device_interaction",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-eight_atomic_gesture",
      "skos:broader",
      "Entity-atomic_gesture"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gestural_sign",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-device",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-class_and_property_of_the_hdgi_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__devicecontext",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-a_how-to__documentation",
      "skos:broader",
      "Entity-documentation"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-upper_arm",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-finger_pose",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-a_referent",
      "skos:broader",
      "Entity-referent"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-human_device_interaction"
    ],
    [
      "Entity-currently_available_and_contemporary_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-endpoint_structure",
      "skos:broader",
      "Entity-endpoint"
    ],
    [
      "Entity-hdgi__actuatableaffordance",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi_web_app",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-hdgi__ringfinger",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-usability",
      "skos:broader",
      "Entity-ux"
    ],
    [
      "Entity-api_client",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-effect_of_a_gesture",
      "skos:broader",
      "Entity-effect"
    ],
    [
      "Entity-independent_layer",
      "skos:broader",
      "Entity-design"
    ],
    [
      "Entity-gesture_elicitation_study__ge_",
      "skos:broader",
      "Entity-study"
    ],
    [
      "Entity-referent",
      "skos:broader",
      "Entity-meaning"
    ],
    [
      "Entity-a_particular_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-the_research_community",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-gestural_information"
    ],
    [
      "Entity-idrive",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-end_pose",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-mid-air_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-bloom__gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-semantic_model",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-the_relevant_code__data__and_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__littlefinger",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-a_similar_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-the_shape_and_dynamic_of_a_certain_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-physical_movement"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-all_the_class_used_in_the_ontology",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-an_arm_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-pose_modeling"
    ],
    [
      "Entity-necessary_affordances",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-hdgi__yposition",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-the_right_palm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-effect_of_a_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-qualisys_motion_capture",
      "skos:broader",
      "Entity-motion_capture"
    ],
    [
      "Entity-geometrical_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-a_user_(3)",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-ubiquitousness",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-upper_limb_of_the_human_body"
    ],
    [
      "Entity-forearm",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-semantics",
      "skos:broader",
      "Entity-meaning"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-augmented_reality",
      "skos:broader",
      "Entity-virtual_reality"
    ],
    [
      "Entity-the_attempt_above",
      "skos:broader",
      "Entity-attempt"
    ],
    [
      "Entity-extrinsic_property",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-user_need",
      "skos:broader",
      "Entity-a_user_(2)"
    ],
    [
      "Entity-affordance",
      "skos:broader",
      "Entity-feature"
    ],
    [
      "Entity-an_arm_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-static_gesture",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-owl2",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-a_new_namespace",
      "skos:broader",
      "Entity-namespace"
    ],
    [
      "Entity-standard",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-mid-air_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-ontological_framework",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-existing_gesture_recognition_system"
    ],
    [
      "Entity-existing_gesture_recognition_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-hdgi__device",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-eight_section_of_upper_limb_region",
      "skos:broader",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-particular_set_of_user",
      "skos:broader",
      "Entity-a_user_(2)"
    ],
    [
      "Entity-affordance_y",
      "skos:broader",
      "Entity-capability"
    ],
    [
      "Entity-yaw",
      "skos:broader",
      "Entity-rotation"
    ],
    [
      "Entity-redundant_gesture_vocabulary",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-a_large_number_of_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-hdgi__middlefinger",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-external_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__hasrotation",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-user_s_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-knowledge_of_ge",
      "skos:broader",
      "Entity-knowledge"
    ],
    [
      "Entity-call",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-device_manufacturer",
      "skos:broader",
      "Entity-a_user_(2)"
    ],
    [
      "Entity-systematic_analysis_and_description_of_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-existing_gesture_vocabulary",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-relationship_between_each_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-the_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-universal_gesture_standard",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-sequence_of_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_subclass",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-existing_gesture_vocabulary",
      "skos:broader",
      "Entity-gesture_vocabulary"
    ],
    [
      "Entity-physical_movement",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-affordance",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-pose_modeling"
    ],
    [
      "Entity-pose_and-or_movement",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-geometrical_gesture",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-modelling_the_infinite_set_of_concept__feature__attribute__and_relationship",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-affordance_of_answering_a_call_in_a_car",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-one_manufacturer",
      "skos:broader",
      "Entity-manufacturer"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-arm-based_gesture"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-context",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_repository",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-solo",
      "skos:broader",
      "Entity-existing_gesture_recognition_system"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-detailed_representation_of_the_hand",
      "skos:broader",
      "Entity-hand"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "skos:broader",
      "Entity-semantics"
    ],
    [
      "Entity-hdgi__movement",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-the_relevant_code__data__and_ontology",
      "skos:broader",
      "Entity-code"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-meaning",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-review_conducted_by_villarreal_narvaez_et_al_._in_2020",
      "skos:broader",
      "Entity-study"
    ],
    [
      "Entity-gesture_type",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-swagger_ui",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-sequence_of_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-a_swipe_gesture_",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-sensor-independent_ontology",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-external_ontology",
      "skos:broader",
      "Entity-knowledge_base"
    ],
    [
      "Entity-sensor-independent_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-a_particular_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-affordance",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-semantic_web_standard__rdf__rdfs__and_owl2_",
      "skos:broader",
      "Entity-standard"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__xrotation",
      "skos:broader",
      "Entity-rotation"
    ],
    [
      "Entity-mapping",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-hdgi",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-the_pose_and_movement_of_human_upper_limb",
      "skos:broader",
      "Entity-upper_limb"
    ],
    [
      "Entity-the_perceived_and_actual_property_of_the_thing",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__thumb",
      "skos:broader",
      "Entity-finger"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-solo",
      "skos:broader",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-geometrical_gesture",
      "skos:broader",
      "Entity-shape"
    ],
    [
      "Entity-arm",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-zposition",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-one_or_more_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-manufacturer-defined_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-different_vendor",
      "skos:broader",
      "Entity-vendor"
    ],
    [
      "Entity-knowledge_of_the_arm_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-certain_affordances",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-the_concept_of_guessability_of_a_system_",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-arm-based_gesture",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-43_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-position",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-hand",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-complete_api_documentation",
      "skos:broader",
      "Entity-documentation"
    ],
    [
      "Entity-their_preferred_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gestural_input",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-gesture_recognition_device"
    ],
    [
      "Entity-use",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-feature_of_interest",
      "skos:broader",
      "Entity-feature"
    ],
    [
      "Entity-upper_arm",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-many_to_many",
      "skos:broader",
      "Entity-cardinality"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-human_behavior"
    ],
    [
      "Entity-user_experience__ux_",
      "skos:broader",
      "Entity-user_experience"
    ],
    [
      "Entity-api_and_architecture_documentation",
      "skos:broader",
      "Entity-documentation"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-ontology_design_pattern_initiative",
      "skos:broader",
      "Entity-community"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-manufacturer-defined_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__device",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-new_ge",
      "skos:broader",
      "Entity-ge"
    ],
    [
      "Entity-relevant_mapping_to_device_affordances",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-forearmpose",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-usability",
      "skos:broader",
      "Entity-user_experience__ux_"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-sensor-independent_ontology",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-43_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-existing_gesture_recognition_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-this_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-different_sdks-systems",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-smart_home",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-human_device_interaction__hdi_",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-mid-air_gesture_of_the_human_body",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-this_research",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-our_model",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-affordance_mapping",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-relationship_between_each_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-upper_arm"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-knowledge_of_the_arm_gesture",
      "skos:broader",
      "Entity-arm"
    ],
    [
      "Entity-sequence_of_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__timestamp",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-gesture_type",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-rich_gestural_input",
      "skos:broader",
      "Entity-gestural_input"
    ],
    [
      "Entity-pose_modeling",
      "skos:broader",
      "Entity-systematic_analysis_and_description_of_gesture"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-end_hdgi__pose",
      "skos:broader",
      "Entity-instance"
    ],
    [
      "Entity-right_forearm",
      "skos:broader",
      "Entity-forearm"
    ],
    [
      "Entity-an_arm_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-relationship_between_each_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__quaternion",
      "skos:broader",
      "Entity-quaternion"
    ],
    [
      "Entity-hdgi_v0.1",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-these_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-sequence_of_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-all_these_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-affordance",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-formalization",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-face",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-sparql_endpoint",
      "skos:broader",
      "Entity-endpoint"
    ],
    [
      "Entity-rotation",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-mid-air_gesture_of_the_human_body",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-internet_of_thing",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-hdgi_ontology_mapping",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-arm-based_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hdgi__yrotation",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-conventional_control",
      "skos:broader",
      "Entity-ux"
    ],
    [
      "Entity-eight_atomic_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-api_client_stub",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-relevant_mapping",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-hdgi__devicecontext",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-sosa__sensor",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-owl2",
      "skos:broader",
      "Entity-semantic_web_standard"
    ],
    [
      "Entity-designer",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-a_tv",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-local_coordinate_system",
      "skos:broader",
      "Entity-coordinate_system"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-43_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-private_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-the_design_and_development_of_gestural_interface",
      "skos:broader",
      "Entity-design"
    ],
    [
      "Entity-different_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-expectation",
      "skos:broader",
      "Entity-user_experience"
    ],
    [
      "Entity-command",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-atomic_gesture",
      "skos:broader",
      "Entity-gesture_type"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-commonly_used_gesture"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-microsoft_hololens",
      "skos:broader",
      "Entity-mixed_reality"
    ],
    [
      "Entity-6_command__43_gesture_",
      "skos:broader",
      "Entity-command"
    ],
    [
      "Entity-ar",
      "skos:broader",
      "Entity-augmented_reality"
    ],
    [
      "Entity-device_b",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-hand_gesture",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-43_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-existing_gesture_recognition_system"
    ],
    [
      "Entity-an_increased_number_of_command",
      "skos:broader",
      "Entity-command"
    ],
    [
      "Entity-data_received_from_different_manufacturers-devices",
      "skos:broader",
      "Entity-manufacturer"
    ],
    [
      "Entity-the_human_body",
      "skos:broader",
      "Entity-human"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-forearmpose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-user_s_choice_of_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-user_context",
      "skos:broader",
      "Entity-user_experience"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-w3id.org",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-upper_limb_related_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-device_a",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-hdgi__movement",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__devicecontext",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-bodypart",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-position_change",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-expressive_power",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-different_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gestural_sign",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-gesture-based_system"
    ],
    [
      "Entity-gestural_interface",
      "skos:broader",
      "Entity-gestural_input"
    ],
    [
      "Entity-a_particular_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-mid-air_gesture_of_the_human_body",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-human",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-ge",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-atomic_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-restful_apis",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-atomic_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-osumar_et_al_.",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-end_hdgi__pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-different_sdks-systems",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-their_hand",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-gesture_type",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-potential_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-new_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__movement",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-start_pose",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-gesture_representation",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-affordance_y",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-mid-air_gesture_of_the_human_body",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-individual_study",
      "skos:broader",
      "Entity-study"
    ],
    [
      "Entity-user_experience__ux_",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-wobbrock_et_al_.",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-personalization_of_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-user_s_choice_of_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_type",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-gesture_to_answer_a_call_in_a_car",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-relevant_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-xposition",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-user_need",
      "skos:broader",
      "Entity-ux"
    ],
    [
      "Entity-ontology",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-human_s_upper_limb_region"
    ],
    [
      "Entity-upper_limb",
      "skos:broader",
      "Entity-the_human_body"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-a_greater_variation_of_standard",
      "skos:broader",
      "Entity-standard"
    ],
    [
      "Entity-formalization_of_hdgi_v0.1",
      "skos:broader",
      "Entity-formalization"
    ],
    [
      "Entity-new_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-user_experience",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-several_possible_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-size_or_speed_of_hand_gesture",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-semantic_model_of_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-effect_of_a_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__affordedby",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-bmw_idrive_touchscreen",
      "skos:broader",
      "Entity-touchscreen"
    ],
    [
      "Entity-eight_atomic_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-their_research",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-bmw_idrive_touchscreen",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-solo",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-internet_of_thing",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-each_individual_hdgi__finger_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-the_human_body",
      "skos:broader",
      "Entity-human_body"
    ],
    [
      "Entity-hdgi__position_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-forearm",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_representation",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__zaxisdirection",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-norman",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-gesture_representation"
    ],
    [
      "Entity-tool_for_mapping_hdgi_v0.1_to_leap_motion_and_the_oculus_quest_device",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-linked_data",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-personalization_of_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-the_human",
      "skos:broader",
      "Entity-human"
    ],
    [
      "Entity-mixed_reality",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hand-gesture_supported_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-device_affordances",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-currently_available_and_contemporary_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_recognition_softwareservices",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-hdgi__usercontext",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-relationship_between_each_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi_mapping_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-forearm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-sequence_of_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-different_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-semantic_model_of_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-eight_section_of_upper_limb_region",
      "skos:broader",
      "Entity-upper_arm"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-api-driven_restful_web_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-human_device_interaction__hdi_"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-user_s_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-vr",
      "skos:broader",
      "Entity-immersive_technology"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-gesture_subclass"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-upper_limb_of_the_human_body"
    ],
    [
      "Entity-hdgi__gesture_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-device_affordances",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-alignment",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-hdgi__ringfinger",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-all_the_class_used_in_the_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-universal_gesture_standard",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-the_design_and_development_of_gestural_interface",
      "skos:broader",
      "Entity-gestural_input"
    ],
    [
      "Entity-the_shape_and_dynamic_of_a_certain_gesture",
      "skos:broader",
      "Entity-dynamic"
    ],
    [
      "Entity-different_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__context",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-geometrical_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-currently_available_and_contemporary_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-user_s_choice_of_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-designer",
      "skos:broader",
      "Entity-a_user_(2)"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__littlefinger",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-movement",
      "skos:broader",
      "Entity-physical_movement"
    ],
    [
      "Entity-upper_limb_related_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-leap-motion_sdk",
      "skos:broader",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-upper_limb_region",
      "skos:broader",
      "Entity-upper_arm"
    ],
    [
      "Entity-predefined_one_to_one_mapping",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-the_problem_at_hand",
      "skos:broader",
      "Entity-problem"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-several_sensor",
      "skos:broader",
      "Entity-sensor"
    ],
    [
      "Entity-userdevice_context",
      "skos:broader",
      "Entity-context"
    ],
    [
      "Entity-palm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-guarded_local_restriction",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-device",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-a_device",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-the_pose_and_movement_of_human_upper_limb",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-pose_modeling",
      "skos:broader",
      "Entity-technique"
    ],
    [
      "Entity-atomic_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-affordance_y",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-human_device_gesture_interaction__hdgi_",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-github",
      "skos:broader",
      "Entity-github_code_repository"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-user_s_choice_of_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-upper_limb_related_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-human_s_upper_limb_region",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-ge",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-gesture_recognition_system",
      "skos:broader",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture_representation",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-human_device_interaction",
      "skos:broader",
      "Entity-ux"
    ],
    [
      "Entity-redundant_gesture_vocabulary",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-human_gesture",
      "skos:broader",
      "Entity-physical_movement"
    ],
    [
      "Entity-geometrical_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-atomic_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-relationship_between_each_gesture",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-43_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-villarreal_narvaez",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-hdgi__yaxisdirection",
      "skos:broader",
      "Entity-axis_direction"
    ],
    [
      "Entity-user_context",
      "skos:broader",
      "Entity-ux"
    ],
    [
      "Entity-modelling_the_infinite_set_of_concept__feature__attribute__and_relationship",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-a_set_of_conventional_control",
      "skos:broader",
      "Entity-conventional_control"
    ],
    [
      "Entity-expressive_power_of_our_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-gesture_subclass",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-necessary_data",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-gesture_representation",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-these_finger",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-gesture_to_answer_a_call_in_a_car",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-devicemanufacturer",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__middlefinger",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-extensibility",
      "skos:broader",
      "Entity-capability"
    ],
    [
      "Entity-hdgi__supportsgesture",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-semantic_model_of_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi_v0.1",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-semantics"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hand",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-position",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_repository",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-redundant_gesture_vocabulary",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-hdgi__actuatableaffordance",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-solo",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-semantic_sensor_network__ssn_",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-semantic_model_of_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-user_need",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-movement",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-a_swipe_gesture_",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hdgi__device",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-class_and_property",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_subclass",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-mid-air_gesture_of_the_human_body",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-sensor-independent_ontology",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hand",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-individual_body_part",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__usercontext",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-gesture_type",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-our_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-start_icon",
      "skos:broader",
      "Entity-the_icon"
    ],
    [
      "Entity-hdgi__yrotation",
      "skos:broader",
      "Entity-rotation"
    ],
    [
      "Entity-gesture_interaction_in_mixed_reality",
      "skos:broader",
      "Entity-mixed_reality"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-further_experiment",
      "skos:broader",
      "Entity-experiment"
    ],
    [
      "Entity-leap_motion",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-currently_available_and_contemporary_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-predefined_mapping_of_a_gesture",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-arm",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-particular_set_of_user",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-hdgi__position",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-referent",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-knowledge_of_the_arm_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-one_of_the_major_contribution_in_this_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-blind",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-gesture_repository",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-endpoint",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-human_upper_limb_region_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-human_gesture",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-usability",
      "skos:broader",
      "Entity-user_experience"
    ],
    [
      "Entity-hdgi__hasposition",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-those_author",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gesture_set",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__bodypart",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-device_manufacturer",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "skos:broader",
      "Entity-coordinate_system"
    ],
    [
      "Entity-affordance_mapping",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-hdgi__timestamp",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-this_view",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-eight_section_of_upper_limb_region",
      "skos:broader",
      "Entity-human_s_upper_limb_region"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-gesture_type"
    ],
    [
      "Entity-sensor-independent_ontology",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-arm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-finger_pose",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-arm-based_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-rationale_behind_such_a_design",
      "skos:broader",
      "Entity-rationale"
    ],
    [
      "Entity-each_hdgi__movement",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-hdgi__footpose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-eight_atomic_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-gesture_a",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-context",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__legpose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__involves",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-element_observed_from_existing_gesture_vocabulary",
      "skos:broader",
      "Entity-gesture-related_vocabulary"
    ],
    [
      "Entity-the_challenge_of_how_to_increase_the_knowledge_level_of_computational_system",
      "skos:broader",
      "Entity-knowledge"
    ],
    [
      "Entity-hdgi__yaxisdirection",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-geometrical_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_recognition_software_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-device_manufacturer",
      "skos:broader",
      "Entity-manufacturer"
    ],
    [
      "Entity-6_command__43_gesture_",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-their_other_hand",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__observableaffordance",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-touchscreen",
      "skos:broader",
      "Entity-interface"
    ],
    [
      "Entity-emerging_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-right_forearm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-human_upper_limb_region_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-range_of_the_property",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-static_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-typing_command",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-the_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-brown_et_al_.",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-the_shape_and_dynamic_of_a_certain_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-dynamic",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-gesture_set",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-interface",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-api-driven_restful_web_service",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-sosa__actuator",
      "skos:broader",
      "Entity-actuator"
    ],
    [
      "Entity-owl2",
      "skos:broader",
      "Entity-semantic_web"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-human_behavior"
    ],
    [
      "Entity-device",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-upper_arm"
    ],
    [
      "Entity-gesture_recognition_software_tool",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-solo",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-different_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-sequence_of_gesture"
    ],
    [
      "Entity-gesture_subclass",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__movement",
      "skos:broader",
      "Entity-gesture_type"
    ],
    [
      "Entity-existing_gesture_recognition_system",
      "skos:broader",
      "Entity-gesture_recognition_device"
    ],
    [
      "Entity-best_gesture_",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-the_capability_of_identifying_the_relationship",
      "skos:broader",
      "Entity-capability"
    ],
    [
      "Entity-existing_research_using_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-gesture-related_vocabulary"
    ],
    [
      "Entity-eight_section_of_upper_limb_region",
      "skos:broader",
      "Entity-upper_limb_of_the_human_body"
    ],
    [
      "Entity-bmw__s_idrive_infotainment_system",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-their_own_private_cloud",
      "skos:broader",
      "Entity-private_cloud"
    ],
    [
      "Entity-hdgi__littlefinger",
      "skos:broader",
      "Entity-finger"
    ],
    [
      "Entity-emerging_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-upper_limb",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__device",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-leap-motion_sdk",
      "skos:broader",
      "Entity-existing_gesture_recognition_system"
    ],
    [
      "Entity-gesture_subclass",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-static_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-relative_position",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-research",
      "skos:broader",
      "Entity-study"
    ],
    [
      "Entity-foundational_model_of_anatomy",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-user_s_choice_of_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_a",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-upper_limb_related_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-mid-air_gesture",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-multiple_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-a_search_query",
      "skos:broader",
      "Entity-search_query"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-intrinsic_and_extrinsic_property",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__hasrotation",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-modern_automobile",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-universal_and_existential_class_restriction",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-atomic_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-size_or_speed_of_hand_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_repository",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-developer",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-communication"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-restful_apis",
      "skos:broader",
      "Entity-interface"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-a_particular_gesture"
    ],
    [
      "Entity-notation_method",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-gesture_representation",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-restful_apis",
      "skos:broader",
      "Entity-restful"
    ],
    [
      "Entity-sensor-independent_ontology",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-upper_arm"
    ],
    [
      "Entity-hdgi-service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-appropriate_technique",
      "skos:broader",
      "Entity-technique"
    ],
    [
      "Entity-human_upper_limb_region_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-design",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-rotation_change",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-the_result_of_this_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__middlefinger",
      "skos:broader",
      "Entity-finger"
    ],
    [
      "Entity-gesture_set",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gesture-controlled_interface",
      "skos:broader",
      "Entity-arm-based_gesture"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-human_s_upper_limb_region",
      "skos:broader",
      "Entity-upper_arm"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-finger_pose",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-their_relationship",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-ontology",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-semantic_model_of_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-human_upper_limb_region_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_rotation_of_a_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-the_icon",
      "skos:broader",
      "Entity-icon"
    ],
    [
      "Entity-hdgi__context",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_set",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gesture_recognition_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-a_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi-service_endpoint",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-6_command__43_gesture_",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-user__s_right_arm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-pose_modeling"
    ],
    [
      "Entity-xposition",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_selection",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-internet_of_thing__iot__system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-manufacturer__s_design_decision",
      "skos:broader",
      "Entity-manufacturer"
    ],
    [
      "Entity-human_device_interaction",
      "skos:broader",
      "Entity-communication"
    ],
    [
      "Entity-sosa__actuatableproperty",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-emerging_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-local_coordinate_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-observation",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-static_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-predefined_mapping_of_a_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-the_shape_and_dynamic_of_a_certain_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-necessary_affordances",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-6_command__43_gesture_",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdi",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-movement",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-foundational_model_of_anatomy__fma_",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-swagger_codegen",
      "skos:broader",
      "Entity-documentation"
    ],
    [
      "Entity-mid-air_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-interface",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-emerging_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-a_new_namespace_http__w3id.orghdgi",
      "skos:broader",
      "Entity-namespace"
    ],
    [
      "Entity-static_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-one_or_more_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-leap-motion_sdk",
      "skos:broader",
      "Entity-gesture_recognition_device"
    ],
    [
      "Entity-affordance_y",
      "skos:broader",
      "Entity-feature"
    ],
    [
      "Entity-designer_and_manufacturer",
      "skos:broader",
      "Entity-designer"
    ],
    [
      "Entity-notation_method",
      "skos:broader",
      "Entity-technique"
    ],
    [
      "Entity-corresponding_affordances",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-tv",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-this_notation",
      "skos:broader",
      "Entity-notation"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__upperarm_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-bloom__gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-predefined_mapping_of_a_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__zrotation",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-gestural_interface",
      "skos:broader",
      "Entity-the_design_and_development_of_gestural_interface"
    ],
    [
      "Entity-hdgi__human",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-left-hand_rule_coordinate_system",
      "skos:broader",
      "Entity-coordinate_system"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-interaction_intention",
      "skos:broader",
      "Entity-user_intent"
    ],
    [
      "Entity-new_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-human-computer_interaction__hci_",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-previous_study",
      "skos:broader",
      "Entity-study"
    ],
    [
      "Entity-w3id.org",
      "skos:broader",
      "Entity-the_permanent_url_service"
    ],
    [
      "Entity-the_provided_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-mapping_to_concept_and_property",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-equivalent_class_and_property",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-atomic_gesture"
    ],
    [
      "Entity-affordance_of_answering_a_call_in_a_car",
      "skos:broader",
      "Entity-context"
    ],
    [
      "Entity-riener_et_al_.",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-device_affordances",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-infinite_set_of_concept__feature__attribute__and_relationship",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-smart_home",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-the_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-gesture_interaction",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-affordance_of_answering_a_call_in_a_car",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-conventional_control",
      "skos:broader",
      "Entity-user_experience"
    ],
    [
      "Entity-a_movement",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-web_service_interface",
      "skos:broader",
      "Entity-interface"
    ],
    [
      "Entity-gesture_data",
      "skos:broader",
      "Entity-gesture_interaction"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-hdgi__usercontext",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-sequence_of_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hdgi_mapping",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-notation_method",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-the_icon_that_appears_near_the_wrist",
      "skos:broader",
      "Entity-the_icon"
    ],
    [
      "Entity-ar",
      "skos:broader",
      "Entity-immersive_technology"
    ],
    [
      "Entity-user_context",
      "skos:broader",
      "Entity-context"
    ],
    [
      "Entity-new_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-mapping_to_concept_and_property",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-multiple_movement_and_pose_of_body_part",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-gestural_sign",
      "skos:broader",
      "Entity-symbol"
    ],
    [
      "Entity-microsoft_kinect",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-the_provided_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-effect_of_a_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-interconnected_knowledge_base",
      "skos:broader",
      "Entity-knowledge_base"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-hdgi__devicemanufacturer",
      "skos:broader",
      "Entity-manufacturer"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-systematic_analysis_and_description_of_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-developer",
      "skos:broader",
      "Entity-a_user_(2)"
    ],
    [
      "Entity-example_model",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-anyone_interested_to_join_a_a_contributor",
      "skos:broader",
      "Entity-contributor"
    ],
    [
      "Entity-khairunizam_et_al_.",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-an_ontology_(1)",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__context",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-a_comprehensive_view_of_the_api",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-modelling_the_infinite_set_of_concept__feature__attribute__and_relationship",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-experiment",
      "skos:broader",
      "Entity-study"
    ],
    [
      "Entity-upper_arm_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-api_documentation",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-pitch",
      "skos:broader",
      "Entity-rotation"
    ],
    [
      "Entity-gesture_recognition_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-ge",
      "skos:broader",
      "Entity-gesture-referent_mapping"
    ],
    [
      "Entity-predefined_mapping_of_a_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-all_class_and_relationship",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-internet_of_thing__iot__system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-3d_hand_gesture_taxonomy",
      "skos:broader",
      "Entity-taxonomy"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-mid-air_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-relationship_introduced_in_hdgi",
      "skos:broader",
      "Entity-hdgi"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-predefined_mapping_of_a_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__usercontext",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-a_swipe_gesture_",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-haslocalcoordinatesystem",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-manufacturer-defined_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-this_core_ontology_design_pattern",
      "skos:broader",
      "Entity-ontology_design_pattern_initiative"
    ],
    [
      "Entity-upper_arm_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-multiple_movement_and_pose_of_body_part",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-43_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-each_different_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-hdgi__affordance",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-human_upper_limb_region_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi-mapping_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-hand",
      "skos:broader",
      "Entity-human_body"
    ],
    [
      "Entity-mid-air_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gestural_interface",
      "skos:broader",
      "Entity-gestural_information"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-virtual_reality",
      "skos:broader",
      "Entity-vr"
    ],
    [
      "Entity-villarreal-narvaez",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-affordances_of_a_device",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_set",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__palm",
      "skos:broader",
      "Entity-upper_limb"
    ],
    [
      "Entity-endpoint",
      "skos:broader",
      "Entity-interface"
    ],
    [
      "Entity-start_hdgi__pose",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-user",
      "skos:broader",
      "Entity-actor"
    ],
    [
      "Entity-choi_et_al_.",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-manufacturers-devices",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-start_pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-a_set_of_predefined_sparql_endpoint",
      "skos:broader",
      "Entity-endpoint"
    ],
    [
      "Entity-hdgi__timestamp",
      "skos:broader",
      "Entity-timestamp"
    ],
    [
      "Entity-finger_pose",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-knowledge_of_the_arm_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-new_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-each_body_part",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-ubiquitousness_in_human-device_gesture_interaction",
      "skos:broader",
      "Entity-problem"
    ],
    [
      "Entity-the_provided_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-it_own_namespace",
      "skos:broader",
      "Entity-namespace"
    ],
    [
      "Entity-human_s_upper_limb_region",
      "skos:broader",
      "Entity-upper_limb_of_the_human_body"
    ],
    [
      "Entity-hand_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gestural_information",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-6_command__43_gesture_",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-foundational_model_of_anatomy",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-user_s_choice_of_gesture",
      "skos:broader",
      "Entity-human_behavior"
    ],
    [
      "Entity-holistic_posture",
      "skos:broader",
      "Entity-human_body"
    ],
    [
      "Entity-user_need",
      "skos:broader",
      "Entity-user_experience"
    ],
    [
      "Entity-upper_arm",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-emerging_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-rdf",
      "skos:broader",
      "Entity-semantic_web_standard"
    ],
    [
      "Entity-new_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-static_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-the_shape_and_dynamic_of_a_certain_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-designer",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-similar_referent",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-the_provided_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-different_coordinate_system",
      "skos:broader",
      "Entity-coordinate_system"
    ],
    [
      "Entity-mid-air_gesture_of_the_human_body",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-a_gesture_(1)",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-smart_home",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-mapping_service",
      "skos:broader",
      "Entity-web_application"
    ],
    [
      "Entity-hdgi__yaxisdirection",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__xaxisdirection",
      "skos:broader",
      "Entity-axis_direction"
    ],
    [
      "Entity-affordance_y",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-semantic_web_standard",
      "skos:broader",
      "Entity-standard"
    ],
    [
      "Entity-private_cloud",
      "skos:broader",
      "Entity-cloud"
    ],
    [
      "Entity-upper_limb_region",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-upper_arm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi_ontology",
      "skos:broader",
      "Entity-hdgi"
    ],
    [
      "Entity-solo",
      "skos:broader",
      "Entity-gesture_recognition_device"
    ],
    [
      "Entity-range_of_the_property",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-device_interaction",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-hand",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-hand-gesture_supported_system"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-hdgi__observer",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-sample_mapping_service",
      "skos:broader",
      "Entity-web_application"
    ],
    [
      "Entity-core_ontology_design_pattern",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-pinch_their_thumb_and_index_finger_together",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-element_observed_from_existing_gesture_vocabulary",
      "skos:broader",
      "Entity-element"
    ],
    [
      "Entity-upper_arm_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__bodypart",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__xrotation",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-hdgi__observableaffordance",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-different_gesture"
    ],
    [
      "Entity-author",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-our_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-this_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture-related_vocabulary",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-mapping_to_concept_and_property",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-affordance_of_answering_a_call_in_a_car",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-further_body_part",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_a",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-upper_limb",
      "skos:broader",
      "Entity-human_body"
    ],
    [
      "Entity-upper_limb_region",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-maier_et_al_.",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-upper_arm_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-hdgi__bodypart",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-the_device",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-architecture_documentation",
      "skos:broader",
      "Entity-documentation"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-gesture_representation"
    ],
    [
      "Entity-scoditti_et_al_.",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-semantic_web",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-pinch_their_thumb_and_index_finger_together",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-manufacturer-defined_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__localcoordinatesystem_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-existing_gesture_recognition_system"
    ],
    [
      "Entity-an_arm_gesture",
      "skos:broader",
      "Entity-arm"
    ],
    [
      "Entity-web_service_interface",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-foundational_model_of_anatomy__fma_",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-different_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-a_user",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture-related_vocabulary",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-gesture_type"
    ],
    [
      "Entity-each_different_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-manufacturer-defined_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-holistic_posture",
      "skos:broader",
      "Entity-the_human_body"
    ],
    [
      "Entity-gesture_a",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-microsoft_hololens",
      "skos:broader",
      "Entity-augmented_reality"
    ],
    [
      "Entity-time_stamp",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-commonly_used_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__position",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-best_gesture_",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-different_expectation",
      "skos:broader",
      "Entity-expectation"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-human_device_interaction",
      "skos:broader",
      "Entity-user_experience"
    ],
    [
      "Entity-integration_and_documentation",
      "skos:broader",
      "Entity-documentation"
    ],
    [
      "Entity-upper_arm_position",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-roll",
      "skos:broader",
      "Entity-rotation"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-arm"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-gesture_representation"
    ],
    [
      "Entity-hdgi__xaxisdirection",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-communication"
    ],
    [
      "Entity-user_s_choice_of_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-interactive_information",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-body",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-gesture_elicitation_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-gesture_to_answer_a_call_in_a_car",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__observableaffordance",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-several_possible_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-mapping_different_gesture_with_their_semantic_relationship_to_affordances",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-sosa__sensor",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gestural_interaction_taxonomy",
      "skos:broader",
      "Entity-taxonomy"
    ],
    [
      "Entity-predefined_mapping_of_a_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__leggesture",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-a_user_(2)"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-oculus_quest",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-semantics"
    ],
    [
      "Entity-the_movement_of_the_user__s_right_arm",
      "skos:broader",
      "Entity-arm"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-upper_limb_region"
    ],
    [
      "Entity-semantical_relationship",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-commonly_used_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-mid-air_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-size_or_speed_of_hand_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-best_gesture_",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-research_community",
      "skos:broader",
      "Entity-community"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi-mapping_service",
      "skos:broader",
      "Entity-apis"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-hdgi__observableaffordance",
      "skos:broader",
      "Entity-affordance_x"
    ],
    [
      "Entity-gesture_representation",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-new_movement",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-affordance_x",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-a_particular_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-human_device_interaction",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-personalization_of_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-the_term_affordance",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-received_data",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-pinch_their_thumb_and_index_finger_together",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_alignment_of_the_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hand_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-rotation_",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-the_problem_of_having_different_origin_point",
      "skos:broader",
      "Entity-problem"
    ],
    [
      "Entity-these_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-eight_section_of_upper_limb_region",
      "skos:broader",
      "Entity-upper_limb"
    ],
    [
      "Entity-an_example_of_a_pose_modeling",
      "skos:broader",
      "Entity-pose_modeling"
    ],
    [
      "Entity-user_intent",
      "skos:broader",
      "Entity-intent"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-the_start_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-all_these_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-feature_of_interest",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-their_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-semantic_model_of_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-new_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-seven_main_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-pinch_their_thumb_and_index_finger_together",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-size_or_speed_of_hand_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture-related_vocabulary",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-the_provided_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-software_development_kit",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-hdgi__context",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-supported_gesture",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-a_dictionary_for_manufacturer__designer__and_developer",
      "skos:broader",
      "Entity-dictionary"
    ],
    [
      "Entity-gesture_recognition_device_configuration",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-gesture_recognition_device"
    ],
    [
      "Entity-restful_endpoint",
      "skos:broader",
      "Entity-endpoint"
    ],
    [
      "Entity-the_capability_of_identifying_the_relationship",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-hdgi__zrotation",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_selection",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent_to_a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-all_class_and_relationship",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture-related_vocabulary",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-sosa__actuatableproperty",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-device_b",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-upper_limb_region",
      "skos:broader",
      "Entity-upper_limb"
    ],
    [
      "Entity-currently_available_and_contemporary_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-limb",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-gesture_a",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-human-computer_interaction__hci_",
      "skos:broader",
      "Entity-hci"
    ],
    [
      "Entity-body-based_contextual_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__localcoordinatesystem",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__hasposition",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-end_hdgi__pose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-relevant_mapping_to_device_affordances",
      "skos:broader",
      "Entity-device_affordances"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-the_gestural_sign",
      "skos:broader",
      "Entity-gestural_sign"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-gesture_recognition_device"
    ],
    [
      "Entity-existing_research",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-coordinate_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-human_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-infinite_set_of_concept__feature__attribute__and_relationship",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi_ontology",
      "skos:broader",
      "Entity-semantic_model"
    ],
    [
      "Entity-the_relevant_code",
      "skos:broader",
      "Entity-code"
    ],
    [
      "Entity-hdgi__pose_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-commonly_used_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-one_or_more_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__affordance",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-sosa__actuatableproperty",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-relationship_between_each_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-start_hdgi__pose",
      "skos:broader",
      "Entity-instance"
    ],
    [
      "Entity-gesture_selection",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-user_specific_gesture_semantics",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-one_or_more_pose_(1)",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-geometrical_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-personalization_of_gesture",
      "skos:broader",
      "Entity-personalization"
    ],
    [
      "Entity-upper_arm_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-bloom__gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-the_proposed_taxonomy_and_notation_method",
      "skos:broader",
      "Entity-taxonomy"
    ],
    [
      "Entity-gesture_related_to_device_interaction",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-predefined_mapping",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-commonly_used_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gesture_to_answer_a_call_in_a_car",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-position_change",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-gesture_subclass",
      "skos:broader",
      "Entity-gesture_type"
    ],
    [
      "Entity-hdgi__human",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-device",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-fma",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-actuator",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-extensibility",
      "skos:broader",
      "Entity-feature"
    ],
    [
      "Entity-a_user",
      "skos:broader",
      "Entity-a_user_(2)"
    ],
    [
      "Entity-conventional_control",
      "skos:broader",
      "Entity-interface"
    ],
    [
      "Entity-gesture_elicitation_study__ge_",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_relevant_code__data__and_ontology",
      "skos:broader",
      "Entity-data"
    ],
    [
      "Entity-hdgi-service_endpoint",
      "skos:broader",
      "Entity-endpoint"
    ],
    [
      "Entity-existing_gesture_vocabulary",
      "skos:broader",
      "Entity-gesture-related_vocabulary"
    ],
    [
      "Entity-rotation_change",
      "skos:broader",
      "Entity-rotation"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-the_research_community",
      "skos:broader",
      "Entity-community"
    ],
    [
      "Entity-one_or_more_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture_to_answer_a_call_in_a_car",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-interoperability_among_interface",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__legpose",
      "skos:broader",
      "Entity-pose_modeling"
    ],
    [
      "Entity-tool_for_mapping_hdgi_v0.1_to_leap_motion_and_the_oculus_quest_device",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-affordance",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-arm_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-relationship_between_gesture_and_device_affordances",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-ge",
      "skos:broader",
      "Entity-predefined_mapping_of_a_gesture"
    ],
    [
      "Entity-manufacturer-defined_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-redundant_gesture_vocabulary",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-technique",
      "skos:broader",
      "Entity-approach"
    ],
    [
      "Entity-a_hdgi__devicemanufacturer_relationship",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-human_device_interaction",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-personalization_of_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-bloom__gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-biological_concept",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-relationship_introduced_in_hdgi",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-existing_gesture_vocabulary",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-size_or_speed_of_hand_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-similar_referent",
      "skos:broader",
      "Entity-referent"
    ],
    [
      "Entity-equivalent_class_and_property",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-class",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-gesture_subclass",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-human_device_gesture_interaction"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-designer_and_manufacturer",
      "skos:broader",
      "Entity-manufacturer"
    ],
    [
      "Entity-semantic_sensor_network",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-turtle_syntax",
      "skos:broader",
      "Entity-syntax"
    ],
    [
      "Entity-this_variety",
      "skos:broader",
      "Entity-variety"
    ],
    [
      "Entity-swagger_codegen",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-gesture_type",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-personalization_of_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-tv_and_blind",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-automated_reasoning_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-gesture_type"
    ],
    [
      "Entity-43_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-many_researcher",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-existing_research_using_ontology",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-action"
    ],
    [
      "Entity-quaternion",
      "skos:broader",
      "Entity-rotation"
    ],
    [
      "Entity-concept_and_property_in_these_ontology",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-systematic_analysis_and_description_of_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-villarreal-narvaez",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-java_version_1.9_or_higher",
      "skos:broader",
      "Entity-java"
    ],
    [
      "Entity-potential_human_behavior",
      "skos:broader",
      "Entity-human"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-end_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-gesture_repository",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-multiple_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-multiple_movement_and_pose_of_body_part",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-existing_gesture_vocabulary",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-human_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-currently_available_and_contemporary_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-namespace",
      "skos:broader",
      "Entity-context"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-gesture_type"
    ],
    [
      "Entity-allen_time",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-sensor-independent_ontology",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-arm-based_gesture",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-forearmpose",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__device",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-gesture_selection",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__facialgesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gestural_input",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-5_geometrical_shape",
      "skos:broader",
      "Entity-geometrical_shape"
    ],
    [
      "Entity-systematic_analysis_and_description_of_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__observer",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-start_hdgi__pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-mid-air_gesture_of_the_human_body",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_recognition_system",
      "skos:broader",
      "Entity-gesture_recognition_device"
    ],
    [
      "Entity-third_party_software_development_kit_and_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-one_or_more_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-a_user_(2)",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-coordinate_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-human_upper_limb_region_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture_recognition_device",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-semantic_web_standard__rdf__rdfs__and_owl2_",
      "skos:broader",
      "Entity-semantic_web"
    ],
    [
      "Entity-hdgi__affordance",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-pinch_their_thumb_and_index_finger_together",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-call",
      "skos:broader",
      "Entity-communication"
    ],
    [
      "Entity-action",
      "skos:broader",
      "Entity-human_behavior"
    ],
    [
      "Entity-gesture_type",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_set",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hand_gesture_recognition",
      "skos:broader",
      "Entity-problem"
    ],
    [
      "Entity-this_core_ontology_design_pattern",
      "skos:broader",
      "Entity-core_ontology_design_pattern"
    ],
    [
      "Entity-geometrical_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-upper_limb"
    ],
    [
      "Entity-microsoft_hololens",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-palm_and_finger_position",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-their_preferred_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-user_experience__mbux_",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-review_conducted_by_villarreal_narvaez_et_al_._in_2020",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-upper_arm"
    ],
    [
      "Entity-one_or_more_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-various_application",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-hdgi__devicemanufacturer",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-gesture-related_vocabulary",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-this_paper",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-human_device_interaction__hdi_",
      "skos:broader",
      "Entity-human-computer_interaction"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-better_user_experience",
      "skos:broader",
      "Entity-user_experience__ux_"
    ],
    [
      "Entity-expressive_power_of_our_ontology",
      "skos:broader",
      "Entity-evaluation"
    ],
    [
      "Entity-developer",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-communication"
    ],
    [
      "Entity-6_command__43_gesture_",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-device_affordances",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-bloom__gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gestural_information",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-upper_limb_of_the_human_body",
      "skos:broader",
      "Entity-the_human_body"
    ],
    [
      "Entity-affordance_x",
      "skos:broader",
      "Entity-capability"
    ],
    [
      "Entity-emerging_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-arm-based_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-static_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-upper_arm",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-eight_atomic_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-affordance",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-upper_limb_region",
      "skos:broader",
      "Entity-human_s_upper_limb_region"
    ],
    [
      "Entity-solo",
      "skos:broader",
      "Entity-gesture_recognition_software_tool"
    ],
    [
      "Entity-redundant_gesture_vocabulary",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__hasrotation",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-start_icon",
      "skos:broader",
      "Entity-icon"
    ],
    [
      "Entity-virtual_reality",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-sosa__sensor",
      "skos:broader",
      "Entity-sensor"
    ],
    [
      "Entity-data",
      "skos:broader",
      "Entity-knowledge"
    ],
    [
      "Entity-their_preferred_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__movement",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-bodypart",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-existing_gesture_vocabulary",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__rotation",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__ringfinger",
      "skos:broader",
      "Entity-finger"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-designer_and_researcher",
      "skos:broader",
      "Entity-researcher"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-gesture_recognition_system"
    ],
    [
      "Entity-redundant_gesture_vocabulary",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-higher_accuracy",
      "skos:broader",
      "Entity-accuracy"
    ],
    [
      "Entity-hdgi__includesgesture",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-commonly_used_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__forearmgesture",
      "skos:broader",
      "Entity-gesture_subclass"
    ],
    [
      "Entity-gesture_that_do_not_carry_a_referent",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-a_hdgi__pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__actuatableaffordance",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-gestural_information",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-leading_hand-gesture_supported_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-existing_gesture_vocabulary",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_current_literature",
      "skos:broader",
      "Entity-literature"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-different_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-upper_limb"
    ],
    [
      "Entity-user__s_expectation",
      "skos:broader",
      "Entity-expectation"
    ],
    [
      "Entity-upper_arm",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-mapping_of_other_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-gesture_repository",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gesture_to_answer_a_call_in_a_car",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__upperarmgesture",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-it_associated_knowledge",
      "skos:broader",
      "Entity-knowledge"
    ],
    [
      "Entity-semantic_relationship",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-hdgi__observableaffordance",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-smart_home",
      "skos:broader",
      "Entity-automated_system"
    ],
    [
      "Entity-facial_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-arm_movement",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-human_s_upper_limb_region",
      "skos:broader",
      "Entity-upper_limb"
    ],
    [
      "Entity-new_pose",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-hdgi__footpose",
      "skos:broader",
      "Entity-hdgi__pose"
    ],
    [
      "Entity-systematic_analysis_and_description_of_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_web_application",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-gesture_vocabulary",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-sosa",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-sensor-independent_ontology",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-dynamic_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-upper_limb_region",
      "skos:broader",
      "Entity-upper_limb_of_the_human_body"
    ],
    [
      "Entity-hdgi__yposition",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-user_s_choice_of_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__xaxisdirection",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-upper_limb_related_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-the_problem_of_the_absence_of_a_systematic_analysis_and_description_of_gesture",
      "skos:broader",
      "Entity-problem"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hdgi__position",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hand_gesture",
      "skos:broader",
      "Entity-human-computer_interaction__hci_"
    ],
    [
      "Entity-interoperability_among_interface",
      "skos:broader",
      "Entity-interface"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-computer_game",
      "skos:broader",
      "Entity-product"
    ],
    [
      "Entity-expressive_power",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-affordance_mapping",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-expectation",
      "skos:broader",
      "Entity-user_experience__ux_"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-modelling_the_infinite_set_of_concept__feature__attribute__and_relationship",
      "skos:broader",
      "Entity-modelling"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-how-to__documentation",
      "skos:broader",
      "Entity-documentation"
    ],
    [
      "Entity-personalization_of_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-atomic_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-osumar_et_al_.",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-sosa__platform",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-detail_like_the_finger_pose_or_movement",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-hdgi__zrotation",
      "skos:broader",
      "Entity-rotation"
    ],
    [
      "Entity-hdgi__quaternion",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-microsoft_kinect",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-ontology_engineering",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__zaxisdirection",
      "skos:broader",
      "Entity-axis_direction"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-finger_pose",
      "skos:broader",
      "Entity-physical_movement"
    ],
    [
      "Entity-their_preferred_gesture",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hand_gesture",
      "skos:broader",
      "Entity-communication"
    ],
    [
      "Entity-gesture_representation",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-wobbrock_et_al_.",
      "skos:broader",
      "Entity-author"
    ],
    [
      "Entity-ontology_building_and_annotating",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__handgesture",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-observed_property",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-human_device_gesture_interaction",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__observableaffordance",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-augmented_reality",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-their_preferred_gesture",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-the_cloud",
      "skos:broader",
      "Entity-cloud"
    ],
    [
      "Entity-gestural_information",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-hand__forearm__and_upper_arm_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-pose_modeling",
      "skos:broader",
      "Entity-modeling"
    ],
    [
      "Entity-gestural_interaction_taxonomy",
      "skos:broader",
      "Entity-gestural_interface"
    ],
    [
      "Entity-sosa",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-semantic_model_of_gesture",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__supportsgesture",
      "skos:broader",
      "Entity-relationship"
    ],
    [
      "Entity-a_particular_actor",
      "skos:broader",
      "Entity-actor"
    ],
    [
      "Entity-predefined_mapping_of_a_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-currently_available_and_contemporary_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__upperarm",
      "skos:broader",
      "Entity-human_s_upper_limb_region"
    ],
    [
      "Entity-gestural_sign",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-relevant_class",
      "skos:broader",
      "Entity-hdi"
    ],
    [
      "Entity-specific_property",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-a_particular_affordance_of_a_device",
      "skos:broader",
      "Entity-certain_affordances"
    ],
    [
      "Entity-shape",
      "skos:broader",
      "Entity-property"
    ],
    [
      "Entity-gestural_information",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-gesture_used_in_human_device_interaction__hdi_",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-related_referent",
      "skos:broader",
      "Entity-referent"
    ],
    [
      "Entity-gesture-based_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-one_or_more_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-relative_position",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-a_particular_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-turtle",
      "skos:broader",
      "Entity-syntax"
    ],
    [
      "Entity-end_user",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-gesture_representation",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-geometrical_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-human_s_upper_limb_region"
    ],
    [
      "Entity-the_web_application_(1)",
      "skos:broader",
      "Entity-application"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-the_pose_and_movement_of_human_upper_limb",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-atomic_gesture",
      "skos:broader",
      "Entity-movement"
    ],
    [
      "Entity-leading_hand-gesture_supported_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-gestural_sign",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-a_tv",
      "skos:broader",
      "Entity-tv"
    ],
    [
      "Entity-interoperability_among_interface",
      "skos:broader",
      "Entity-interoperability"
    ],
    [
      "Entity-new_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-timestamp",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-hdgi__movement_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-effect_of_a_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-the_problem_of_hand_gesture_recognition",
      "skos:broader",
      "Entity-problem"
    ],
    [
      "Entity-the_provided_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-hdgi__thumbcurled",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-zposition",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-opensource_project",
      "skos:broader",
      "Entity-opensource"
    ],
    [
      "Entity-right_hand",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-hdgi__zaxisdirection",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-gesture_right_hand_swipe_left_",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture-related_semantics",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-forearm",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-hdgi__indexfinger",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-gesture-referent_mapping",
      "skos:broader",
      "Entity-mapping"
    ],
    [
      "Entity-sensor",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-knowledge_of_ge",
      "skos:broader",
      "Entity-ge"
    ],
    [
      "Entity-a_particular_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-the_semantics_of_these_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-global_domain_and_range_restriction",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-hdgi__finger_class",
      "skos:broader",
      "Entity-class"
    ],
    [
      "Entity-redundant_gesture_vocabulary",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi__position",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-detail_like_the_finger_pose_or_movement",
      "skos:broader",
      "Entity-finger_pose"
    ],
    [
      "Entity-individual_study",
      "skos:broader",
      "Entity-research"
    ],
    [
      "Entity-gesture_ontology",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-user_gesture",
      "skos:broader",
      "Entity-user"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-github_code_repository",
      "skos:broader",
      "Entity-code"
    ],
    [
      "Entity-existing_gesture_vocabulary",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-gesture-controlled_interface",
      "skos:broader",
      "Entity-hand-gesture_supported_system"
    ],
    [
      "Entity-gesture_subclass",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-future_work",
      "skos:broader",
      "Entity-future_work_(1)"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-human_gesture"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-one_or_more_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-villarreal-narvaez_et_al_._s_most_recent_survey_paper",
      "skos:broader",
      "Entity-paper"
    ],
    [
      "Entity-hdgi__finger",
      "skos:broader",
      "Entity-upper_limb_of_the_human_body"
    ],
    [
      "Entity-microsoft_kinect",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-the_presented_ontology",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-movement_of_multiple_body_part",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-mapping_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-user_s_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-forearm",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-separate_ontology_file",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-their_own_preference",
      "skos:broader",
      "Entity-preference"
    ],
    [
      "Entity-the_alignment_of_the_ontology",
      "skos:broader",
      "Entity-alignment"
    ],
    [
      "Entity-hdgi__affordance",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-human_s_upper_limb_region"
    ],
    [
      "Entity-relationship_between_each_gesture",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-universal_gesture_standard",
      "skos:broader",
      "Entity-gesture"
    ],
    [
      "Entity-gesture_affordance_mapping",
      "skos:broader",
      "Entity-hand_gesture_recognition"
    ],
    [
      "Entity-upper_arm_gesture",
      "skos:broader",
      "Entity-an_arm_gesture"
    ],
    [
      "Entity-gesture_repository",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-automated_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-commonly_used_gesture_for_certain_affordances",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-small-scale_user_study",
      "skos:broader",
      "Entity-user_study"
    ],
    [
      "Entity-hdgi__forearmpose",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-start_pose",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-hdgi__duration",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-sample_mapping_service",
      "skos:broader",
      "Entity-service"
    ],
    [
      "Entity-swagger_ui",
      "skos:broader",
      "Entity-api_and_architecture_documentation"
    ],
    [
      "Entity-rdf",
      "skos:broader",
      "Entity-standard"
    ],
    [
      "Entity-virtual_reality",
      "skos:broader",
      "Entity-immersive_technology"
    ],
    [
      "Entity-gesture",
      "skos:broader",
      "Entity-physical_movement"
    ],
    [
      "Entity-gestural_sign",
      "skos:broader",
      "Entity-hand_gesture"
    ],
    [
      "Entity-http__w3id.orghdgi",
      "skos:broader",
      "Entity-ontology"
    ],
    [
      "Entity-sensor-independent_ontology",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-local_coordinate_system",
      "skos:broader",
      "Entity-system_(1)"
    ],
    [
      "Entity-tv",
      "skos:broader",
      "Entity-device"
    ],
    [
      "Entity-upper_limb_of_the_human_body",
      "skos:broader",
      "Entity-body_part"
    ],
    [
      "Entity-a_user_(3)",
      "skos:broader",
      "Entity-a_user_(1)"
    ],
    [
      "Entity-user_s_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-corresponding_affordances",
      "skos:broader",
      "Entity-affordance"
    ],
    [
      "Entity-hdgi__pose",
      "skos:broader",
      "Entity-position"
    ],
    [
      "Entity-ge",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-head_gesture",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-hdgi-gesture_repository",
      "skos:broader",
      "Entity-a_gesture_(1)"
    ],
    [
      "Entity-existing_approach",
      "skos:broader",
      "Entity-approach"
    ],
    [
      "Entity-affordance_x",
      "skos:broader",
      "Entity-the_term_affordance"
    ],
    [
      "Entity-relationship_between_each_gesture",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-the_icon_that_appears_near_the_wrist",
      "skos:broader",
      "Entity-icon"
    ],
    [
      "Entity-universal_gesture_standard",
      "skos:broader",
      "Entity-the_gesture"
    ],
    [
      "Entity-interactive_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-hdgi__forearm",
      "skos:broader",
      "Entity-a_pose"
    ],
    [
      "Entity-gestural_sign",
      "skos:broader",
      "Entity-a_gesture"
    ],
    [
      "Entity-syntax",
      "skos:broader",
      "Entity-concept"
    ],
    [
      "Entity-fma",
      "skos:broader",
      "Entity-biological_concept"
    ]
  ],
  "predicates": {
    "Predicate-are_becoming_popular_with": {
      "label": "are becoming popular with",
      "description": "The predicate 'are becoming popular with' indicates a growing trend or increasing acceptance of the subject among a specific group or category represented by the object. It suggests that the subject is gaining favor, recognition, or usage within the context of the object, reflecting a shift in preferences or practices.",
      "disambiguation_index": 0
    },
    "Predicate-is_related_to": {
      "label": "is related to",
      "description": "The predicate 'is related to' establishes a connection or association between the subject and the object, indicating that they share a relevant relationship or are linked in some meaningful way. This relationship can encompass various forms of connection, such as conceptual, functional, causal, or contextual ties, and does not imply a specific nature or directionality of the relationship.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_type_of": {
      "label": "is a type of",
      "description": "The predicate 'is a type of' establishes a hierarchical relationship between the subject and the object, indicating that the subject belongs to a broader category represented by the object. It signifies that the subject is a specific instance or variation within the classification defined by the object, thereby linking the two in a way that emphasizes the subject's characteristics as part of the larger group.",
      "disambiguation_index": 0
    },
    "Predicate-have_become_prevalent_in": {
      "label": "have become prevalent in",
      "description": "The predicate 'have become prevalent in' indicates a significant increase in the occurrence or acceptance of the subject within the context or domain represented by the object. It suggests that the subject has gained widespread recognition, usage, or importance in relation to the object over a period of time.",
      "disambiguation_index": 0
    },
    "Predicate-integrating": {
      "label": "integrating",
      "description": "The predicate 'integrating' signifies the action of combining or incorporating different elements, components, or systems into a cohesive whole. It implies a process where the subject, which can be a group of individuals or entities, actively works to merge or unify the object, which represents a specific concept, technology, or methodology. This action often involves collaboration, adaptation, and enhancement to create a functional and harmonious integration that serves a particular purpose or improves overall effectiveness.",
      "disambiguation_index": 0
    },
    "Predicate-have_increased_in_numbers": {
      "label": "have increased in numbers",
      "description": "The predicate 'have increased in numbers' indicates a growth or rise in the quantity or presence of the subject, which is typically a group or category of entities. This growth is often quantified or described in relation to the object, which represents the specific items, entities, or aspects that are being affected by this increase. In general, the predicate connects the subject and object by highlighting a change in scale or volume, suggesting that the subject's influence, availability, or representation has expanded in relation to the object.",
      "disambiguation_index": 0
    },
    "Predicate-utilizing": {
      "label": "utilizing",
      "description": "The predicate 'utilizing' indicates that the subject is actively employing or making use of the object in a practical or functional manner. It suggests a relationship where the subject leverages the object to achieve a specific purpose or to enhance its capabilities.",
      "disambiguation_index": 0
    },
    "Predicate-giving_rise_to": {
      "label": "giving rise to",
      "description": "The predicate 'giving rise to' indicates a causal relationship where the subject is the source or cause that leads to the emergence or development of the object. It suggests that the subject contributes to the creation, formation, or increase of the object, implying a dynamic process where the existence or change of the object is a direct result of the influence exerted by the subject.",
      "disambiguation_index": 0
    },
    "Predicate-can_confuse": {
      "label": "can confuse",
      "description": "The predicate 'can confuse' indicates a potential ability of the subject to create uncertainty or misunderstanding in the object. It suggests that the subject possesses characteristics or qualities that may lead to a lack of clarity or difficulty in comprehension for the object, which in this case is typically a person or entity that is trying to understand or interpret the subject.",
      "disambiguation_index": 0
    },
    "Predicate-is_accustomed_to": {
      "label": "is accustomed to",
      "description": "The predicate 'is accustomed to' indicates a state of familiarity or habitual adaptation of the subject towards the object. It suggests that the subject has developed a comfort or routine with the object, often through repeated exposure or experience, leading to an expectation of interaction with the object in a certain way.",
      "disambiguation_index": 0
    },
    "Predicate-has": {
      "label": "has",
      "description": "The predicate 'has' indicates a relationship of possession or ownership between the subject and the object. It signifies that the subject possesses, contains, or is associated with the object, which represents an attribute, quality, or entity that is relevant to the subject. This relationship can encompass physical items, abstract concepts, or characteristics, establishing a connection where the subject is recognized as the holder or bearer of the object.",
      "disambiguation_index": 0
    },
    "Predicate-adjusts_to": {
      "label": "adjusts to",
      "description": "The predicate 'adjusts to' indicates a process in which the subject modifies its behavior, actions, or responses in order to better align with or accommodate the characteristics, requirements, or conditions of the object. This relationship suggests a dynamic interaction where the subject is actively responding to the object, leading to a state of increased compatibility or effectiveness.",
      "disambiguation_index": 0
    },
    "Predicate-are_not_intuitive_and_contrary_to": {
      "label": "are not intuitive and contrary to",
      "description": "The predicate 'are not intuitive and contrary to' establishes a relationship where the subject fails to align with or meet the anticipated understanding or behavior of the object. It indicates a disconnect or mismatch between the inherent qualities or functionalities of the subject and the preconceived notions or expectations held by the object, suggesting that the subject may lead to confusion or frustration due to this lack of intuitiveness.",
      "disambiguation_index": 0
    },
    "Predicate-addresses": {
      "label": "addresses",
      "description": "The predicate 'addresses' indicates that the subject is engaging with, discussing, or providing information about the object. It implies a focus on a particular issue, topic, or concern, suggesting that the subject seeks to clarify, analyze, or propose solutions related to the object.",
      "disambiguation_index": 0
    },
    "Predicate-develops": {
      "label": "develops",
      "description": "The predicate 'develops' indicates an action or process in which the subject engages in the creation, elaboration, or enhancement of the object. It implies a transformation or progression from a less defined state to a more structured or advanced state, where the subject actively contributes to the formation or improvement of the object.",
      "disambiguation_index": 0
    },
    "Predicate-describes": {
      "label": "describes",
      "description": "The predicate 'describes' serves to establish a relationship where the subject provides an explanation, representation, or characterization of the object. It indicates that the subject conveys information or details about the object, thereby enhancing understanding or knowledge regarding the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-is_based_on": {
      "label": "is based on",
      "description": "The predicate 'is based on' establishes a foundational relationship between the subject and the object, indicating that the subject derives its principles, structure, or functionality from the object. It suggests that the subject is built upon, influenced by, or relies upon the object as a source of support or reference.",
      "disambiguation_index": 0
    },
    "Predicate-includes": {
      "label": "includes",
      "description": "The predicate 'includes' establishes a relationship where the subject encompasses or contains the object as a part of its broader category or framework. It indicates that the object is one of the components, elements, or aspects that are part of the subject, suggesting a hierarchical or associative connection between the two.",
      "disambiguation_index": 0
    },
    "Predicate-is_capable_of_describing": {
      "label": "is capable of describing",
      "description": "The predicate 'is capable of describing' establishes a relationship where the subject possesses the ability or potential to convey information, characteristics, or details about the object. This implies that the subject has the necessary attributes, features, or framework to effectively represent or articulate the nature of the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-includes_mappings_to": {
      "label": "includes mappings to",
      "description": "The predicate 'includes mappings to' indicates a relationship where the subject contains or provides a set of connections or correspondences to the object, suggesting that the subject is structured or designed to reference, relate to, or incorporate the object within its framework or system.",
      "disambiguation_index": 0
    },
    "Predicate-is_described_in": {
      "label": "is described in",
      "description": "The predicate 'is described in' establishes a relationship where the subject is characterized or explained through the lens of the object. It indicates that the subject is presented or articulated using the framework, method, or context provided by the object, thereby conveying how the subject can be understood or interpreted.",
      "disambiguation_index": 0
    },
    "Predicate-are_explored_as": {
      "label": "are explored as",
      "description": "The predicate 'are explored as' indicates that the subject is being investigated or examined in the context of the object, suggesting a relationship where the subject is considered or analyzed in terms of its potential, functionality, or application as represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_becoming": {
      "label": "are becoming",
      "description": "The predicate 'are becoming' indicates a process of transformation or evolution where the subject is transitioning into or developing characteristics of the object. It suggests a change in state or identity, implying that the subject is increasingly embodying the qualities or functions associated with the object over time.",
      "disambiguation_index": 0
    },
    "Predicate-consist_of": {
      "label": "consist of",
      "description": "The predicate 'consist of' indicates that the subject is made up of, or is composed of, the elements or components represented by the object. It establishes a relationship where the subject is understood as a whole that includes the specified parts or constituents denoted by the object.",
      "disambiguation_index": 0
    },
    "Predicate-allow": {
      "label": "allow",
      "description": "The predicate 'allow' indicates a relationship where the subject provides permission or enables the object to perform an action or access a resource. In this context, it signifies that the subject facilitates the object in engaging with or utilizing something, thereby granting the object the ability to act or interact in a certain way.",
      "disambiguation_index": 0
    },
    "Predicate-express": {
      "label": "express",
      "description": "The predicate 'express' denotes the action of conveying or communicating thoughts, feelings, or intentions from the subject to the object. In this context, it signifies that the subject actively shares or articulates their internal state or desires, which are represented by the object. This connection highlights the transfer of meaning or sentiment from the individual to the concept or entity being expressed.",
      "disambiguation_index": 0
    },
    "Predicate-send_out": {
      "label": "send out",
      "description": "The predicate 'send out' indicates an action performed by the subject that involves transmitting or distributing something to one or more recipients. In this context, the subject initiates the process of delivering the object, which can be any type of content, data, or information, to others, thereby facilitating communication or sharing.",
      "disambiguation_index": 0
    },
    "Predicate-sent_out_to": {
      "label": "sent out to",
      "description": "The predicate 'sent out to' indicates a transfer or communication of information, data, or signals from a subject to an object, where the subject is the source or origin of the content and the object is the recipient or target that receives the content. This relationship implies a directional flow of information, suggesting that the subject actively disseminates or transmits something to the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_built_based_on": {
      "label": "are built based on",
      "description": "The predicate 'are built based on' indicates that the subject is constructed or developed with reference to the criteria, principles, or decisions represented by the object. It implies a foundational relationship where the object serves as a guiding factor or rationale for the creation or formation of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-emphasize_that": {
      "label": "emphasize that",
      "description": "The predicate 'emphasize that' indicates a strong assertion or highlighting of a particular idea, concept, or fact by the subject. It connects the subject to the object by showing that the subject is drawing attention to the importance or significance of the object, often to persuade or inform an audience about its relevance or value.",
      "disambiguation_index": 0
    },
    "Predicate-must_be_met_with": {
      "label": "must be met with",
      "description": "The predicate 'must be met with' indicates a necessary condition or requirement that the subject is expected to encounter or achieve in relation to the object. It implies that the subject's actions or circumstances should lead to the object being realized or attained, suggesting a sense of obligation or expectation regarding the outcome.",
      "disambiguation_index": 0
    },
    "Predicate-involve": {
      "label": "involve",
      "description": "The predicate 'involve' indicates a relationship where the subject engages in or incorporates the actions, elements, or components represented by the object. It suggests that the subject's activities or processes are characterized by or require the inclusion of the specified actions or methods, highlighting the connection between what the subject is doing and the means or techniques employed.",
      "disambiguation_index": 0
    },
    "Predicate-introduce": {
      "label": "introduce",
      "description": "The predicate 'introduce' signifies the act of presenting or bringing forth a new idea, concept, or entity to an audience or context. It establishes a relationship where the subject is the source or initiator of the introduction, and the object is the new idea or concept being presented. This action often implies a level of explanation or clarification regarding the significance or relevance of the object in relation to the subject.",
      "disambiguation_index": 0
    },
    "Predicate-enables": {
      "label": "enables",
      "description": "The predicate 'enables' indicates a facilitative relationship where the subject provides the means, capability, or opportunity for the object to occur or be realized. It suggests that the subject plays a crucial role in allowing or supporting the object, thereby enhancing the potential for the object to be achieved or utilized.",
      "disambiguation_index": 0
    },
    "Predicate-is_considered": {
      "label": "is considered",
      "description": "The predicate 'is considered' establishes a relationship of perception or evaluation between the subject and the object, indicating that the subject is viewed or regarded in a certain way that aligns with the characteristics or identity of the object. This implies a subjective judgment or consensus about the subject's nature, significance, or classification, suggesting that the subject is recognized or acknowledged as being equivalent to or representative of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_abbreviated_as": {
      "label": "is abbreviated as",
      "description": "The predicate 'is abbreviated as' establishes a relationship between a subject and an object where the subject is a longer or more complex term, phrase, or name, and the object represents a shorter form or acronym that is derived from the subject. This predicate indicates that the object serves as a concise representation of the subject, often used for ease of reference or communication.",
      "disambiguation_index": 0
    },
    "Predicate-is_considered_the_introduction_of": {
      "label": "is considered the introduction of",
      "description": "The predicate 'is considered the introduction of' establishes a relationship where the subject is recognized or acknowledged as the initial or foundational instance of the object. This implies that the subject has played a significant role in the emergence or development of the object, suggesting a historical or conceptual precedence.",
      "disambiguation_index": 0
    },
    "Predicate-attempted_to_define": {
      "label": "attempted to define",
      "description": "The predicate 'attempted to define' indicates an effort or endeavor made by the subject to clarify, explain, or establish the meaning or parameters of the object. It suggests that the subject is actively engaging in a process of interpretation or specification regarding the object, which in this context refers to a concept, term, or category that requires elucidation.",
      "disambiguation_index": 0
    },
    "Predicate-are_limited_in": {
      "label": "are limited in",
      "description": "The predicate 'are limited in' indicates a restriction or constraint that the subject experiences regarding the object. It suggests that the subject has certain boundaries or limitations that affect their capabilities, characteristics, or extent in relation to the object. This connection implies that while the subject may possess certain qualities or potential, these are not fully realized due to the specified limitations.",
      "disambiguation_index": 0
    },
    "Predicate-has_resulted_in": {
      "label": "has resulted in",
      "description": "The predicate 'has resulted in' indicates a causal relationship where the subject has led to or produced the object as a consequence of its actions, characteristics, or existence. It implies that there is a direct connection between the subject and the object, with the subject being the source of change or outcome represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-show": {
      "label": "show",
      "description": "The predicate 'show' indicates that the subject provides evidence, demonstration, or illustration of the object, suggesting a relationship where the subject reveals or makes apparent the characteristics, qualities, or findings represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-refer_to": {
      "label": "refer to",
      "description": "The predicate 'refer to' establishes a relationship between the subject and the object by indicating that the subject is a term, concept, or expression that points to or denotes the object. In this context, the subject is used to signify or identify the object, which is often a specific entity, idea, or referent that the subject is associated with or represents.",
      "disambiguation_index": 0
    },
    "Predicate-refers_to": {
      "label": "refers to",
      "description": "The predicate 'refers to' establishes a relationship in which the subject is associated with or denotes the object, indicating that the subject serves as a representation, symbol, or indication of the object in a conceptual or communicative context.",
      "disambiguation_index": 0
    },
    "Predicate-are": {
      "label": "are",
      "description": "The predicate 'are' serves as a linking verb that establishes an identity or equivalence between the subject and the object. It indicates that the subject is defined or characterized by the object, suggesting that they belong to the same category or share essential qualities.",
      "disambiguation_index": 0
    },
    "Predicate-is_linked": {
      "label": "is linked",
      "description": "The predicate 'is linked' indicates a relationship or connection between the subject and the object, suggesting that they are associated in some meaningful way. This connection can imply a variety of relationships, such as correlation, influence, or relevance, depending on the context in which the subject and object are situated.",
      "disambiguation_index": 0
    },
    "Predicate-are_defined_for": {
      "label": "are defined for",
      "description": "The predicate 'are defined for' establishes a relationship where the subject is characterized or specified in relation to the object, indicating that the subject serves a particular purpose, function, or context that is relevant to the object. This connection implies that the subject is designed or intended to address, represent, or relate to the object in a meaningful way.",
      "disambiguation_index": 0
    },
    "Predicate-conducting": {
      "label": "conducting",
      "description": "The predicate 'conducting' signifies the action performed by the subject, which involves the execution or management of a specific activity or process related to the object. It implies an active engagement in a systematic or organized manner, often associated with research, experiments, or investigations, where the subject is responsible for overseeing or carrying out the tasks necessary to achieve the objectives associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-need": {
      "label": "need",
      "description": "The predicate 'need' establishes a relationship between the subject and the object, indicating that the subject requires or depends on the object for a specific purpose or to achieve a certain goal. It implies a necessity or essential condition where the subject cannot fulfill its objectives or function effectively without the object.",
      "disambiguation_index": 0
    },
    "Predicate-using": {
      "label": "using",
      "description": "The predicate 'using' indicates an action or process in which the subject actively employs or utilizes the object in order to achieve a specific purpose or outcome. It signifies a relationship where the subject leverages the object as a resource, tool, or means to facilitate an activity or to enhance understanding, effectiveness, or efficiency in a given context.",
      "disambiguation_index": 0
    },
    "Predicate-conduct": {
      "label": "conduct",
      "description": "The predicate 'conduct' signifies the action of carrying out, managing, or overseeing a particular activity or process, typically involving systematic effort or organization. It connects the subject, which is the entity performing the action, with the object, which is the activity or process being executed. In this context, the subject is responsible for initiating and guiding the object towards completion or realization.",
      "disambiguation_index": 0
    },
    "Predicate-can_describe": {
      "label": "can describe",
      "description": "The predicate 'can describe' indicates the ability of the subject to provide an explanation, representation, or characterization of the object. It establishes a relationship where the subject conveys information or details about the object, thereby enhancing understanding or knowledge of the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates": {
      "label": "facilitates",
      "description": "The predicate 'facilitates' indicates that the subject enables, supports, or makes easier the process or occurrence of the object. It implies a relationship where the subject contributes positively to the effectiveness or efficiency of the object, often by providing necessary resources, conditions, or frameworks.",
      "disambiguation_index": 0
    },
    "Predicate-define_and_capture": {
      "label": "define and capture",
      "description": "The predicate 'define and capture' indicates an action where the subject establishes a clear understanding or representation of a concept, phenomenon, or object, and simultaneously records or documents it in a way that allows for further analysis, interpretation, or utilization. This process often involves both conceptualization and practical implementation, bridging the gap between theoretical understanding and tangible application.",
      "disambiguation_index": 0
    },
    "Predicate-are_used_in": {
      "label": "are used in",
      "description": "The predicate 'are used in' establishes a relationship where the subject is associated with or employed within the context of the object, indicating that the subject serves a functional role or purpose in the scenarios or fields represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-allows": {
      "label": "allows",
      "description": "The predicate 'allows' indicates that the subject provides the capability or opportunity for the action or state described by the object to occur. It signifies a permissive relationship where the subject enables or facilitates the realization of the object.",
      "disambiguation_index": 0
    },
    "Predicate-advancements_in": {
      "label": "advancements in",
      "description": "The predicate 'advancements in' signifies progress or improvements made in a particular field or area of study, connecting the subject, which represents a specific technology, discipline, or concept, to the object, which denotes the specific aspect, technique, or application that has seen development or enhancement. This relationship highlights the evolution and innovation occurring within the subject area, emphasizing the dynamic nature of the field.",
      "disambiguation_index": 0
    },
    "Predicate-use": {
      "label": "use",
      "description": "The predicate 'use' denotes the action or process by which the subject employs or utilizes the object in a particular context or domain. It signifies a functional relationship where the subject actively engages with the object to achieve a specific purpose or outcome.",
      "disambiguation_index": 0
    },
    "Predicate-have_the_capability_to_detect": {
      "label": "have the capability to detect",
      "description": "The predicate 'have the capability to detect' indicates that the subject possesses the necessary features, tools, or functionalities to identify or recognize the characteristics or presence of the object. It implies a level of proficiency or competence in perceiving or interpreting the object, which in this case refers to a specific type of input or signal.",
      "disambiguation_index": 0
    },
    "Predicate-contributing_to": {
      "label": "contributing to",
      "description": "The predicate 'contributing to' indicates a relationship where the subject plays a significant role in facilitating, enhancing, or leading to the occurrence or increase of the object. It suggests that the subject has a positive impact or influence on the object, resulting in a measurable change or development.",
      "disambiguation_index": 0
    },
    "Predicate-causing": {
      "label": "causing",
      "description": "The predicate 'causing' indicates a relationship where the subject brings about or leads to a specific effect or outcome represented by the object. It implies a causal connection, suggesting that the existence or action of the subject directly influences or results in the changes or variations described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-define": {
      "label": "define",
      "description": "The predicate 'define' indicates an action where the subject articulates, clarifies, or establishes the meaning, characteristics, or parameters of the object. It implies a process of explanation or specification that helps to create a shared understanding of the object among individuals or within a particular context.",
      "disambiguation_index": 0
    },
    "Predicate-evaluate": {
      "label": "evaluate",
      "description": "The predicate 'evaluate' signifies the action of assessing or appraising the quality, effectiveness, or significance of the object by the subject. It implies a process of analysis where the subject examines the object to form a judgment or conclusion based on specific criteria or standards.",
      "disambiguation_index": 0
    },
    "Predicate-teach": {
      "label": "teach",
      "description": "The predicate 'teach' denotes the action of imparting knowledge, skills, or information from a subject to an object. In this context, the subject is typically an individual or group with expertise or authority in a particular area, while the object represents individuals or groups who are receiving the instruction or learning. The relationship established by 'teach' implies a transfer of understanding or capability, where the subject facilitates the learning process for the object.",
      "disambiguation_index": 0
    },
    "Predicate-have": {
      "label": "have",
      "description": "The predicate 'have' indicates a relationship of possession or ownership between the subject and the object. It signifies that the subject possesses, holds, or experiences the object in some form, which can be tangible or intangible. In this context, 'have' connects the subject to the object by expressing that the subject contains or is associated with the qualities, attributes, or items represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-to_perform": {
      "label": "to perform",
      "description": "The predicate 'to perform' indicates an action or process undertaken by the subject that results in the execution or completion of the object. It establishes a relationship where the subject actively engages in carrying out the specified task or activity represented by the object, highlighting the subject's role in initiating and conducting the action.",
      "disambiguation_index": 0
    },
    "Predicate-is_problematic_because": {
      "label": "is problematic because",
      "description": "The predicate 'is problematic because' establishes a causal or explanatory relationship between the subject and the object, indicating that the subject presents issues or challenges that are specifically attributed to the object. It suggests that the presence or characteristics of the object contribute to the problematic nature of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-opens": {
      "label": "opens",
      "description": "The predicate 'opens' indicates an action performed by the subject that results in the activation or display of the object, typically involving the removal of barriers or the initiation of access to the object. In this context, the subject performs an action that allows the object to become visible or accessible, facilitating interaction or engagement with it.",
      "disambiguation_index": 0
    },
    "Predicate-holds_out": {
      "label": "holds out",
      "description": "The predicate 'holds out' indicates an action performed by the subject where they extend or present something towards another entity, typically in a gesture of offering, invitation, or request. It conveys a physical movement that involves the subject reaching forward with an object, often implying a willingness to share, give, or engage with the object in some manner.",
      "disambiguation_index": 0
    },
    "Predicate-appears_near": {
      "label": "appears near",
      "description": "The predicate 'appears near' indicates a spatial relationship between the subject and the object, suggesting that the subject is located in close proximity to the object. This connection implies that the subject can be visually or physically observed in the vicinity of the object, highlighting a contextual or situational relevance between the two.",
      "disambiguation_index": 0
    },
    "Predicate-looks_at": {
      "label": "looks at",
      "description": "The predicate 'looks at' indicates a visual attention or observation relationship between the subject and the object. It implies that the subject is directing their gaze towards the object, suggesting an engagement or interest in the object being observed. This action can denote various contexts, such as examining, contemplating, or simply noticing the object.",
      "disambiguation_index": 0
    },
    "Predicate-requires": {
      "label": "requires",
      "description": "The predicate 'requires' establishes a relationship in which the subject depends on or needs the object in order to function, operate, or achieve a specific purpose. It indicates that the subject cannot fulfill its intended role or perform its activities without the presence or involvement of the object.",
      "disambiguation_index": 0
    },
    "Predicate-faces": {
      "label": "faces",
      "description": "The predicate 'faces' indicates a directional relationship where the subject is oriented towards or in the direction of the object. It implies that the subject is positioned such that the object is in front of it or is the focal point of its attention.",
      "disambiguation_index": 0
    },
    "Predicate-taps": {
      "label": "taps",
      "description": "The predicate 'taps' indicates a physical action performed by the subject, where the subject makes a light, quick contact with the object, typically using a finger or hand. This action often implies an intention to interact with or activate the object, which in this context is something that can be pressed or selected.",
      "disambiguation_index": 0
    },
    "Predicate-has_to_pinch": {
      "label": "has to pinch",
      "description": "The predicate 'has to pinch' indicates a necessity or requirement for the subject to perform a pinching action on the object, which typically involves a gesture used to interact with a touch-sensitive interface. This action often serves to zoom in or out, select, or manipulate the object in a specific way, reflecting a direct relationship between the subject's action and the object's functionality.",
      "disambiguation_index": 0
    },
    "Predicate-can_tap": {
      "label": "can tap",
      "description": "The predicate 'can tap' indicates the ability or capability of the subject to perform a tapping action on the object, which typically refers to a specific target or interface element. This action suggests an interaction where the subject engages with the object, often in a digital or physical context, to trigger a response or function.",
      "disambiguation_index": 0
    },
    "Predicate-expects": {
      "label": "expects",
      "description": "The predicate 'expects' indicates a relationship where the subject holds a belief or anticipation regarding the object. It suggests that the subject has a certain expectation or assumption about the behavior, actions, or characteristics of the object, implying a level of reliance or trust in the object to meet those anticipated conditions.",
      "disambiguation_index": 0
    },
    "Predicate-do_not_provide": {
      "label": "do not provide",
      "description": "The predicate 'do not provide' indicates a lack of availability or supply of the object by the subject. It signifies that the subject fails to offer, deliver, or make accessible the specified object, implying an absence or deficiency in the expected provision.",
      "disambiguation_index": 0
    },
    "Predicate-retrieve": {
      "label": "retrieve",
      "description": "The predicate 'retrieve' indicates the action of obtaining or bringing back information, objects, or responses from a source or memory. It connects the subject, which initiates the action, with the object, which represents the specific information or item being obtained. In this context, 'retrieve' implies a process where the subject seeks to access or recover something that is relevant or needed.",
      "disambiguation_index": 0
    },
    "Predicate-supported_by": {
      "label": "supported by",
      "description": "The predicate 'supported by' indicates a relationship where the subject is aided, backed, or reinforced by the object. It implies that the object provides resources, assistance, or validation that enhances or sustains the subject in some capacity.",
      "disambiguation_index": 0
    },
    "Predicate-have_to_find": {
      "label": "have to find",
      "description": "The predicate 'have to find' indicates a necessity or obligation for the subject to locate or discover the object. It implies that the subject is required to engage in a search or inquiry process to obtain the object, which is often essential for fulfilling a task, solving a problem, or achieving a goal.",
      "disambiguation_index": 0
    },
    "Predicate-have_to_read_or_learn": {
      "label": "have to read or learn",
      "description": "The predicate 'have to read or learn' indicates an obligation or necessity for the subject to acquire knowledge or information about the object. It implies that the subject must engage in the process of reading or learning in order to understand, utilize, or apply the object effectively. This connection highlights the importance of the object as a source of essential knowledge that the subject needs to fulfill their responsibilities or tasks.",
      "disambiguation_index": 0
    },
    "Predicate-read_or_learn": {
      "label": "read or learn",
      "description": "The predicate 'read or learn' signifies the action of acquiring knowledge or information through various means, such as reading written material or engaging in educational activities. It connects the subject, which represents individuals or groups seeking knowledge, to the object, which denotes the specific information or skills being sought. This relationship highlights the process of gaining understanding or expertise in a particular area.",
      "disambiguation_index": 0
    },
    "Predicate-maps_to": {
      "label": "maps to",
      "description": "The predicate 'maps to' indicates a relationship where the subject is associated with or represents a specific concept, function, or meaning denoted by the object. It suggests that the subject serves as a symbolic or functional representation that can be understood in the context of the object, establishing a connection between the two in terms of interpretation or utility.",
      "disambiguation_index": 0
    },
    "Predicate-would_find_convenient": {
      "label": "would find convenient",
      "description": "The predicate 'would find convenient' expresses a subjective evaluation or preference of the subject regarding the object, indicating that the subject perceives the object as beneficial, useful, or advantageous in a particular context or situation.",
      "disambiguation_index": 0
    },
    "Predicate-would_be_convenient_for": {
      "label": "would be convenient for",
      "description": "The predicate 'would be convenient for' indicates a relationship where the subject provides a benefit or ease of use to the object, suggesting that the object is made more accessible, efficient, or practical due to the subject's actions, designs, or characteristics.",
      "disambiguation_index": 0
    },
    "Predicate-helps_to_bring": {
      "label": "helps to bring",
      "description": "The predicate 'helps to bring' indicates a facilitative relationship where the subject contributes to the achievement or realization of the object. It suggests that the subject plays a supportive or enabling role in making the object more accessible, effective, or present, thereby enhancing the connection or interaction between the two.",
      "disambiguation_index": 0
    },
    "Predicate-increases": {
      "label": "increases",
      "description": "The predicate 'increases' denotes a relationship where the subject contributes to a positive change or enhancement in the object. It implies that the subject's presence, action, or quality leads to a greater degree or level of the object, suggesting a causal or beneficial effect.",
      "disambiguation_index": 0
    },
    "Predicate-will_help_to_bring": {
      "label": "will help to bring",
      "description": "The predicate 'will help to bring' indicates a supportive or facilitative action that connects the subject to the object, suggesting that the subject contributes positively towards achieving or establishing the object. It implies a future-oriented outcome where the subject's influence or characteristics are expected to lead to the realization or enhancement of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_to_design": {
      "label": "is to design",
      "description": "The predicate 'is to design' establishes a relationship where the subject is identified as having the purpose or intention of creating or formulating the object. It implies that the subject's primary goal or function involves the act of designing, which can pertain to various contexts such as systems, structures, or conceptual frameworks represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-and_their_relationships_to": {
      "label": "and their relationships to",
      "description": "This predicate indicates a connection or association between the subject and the object, highlighting the nature, dynamics, or significance of their interactions or interdependencies. It suggests an exploration of how the subject influences, is influenced by, or interacts with the object, thereby providing insight into the broader context of their relationship.",
      "disambiguation_index": 0
    },
    "Predicate-to_understand_and_interpret": {
      "label": "to understand and interpret",
      "description": "The predicate 'to understand and interpret' signifies the cognitive process through which the subject comprehends and derives meaning from the object. It involves analyzing the information or signals presented by the object, allowing the subject to grasp their significance and implications. This process is essential for effective communication and interaction, as it enables the subject to respond appropriately based on the interpreted information.",
      "disambiguation_index": 0
    },
    "Predicate-maps": {
      "label": "maps",
      "description": "The predicate 'maps' indicates a relationship where the subject provides a structured representation or framework that corresponds to the object, illustrating how the elements of the object are organized, categorized, or related within the context of the subject. This connection often implies a systematic or conceptual alignment between the two, allowing for the translation or interpretation of the object through the lens of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-have_relationships_to": {
      "label": "have relationships to",
      "description": "The predicate 'have relationships to' indicates a connection or association between the subject and the object, suggesting that the subject is linked to the object in some meaningful way. This relationship can encompass various forms of interaction, influence, or dependency, highlighting how the two entities are related within a broader context.",
      "disambiguation_index": 0
    },
    "Predicate-shown": {
      "label": "shown",
      "description": "The predicate 'shown' indicates that the subject has been presented with or made aware of the object, which represents a specific outcome or result of an action. This connection implies that the subject has received information or evidence regarding the object, allowing for understanding or recognition of the desired effect.",
      "disambiguation_index": 0
    },
    "Predicate-called": {
      "label": "called",
      "description": "The predicate 'called' serves to establish a naming or identification relationship between the subject and the object. It indicates that the subject, which represents a concept, action, or phenomenon, is referred to or designated by the term or phrase represented by the object. This connection implies that the object provides a label or title that encapsulates the essence or nature of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-are_shown": {
      "label": "are shown",
      "description": "The predicate 'are shown' indicates a relationship where the subject is presented with information, data, or visual representations that illustrate or convey the object. This connection implies that the subject receives or perceives the object in a manner that enhances understanding or awareness of the object's significance or characteristics.",
      "disambiguation_index": 0
    },
    "Predicate-is_called": {
      "label": "is called",
      "description": "The predicate 'is called' serves to establish a naming or identification relationship between the subject and the object. It indicates that the subject, which represents a concept, phenomenon, or entity, is referred to by the term or phrase specified in the object. This connection highlights how language is used to label or denote the subject, facilitating communication and understanding of the referent in various contexts.",
      "disambiguation_index": 0
    },
    "Predicate-are_performed_using": {
      "label": "are performed using",
      "description": "The predicate 'are performed using' indicates the means or method by which the subject carries out an action or activity, linking the subject to the object that serves as the tool, instrument, or medium employed in the execution of that action.",
      "disambiguation_index": 0
    },
    "Predicate-are_part_of": {
      "label": "are part of",
      "description": "The predicate 'are part of' indicates a relationship of inclusion or membership, where the subject is a component or element that contributes to the whole represented by the object. This relationship signifies that the subject is a constituent of the object, highlighting a hierarchical or structural connection between the two.",
      "disambiguation_index": 0
    },
    "Predicate-is_designed_to_describe": {
      "label": "is designed to describe",
      "description": "The predicate 'is designed to describe' establishes a functional relationship between the subject and the object, indicating that the subject has been intentionally created or structured to provide an explanation, representation, or characterization of the object. This implies that the subject serves a specific purpose in conveying information about the object, which in this context refers to the characteristics or attributes of the object being described.",
      "disambiguation_index": 0
    },
    "Predicate-query": {
      "label": "query",
      "description": "The predicate 'query' denotes an action where the subject seeks information or data from the object. In this context, it implies that the subject is actively requesting or retrieving specific details or insights from the object, which is typically a structured set of information or knowledge, such as an ontology. This relationship highlights the interaction between the subject's need for information and the object's role as a source of that information.",
      "disambiguation_index": 0
    },
    "Predicate-recognizing": {
      "label": "recognizing",
      "description": "The predicate 'recognizing' denotes the action or process by which the subject identifies or acknowledges the existence, significance, or meaning of the object. In this context, it implies a cognitive or perceptual engagement where the subject discerns the relationship between itself and the object, leading to an understanding or awareness of the object's attributes or implications.",
      "disambiguation_index": 0
    },
    "Predicate-understands": {
      "label": "understands",
      "description": "The predicate 'understands' denotes a cognitive process in which the subject comprehends, interprets, or grasps the meaning, significance, or implications of the object. It implies a level of awareness or insight that allows the subject to connect with the object in a meaningful way, often involving the recognition of relationships, intentions, or contexts associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-helps": {
      "label": "helps",
      "description": "The predicate 'helps' indicates a supportive or beneficial relationship between the subject and the object, where the subject contributes positively to the achievement or enhancement of the object. In this context, the subject is seen as providing assistance, facilitation, or improvement towards the realization or effectiveness of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_for": {
      "label": "is for",
      "description": "The predicate 'is for' establishes a relationship of purpose or intended use between the subject and the object, indicating that the subject serves a specific function or is designed to benefit, target, or cater to the object.",
      "disambiguation_index": 0
    },
    "Predicate-does_not_have_to_memorize": {
      "label": "does not have to memorize",
      "description": "The predicate 'does not have to memorize' indicates that the subject is not required to commit the object to memory, suggesting that the subject can interact with or utilize the object without the necessity of recalling it from memory. This implies a level of ease or accessibility in the relationship between the subject and the object, where reliance on memory is not a prerequisite for engagement.",
      "disambiguation_index": 0
    },
    "Predicate-improves": {
      "label": "improves",
      "description": "The predicate 'improves' indicates a positive change or enhancement brought about by the subject to the object, suggesting that the quality, performance, or effectiveness of the object is elevated as a result of the actions or characteristics of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-is_part_of": {
      "label": "is part of",
      "description": "The predicate 'is part of' indicates a relationship where the subject is a component, element, or constituent of the object. This connection implies that the subject contributes to the overall structure, function, or identity of the object, suggesting a hierarchical or integrative relationship between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-illustrate": {
      "label": "illustrate",
      "description": "The predicate 'illustrate' connects the subject and object by indicating that the subject provides a visual representation, explanation, or demonstration of the concept or entity represented by the object. It suggests that the subject serves to clarify, exemplify, or make the object more understandable through visual means.",
      "disambiguation_index": 0
    },
    "Predicate-illustrate_(1)": {
      "label": "illustrate",
      "description": "The predicate 'illustrate' connects the subject and object by indicating that the subject provides a visual representation, explanation, or demonstration of the concept, idea, or entity represented by the object. It suggests that the subject serves to clarify or exemplify the object through visual means.",
      "disambiguation_index": 1
    },
    "Predicate-serves_as": {
      "label": "serves as",
      "description": "The predicate 'serves as' indicates a functional or representational relationship between the subject and the object, suggesting that the subject fulfills a role or provides a specific capability that is characterized by the object. It implies that the subject acts in a capacity that is defined or described by the object, highlighting the purpose or significance of the subject in relation to the object.",
      "disambiguation_index": 0
    },
    "Predicate-provides": {
      "label": "provides",
      "description": "The predicate 'provides' indicates a relationship in which the subject offers, supplies, or makes available certain resources, tools, or benefits to the object. In this context, the subject is an entity that has the capability or authority to furnish something, while the object represents the recipients or beneficiaries of what is being provided. This relationship emphasizes the act of giving or supplying, highlighting the utility or support that the subject extends to the object.",
      "disambiguation_index": 0
    },
    "Predicate-of": {
      "label": "of",
      "description": "The predicate 'of' serves to establish a relationship of belonging or association between the subject and the object. It indicates that the object is a characteristic, quality, or aspect that pertains to or is derived from the subject, thereby providing context or specificity to the subject's meaning. In general, 'of' connects two entities by suggesting that one is related to or defined by the other.",
      "disambiguation_index": 0
    },
    "Predicate-deals_with": {
      "label": "deals with",
      "description": "The predicate 'deals with' indicates a relationship in which the subject engages with, addresses, or is concerned with the object. It implies that the subject is involved in the exploration, analysis, or discussion of the object, which often represents a topic, issue, or area of study. This connection suggests that the subject provides insights, findings, or contributions related to the object.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_found_dealing_with": {
      "label": "can be found dealing with",
      "description": "The predicate 'can be found dealing with' indicates that the subject is associated with or relevant to the object, suggesting that the subject contains information, research, or content that pertains to the object. It implies a connection where the subject provides insights, analysis, or exploration of the themes or topics represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_predefined_with": {
      "label": "are predefined with",
      "description": "The predicate 'are predefined with' indicates that the subject possesses certain established characteristics, attributes, or associations that are defined in advance. It suggests a relationship where the subject is linked to specific qualities or elements that have been predetermined, thereby providing clarity and context to the subject's nature or function.",
      "disambiguation_index": 0
    },
    "Predicate-explore": {
      "label": "explore",
      "description": "The predicate 'explore' indicates an active process of investigation or examination undertaken by the subject, which seeks to uncover, analyze, or understand the characteristics, features, or implications of the object. In this context, the subject engages with the object in a manner that involves inquiry, discovery, or experimentation, aiming to gain deeper insights or knowledge about the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-identifies": {
      "label": "identifies",
      "description": "The predicate 'identifies' serves to establish a connection between the subject and the object by indicating that the subject possesses the ability or function to recognize, determine, or specify the nature or characteristics of the object. In this context, the subject is typically an entity or concept that has the capacity to discern or classify, while the object represents the specific entity or concept being recognized or defined.",
      "disambiguation_index": 0
    },
    "Predicate-attempted_to_define_and_formalise": {
      "label": "attempted to define and formalise",
      "description": "The predicate 'attempted to define and formalise' indicates an effort made by the subject to clarify, articulate, and establish a structured understanding of the object. It suggests a process of exploration and analysis aimed at creating a coherent framework or set of principles that encapsulate the nature or characteristics of the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-indicates": {
      "label": "indicates",
      "description": "The predicate 'indicates' serves to establish a relationship where the subject provides evidence, signals, or suggests the existence or relevance of the object. It implies that the subject conveys information or meaning that points towards the object, thereby establishing a connection between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-increases_the_need_for": {
      "label": "increases the need for",
      "description": "The predicate 'increases the need for' indicates a relationship where the subject creates a heightened demand or requirement for the object. It suggests that as the subject becomes more prominent or relevant, the necessity or urgency for the object grows, implying a direct correlation between the two elements.",
      "disambiguation_index": 0
    },
    "Predicate-adopt": {
      "label": "adopt",
      "description": "The predicate 'adopt' signifies the action of a subject taking on or accepting an object, which often represents a method, idea, practice, or policy. It implies a decision to embrace or implement the object in a way that suggests commitment or integration into the subject's activities or beliefs.",
      "disambiguation_index": 0
    },
    "Predicate-define_(1)": {
      "label": "define",
      "description": "The predicate 'define' establishes a relationship where the subject provides a clear and precise explanation or description of the object, which is typically a concept, term, or category. This relationship indicates that the subject is articulating the meaning, characteristics, or boundaries of the object, thereby enhancing understanding of the object in question.",
      "disambiguation_index": 1
    },
    "Predicate-adopted": {
      "label": "adopted",
      "description": "The predicate 'adopted' indicates that the subject has accepted, embraced, or implemented the object, which typically represents a method, idea, practice, or policy. This connection implies a transition from consideration or evaluation to active use or support, suggesting a positive endorsement or integration of the object into the subject's activities or framework.",
      "disambiguation_index": 0
    },
    "Predicate-proposed": {
      "label": "proposed",
      "description": "The predicate 'proposed' indicates that the subject has put forward a suggestion, idea, or plan regarding the object. It signifies an act of recommending or advocating for the object, which often involves introducing a new concept, framework, or methodology for consideration or discussion.",
      "disambiguation_index": 0
    },
    "Predicate-guides": {
      "label": "guides",
      "description": "The predicate 'guides' indicates a directional influence or support provided by the subject to the object, suggesting that the subject offers insights, frameworks, or methodologies that assist the object in their activities or decision-making processes.",
      "disambiguation_index": 0
    },
    "Predicate-create": {
      "label": "create",
      "description": "The predicate 'create' signifies the action of bringing something into existence or producing it through a process of design, development, or innovation. It connects the subject, which represents the agents or entities performing the action, with the object, which denotes the result or product of that action. In this context, the subject actively engages in the formulation or construction of the object, resulting in the establishment of new ideas, methods, or tangible items.",
      "disambiguation_index": 0
    },
    "Predicate-address": {
      "label": "address",
      "description": "The predicate 'address' signifies the action of dealing with, confronting, or responding to a particular issue, challenge, or topic. It establishes a relationship where the subject is actively engaging with the object, which represents the matter that requires attention or resolution. This connection implies a focus on finding solutions, providing insights, or taking necessary actions related to the object.",
      "disambiguation_index": 0
    },
    "Predicate-do_not_map": {
      "label": "do not map",
      "description": "The predicate 'do not map' indicates a lack of correspondence or relationship between the subject and the object, suggesting that the subject does not align, relate to, or represent the characteristics or elements of the object in any meaningful way.",
      "disambiguation_index": 0
    },
    "Predicate-developed": {
      "label": "developed",
      "description": "The predicate 'developed' indicates that the subject has created, designed, or advanced a particular concept, system, or item represented by the object. It implies a process of innovation or improvement, where the subject has actively contributed to the formation or enhancement of the object.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_used_as": {
      "label": "can be used as",
      "description": "The predicate 'can be used as' indicates a functional relationship between the subject and the object, suggesting that the subject has the potential or capability to serve a specific role or purpose represented by the object. It implies that the subject can be applied, interpreted, or utilized in a manner that aligns with the characteristics or intentions of the object.",
      "disambiguation_index": 0
    },
    "Predicate-to_organize": {
      "label": "to organize",
      "description": "The predicate 'to organize' denotes the action of arranging or structuring elements in a systematic way, where the subject is responsible for the act of organization and the object represents the elements being arranged. This action implies a process of categorization, planning, or coordination to achieve a coherent and functional outcome.",
      "disambiguation_index": 0
    },
    "Predicate-is_restricted_to": {
      "label": "is restricted to",
      "description": "The predicate 'is restricted to' indicates a limitation or constraint that defines the scope or range of the subject in relation to the object. It signifies that the subject is confined or limited exclusively to the characteristics, elements, or instances represented by the object, implying that no other elements outside of this specified object are included or applicable.",
      "disambiguation_index": 0
    },
    "Predicate-were_used_in": {
      "label": "were used in",
      "description": "The predicate 'were used in' indicates that the subject, which can be a collection of items, tools, or methods, played a role or served a purpose within the context of the object, typically an event, process, or study. It implies that the subject contributed to or was involved in the execution or realization of the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_necessary_to_see": {
      "label": "are necessary to see",
      "description": "The predicate 'are necessary to see' indicates that the subject is essential or required in order to observe, understand, or evaluate the object. It implies a causal relationship where the presence or execution of the subject is a prerequisite for gaining insight or clarity regarding the object.",
      "disambiguation_index": 0
    },
    "Predicate-follow": {
      "label": "follow",
      "description": "The predicate 'follow' indicates a relationship where the subject engages in the act of adhering to, observing, or taking guidance from the object. It implies a directional influence where the subject seeks to align their actions, decisions, or understanding with the principles, instructions, or information provided by the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_provided": {
      "label": "is provided",
      "description": "The predicate 'is provided' indicates that the subject is made available or supplied to fulfill a need or requirement represented by the object. It establishes a relationship where the subject serves as a source or resource that offers the object to the recipient or user.",
      "disambiguation_index": 0
    },
    "Predicate-have_not_been_considered_in": {
      "label": "have not been considered in",
      "description": "The predicate 'have not been considered in' indicates that the subject has been excluded or overlooked in the context of the object. It suggests a lack of acknowledgment or incorporation of the subject within the framework, methodology, or perspective represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-uses": {
      "label": "uses",
      "description": "The predicate 'uses' indicates a functional relationship where the subject actively employs or utilizes the object in order to achieve a specific purpose or outcome. It signifies that the subject relies on the object as a tool, resource, or method in its operations or activities.",
      "disambiguation_index": 0
    },
    "Predicate-moves_beyond": {
      "label": "moves beyond",
      "description": "The predicate 'moves beyond' indicates a progression or advancement from the subject to a state or concept represented by the object. It suggests that the subject transcends, surpasses, or evolves past the limitations or characteristics of the object, implying a development that introduces new dimensions, ideas, or methodologies that are not confined to the object.",
      "disambiguation_index": 0
    },
    "Predicate-modelled": {
      "label": "modelled",
      "description": "The predicate 'modelled' indicates that the subject has created, designed, or represented the object in a specific form or framework. It suggests a process of abstraction or conceptualization where the subject provides a structured interpretation or simulation of the object, which in this context refers to a theoretical or practical construct.",
      "disambiguation_index": 0
    },
    "Predicate-aims_to_describe": {
      "label": "aims to describe",
      "description": "The predicate 'aims to describe' indicates the intention or purpose of the subject to provide a detailed representation or explanation of the object. It establishes a relationship where the subject seeks to convey information, characteristics, or understanding about the object, thereby facilitating comprehension or insight into the nature of the object.",
      "disambiguation_index": 0
    },
    "Predicate-focuses_on": {
      "label": "focuses on",
      "description": "The predicate 'focuses on' indicates a relationship where the subject directs attention, consideration, or emphasis towards the object. It suggests that the subject prioritizes or highlights the object as a central theme or area of interest, thereby establishing a connection that underscores the significance or relevance of the object in relation to the subject.",
      "disambiguation_index": 0
    },
    "Predicate-misses": {
      "label": "misses",
      "description": "The predicate 'misses' indicates a lack or absence of certain elements or features in the subject, suggesting that the subject does not include or account for the specified object. It conveys a sense of incompleteness or deficiency, highlighting what is not present or acknowledged in the context of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-prevents": {
      "label": "prevents",
      "description": "The predicate 'prevents' indicates a relationship where the subject acts to hinder, obstruct, or stop the occurrence or effectiveness of the object. In this context, it suggests that the subject has a negative impact on the ability or potential of the object to be utilized or developed.",
      "disambiguation_index": 0
    },
    "Predicate-is_not_openly_shared": {
      "label": "is not openly shared",
      "description": "The predicate 'is not openly shared' indicates a lack of public availability or accessibility of the subject's attributes, features, or components, as represented by the object. It suggests that the subject is restricted in its dissemination or use, implying that the information or resources related to the object are not freely provided or made accessible to the general public or specific users.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_contribution_to": {
      "label": "is a contribution to",
      "description": "The predicate 'is a contribution to' indicates that the subject plays a significant role in enhancing, supporting, or advancing the object. It suggests that the subject provides valuable input, resources, or insights that positively impact the development or understanding of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_not_considered": {
      "label": "is not considered",
      "description": "The predicate 'is not considered' indicates a negation of recognition or acknowledgment between the subject and the object. It suggests that the subject does not hold the object in regard or does not classify it as relevant, important, or applicable within a certain context or framework. This predicate establishes a relationship where the subject's attributes, actions, or characteristics are explicitly excluded from being associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-have_semantic_relationships_to": {
      "label": "have semantic relationships to",
      "description": "The predicate 'have semantic relationships to' indicates a connection between the subject and the object, where the subject possesses meanings, implications, or associations that relate to the object. This relationship suggests that the subject conveys or represents concepts that are relevant to the object, highlighting how they interact or influence each other within a particular context.",
      "disambiguation_index": 0
    },
    "Predicate-focuses_on_capturing": {
      "label": "focuses on capturing",
      "description": "The predicate 'focuses on capturing' indicates that the subject is dedicated to the process of identifying, representing, or embodying the characteristics or essence of the object. It implies an intentional effort to understand or depict the object in a meaningful way, suggesting that the subject prioritizes this aspect in its analysis or representation.",
      "disambiguation_index": 0
    },
    "Predicate-conducted": {
      "label": "conducted",
      "description": "The predicate 'conducted' indicates that the subject is actively carrying out or performing an organized activity or process, typically involving research, experiments, or studies, which results in the object being the focus of that activity. It establishes a relationship where the subject is responsible for initiating and overseeing the execution of the action represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-with_regard_to": {
      "label": "with regard to",
      "description": "The predicate 'with regard to' establishes a relationship of relevance or focus between the subject and the object, indicating that the subject is being considered, analyzed, or discussed in relation to the object. It serves to clarify the context or specific aspect of the subject that pertains to the object.",
      "disambiguation_index": 0
    },
    "Predicate-have_conducted": {
      "label": "have conducted",
      "description": "The predicate 'have conducted' indicates that the subject has actively carried out or performed a specific action or process, typically involving research, experiments, or studies, resulting in the object, which represents the outcome or focus of that action.",
      "disambiguation_index": 0
    },
    "Predicate-attempted_to_recognize": {
      "label": "attempted to recognize",
      "description": "The predicate 'attempted to recognize' indicates an effort or endeavor made by the subject to identify, understand, or interpret the object. It suggests an active process where the subject engages with the object in order to discern its meaning or significance, often implying a level of challenge or difficulty in achieving this recognition.",
      "disambiguation_index": 0
    },
    "Predicate-recognizes": {
      "label": "recognizes",
      "description": "The predicate 'recognizes' indicates a relationship where the subject identifies, acknowledges, or perceives the existence or significance of the object. It implies an understanding or awareness that connects the subject to the object, suggesting that the subject has the capacity to discern or interpret the object in a meaningful way.",
      "disambiguation_index": 0
    },
    "Predicate-has_tried_to_describe": {
      "label": "has tried to describe",
      "description": "The predicate 'has tried to describe' indicates an effort or attempt made by the subject to articulate, explain, or convey information about the object. It suggests that the subject is engaged in a process of communication or representation, aiming to clarify or provide insight into the nature or characteristics of the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-used_to_capture": {
      "label": "used to capture",
      "description": "The predicate 'used to capture' indicates a functional relationship where the subject is employed or utilized for the purpose of recording, observing, or documenting the characteristics, actions, or behaviors represented by the object. It implies that the subject serves as a tool, method, or system that facilitates the acquisition of data or information pertaining to the object.",
      "disambiguation_index": 0
    },
    "Predicate-performed_during": {
      "label": "performed during",
      "description": "The predicate 'performed during' establishes a temporal relationship between the subject and the object, indicating that the action or activity represented by the subject occurs within the timeframe or context of the event or activity represented by the object. It suggests that the subject's action is a component or aspect of the broader event denoted by the object.",
      "disambiguation_index": 0
    },
    "Predicate-was_used_to_capture": {
      "label": "was used to capture",
      "description": "The predicate 'was used to capture' indicates that the subject is an entity or system that serves the purpose of recording, observing, or documenting a specific phenomenon or action represented by the object. It implies a functional relationship where the subject facilitates the acquisition of data or information about the object, which often involves a process of measurement or observation.",
      "disambiguation_index": 0
    },
    "Predicate-was_mainly_on": {
      "label": "was mainly on",
      "description": "The predicate 'was mainly on' indicates that the subject had a primary emphasis or concentration directed towards the object. It suggests that while there may be other elements involved, the object represents the central theme or area of interest for the subject.",
      "disambiguation_index": 0
    },
    "Predicate-was_limited_to": {
      "label": "was limited to",
      "description": "The predicate 'was limited to' indicates a restriction or constraint on the subject, specifying that it can only encompass or include the elements represented by the object. This implies that the subject has a defined boundary or scope, beyond which it cannot extend, thereby establishing a clear relationship of limitation between the subject and the object.",
      "disambiguation_index": 0
    },
    "Predicate-does_not_consider": {
      "label": "does not consider",
      "description": "The predicate 'does not consider' indicates a lack of acknowledgment or evaluation by the subject towards the object. It implies that the subject is either unaware of, dismissive of, or intentionally excluding the object from their thoughts, analyses, or frameworks. This relationship highlights a gap or absence in the subject's perspective regarding the object, suggesting that the object is not deemed relevant or significant in the context of the subject's considerations.",
      "disambiguation_index": 0
    },
    "Predicate-carries": {
      "label": "carries",
      "description": "The predicate 'carries' indicates a relationship in which the subject possesses or conveys the qualities, meanings, or implications represented by the object. It suggests that the subject serves as a medium or vehicle through which the object is expressed or understood, highlighting a connection where the subject holds or transmits the essence of the object.",
      "disambiguation_index": 0
    },
    "Predicate-tried_to_describe": {
      "label": "tried to describe",
      "description": "The predicate 'tried to describe' indicates an effort made by the subject to convey or explain information, concepts, or phenomena related to the object. It suggests that the subject is engaging in an act of communication aimed at providing clarity or understanding about the object, which can encompass a wide range of topics, ideas, or experiences.",
      "disambiguation_index": 0
    },
    "Predicate-have_a_different_scope_compared_to": {
      "label": "have a different scope compared to",
      "description": "The predicate 'have a different scope compared to' indicates a relationship where the subject and object are being evaluated in terms of their range, applicability, or focus. It suggests that the subject encompasses or addresses a set of concepts, issues, or contexts that are distinct from those covered by the object, highlighting a divergence in their intended use or relevance.",
      "disambiguation_index": 0
    },
    "Predicate-is_not_on": {
      "label": "is not on",
      "description": "The predicate 'is not on' indicates a negation of focus or attention, suggesting that the subject does not prioritize, emphasize, or concentrate on the object. It establishes a relationship where the subject explicitly excludes the object from its area of interest or consideration.",
      "disambiguation_index": 0
    },
    "Predicate-are_attached_to": {
      "label": "are attached to",
      "description": "The predicate 'are attached to' indicates a connection or association between the subject and the object, suggesting that the subject is linked or related to the object in a significant way. This connection can imply dependency, relevance, or a form of integration, where the subject cannot be fully understood or appreciated without considering its relationship to the object.",
      "disambiguation_index": 0
    },
    "Predicate-do_not_carry": {
      "label": "do not carry",
      "description": "The predicate 'do not carry' indicates a lack of transmission or representation between the subject and the object, suggesting that the subject fails to convey, signify, or embody the qualities or characteristics associated with the object. In this context, it implies that the subject does not provide the intended meaning or relevance that the object represents.",
      "disambiguation_index": 0
    },
    "Predicate-carry_a_referent_to": {
      "label": "carry a referent to",
      "description": "The predicate 'carry a referent to' indicates a relationship where the subject conveys or represents a specific concept, idea, or object (the referent) to the object, which is typically an aspect, feature, or capability associated with the subject. This connection implies that the subject serves as a medium or means through which the referent is understood or interpreted in relation to the object.",
      "disambiguation_index": 0
    },
    "Predicate-do_not_consider": {
      "label": "do not consider",
      "description": "The predicate 'do not consider' indicates a negation of attention or regard towards the object in relation to the subject. It implies that the subject is disregarding or failing to take into account the object, suggesting a lack of relevance, importance, or applicability of the object to the subject's context or understanding.",
      "disambiguation_index": 0
    },
    "Predicate-be_extended_to": {
      "label": "be extended to",
      "description": "The predicate 'be extended to' indicates a relationship where the subject is capable of being applied, adapted, or expanded in scope to include the object. It suggests that the characteristics, functions, or effects of the subject can reach beyond its original context or boundaries to encompass the object, thereby establishing a connection or relevance between the two.",
      "disambiguation_index": 0
    },
    "Predicate-extend_beyond": {
      "label": "extend beyond",
      "description": "The predicate 'extend beyond' indicates a relationship where the subject encompasses or reaches out to areas, concepts, or entities that are not limited to the immediate or typical boundaries defined by the object. It suggests an expansion or an increase in scope, influence, or relevance, implying that the subject has a capacity or effect that surpasses the confines of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_extensible_to_allow_the_addition_of": {
      "label": "is extensible to allow the addition of",
      "description": "The predicate 'is extensible to allow the addition of' indicates that the subject possesses the capability or flexibility to incorporate new elements or components, represented by the object, into its existing structure or framework. This suggests that the subject is designed or can be modified to accommodate growth or change, thereby enhancing its functionality or relevance by integrating additional features, concepts, or items.",
      "disambiguation_index": 0
    },
    "Predicate-is_extended_to": {
      "label": "is extended to",
      "description": "The predicate 'is extended to' indicates a relationship where the subject encompasses or includes additional elements represented by the object. It suggests that the subject has a foundational or core aspect that can be broadened or applied to the object, thereby expanding its scope or relevance.",
      "disambiguation_index": 0
    },
    "Predicate-fit": {
      "label": "fit",
      "description": "The predicate 'fit' indicates a relationship where the subject is compatible with, suitable for, or aligns well with the object. It suggests that the characteristics or qualities of the subject correspond positively to the requirements or standards represented by the object, implying a harmonious or effective integration between the two.",
      "disambiguation_index": 0
    },
    "Predicate-provided_mappings_to": {
      "label": "provided mappings to",
      "description": "The predicate 'provided mappings to' indicates a relationship where the subject offers a structured connection or correspondence to the elements represented in the object. This implies that the subject facilitates an understanding or integration of the object by establishing a framework that links the two, allowing for the interpretation, utilization, or application of the object in relation to the subject.",
      "disambiguation_index": 0
    },
    "Predicate-models": {
      "label": "models",
      "description": "The predicate 'models' indicates a relationship where the subject provides a representation, simulation, or abstraction of the object. In this context, it suggests that the subject is capable of capturing, illustrating, or analyzing the characteristics, behaviors, or dynamics of the object, which can encompass various phenomena, systems, or concepts.",
      "disambiguation_index": 0
    },
    "Predicate-are_used_to_interact_with": {
      "label": "are used to interact with",
      "description": "The predicate 'are used to interact with' establishes a functional relationship between the subject and the object, indicating that the subject possesses the capability or purpose of engaging with, manipulating, or communicating with the object. This interaction can involve physical, sensory, or cognitive processes, highlighting the role of the subject in facilitating a connection or exchange with the object.",
      "disambiguation_index": 0
    },
    "Predicate-acts_as": {
      "label": "acts as",
      "description": "The predicate 'acts as' establishes a functional relationship between the subject and the object, indicating that the subject serves a specific role or purpose that is equivalent to or similar to that of the object. It implies that the subject fulfills the duties or characteristics associated with the object in a particular context.",
      "disambiguation_index": 0
    },
    "Predicate-search_and_identify": {
      "label": "search and identify",
      "description": "The predicate 'search and identify' describes an action where the subject actively seeks out information or items and recognizes or determines their significance or characteristics. This process involves exploration, analysis, and discernment, leading to the understanding or categorization of the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-for": {
      "label": "for",
      "description": "The predicate 'for' establishes a relationship of purpose or suitability between the subject and the object, indicating that the subject serves a specific function, role, or benefit related to the object.",
      "disambiguation_index": 0
    },
    "Predicate-introduces": {
      "label": "introduces",
      "description": "The predicate 'introduces' signifies the action of presenting or bringing forth something new or previously unrecognized, establishing a connection between the subject and the object. In this context, the subject is the entity that performs the act of introduction, while the object represents the new concept, idea, or item being presented. This relationship implies a transfer of knowledge or innovation from the subject to the object, highlighting the subject's role in expanding understanding or awareness regarding the object.",
      "disambiguation_index": 0
    },
    "Predicate-aims_to_define": {
      "label": "aims to define",
      "description": "The predicate 'aims to define' indicates an intention or goal of the subject to establish a clear and precise understanding or characterization of the object. It suggests that the subject is engaged in a process of exploration, analysis, or formulation that seeks to articulate the nature, properties, or framework of the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-is_combined_with": {
      "label": "is combined with",
      "description": "The predicate 'is combined with' indicates a relationship where two entities are brought together to form a unified whole, suggesting that they interact or integrate in a way that enhances or modifies their individual characteristics. This combination often implies a synergistic effect, where the resulting entity possesses qualities or functionalities that are derived from both components.",
      "disambiguation_index": 0
    },
    "Predicate-defined_with": {
      "label": "defined with",
      "description": "The predicate 'defined with' establishes a relationship where the subject is characterized or specified by the object, indicating that the object serves as a defining element or descriptor for the subject. This connection implies that the object provides essential information or context that clarifies the nature or purpose of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-used_for": {
      "label": "used for",
      "description": "The predicate 'used for' establishes a functional relationship between the subject and the object, indicating that the subject serves a specific purpose or function that is fulfilled by the object. It implies that the subject is intended to facilitate, support, or enable the activities or characteristics described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-independent_of": {
      "label": "independent of",
      "description": "The predicate 'independent of' establishes a relationship where the subject operates or exists without reliance on or influence from the object. It indicates that the characteristics, functions, or definitions of the subject are not affected by the object, suggesting a separation or autonomy in their respective contexts.",
      "disambiguation_index": 0
    },
    "Predicate-defined_as": {
      "label": "defined as",
      "description": "The predicate 'defined as' establishes a relationship where the subject is explicitly characterized or identified by the object. It indicates that the object provides a definition, description, or clarification of the subject, effectively equating the two in terms of meaning or identity.",
      "disambiguation_index": 0
    },
    "Predicate-provided_to": {
      "label": "provided to",
      "description": "The predicate 'provided to' indicates a transfer or allocation of resources, information, or support from the subject to the object. It signifies that the subject is the source or supplier of something that is being made available or accessible to the object, which receives or benefits from this provision.",
      "disambiguation_index": 0
    },
    "Predicate-is_using": {
      "label": "is using",
      "description": "The predicate 'is using' indicates a relationship where the subject actively employs or utilizes the object for a specific purpose or function. It signifies that the subject engages with the object in a manner that involves practical application or operational use.",
      "disambiguation_index": 0
    },
    "Predicate-used_as": {
      "label": "used as",
      "description": "The predicate 'used as' indicates the function or role that the subject fulfills in relation to the object. It connects the subject to the object by specifying that the subject serves a particular purpose or is employed in a specific capacity represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_made_available_for": {
      "label": "are made available for",
      "description": "The predicate 'are made available for' indicates that the subject is provided or accessible to the object, facilitating the use, benefit, or engagement of the object with the subject. It implies a transfer of resources, information, or tools from the subject to the object, enabling the object to utilize or interact with what is being offered.",
      "disambiguation_index": 0
    },
    "Predicate-represent": {
      "label": "represent",
      "description": "The predicate 'represent' establishes a relationship where the subject embodies, signifies, or illustrates the characteristics, concepts, or entities denoted by the object. It indicates that the subject serves as a model or a framework that conveys the meaning or essence of the object, thereby facilitating understanding or interpretation of the object in a specific context.",
      "disambiguation_index": 0
    },
    "Predicate-associated_with": {
      "label": "associated with",
      "description": "The predicate 'associated with' indicates a relationship between the subject and the object, suggesting that they are connected or related in some meaningful way. This connection can imply a variety of interactions, influences, or correlations, where the subject may exhibit characteristics, behaviors, or properties that are relevant to the object, or vice versa. The association does not necessarily imply causation but rather denotes a significant link that can be explored or analyzed.",
      "disambiguation_index": 0
    },
    "Predicate-associates_with": {
      "label": "associates with",
      "description": "The predicate 'associates with' indicates a relationship of connection or relevance between the subject and the object. It suggests that the subject has a meaningful link or correlation to the object, implying that they share some commonality, influence, or interaction within a particular context. This relationship can encompass various forms of association, such as conceptual, functional, or contextual ties.",
      "disambiguation_index": 0
    },
    "Predicate-is_designed_around": {
      "label": "is designed around",
      "description": "The predicate 'is designed around' indicates that the subject is structured or organized with a central focus or framework that is represented by the object. It implies that the object serves as a foundational element or guiding principle in the creation or configuration of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-consists_of": {
      "label": "consists of",
      "description": "The predicate 'consists of' indicates a relationship where the subject is composed of or made up of the elements represented by the object. It signifies that the object is a part or component of the subject, highlighting the structural or categorical composition of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-establishes_relationships_with": {
      "label": "establishes relationships with",
      "description": "The predicate 'establishes relationships with' indicates a connection or association between the subject and the object, suggesting that the subject interacts or forms a link with the object in a meaningful way. This relationship can encompass various types of interactions, such as collaboration, influence, or mutual recognition, and highlights the significance of the connection in the context of the subject's role or function.",
      "disambiguation_index": 0
    },
    "Predicate-will_be_registered_in": {
      "label": "will be registered in",
      "description": "The predicate 'will be registered in' indicates a future action where the subject is intended to be officially recorded or included within the context or framework of the object. It implies a formal acknowledgment or acceptance of the subject by the entity represented by the object, suggesting a relationship of affiliation or categorization.",
      "disambiguation_index": 0
    },
    "Predicate-in": {
      "label": "in",
      "description": "The predicate 'in' indicates a spatial or contextual relationship where the subject is contained within or associated with the object, suggesting that the subject operates or exists within the boundaries or framework defined by the object.",
      "disambiguation_index": 0
    },
    "Predicate-from": {
      "label": "from",
      "description": "The predicate 'from' indicates a source or origin relationship between the subject and the object. It signifies that the subject is derived from, or is associated with, the object, which represents the source or context from which the subject is obtained. This connection often implies a transfer of knowledge, properties, or characteristics from the object to the subject.",
      "disambiguation_index": 0
    },
    "Predicate-are_expressed_in": {
      "label": "are expressed in",
      "description": "The predicate 'are expressed in' indicates a relationship where the subject is represented, articulated, or defined within the context of the object. It suggests that the subject's characteristics, features, or concepts are conveyed through the framework, language, or system denoted by the object.",
      "disambiguation_index": 0
    },
    "Predicate-asserts": {
      "label": "asserts",
      "description": "The predicate 'asserts' serves to establish a relationship where the subject is making a declaration or statement about the object, indicating that the subject holds a certain belief or claim regarding the object. In the context of the provided triple, it connects a specific property to its range by affirming that the property is true or applicable within the defined scope of the object.",
      "disambiguation_index": 0
    },
    "Predicate-helps_in": {
      "label": "helps in",
      "description": "The predicate 'helps in' indicates a supportive or facilitating relationship between the subject and the object, suggesting that the subject contributes positively to the process, development, or understanding of the object. It implies that the subject plays a role in enhancing, improving, or enabling the object in some capacity.",
      "disambiguation_index": 0
    },
    "Predicate-to": {
      "label": "to",
      "description": "The predicate 'to' indicates a directional or relational connection between the subject and the object, suggesting that the subject is directed towards, associated with, or intended for the object. It often implies a movement, transformation, or purpose that links the two entities in a meaningful way.",
      "disambiguation_index": 0
    },
    "Predicate-as": {
      "label": "as",
      "description": "The predicate 'as' is used to indicate a role, function, or identity that the subject assumes in relation to the object. It establishes a connection where the subject is characterized or defined by the object, suggesting that the subject can be understood or interpreted in the context of the object.",
      "disambiguation_index": 0
    },
    "Predicate-aligns_with": {
      "label": "aligns with",
      "description": "The predicate 'aligns with' indicates a relationship of compatibility or correspondence between the subject and the object. It suggests that the subject is in agreement or harmony with the object, often in terms of structure, principles, or objectives. This alignment can facilitate interoperability, integration, or mutual understanding between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-distinguishes": {
      "label": "distinguishes",
      "description": "The predicate 'distinguishes' indicates a relationship where the subject identifies or recognizes differences between itself and the object, highlighting a specific characteristic or quality that sets them apart. In this context, the subject is capable of discerning or categorizing the object based on certain criteria or features.",
      "disambiguation_index": 0
    },
    "Predicate-involves": {
      "label": "involves",
      "description": "The predicate 'involves' indicates a relationship where the subject is connected to or includes the object as a necessary component or aspect of its nature or function. It suggests that the subject cannot be fully understood or realized without considering the object, which plays a significant role in the context of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-can_have": {
      "label": "can have",
      "description": "The predicate 'can have' indicates a potential or capability of the subject to possess or exhibit the object. It suggests that the subject is not limited to a single instance or form of the object, but rather has the ability to encompass various instances or forms of it. This relationship highlights the flexibility or diversity inherent in the subject's characteristics or functions.",
      "disambiguation_index": 0
    },
    "Predicate-is_designed_to_capture_and_describe": {
      "label": "is designed to capture and describe",
      "description": "The predicate 'is designed to capture and describe' indicates that the subject has been intentionally created or structured to represent and articulate specific characteristics, features, or elements of the object. This implies a purposeful relationship where the subject serves as a framework or tool for understanding, categorizing, or detailing the object in a meaningful way.",
      "disambiguation_index": 0
    },
    "Predicate-aggregates": {
      "label": "aggregates",
      "description": "The predicate 'aggregates' denotes a relationship where the subject encompasses or combines multiple elements or instances represented by the object. In this context, it implies that the subject serves as a collective entity that includes or integrates various components, which are categorized under the object. This relationship highlights the notion of unity or totality formed by the aggregation of the specified elements.",
      "disambiguation_index": 0
    },
    "Predicate-captures": {
      "label": "captures",
      "description": "The predicate 'captures' denotes a relationship where the subject encompasses or represents the object in a way that conveys or embodies its essence or characteristics. In this context, it implies that the subject has the ability to include or depict the object, thereby allowing for a representation or acknowledgment of the object's attributes or components.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_described_using": {
      "label": "can be described using",
      "description": "The predicate 'can be described using' establishes a relationship where the subject is characterized or defined by the object, indicating that the object provides a means or method to articulate the qualities, features, or attributes of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-puts_in_sequence_or_concurrent": {
      "label": "puts in sequence or concurrent",
      "description": "The predicate 'puts in sequence or concurrent' indicates a relationship where the subject is organized or arranged in relation to the object, either in a sequential manner or simultaneously. This suggests that the subject's actions, events, or elements are positioned in a specific order or are occurring at the same time as the object, thereby establishing a temporal or logical connection between them.",
      "disambiguation_index": 0
    },
    "Predicate-can_contain": {
      "label": "can contain",
      "description": "The predicate 'can contain' indicates a relationship where the subject has the capacity or potential to include, hold, or encompass the object within its scope or definition. It suggests that the subject may possess one or more instances of the object, highlighting a possible inclusion or composition of elements.",
      "disambiguation_index": 0
    },
    "Predicate-performed_with": {
      "label": "performed with",
      "description": "The predicate 'performed with' indicates the means or instrument through which an action or activity (the subject) is executed, linking the subject to the object that represents the tool, body part, or method utilized in the performance of that action.",
      "disambiguation_index": 0
    },
    "Predicate-performs": {
      "label": "performs",
      "description": "The predicate 'performs' indicates an action or activity that the subject is executing or carrying out, which is represented by the object. It establishes a dynamic relationship where the subject is the agent that actively engages in the specified action, leading to the execution of the object, which describes the nature of that action.",
      "disambiguation_index": 0
    },
    "Predicate-illustrated_in": {
      "label": "illustrated in",
      "description": "The predicate 'illustrated in' serves to indicate that the subject is represented or depicted within the context of the object. It establishes a relationship where the subject is visually or conceptually explained, demonstrated, or exemplified by the object, often in a way that enhances understanding or provides clarity.",
      "disambiguation_index": 0
    },
    "Predicate-are_listed_in": {
      "label": "are listed in",
      "description": "The predicate 'are listed in' indicates that the subject is included or mentioned within the context of the object, which typically represents a document, section, or enumeration. This connection implies that the subject can be found or referenced in the specified object, suggesting a relationship of inclusion or categorization.",
      "disambiguation_index": 0
    },
    "Predicate-added": {
      "label": "added",
      "description": "The predicate 'added' signifies the action of incorporating or including an object into a subject, indicating that the subject has been expanded or modified to include the specified object. This relationship often implies a formal or systematic enhancement of the subject's scope or classification by the introduction of the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_modeled_in_detail_in": {
      "label": "are modeled in detail in",
      "description": "The predicate 'are modeled in detail in' indicates that the subject is represented or depicted with a high level of specificity and thoroughness within the context of the object. It suggests that the subject's characteristics, behaviors, or features are carefully analyzed and illustrated in the object, which serves as a framework, system, or medium for this detailed representation.",
      "disambiguation_index": 0
    },
    "Predicate-modeled_in_detail": {
      "label": "modeled in detail",
      "description": "The predicate 'modeled in detail' indicates that the subject has been represented or constructed with a high level of specificity and accuracy in relation to the object. This suggests a thorough and comprehensive approach to capturing the characteristics, movements, or features of the subject, ensuring that the object reflects these intricacies effectively.",
      "disambiguation_index": 0
    },
    "Predicate-reuses_and_extends": {
      "label": "reuses and extends",
      "description": "The predicate 'reuses and extends' indicates that the subject incorporates existing elements or ideas from the object while also adding new features or enhancements to them. This relationship suggests a process of building upon prior knowledge or frameworks, thereby creating a more comprehensive or advanced version of the original concepts represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-allows_representation_of": {
      "label": "allows representation of",
      "description": "The predicate 'allows representation of' establishes a relationship where the subject is capable of depicting, illustrating, or symbolizing the object. In this context, it indicates that the subject can serve as a framework or category that encompasses or includes the object, facilitating a connection between the two entities. This relationship implies that the subject provides a means to understand or visualize the object in a broader or more detailed context.",
      "disambiguation_index": 0
    },
    "Predicate-are_modeled_for": {
      "label": "are modeled for",
      "description": "The predicate 'are modeled for' indicates a relationship where the subject is designed, structured, or represented in a way that is intended to serve or correspond to the object. It implies that the subject has been conceptualized or formulated with the specific purpose of addressing, illustrating, or accommodating the characteristics or requirements of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_building_block_of": {
      "label": "is a building block of",
      "description": "The predicate 'is a building block of' indicates a foundational relationship where the subject serves as a fundamental component or part that contributes to the formation or structure of the object. This implies that the subject is essential for the existence or functionality of the object, suggesting a hierarchical or compositional relationship in which the object is made up of or relies on the subject.",
      "disambiguation_index": 0
    },
    "Predicate-are_preserved_with": {
      "label": "are preserved with",
      "description": "The predicate 'are preserved with' indicates a relationship where the subject is maintained or kept in a state of existence or integrity alongside the object. This suggests a mutual preservation or safeguarding, implying that both the subject and object share a connection that ensures their continued relevance or functionality together.",
      "disambiguation_index": 0
    },
    "Predicate-is_an_equivalent_class_to": {
      "label": "is an equivalent class to",
      "description": "The predicate 'is an equivalent class to' establishes a relationship of equivalence between two classes, indicating that they represent the same concept or category within a given context. This means that any instance or member of the subject class can be considered a member of the object class and vice versa, thereby allowing for interchangeable use in discussions or analyses involving these classes.",
      "disambiguation_index": 0
    },
    "Predicate-is_equivalent_to": {
      "label": "is equivalent to",
      "description": "The predicate 'is equivalent to' establishes a relationship of equivalence between the subject and the object, indicating that they represent the same concept or entity within a given context. This means that any properties, characteristics, or attributes associated with the subject can be equally applied to the object, and vice versa, suggesting a complete interchangeability in meaning or function.",
      "disambiguation_index": 0
    },
    "Predicate-is_divided_to_represent": {
      "label": "is divided to represent",
      "description": "The predicate 'is divided to represent' indicates a relationship where the subject is segmented or categorized in a way that allows for the identification or representation of the object. This suggests that the subject encompasses various components or subclasses, with the object serving as a specific instance or category that exemplifies one of those divisions.",
      "disambiguation_index": 0
    },
    "Predicate-mapped_to": {
      "label": "mapped to",
      "description": "The predicate 'mapped to' establishes a relationship of correspondence or association between the subject and the object, indicating that the subject is linked or related to the object in a specific context or framework. This connection often implies that the subject can be understood, represented, or categorized in terms of the object, suggesting a mapping of concepts, attributes, or roles.",
      "disambiguation_index": 0
    },
    "Predicate-are_divided_into": {
      "label": "are divided into",
      "description": "The predicate 'are divided into' indicates a relationship where the subject is segmented or categorized into distinct parts or groups represented by the object. This division implies a classification or partitioning of the subject into multiple components, which can be understood as separate entities that collectively represent the whole.",
      "disambiguation_index": 0
    },
    "Predicate-are_further_divided_into": {
      "label": "are further divided into",
      "description": "The predicate 'are further divided into' indicates a relationship where the subject is categorized or segmented into more specific or distinct components represented by the object. It implies a hierarchical or structural breakdown, suggesting that the subject consists of multiple parts that can be identified separately, thereby enhancing the understanding of the subject's composition.",
      "disambiguation_index": 0
    },
    "Predicate-depicts": {
      "label": "depicts",
      "description": "The predicate 'depicts' establishes a relationship where the subject provides a visual representation or illustration of the object. It indicates that the subject conveys or shows the characteristics, features, or aspects of the object through imagery or graphical means.",
      "disambiguation_index": 0
    },
    "Predicate-is_defined_in": {
      "label": "is defined in",
      "description": "The predicate 'is defined in' establishes a relationship where the subject is characterized or described within the context of the object. It indicates that the subject's meaning, properties, or classification are articulated or formalized in the framework or reference provided by the object. This connection often implies that the object serves as a foundational or authoritative source for understanding the subject.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_involved_in": {
      "label": "can be involved in",
      "description": "The predicate 'can be involved in' indicates a potential or capability of the subject to participate or play a role in the context of the object. It suggests that the subject has the ability to engage with, contribute to, or be a part of the situation or activity represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-hdgiinvolves": {
      "label": "hdgi:involves",
      "description": "The predicate 'hdgi:involves' establishes a relationship where the subject, typically representing an action or concept, is associated with the object, which usually denotes a component or element that is integral to the execution or understanding of that action or concept. In this context, it indicates that the subject cannot be fully realized or understood without the inclusion of the object, highlighting the interdependence between the two.",
      "disambiguation_index": 0
    },
    "Predicate-must_hdgiinvolves": {
      "label": "must hdgi:involves",
      "description": "The predicate 'must hdgi:involves' establishes a necessary relationship between the subject and the object, indicating that the subject inherently requires or includes the object as a fundamental component or aspect. In the context of the example, it suggests that the subject, such as a pose, cannot exist or be fully realized without the inclusion of the specified object, which in this case is a body part. This predicate emphasizes the essential nature of the connection between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-corresponds_to": {
      "label": "corresponds to",
      "description": "The predicate 'corresponds to' indicates a relationship of equivalence or association between the subject and the object, suggesting that the subject is related to or aligned with the object in a meaningful way. This relationship can imply that the subject and object share characteristics, functions, or roles that connect them conceptually or contextually.",
      "disambiguation_index": 0
    },
    "Predicate-placed_in": {
      "label": "placed in",
      "description": "The predicate 'placed in' indicates a spatial relationship where the subject is situated or located within the confines or boundaries of the object. It conveys the idea of positioning or embedding the subject in a specific environment or context, which is represented by the object. This relationship emphasizes the interaction between the subject and the object in terms of location and spatial arrangement.",
      "disambiguation_index": 0
    },
    "Predicate-hasPosition": {
      "label": "hasPosition",
      "description": "The predicate 'hasPosition' establishes a relationship between a subject and an object by indicating the specific spatial or positional state of the subject. In this context, the subject is characterized by a particular position represented by the object, which can be a coordinate, a state, or a descriptor of location. This relationship helps to define how the subject is situated in relation to a reference point or within a defined space.",
      "disambiguation_index": 0
    },
    "Predicate-considers": {
      "label": "considers",
      "description": "The predicate 'considers' indicates that the subject evaluates, reflects upon, or takes into account the object. It suggests a cognitive process where the subject acknowledges the relevance or significance of the object in a particular context or framework.",
      "disambiguation_index": 0
    },
    "Predicate-are_relative_to": {
      "label": "are relative to",
      "description": "The predicate 'are relative to' indicates a relationship of dependence or correlation between the subject and the object, suggesting that the characteristics, positions, or states of the subject are determined or influenced by the object. This relationship often implies a spatial, functional, or contextual connection where the subject cannot be fully understood without considering the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_referenced_in": {
      "label": "is referenced in",
      "description": "The predicate 'is referenced in' establishes a relationship where the subject is mentioned or cited within the context of the object. This indicates that the subject serves as a specific point of interest or detail that is included in the broader content or framework represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_always_relative_to": {
      "label": "are always relative to",
      "description": "The predicate 'are always relative to' indicates a relationship of dependence or correlation between the subject and the object, suggesting that the characteristics, properties, or states of the subject cannot be fully understood or defined without considering the context or reference provided by the object. This implies that the subject's attributes are influenced by, or are in relation to, the object, establishing a framework for comparison or analysis.",
      "disambiguation_index": 0
    },
    "Predicate-are_based_on": {
      "label": "are based on",
      "description": "The predicate 'are based on' indicates a foundational relationship where the subject derives its characteristics, properties, or values from the object. It suggests that the subject is dependent on or influenced by the object, establishing a connection that implies the object serves as a reference point, framework, or source for the subject's existence or understanding.",
      "disambiguation_index": 0
    },
    "Predicate-has_range": {
      "label": "has range",
      "description": "The predicate 'has range' establishes a relationship between a subject and an object, indicating that the subject possesses a specific set of values, dimensions, or extents that are represented by the object. This relationship often implies that the subject can operate within the confines or limits defined by the object, thereby defining the scope or boundaries of the subject's applicability or functionality.",
      "disambiguation_index": 0
    },
    "Predicate-hasLocalCoordinateSystem": {
      "label": "hasLocalCoordinateSystem",
      "description": "The predicate 'hasLocalCoordinateSystem' establishes a relationship between a subject, typically representing a spatial entity or position, and an object that denotes a specific local coordinate system. This connection indicates that the subject is defined or described in relation to the specified local coordinate system, which provides a framework for understanding its spatial properties and orientation within a defined context.",
      "disambiguation_index": 0
    },
    "Predicate-points_outwards_from": {
      "label": "points outwards from",
      "description": "The predicate 'points outwards from' establishes a directional relationship between the subject and the object, indicating that the subject extends or radiates away from the object in a specific orientation. This implies that the subject is positioned in such a way that it is oriented away from the object, suggesting a spatial or conceptual separation where the subject is defined in relation to the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_pointed_inwards": {
      "label": "is pointed inwards",
      "description": "The predicate 'is pointed inwards' indicates a directional orientation of the subject towards a central point or interior space, suggesting that the subject is aligned or directed in a way that it faces or converges towards itself or another specified reference point. In the context of the example triple, it implies that the Z-axis has a directional quality that leads inward, reinforcing the idea of spatial orientation.",
      "disambiguation_index": 0
    },
    "Predicate-relationship_with": {
      "label": "relationship with",
      "description": "The predicate 'relationship with' denotes a connection or association between the subject and the object, indicating how they interact, influence, or relate to each other within a specific context. It serves to establish a link that can encompass various types of relationships, such as spatial, functional, or conceptual, thereby providing insight into the nature of the connection between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-describes_the_rotation_of": {
      "label": "describes the rotation of",
      "description": "The predicate 'describes the rotation of' establishes a relationship where the subject represents a specific type of rotational movement or orientation, while the object signifies a physical entity or system that undergoes this rotation. This connection indicates that the subject provides a characterization or explanation of how the object rotates in a defined space, often in relation to axes or angles.",
      "disambiguation_index": 0
    },
    "Predicate-used_by_some_systems": {
      "label": "used by some systems",
      "description": "The predicate 'used by some systems' indicates that the subject is employed or utilized within certain frameworks, methodologies, or technologies to achieve specific functions or outcomes related to the object. It suggests a relationship where the subject serves a purpose or provides a capability that is beneficial or necessary for the operation or implementation of the object in various contexts.",
      "disambiguation_index": 0
    },
    "Predicate-keeps": {
      "label": "keeps",
      "description": "The predicate 'keeps' indicates a continuous or sustained relationship between the subject and the object, suggesting that the subject maintains, preserves, or holds onto the object over time. It implies an ongoing action or state where the subject ensures the presence or availability of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_able_to_model": {
      "label": "is able to model",
      "description": "The predicate 'is able to model' indicates the capability of the subject to represent, simulate, or understand the characteristics and behaviors of the object. It establishes a relationship where the subject possesses the necessary attributes or functionalities to effectively interpret or generate insights from the object, which in this context refers to a set of information or data.",
      "disambiguation_index": 0
    },
    "Predicate-is_similar_to": {
      "label": "is similar to",
      "description": "The predicate 'is similar to' establishes a comparative relationship between the subject and the object, indicating that they share common characteristics, features, or attributes. This relationship suggests a degree of likeness or resemblance, allowing for the understanding that the subject and object can be categorized or understood in relation to one another based on their similarities.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_modeled_separately": {
      "label": "can be modeled separately",
      "description": "The predicate 'can be modeled separately' indicates that the subject and object are distinct entities or components that can be represented or analyzed independently from one another. This suggests that each entity possesses its own characteristics and can be understood without the need for the other, allowing for a modular approach to modeling or representation.",
      "disambiguation_index": 0
    },
    "Predicate-added_as_subclasses": {
      "label": "added as subclasses",
      "description": "The predicate 'added as subclasses' indicates a relationship where the subject is being categorized or classified under the object, which serves as a broader or more general category. This implies that the subject represents specific instances or variations that fall within the scope of the object, thereby establishing a hierarchical structure in which the subject is a specialized form of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_modeled_as": {
      "label": "is modeled as",
      "description": "The predicate 'is modeled as' establishes a relationship where the subject is represented or conceptualized in a specific way, as indicated by the object. It implies that the subject is being interpreted, depicted, or defined through the lens of the object, suggesting a framework or reference point for understanding the subject's characteristics or behavior.",
      "disambiguation_index": 0
    },
    "Predicate-is_modeled_as_(1)": {
      "label": "is modeled as",
      "description": "The predicate 'is modeled as' indicates a relationship where the subject is represented or conceptualized in a manner that aligns it with the characteristics or attributes of the object. This suggests that the subject serves as a basis or reference point for understanding or visualizing the object, often in a theoretical, artistic, or computational context.",
      "disambiguation_index": 1
    },
    "Predicate-used": {
      "label": "used",
      "description": "The predicate 'used' indicates a functional relationship where the subject is actively employing or utilizing the object in a specific context or action. It suggests that the subject relies on the object to achieve a particular purpose or outcome, highlighting the role of the object as a tool, component, or element that facilitates the subject's intended activity.",
      "disambiguation_index": 0
    },
    "Predicate-has_a_maximum_of": {
      "label": "has a maximum of",
      "description": "The predicate 'has a maximum of' establishes a quantitative relationship between the subject and the object, indicating that the subject is limited to a specified upper boundary or threshold represented by the object. This implies that the subject cannot exceed the quantity or value defined by the object in any relevant context.",
      "disambiguation_index": 0
    },
    "Predicate-could_be_modeled_using": {
      "label": "could be modeled using",
      "description": "The predicate 'could be modeled using' indicates a relationship where the subject can be represented or described through the methods, techniques, or frameworks denoted by the object. It suggests that the object provides a suitable means or approach for understanding, simulating, or analyzing the characteristics or behavior of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-used_only": {
      "label": "used only",
      "description": "The predicate 'used only' establishes a restrictive relationship between the subject and the object, indicating that the subject is exclusively associated with or applicable to the object. In this context, it implies that the subject can function or be relevant solely in relation to the object, without any other alternatives or associations.",
      "disambiguation_index": 0
    },
    "Predicate-has_exactly_one": {
      "label": "has exactly one",
      "description": "The predicate 'has exactly one' establishes a relationship between the subject and the object, indicating that the subject possesses a singular instance of the object. This means that for any given subject, there is a unique and specific association with one and only one instance of the object, emphasizing exclusivity in the relationship.",
      "disambiguation_index": 0
    },
    "Predicate-explains": {
      "label": "explains",
      "description": "The predicate 'explains' denotes a relationship where the subject provides clarification, interpretation, or detailed information about the object. It indicates that the subject serves to illuminate or make comprehensible the concepts, processes, or phenomena represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-has_a_maximum_of_one": {
      "label": "has a maximum of one",
      "description": "The predicate 'has a maximum of one' establishes a relationship between the subject and the object, indicating that the subject can be associated with at most one instance of the object. This implies a constraint on the number of connections or instances that can exist between the subject and the object, ensuring exclusivity in the relationship.",
      "disambiguation_index": 0
    },
    "Predicate-is_either": {
      "label": "is either",
      "description": "The predicate 'is either' establishes a relationship between the subject and the object by indicating that the subject can be classified or identified as one of two or more distinct options or states represented by the object. It suggests a choice or alternative, where the subject is associated with one of the specified possibilities, thereby providing a clear dichotomy or selection among the given options.",
      "disambiguation_index": 0
    },
    "Predicate-relates_to": {
      "label": "relates to",
      "description": "The predicate 'relates to' establishes a connection or association between the subject and the object, indicating that they share a relevant relationship or are linked in some meaningful way. This connection can encompass various forms of relationships, such as categorization, influence, or thematic relevance, thereby providing context and understanding of how the subject and object interact or correspond within a broader framework.",
      "disambiguation_index": 0
    },
    "Predicate-has_no_relationship_to": {
      "label": "has no relationship to",
      "description": "The predicate 'has no relationship to' indicates that there is no meaningful or relevant connection between the subject and the object within the context being considered. It signifies a lack of association, interaction, or influence between the two entities, suggesting that they operate independently of one another.",
      "disambiguation_index": 0
    },
    "Predicate-must_have": {
      "label": "must have",
      "description": "The predicate 'must have' indicates a necessary relationship between the subject and the object, signifying that the subject is required to possess or include the object as an essential component or characteristic. In this context, it implies that for any instance of the subject, the presence of the object is obligatory for its definition or functionality.",
      "disambiguation_index": 0
    },
    "Predicate-derived_from": {
      "label": "derived from",
      "description": "The predicate 'derived from' indicates a relationship where the subject is a result or outcome that originates from the object. It signifies that the subject has been generated, influenced, or created based on the characteristics, properties, or data provided by the object. This connection often implies a transformation or processing of the object to produce the subject.",
      "disambiguation_index": 0
    },
    "Predicate-is_between": {
      "label": "is between",
      "description": "The predicate 'is between' establishes a relational context where the subject is positioned within a range defined by the object. It indicates that the subject exists in a state or condition that falls within the limits or boundaries set by the object, suggesting a temporal, spatial, or conceptual intermediary status.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_derived_from": {
      "label": "can be derived from",
      "description": "The predicate 'can be derived from' indicates a relationship where the subject is a result or outcome that is obtained through a process or calculation involving the object. It signifies that the object provides the necessary information, data, or basis from which the subject is generated or inferred.",
      "disambiguation_index": 0
    },
    "Predicate-has_become_standard_in": {
      "label": "has become standard in",
      "description": "The predicate 'has become standard in' indicates that the subject has reached a level of acceptance or recognition within the context of the object, suggesting that it is now commonly accepted, practiced, or utilized in that particular field or area of study.",
      "disambiguation_index": 0
    },
    "Predicate-to_be_potential_uses_of": {
      "label": "to be potential uses of",
      "description": "The predicate 'to be potential uses of' establishes a relationship where the subject represents a concept, feature, or capability that can be applied or utilized in various ways, while the object denotes a specific entity, tool, or system that can embody or realize those applications. This connection implies that the subject provides opportunities or functions that the object can fulfill or leverage.",
      "disambiguation_index": 0
    },
    "Predicate-is_able_to_do_something_using": {
      "label": "is able to do something using",
      "description": "The predicate 'is able to do something using' establishes a relationship where the subject possesses the capability or skill to perform an action or task by means of the object. It indicates that the subject can leverage the object as a tool, resource, or medium to achieve a specific outcome or fulfill a particular function.",
      "disambiguation_index": 0
    },
    "Predicate-might_allow": {
      "label": "might allow",
      "description": "The predicate 'might allow' indicates a potential or conditional capability of the subject to enable, permit, or facilitate the occurrence or expression of the object. It suggests that under certain circumstances, the subject has the ability to create opportunities for the object to manifest or be realized, without guaranteeing that this will always happen.",
      "disambiguation_index": 0
    },
    "Predicate-conclude_that": {
      "label": "conclude that",
      "description": "The predicate 'conclude that' indicates a judgment or determination made by the subject based on evidence, reasoning, or analysis, leading to a specific assertion or belief represented by the object. It signifies the process of arriving at a final decision or opinion regarding the object after considering relevant information.",
      "disambiguation_index": 0
    },
    "Predicate-from_the_point_of_view_of": {
      "label": "from the point of view of",
      "description": "The predicate 'from the point of view of' establishes a perspective or subjective lens through which the subject is evaluated or understood in relation to the object. It indicates that the interpretation or assessment of the subject is influenced by the specific experiences, beliefs, or knowledge of the actor represented by the object. This connection highlights the variability of understanding based on differing viewpoints, suggesting that the same subject may be perceived differently depending on the actor's unique context or position.",
      "disambiguation_index": 0
    },
    "Predicate-requires_modeling_of": {
      "label": "requires modeling of",
      "description": "The predicate 'requires modeling of' indicates that the subject necessitates the creation or representation of a conceptual or functional framework related to the object. This implies that in order to understand, analyze, or implement the subject effectively, it is essential to develop a model that encapsulates the characteristics, behaviors, or interactions associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-communicates": {
      "label": "communicates",
      "description": "The predicate 'communicates' denotes the action of conveying information, ideas, or feelings from the subject to the object. In this context, it implies that the subject is actively sharing or expressing something that is intended to be understood by the object, which can represent a concept, a feature, or an opportunity for interaction. This interaction can occur through various means such as verbal, non-verbal, written, or digital communication.",
      "disambiguation_index": 0
    },
    "Predicate-integrates": {
      "label": "integrates",
      "description": "The predicate 'integrates' denotes a relationship in which the subject combines or unifies with the object to form a cohesive whole. This implies that the subject incorporates elements or functionalities of the object, enhancing its capabilities or effectiveness. The integration process often results in a synergistic effect, where the combined entities work together more efficiently than they would separately.",
      "disambiguation_index": 0
    },
    "Predicate-cater_for": {
      "label": "cater for",
      "description": "The predicate 'cater for' indicates that the subject provides support, services, or solutions that meet the requirements or preferences of the object. It implies a relationship where the subject is designed or intended to fulfill the needs or expectations of the object.",
      "disambiguation_index": 0
    },
    "Predicate-detects": {
      "label": "detects",
      "description": "The predicate 'detects' indicates an action performed by the subject that involves identifying or recognizing the presence, state, or characteristics of the object. In the context of the example, it signifies that the subject (e.g., Device B) is capable of perceiving or interpreting information related to the object (e.g., user intent), thereby establishing a relationship where the subject actively engages in the process of observation or analysis to gain insights about the object.",
      "disambiguation_index": 0
    },
    "Predicate-interacts_with": {
      "label": "interacts with",
      "description": "The predicate 'interacts with' denotes a relationship in which the subject engages or communicates with the object, resulting in a reciprocal influence or effect. This interaction can involve various forms of engagement, such as physical contact, functional use, or conceptual association, where the subject's actions or presence affect the characteristics or behavior of the object, and vice versa. In the context of the example, it implies that Device B has a relationship with affordance X that allows for a meaningful exchange or utilization of capabilities.",
      "disambiguation_index": 0
    },
    "Predicate-receives": {
      "label": "receives",
      "description": "The predicate 'receives' indicates an action where the subject is the entity that takes in or accepts information, signals, or inputs from an external source, represented by the object. In this context, it implies a transfer of data or intent from the object to the subject, establishing a relationship where the subject becomes aware of or responsive to the information conveyed by the object.",
      "disambiguation_index": 0
    },
    "Predicate-would_be_able_to_understand": {
      "label": "would be able to understand",
      "description": "The predicate 'would be able to understand' indicates a potential capability or capacity of the subject to comprehend or grasp the meaning, significance, or nuances of the object. In the context of the example triple, it suggests that the subject, which could be any entity such as a device or system, has the ability to interpret or make sense of the user intent, which is the object. This implies a level of intelligence or functionality that allows the subject to process information and respond appropriately based on its understanding.",
      "disambiguation_index": 0
    },
    "Predicate-is_to_interact_with": {
      "label": "is to interact with",
      "description": "The predicate 'is to interact with' establishes a relationship where the subject is defined by its intention or purpose to engage or connect with the object. This interaction implies a dynamic exchange or relationship, suggesting that the subject seeks to utilize, influence, or respond to the object in a meaningful way. It highlights the role of the object as a target or medium for the subject's actions or intentions.",
      "disambiguation_index": 0
    },
    "Predicate-understands_(1)": {
      "label": "understands",
      "description": "The predicate 'understands' indicates a cognitive or interpretative relationship where the subject possesses the ability to comprehend, grasp, or make sense of the information or concepts represented by the object. In this context, it suggests that the subject can recognize, interpret, or respond appropriately to the nuances or meanings associated with the object, thereby facilitating effective communication or interaction.",
      "disambiguation_index": 1
    },
    "Predicate-should_be_mapped_to": {
      "label": "should be mapped to",
      "description": "The predicate 'should be mapped to' indicates a relationship where the subject is conceptually linked or associated with the object, suggesting that the subject can be represented, interpreted, or understood in terms of the object. This mapping implies a correspondence or a translation of meaning, where the subject's characteristics or functions are aligned with those of the object, facilitating a clearer understanding or application of the subject in relation to the object.",
      "disambiguation_index": 0
    },
    "Predicate-rather_than": {
      "label": "rather than",
      "description": "The predicate 'rather than' is used to indicate a preference or choice between two alternatives, suggesting that the subject is being contrasted with the object. It implies that the subject is favored or considered more relevant, significant, or appropriate in a given context compared to the object.",
      "disambiguation_index": 0
    },
    "Predicate-supports": {
      "label": "supports",
      "description": "The predicate 'supports' indicates a relationship in which the subject provides assistance, reinforcement, or a foundation for the object. In this context, it suggests that the subject enables, facilitates, or enhances the capabilities or functions of the object, thereby establishing a connection where the object relies on or benefits from the subject.",
      "disambiguation_index": 0
    },
    "Predicate-hosts": {
      "label": "hosts",
      "description": "The predicate 'hosts' indicates a relationship where the subject provides a platform or environment for the object to exist or function. In this context, it suggests that the subject is capable of supporting, containing, or facilitating the object, which can represent a feature, capability, or service associated with the subject.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_hosted_by": {
      "label": "can be hosted by",
      "description": "The predicate 'can be hosted by' indicates a relationship where the subject has the capability or potential to be supported, accommodated, or executed by the object. It implies that the object provides the necessary environment, resources, or conditions for the subject to exist or function effectively.",
      "disambiguation_index": 0
    },
    "Predicate-afforded_by": {
      "label": "afforded by",
      "description": "The predicate 'afforded by' establishes a relationship where the subject represents a capability, opportunity, or potential that is provided or enabled by the object. In this context, the subject is an affordance, which signifies a possibility for action or interaction, while the object is typically a device or entity that facilitates or supports that possibility. This relationship highlights how the characteristics or functionalities of the object contribute to the existence or realization of the affordance.",
      "disambiguation_index": 0
    },
    "Predicate-has_cardinality_of": {
      "label": "has cardinality of",
      "description": "The predicate 'has cardinality of' establishes a relationship between the subject and the object by specifying the quantitative nature of the association or relationship that the subject has with other entities. It indicates the number of instances of one entity that can be associated with instances of another entity, thereby defining the type of relationship in terms of its cardinality, such as one-to-one, one-to-many, or many-to-many.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_sub_class_of": {
      "label": "is a sub class of",
      "description": "The predicate 'is a sub class of' establishes a hierarchical relationship between two entities, where the subject represents a more specific category or type that falls under the broader category represented by the object. This indicates that all instances of the subject share characteristics or properties with the instances of the object, thereby forming a classification structure in which the subject is a specialized version of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_the_core_of": {
      "label": "is the core of",
      "description": "The predicate 'is the core of' indicates a fundamental relationship where the subject serves as the essential or central component that underpins, supports, or constitutes the object. It implies that the subject is integral to the existence, functionality, or identity of the object, suggesting that without the subject, the object would lack its primary characteristics or operational capacity.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_lightweight_but_self-contained_core_ontology_which_itself_is_the_core_of": {
      "label": "is a lightweight but self-contained core ontology which itself is the core of",
      "description": "This predicate indicates that the subject is a fundamental and efficient ontology that encapsulates essential concepts and relationships, serving as the foundational framework for the object. It emphasizes the ontology's lightweight nature, suggesting it is designed to be easily manageable and implementable, while also being comprehensive enough to support the structure and functionality of the object it is associated with.",
      "disambiguation_index": 0
    },
    "Predicate-models_the_relationship_between": {
      "label": "models the relationship between",
      "description": "The predicate 'models the relationship between' indicates a conceptual or functional connection between the subject and the object, suggesting that the subject serves as a representation or framework for understanding how the object interacts with or relates to other entities. This relationship often encompasses aspects such as roles, responsibilities, or dependencies that exist between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-hdgimanufacturedBy": {
      "label": "hdgi:manufacturedBy",
      "description": "The predicate 'hdgi:manufacturedBy' establishes a relationship between a subject, typically representing a device or product, and an object that denotes the entity responsible for its production or manufacturing. This connection indicates that the subject is created or produced by the entity identified as the object, thereby linking the manufactured item to its manufacturer.",
      "disambiguation_index": 0
    },
    "Predicate-manufactured_by": {
      "label": "manufactured by",
      "description": "The predicate 'manufactured by' establishes a relationship between a subject, typically representing a product or device, and an object that denotes the entity responsible for its production. This connection indicates that the subject is the result of the manufacturing processes carried out by the object, thereby linking the creation of the subject to the capabilities, reputation, or characteristics of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_one_of_the_major_contributions_in": {
      "label": "is one of the major contributions in",
      "description": "The predicate 'is one of the major contributions in' establishes a relationship where the subject is identified as a significant element or achievement within the context of the object. It implies that the subject plays a crucial role or has a notable impact in the area represented by the object, highlighting its importance and relevance in that specific domain.",
      "disambiguation_index": 0
    },
    "Predicate-identify": {
      "label": "identify",
      "description": "The predicate 'identify' denotes the action of recognizing, determining, or establishing the nature or characteristics of the object by the subject. It implies a process where the subject analyzes or interprets the object to ascertain its identity, meaning, or significance within a given context.",
      "disambiguation_index": 0
    },
    "Predicate-is_through": {
      "label": "is through",
      "description": "The predicate 'is through' indicates a means or method by which the subject achieves or realizes the object. It suggests that the relationship between the subject and the object is mediated by a process, pathway, or mechanism, highlighting the role of the object as a facilitator or conduit for the subject's action or state.",
      "disambiguation_index": 0
    },
    "Predicate-is_instead_of": {
      "label": "is instead of",
      "description": "The predicate 'is instead of' indicates a substitution or replacement relationship between the subject and the object, suggesting that the subject serves as an alternative to the object. It implies that the subject fulfills a similar role or function as the object but does so in a different manner or through a different approach.",
      "disambiguation_index": 0
    },
    "Predicate-is": {
      "label": "is",
      "description": "The predicate 'is' serves as a linking verb that establishes an identity or relationship between the subject and the object. It indicates that the subject can be defined, classified, or described in terms of the object, suggesting that the object provides essential information about the nature, characteristics, or role of the subject within a given context.",
      "disambiguation_index": 0
    },
    "Predicate-is_done_through": {
      "label": "is done through",
      "description": "The predicate 'is done through' indicates a means or method by which the subject achieves or accomplishes a certain action or process, as represented by the object. It establishes a relationship where the subject relies on the object as a necessary component or facilitator for the completion of the action.",
      "disambiguation_index": 0
    },
    "Predicate-run": {
      "label": "run",
      "description": "The predicate 'run' indicates the action of executing or operating a process or function, where the subject is the entity that initiates or performs the action, and the object represents the specific task, operation, or outcome that is being carried out or achieved as a result of that action.",
      "disambiguation_index": 0
    },
    "Predicate-run_in": {
      "label": "run in",
      "description": "The predicate 'run in' indicates that the subject is executed or operates within the context or framework of the object. It suggests a functional relationship where the subject utilizes or is implemented through the object, often implying a dependency or integration of the subject's processes with the characteristics or capabilities of the object.",
      "disambiguation_index": 0
    },
    "Predicate-illustrates": {
      "label": "illustrates",
      "description": "The predicate 'illustrates' serves to establish a relationship where the subject provides a representation, example, or demonstration of the object. It indicates that the subject conveys or clarifies the characteristics, functionality, or significance of the object through visual, conceptual, or practical means.",
      "disambiguation_index": 0
    },
    "Predicate-wrapped_with": {
      "label": "wrapped with",
      "description": "The predicate 'wrapped with' indicates that the subject is enveloped or encapsulated by the object, suggesting a protective or enhancing layer that modifies the subject's accessibility or functionality. This relationship implies that the object provides additional features, interfaces, or structures that complement or augment the subject, facilitating interaction or integration in a specific context.",
      "disambiguation_index": 0
    },
    "Predicate-make_easier_and_faster_the_integration_with": {
      "label": "make easier and faster the integration with",
      "description": "The predicate 'make easier and faster the integration with' indicates a facilitative relationship where the subject enhances the process of connecting or combining with the object. It suggests that the subject provides tools, methods, or features that streamline and accelerate the integration process, thereby reducing complexity and time required for the object to work effectively with the subject.",
      "disambiguation_index": 0
    },
    "Predicate-makes_easier": {
      "label": "makes easier",
      "description": "The predicate 'makes easier' indicates a facilitative relationship where the subject enhances or simplifies the process or experience associated with the object. It suggests that the subject contributes to reducing complexity, effort, or obstacles in relation to the object, thereby improving accessibility or usability.",
      "disambiguation_index": 0
    },
    "Predicate-can_refer_to": {
      "label": "can refer to",
      "description": "The predicate 'can refer to' establishes a relationship where the subject is capable of indicating, mentioning, or alluding to the object. It implies that the subject has the ability to connect with or point to the object in a meaningful way, often in the context of communication, representation, or categorization.",
      "disambiguation_index": 0
    },
    "Predicate-to_find": {
      "label": "to find",
      "description": "The predicate 'to find' indicates the action of discovering or locating something that is sought after. It connects the subject, which represents the entity or source conducting the search, with the object, which denotes the specific item or information being sought. In this context, 'to find' implies an active process of searching and identifying relevant elements within a broader context.",
      "disambiguation_index": 0
    },
    "Predicate-contains": {
      "label": "contains",
      "description": "The predicate 'contains' indicates that the subject holds, includes, or possesses the object within its scope or boundaries. It establishes a relationship where the subject is seen as a container or repository that encompasses the object, which can be a physical item, a concept, or a collection of items. This relationship implies that the object is an integral part of the subject, contributing to its overall identity or functionality.",
      "disambiguation_index": 0
    },
    "Predicate-upload": {
      "label": "upload",
      "description": "The predicate 'upload' signifies the action of transferring data or files from a source, typically a local system or device, to a destination, often a remote server or repository. In the context of the subject and object, it indicates that the subject is initiating the process of sending or placing information into the object, which serves as the target location for the uploaded content.",
      "disambiguation_index": 0
    },
    "Predicate-will_be_accessible_to": {
      "label": "will be accessible to",
      "description": "The predicate 'will be accessible to' indicates that the subject is expected to be available for use, interaction, or engagement by the object. It implies a future state where the object, which can be an individual, group, or community, will have the ability to access, utilize, or benefit from the subject. This connection suggests a relationship of availability and potential interaction between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-are_available_to": {
      "label": "are available to",
      "description": "The predicate 'are available to' indicates that the subject is accessible or obtainable by the object, suggesting a relationship where the subject can be utilized, accessed, or engaged with by the entity represented by the object. This implies a provision of resources, information, or tools that can be leveraged by the object for various purposes.",
      "disambiguation_index": 0
    },
    "Predicate-help_to_reduce": {
      "label": "help to reduce",
      "description": "The predicate 'help to reduce' indicates a supportive or facilitative relationship between the subject and the object, where the subject contributes to the diminishment or lessening of the qualities, characteristics, or presence of the object. It implies that the subject plays a role in mitigating, lowering, or alleviating the extent or impact of the object in some context.",
      "disambiguation_index": 0
    },
    "Predicate-increase_the_reuse_of": {
      "label": "increase the reuse of",
      "description": "The predicate 'increase the reuse of' indicates an action or process whereby the subject aims to enhance or promote the frequency and extent to which the object is utilized again. This implies a focus on optimizing the application or implementation of the object in various contexts, thereby encouraging its repeated use rather than creating new instances or alternatives.",
      "disambiguation_index": 0
    },
    "Predicate-will_help_to_reduce": {
      "label": "will help to reduce",
      "description": "The predicate 'will help to reduce' indicates a supportive or facilitative relationship between the subject and the object, suggesting that the subject has the capacity or potential to lessen the quantity, intensity, or impact of the object. In this context, the subject is positioned as a proactive agent or factor that contributes to the diminishment of the object, which is characterized as something excessive or unnecessary.",
      "disambiguation_index": 0
    },
    "Predicate-looked_at": {
      "label": "looked at",
      "description": "The predicate 'looked at' indicates an action where the subject directs their attention or observation towards the object, suggesting a process of examination, consideration, or analysis of the object by the subject.",
      "disambiguation_index": 0
    },
    "Predicate-mapped_into": {
      "label": "mapped into",
      "description": "The predicate 'mapped into' indicates a relationship where the subject is transformed, represented, or organized in a way that aligns with the structure or framework of the object. It suggests that the subject has been integrated or adapted to fit within the context or parameters defined by the object, facilitating a connection or correspondence between the two.",
      "disambiguation_index": 0
    },
    "Predicate-query_about": {
      "label": "query about",
      "description": "The predicate 'query about' establishes a relationship where the subject seeks information or clarification regarding the object. It indicates an inquiry made by the subject that is directed towards understanding, learning, or obtaining details related to the object.",
      "disambiguation_index": 0
    },
    "Predicate-allows_using": {
      "label": "allows using",
      "description": "The predicate 'allows using' indicates that the subject provides the capability or permission to utilize the object. In this context, it signifies that the subject enables access to or interaction with the object, facilitating its use in a practical or functional manner.",
      "disambiguation_index": 0
    },
    "Predicate-is_made_under": {
      "label": "is made under",
      "description": "The predicate 'is made under' establishes a relationship between a subject and an object, indicating that the subject is created or developed in accordance with the guidelines, rules, or framework specified by the object. This often refers to the legal, operational, or structural conditions under which the subject operates, such as licenses, standards, or methodologies.",
      "disambiguation_index": 0
    },
    "Predicate-deployed_in": {
      "label": "deployed in",
      "description": "The predicate 'deployed in' indicates the relationship between a subject and an object, where the subject is placed or established within the context or environment represented by the object. It suggests that the subject is actively utilized or operational within the specified setting, highlighting the integration or implementation of the subject in that particular domain.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_deployed_in": {
      "label": "can be deployed in",
      "description": "The predicate 'can be deployed in' indicates the capability or suitability of the subject to be implemented or utilized within the context or environment specified by the object. It suggests that the subject is adaptable to the conditions or infrastructure represented by the object, allowing for its operational use in that particular setting.",
      "disambiguation_index": 0
    },
    "Predicate-continues_the_integration_with": {
      "label": "continues the integration with",
      "description": "The predicate 'continues the integration with' indicates an ongoing process where the subject is actively working to enhance or maintain a collaborative relationship with the object. This suggests that the subject is involved in efforts to ensure compatibility, functionality, or synergy between its own systems or services and those represented by the object, thereby fostering a cohesive operational environment.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_prerequisite_to_run": {
      "label": "is a prerequisite to run",
      "description": "The predicate 'is a prerequisite to run' establishes a necessary condition or requirement that must be fulfilled by the subject in order for the object to function or operate effectively. It indicates that the subject provides essential support or capabilities that enable the successful execution or performance of the object.",
      "disambiguation_index": 0
    },
    "Predicate-run_as": {
      "label": "run as",
      "description": "The predicate 'run as' indicates the operational context or environment in which the subject is executed or functions, specifying the role or type of service it embodies or operates under, thereby linking the subject to the object in terms of its deployment or execution framework.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_made": {
      "label": "can be made",
      "description": "The predicate 'can be made' indicates the potential or capability of the subject to be transformed or created into the object. It suggests that there exists a possibility or method for the subject to be developed, constructed, or configured in such a way that it aligns with the characteristics or functions of the object.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_found": {
      "label": "can be found",
      "description": "The predicate 'can be found' indicates the existence or availability of the subject in relation to the object, suggesting that the subject is accessible or discoverable within the context of the object. It implies a connection where the subject is a source or location where the object can be located or retrieved.",
      "disambiguation_index": 0
    },
    "Predicate-integrating_to": {
      "label": "integrating to",
      "description": "The predicate 'integrating to' signifies a relationship where the subject is being connected or combined with the object in a manner that enhances functionality or interoperability. This integration typically involves the subject adopting or incorporating features, data, or capabilities from the object, thereby creating a cohesive system or workflow that allows for improved performance or user experience.",
      "disambiguation_index": 0
    },
    "Predicate-is_being_integrated_with": {
      "label": "is being integrated with",
      "description": "The predicate 'is being integrated with' indicates an ongoing process in which the subject is being combined or connected with the object, suggesting a collaborative or functional relationship between the two entities. This integration may involve the merging of features, functionalities, or data, and typically aims to enhance the capabilities or performance of the subject by utilizing the resources or attributes of the object.",
      "disambiguation_index": 0
    },
    "Predicate-get": {
      "label": "get",
      "description": "The predicate 'get' indicates an action performed by the subject to obtain or receive the object, which represents information, resources, or experiences. It establishes a relationship where the subject actively seeks to acquire the object, resulting in a transfer of possession or understanding.",
      "disambiguation_index": 0
    },
    "Predicate-try": {
      "label": "try",
      "description": "The predicate 'try' indicates an action where the subject makes an attempt to engage with or experience the object. It conveys a sense of effort or experimentation, suggesting that the subject is seeking to determine the feasibility, effectiveness, or enjoyment of the object, which can be a task, activity, or item.",
      "disambiguation_index": 0
    },
    "Predicate-can_get": {
      "label": "can get",
      "description": "The predicate 'can get' indicates the ability or capacity of the subject to obtain or access the object. It suggests that the subject has the potential to acquire the object, which may involve retrieving information, gaining insights, or achieving a certain level of understanding or possession related to the object.",
      "disambiguation_index": 0
    },
    "Predicate-make_the_integration_of": {
      "label": "make the integration of",
      "description": "The predicate 'make the integration of' indicates the process or action of facilitating the combination or incorporation of the subject with the object, where the subject represents a component, tool, or system that is being utilized to achieve a seamless connection or functionality with the object, which refers to another component, service, or system. This predicate emphasizes the effort or method involved in ensuring that the two elements work together effectively.",
      "disambiguation_index": 0
    },
    "Predicate-are_for": {
      "label": "are for",
      "description": "The predicate 'are for' indicates a purpose or intended use of the subject in relation to the object. It establishes a connection where the subject serves a specific function or is designed to support, facilitate, or enhance the capabilities of the object.",
      "disambiguation_index": 0
    },
    "Predicate-presents": {
      "label": "presents",
      "description": "The predicate 'presents' indicates a relationship where the subject introduces, displays, or offers the object, often in a manner that conveys information, features, or characteristics. In this context, it suggests that the subject is actively showcasing or making the object known to an audience or observer.",
      "disambiguation_index": 0
    },
    "Predicate-maps_with": {
      "label": "maps with",
      "description": "The predicate 'maps with' indicates a relationship where the subject is associated with or corresponds to the object in a way that highlights a connection or alignment between them. This suggests that the subject provides a framework or representation that relates to the characteristics or functionalities of the object, facilitating understanding or interaction between the two.",
      "disambiguation_index": 0
    },
    "Predicate-towards_building": {
      "label": "towards building",
      "description": "The predicate 'towards building' indicates a directional relationship where the subject is contributing to or facilitating the development or creation of the object. It suggests that the subject represents an action, effort, or process that is aimed at achieving the establishment or formation of the object, which is typically a complex system, structure, or body of knowledge.",
      "disambiguation_index": 0
    },
    "Predicate-has_purpose_of_bringing": {
      "label": "has purpose of bringing",
      "description": "The predicate 'has purpose of bringing' establishes a relationship between a subject and an object by indicating that the subject is intended or designed to achieve a specific outcome or benefit represented by the object. It conveys the idea that the actions, functions, or characteristics of the subject are directed towards facilitating or enhancing the experience, condition, or state described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_built_towards": {
      "label": "is built towards",
      "description": "The predicate 'is built towards' indicates a directional relationship where the subject is designed, developed, or structured with the intention of achieving or facilitating the outcome represented by the object. It implies a purposeful alignment of resources, efforts, or features to enhance or realize the specified goal.",
      "disambiguation_index": 0
    },
    "Predicate-can_assist": {
      "label": "can assist",
      "description": "The predicate 'can assist' indicates a supportive or facilitative relationship between the subject and the object, suggesting that the subject has the capability or potential to provide help, guidance, or enhancement to the object in achieving its goals or functions.",
      "disambiguation_index": 0
    },
    "Predicate-helps_to_express": {
      "label": "helps to express",
      "description": "The predicate 'helps to express' indicates a facilitative relationship where the subject provides support, clarification, or enhancement to the object, enabling or improving the communication or representation of the object's meaning or concept. This connection suggests that the subject plays a significant role in articulating, conveying, or manifesting the qualities or characteristics associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-helps_to_carry_out": {
      "label": "helps to carry out",
      "description": "The predicate 'helps to carry out' indicates a supportive or facilitative relationship between the subject and the object, where the subject provides assistance, resources, or mechanisms that enable the successful execution or implementation of the activities or processes represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-developing": {
      "label": "developing",
      "description": "The predicate 'developing' signifies an active process in which the subject is engaged in the creation, enhancement, or elaboration of the object. It implies a transformation or progression from an initial state to a more refined or complex form, often involving the integration of various components or insights. In this context, the subject is taking initiative to build or improve upon the object, which represents the specific elements or concepts being worked on.",
      "disambiguation_index": 0
    },
    "Predicate-extracted_from": {
      "label": "extracted from",
      "description": "The predicate 'extracted from' indicates a relationship where the subject is derived or obtained from the object. It implies that the subject consists of components, features, or information that have been taken or sourced from the object, suggesting a process of selection or identification that highlights the origin of the subject's characteristics.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_integrated_with": {
      "label": "can be integrated with",
      "description": "The predicate 'can be integrated with' indicates a potential compatibility or interoperability between the subject and the object, suggesting that the subject has the capability to work in conjunction with or enhance the functionality of the object. This implies that the subject can be combined or utilized alongside the object to achieve a more comprehensive or effective system.",
      "disambiguation_index": 0
    },
    "Predicate-integrated_with": {
      "label": "integrated with",
      "description": "The predicate 'integrated with' indicates a relationship where the subject is combined or coordinated with the object to function together as a cohesive unit. This integration implies that the subject enhances or complements the capabilities of the object, or vice versa, resulting in improved performance, efficiency, or functionality in a specific context.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_extended_by_incorporating": {
      "label": "can be extended by incorporating",
      "description": "The predicate 'can be extended by incorporating' indicates a relationship where the subject has the potential to be enhanced or broadened through the addition of new elements or components represented by the object. This suggests that the subject is adaptable and can evolve by integrating the specified object, thereby enriching its scope or functionality.",
      "disambiguation_index": 0
    },
    "Predicate-incorporating": {
      "label": "incorporating",
      "description": "The predicate 'incorporating' signifies the action of including or integrating one element within another. In the context of the subject and object, it indicates that the subject encompasses or contains the object as a part of its overall structure or composition. This relationship highlights the process of blending or merging distinct components to form a cohesive whole.",
      "disambiguation_index": 0
    },
    "Predicate-release_and_deploy_in": {
      "label": "release and deploy in",
      "description": "The predicate 'release and deploy in' signifies the process of making a software application or service available for use and subsequently installing it in a specified environment or platform. It connects the subject, which represents the software or service being released, with the object, which denotes the environment or platform where the software is intended to operate. This action typically involves preparing the software for public access and ensuring it is properly configured to function within the designated infrastructure.",
      "disambiguation_index": 0
    },
    "Predicate-release_to": {
      "label": "release to",
      "description": "The predicate 'release to' indicates a transfer or provision of something from the subject to the object, suggesting that the subject is making available or distributing a resource, capability, or information to the object. This connection implies a directional flow where the subject is the source of the release and the object is the recipient, often in the context of enabling functionality or access.",
      "disambiguation_index": 0
    },
    "Predicate-to_leading_hand-gesture_supported_systems": {
      "label": "to leading hand-gesture supported systems",
      "description": "The predicate 'to leading hand-gesture supported systems' indicates a relationship where the subject, such as API clients, is designed to interact with or facilitate communication with systems that utilize hand gestures as a primary mode of input or control. This connection implies that the subject is capable of integrating with or enhancing the functionality of such systems, enabling users to engage with technology through intuitive hand movements.",
      "disambiguation_index": 0
    },
    "Predicate-conduct_using": {
      "label": "conduct using",
      "description": "The predicate 'conduct using' establishes a relationship where the subject is performing an activity or study with the aid of the object. It indicates that the subject utilizes the object as a tool, method, or medium to carry out the specified action or research.",
      "disambiguation_index": 0
    },
    "Predicate-describes_and_maps": {
      "label": "describes and maps",
      "description": "The predicate 'describes and maps' indicates a relationship where the subject provides a detailed explanation and representation of the object, illustrating how the object is characterized, categorized, or understood within a specific context. This connection emphasizes the subject's role in elucidating the features, functions, or significance of the object, often through a systematic or structured approach.",
      "disambiguation_index": 0
    },
    "Predicate-presents_a_systematic_analysis_and_ontology_for_formally_describing": {
      "label": "presents a systematic analysis and ontology for formally describing",
      "description": "The predicate 'presents a systematic analysis and ontology for formally describing' indicates that the subject is providing a structured and comprehensive examination, along with a conceptual framework, aimed at articulating and categorizing the characteristics, relationships, and functions of the object. This implies a scholarly effort to clarify and define the object in a way that is methodical and theoretically grounded, facilitating better understanding and communication about the subject matter.",
      "disambiguation_index": 0
    },
    "Predicate-is_formally_represented_by": {
      "label": "is formally represented by",
      "description": "The predicate 'is formally represented by' establishes a formal relationship between a subject and an object, indicating that the subject is depicted, illustrated, or expressed through the object in a structured or systematic manner. This connection often implies that the object serves as a model, framework, or set of symbols that conveys the essential characteristics or concepts of the subject, thereby facilitating understanding, analysis, or communication of the subject's content.",
      "disambiguation_index": 0
    },
    "Predicate-hdgiincludesGesture": {
      "label": "hdgi:includesGesture",
      "description": "The predicate 'hdgi:includesGesture' establishes a relationship between a set of gestures utilized in Human Device Interactions (HDI) and a specific type of gesture, indicating that the gestures encompassed within the subject are part of or incorporate the gesture represented by the object. This connection highlights the relevance of the object gesture within the broader context of gestures used in HDI.",
      "disambiguation_index": 0
    },
    "Predicate-is_represented_by": {
      "label": "is represented by",
      "description": "The predicate 'is represented by' establishes a relationship where the subject is depicted, illustrated, or symbolized by the object. It indicates that the object serves as a representation, model, or example of the subject, conveying its meaning, characteristics, or essence in a particular context.",
      "disambiguation_index": 0
    },
    "Predicate-is_designed_to_facilitate": {
      "label": "is designed to facilitate",
      "description": "The predicate 'is designed to facilitate' indicates that the subject has been intentionally created or structured to make a particular process, activity, or interaction easier or more effective, as represented by the object. It implies a purposeful intention behind the design, aiming to enhance usability, efficiency, or accessibility in relation to the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_specific_implementation_of": {
      "label": "is a specific implementation of",
      "description": "The predicate 'is a specific implementation of' establishes a relationship where the subject represents a particular instance or application that embodies the principles, concepts, or structures defined by the object. This indicates that the subject is a concrete realization or execution of the broader framework or system described by the object, demonstrating how the subject operationalizes or applies the theoretical aspects of the object in a specific context.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_formal_framework_for_describing_and_mapping_gestures_in_Human_Device_Gesture_Interaction_HDGI": {
      "label": "is a formal framework for describing and mapping gestures in Human Device Gesture Interaction (HDGI)",
      "description": "The predicate 'is a formal framework for describing and mapping gestures in Human Device Gesture Interaction (HDGI)' establishes a relationship where the subject represents a specific domain or concept within HDGI, while the object denotes a structured system or ontology that provides the necessary tools and guidelines for effectively categorizing and interpreting gestures within that domain. This connection highlights the role of the framework in facilitating a deeper understanding and organization of gesture interactions in the context of human-device communication.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_version_of": {
      "label": "is a version of",
      "description": "The predicate 'is a version of' establishes a relationship between two entities where the subject represents a specific iteration, variant, or release of the object, which is the original or foundational entity. This indicates that the subject retains core characteristics or functionalities of the object while potentially incorporating modifications, updates, or enhancements.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_formal_representation_of": {
      "label": "is a formal representation of",
      "description": "The predicate 'is a formal representation of' establishes a relationship where the subject serves as a structured and systematic depiction or model of the object. This indicates that the subject encapsulates the essential concepts, relationships, and rules of the object in a formalized manner, often using specific languages or frameworks to ensure clarity and precision in the representation.",
      "disambiguation_index": 0
    },
    "Predicate-describes_and_maps_gestures_used_in": {
      "label": "describes and maps gestures used in",
      "description": "The predicate 'describes and maps gestures used in' establishes a relationship where the subject provides a detailed account and systematic representation of the gestures that are relevant to the context or domain specified by the object. This implies an analytical framework that categorizes and illustrates how gestures function within the specified area, facilitating understanding and application of these gestures in practical scenarios.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_specific_instance_of": {
      "label": "is a specific instance of",
      "description": "The predicate 'is a specific instance of' establishes a relationship between a subject and an object where the subject represents a particular example or case that falls under the broader category defined by the object. This indicates that the subject embodies the characteristics or properties associated with the object, thereby illustrating how the subject is a concrete realization of the more general concept represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_formal_framework_for_describing_and_mapping_human_gestures_in_Human_Device_Interactions": {
      "label": "is a formal framework for describing and mapping human gestures in Human Device Interactions",
      "description": "This predicate establishes a relationship where the subject represents a structured system or model that serves the purpose of systematically outlining and interpreting the various human gestures that occur during interactions with devices. The object signifies the broader context or domain of Human Device Interactions, indicating that the framework is specifically designed to enhance understanding and facilitate communication between humans and devices through gesture recognition and mapping.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates_the_mapping_of_gestures_to_affordances": {
      "label": "facilitates the mapping of gestures to affordances",
      "description": "The predicate 'facilitates the mapping of gestures to affordances' describes a process in which a subject enables or supports the connection between specific physical gestures and the potential actions or uses that can be derived from those gestures. In this context, the subject plays a crucial role in creating a relationship that allows for the interpretation of gestures in terms of their practical implications or affordances, leading to a structured understanding represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_an_ontology_for": {
      "label": "is an ontology for",
      "description": "The predicate 'is an ontology for' establishes a relationship where the subject represents a conceptual framework or domain of knowledge, while the object denotes a specific instance or application of that framework. This connection implies that the object is defined or categorized within the broader context provided by the subject, serving as a structured representation of concepts, entities, and their relationships relevant to the subject area.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates_the_integration_and_interoperability_of_gesture_data_across_various_devices_and_applications_in_Human_Device_Interaction": {
      "label": "facilitates the integration and interoperability of gesture data across various devices and applications in Human Device Interaction",
      "description": "The predicate 'facilitates the integration and interoperability of gesture data across various devices and applications in Human Device Interaction' describes a process or function that enables different systems and applications to work together seamlessly by sharing and utilizing gesture data. It highlights the role of the subject in promoting a cohesive framework that allows for the effective exchange and use of gesture-related information, thereby enhancing the overall user experience and interaction capabilities across diverse technological platforms.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates_the_integration_and_interoperability_of_gesture_data_across_various_devices_and_applications_in_Human_Device_Interaction_(1)": {
      "label": "facilitates the integration and interoperability of gesture data across various devices and applications in Human Device Interaction",
      "description": "This predicate describes a function that enables the seamless combination and compatibility of gesture data from different sources, ensuring that various devices and applications can effectively communicate and utilize this data within the context of Human Device Interaction. It highlights the role of the subject in promoting a unified framework or system that supports the exchange and use of gesture data, thereby enhancing user experience and interaction across diverse technological platforms.",
      "disambiguation_index": 1
    },
    "Predicate-facilitates_the_mapping_of_gesture_vocabularies_through_HDGI_ontology_mappings": {
      "label": "facilitates the mapping of gesture vocabularies through HDGI ontology mappings",
      "description": "The predicate 'facilitates the mapping of gesture vocabularies through HDGI ontology mappings' indicates a process or action that enables or assists in the organization and representation of gesture vocabularies by utilizing the HDGI ontology. It connects the subject, which is the entity or method performing the facilitation, to the object, which is the HDGI ontology mappings that serve as the framework or tool for achieving this mapping. This implies a supportive role in enhancing the understanding and categorization of gestures within the context of the HDGI ontology.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates_the_integration_of_HDGI_ontology_mappings_with_our_ontology": {
      "label": "facilitates the integration of HDGI ontology mappings with our ontology",
      "description": "This predicate describes an action or process whereby the subject enables or supports the merging or alignment of a specific set of ontology mappings (in this case, HDGI ontology mappings) with another ontology (the subject). It implies a collaborative or supportive role in ensuring that the two ontological structures can work together effectively, enhancing interoperability and coherence between them.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates_the_mapping_of_gestures_to_affordances_within_the_HDGI_ontology": {
      "label": "facilitates the mapping of gestures to affordances within the HDGI ontology",
      "description": "This predicate describes a process or function that enables the connection between gestures and their corresponding affordances as defined within the Human Device Gesture Interaction (HDGI) ontology. It indicates that the subject (HDGI) plays a role in organizing or structuring how gestures can be interpreted in terms of their potential uses or interactions, thereby enhancing the understanding and application of gesture representations in relation to the capabilities they imply.",
      "disambiguation_index": 0
    },
    "Predicate-is_modeled_within": {
      "label": "is modeled within",
      "description": "The predicate 'is modeled within' establishes a relationship where the subject is conceptualized or represented as part of the framework or structure defined by the object. It indicates that the subject is integrated into the conceptual or theoretical boundaries of the object, suggesting that the subject's characteristics, behaviors, or properties are interpreted or organized according to the principles or categories outlined by the object.",
      "disambiguation_index": 0
    },
    "Predicate-presents_a_systematic_analysis_and_ontology_for_gesture_representation": {
      "label": "presents a systematic analysis and ontology for gesture representation",
      "description": "The predicate 'presents a systematic analysis and ontology for gesture representation' indicates that the subject provides a structured examination and conceptual framework regarding the representation of gestures. This involves detailing the characteristics, classifications, and relationships of gestures, thereby enhancing the understanding and categorization of how gestures are represented in various contexts. The object, 'gesture representation', serves as the focal point of this analysis, highlighting the importance of gestures in communication and interaction.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_component_of": {
      "label": "is a component of",
      "description": "The predicate 'is a component of' indicates a relationship where the subject is an integral part or element that contributes to the overall structure, function, or concept represented by the object. This relationship implies that the subject cannot be fully understood or appreciated without recognizing its role within the context of the object.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates_the_mapping_of_human_gestures_to_device_affordances": {
      "label": "facilitates the mapping of human gestures to device affordances",
      "description": "The predicate 'facilitates the mapping of human gestures to device affordances' describes a process or function whereby a subject enables or supports the connection between the physical actions or gestures made by humans and the potential actions or functionalities that devices can offer. This mapping process allows for a better understanding and interaction between users and devices, ensuring that human inputs are effectively translated into corresponding device responses or capabilities.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_specific_ontology_of_Human_Device_Gesture_Interaction": {
      "label": "is a specific ontology of Human Device Gesture Interaction",
      "description": "The predicate 'is a specific ontology of Human Device Gesture Interaction' establishes a relationship where the subject is defined as a particular framework or system that categorizes and organizes knowledge related to the interactions between humans and devices through gestures. This ontology serves to clarify and specify the concepts, terms, and relationships inherent in the domain of Human Device Gesture Interaction, thereby providing a structured understanding of how gestures are utilized in human-device communication.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_class_within": {
      "label": "is a class within",
      "description": "The predicate 'is a class within' establishes a hierarchical relationship between two entities, where the subject represents a broader category or framework, and the object denotes a specific class or type that exists within that framework. This indicates that the object is a subset or a specific instance of the category defined by the subject, thereby contributing to the organization and classification of knowledge within the given ontology.",
      "disambiguation_index": 0
    },
    "Predicate-is_involved_in": {
      "label": "is involved in",
      "description": "The predicate 'is involved in' establishes a relationship between the subject and the object, indicating that the subject actively participates in, contributes to, or is engaged with the entity represented by the object. This connection suggests a level of interaction or association where the subject plays a role in the context or activities related to the object.",
      "disambiguation_index": 0
    },
    "Predicate-describes_the_process_of": {
      "label": "describes the process of",
      "description": "The predicate 'describes the process of' establishes a relationship where the subject provides an explanation or account of the steps, methods, or actions involved in the object. It indicates that the subject offers a detailed representation or narrative that clarifies how the object is achieved or understood.",
      "disambiguation_index": 0
    },
    "Predicate-links": {
      "label": "links",
      "description": "The predicate 'links' establishes a connection or relationship between the subject and the object, indicating that the subject is associated with, related to, or references the object in some meaningful way. This connection can imply various forms of relationships, such as hierarchical, associative, or functional, depending on the context in which the subject and object are situated.",
      "disambiguation_index": 0
    },
    "Predicate-are_a_subset_of": {
      "label": "are a subset of",
      "description": "The predicate 'are a subset of' indicates a relationship where the subject represents a specific group or category that is included within a broader category represented by the object. This implies that all elements or instances of the subject share characteristics or properties that align them with the object, but the object encompasses additional elements that are not part of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-is_defined_within": {
      "label": "is defined within",
      "description": "The predicate 'is defined within' establishes a relationship where the subject is characterized or contextualized by the object, indicating that the subject's meaning, scope, or framework is encompassed by the object. This implies that the subject operates under the parameters or concepts outlined by the object, suggesting a hierarchical or associative connection.",
      "disambiguation_index": 0
    },
    "Predicate-isPerformedBy": {
      "label": "isPerformedBy",
      "description": "The predicate 'isPerformedBy' establishes a relationship between a subject and an object, indicating that the action or behavior represented by the object is executed or carried out by the subject. In this context, it connects an entity, such as a human or an agent, to the specific actions or gestures they perform, particularly in relation to interactions with devices or systems.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_structured_representation_of": {
      "label": "is a structured representation of",
      "description": "The predicate 'is a structured representation of' indicates that the subject serves as an organized and systematic depiction or model of the object. This relationship implies that the subject encapsulates the essential elements, concepts, or processes of the object in a coherent format, facilitating understanding, analysis, or application of the object in various contexts.",
      "disambiguation_index": 0
    },
    "Predicate-map": {
      "label": "map",
      "description": "The predicate 'map' establishes a relationship where the subject is associated with or represents the object, indicating a correspondence or connection between the two. In this context, it suggests that the gestures used in Human Device Interactions (HDI) are related to or can be understood in terms of device interactions, highlighting how one concept can be interpreted or analyzed through the lens of the other.",
      "disambiguation_index": 0
    },
    "Predicate-presents_a_systematic_analysis_and_ontology_for_formally_describing_gestures_used_in_Human_Device_Interactions_HDI": {
      "label": "presents a systematic analysis and ontology for formally describing gestures used in Human Device Interactions (HDI)",
      "description": "The predicate establishes a relationship where the subject provides a structured examination and conceptual framework aimed at accurately defining and categorizing the gestures that are employed in the context of interactions between humans and devices. This analysis serves to enhance the understanding and implementation of gesture-based communication in Human Device Interactions (HDI), thereby linking the subject to the broader field of device interactions.",
      "disambiguation_index": 0
    },
    "Predicate-are_represented_by": {
      "label": "are represented by",
      "description": "The predicate 'are represented by' indicates a relationship where the subject is depicted, illustrated, or symbolized through the object. It suggests that the subject's characteristics, qualities, or concepts are conveyed or expressed by the object, establishing a connection that highlights how one element serves as a representation or manifestation of the other.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates_the_understanding_and_interpretation_of_user_gestures_in_various_interactive_systems": {
      "label": "facilitates the understanding and interpretation of user gestures in various interactive systems",
      "description": "The predicate 'facilitates the understanding and interpretation of user gestures in various interactive systems' describes a relationship where the subject enhances or supports the process of recognizing and making sense of gestures made by users within different interactive environments. This process is crucial for enabling effective communication and interaction between users and systems, and it often involves the use of a structured framework or model, such as a gesture ontology, which serves as the object in this context. The predicate implies that the subject plays a key role in bridging the gap between user actions and system responses, thereby improving user experience and system functionality.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' establishes a hierarchical relationship between the subject and the object, indicating that the subject is a specific instance or example that falls under the more general category represented by the object. This relationship implies that the object encompasses a wider scope or classification that includes the subject as one of its members.",
      "disambiguation_index": 0
    }
  }
}