{
  "iri": "Paper-65",
  "title": "ICCV_2003_151_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-65-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-65-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-65-Section-1-Paragraph-1-Sentence-1",
              "text": "A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications ."
            },
            {
              "iri": "Paper-65-Section-1-Paragraph-1-Sentence-2",
              "text": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact ."
            },
            {
              "iri": "Paper-65-Section-1-Paragraph-1-Sentence-3",
              "text": "Our technique is based on an improved , dynamic-programming , stereo algorithm for efficient novel-view generation ."
            },
            {
              "iri": "Paper-65-Section-1-Paragraph-1-Sentence-4",
              "text": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface ."
            },
            {
              "iri": "Paper-65-Section-1-Paragraph-1-Sentence-5",
              "text": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space ."
            },
            {
              "iri": "Paper-65-Section-1-Paragraph-1-Sentence-6",
              "text": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams ."
            },
            {
              "iri": "Paper-65-Section-1-Paragraph-1-Sentence-7",
              "text": "These include demonstrations of synthesis of cyclopean views of extended conversational sequences ."
            },
            {
              "iri": "Paper-65-Section-1-Paragraph-1-Sentence-8",
              "text": "We further demonstrate synthesis from a freely translating virtual camera ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.00019979476928710938,
    23.25766110420227,
    35.126036405563354,
    35.34375023841858,
    0.04600095748901367,
    0.00012183189392089844,
    0.00015401840209960938,
    63.046507120132446,
    109.99417328834534,
    2.321157455444336,
    1.3196759223937988,
    0.016258716583251953,
    0.0002963542938232422,
    41.90941262245178,
    11.267299175262451,
    0.015561819076538086,
    1.0931055545806885,
    3.944962978363037,
    37.41959595680237,
    38.55144214630127,
    68.92370843887329,
    5.055915117263794,
    45.11770534515381,
    1.7572910785675049,
    0.0009543895721435547,
    0.019562721252441406
  ],
  "nodes": {
    "Entity-the_two_main_contribution_of_this_paper_are__i_-rrb-_a_new_type_of_three-plane_graph_for_dense-stereo_dynamic-programming__that_encourages_correct_occlusion_labeling__ii_-rrb-_a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface": {
      "node_id": "the_two_main_contribution_of_this_paper_are__i_-rrb-_a_new_type_of_three-plane_graph_for_dense-stereo_dynamic-programming__that_encourages_correct_occlusion_labeling__ii_-rrb-_a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface",
      "disambiguation_index": 0,
      "label": "the two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface",
      "aliases": [
        "the two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface"
      ],
      "types": [
        "dynamic programming",
        "graph",
        "contribution"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The two main contributions of this paper are algorithms for dense-stereo dynamic-programming and novel-view synthesis, which enable correct occlusion labeling and efficient generation of images from arbitrary camera positions.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-4",
          "local_name": "the two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface",
          "local_types": [
            "dynamic programming",
            "graph",
            "contribution"
          ],
          "iri": "Entity-the_two_main_contribution_of_this_paper_are__i_-rrb-_a_new_type_of_three-plane_graph_for_dense-stereo_dynamic-programming__that_encourages_correct_occlusion_labeling__ii_-rrb-_a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface-Mention-1"
        }
      ],
      "relevance": 0.78515625
    },
    "Entity-furthermore__this_paper_present_a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model_to_enhance_the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-__and_a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space": {
      "node_id": "furthermore__this_paper_present_a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model_to_enhance_the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-__and_a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space",
      "disambiguation_index": 0,
      "label": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space",
      "aliases": [
        "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space"
      ],
      "types": [
        "algorithm",
        "background model"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A novel set of algorithms, including one for temporal maintenance of background models and another for cost aggregation in three-dimensional matching spaces.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space",
          "local_types": [
            "algorithm",
            "background model"
          ],
          "iri": "Entity-furthermore__this_paper_present_a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model_to_enhance_the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-__and_a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space-Mention-1"
        }
      ],
      "relevance": 0.76416015625
    },
    "Entity-the_proposed_algorithm": {
      "node_id": "the_proposed_algorithm",
      "disambiguation_index": 0,
      "label": "the proposed algorithm",
      "aliases": [
        "the new algorithm",
        "the proposed algorithm"
      ],
      "types": [
        "algorithm",
        "software"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A novel view generation algorithm that synthesizes images from a virtual camera in arbitrary position, facilitating eye contact in one-to-one teleconferencing applications.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "the proposed algorithm",
          "local_types": [
            "algorithm",
            "software"
          ],
          "iri": "Entity-the_proposed_algorithm-Mention-1"
        },
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-6",
          "local_name": "the new algorithm",
          "local_types": [
            "algorithm"
          ],
          "iri": "Entity-the_proposed_algorithm-Mention-2"
        }
      ],
      "relevance": 0.7529296875
    },
    "Entity-the_proposed_algorithm_synthesis_image_from_a_virtual_camera_in_arbitrary_position_-lrb-_typically_located_within_the_monitor_-rrb-_to_facilitate_eye_contact": {
      "node_id": "the_proposed_algorithm_synthesis_image_from_a_virtual_camera_in_arbitrary_position_-lrb-_typically_located_within_the_monitor_-rrb-_to_facilitate_eye_contact",
      "disambiguation_index": 0,
      "label": "the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact",
      "aliases": [
        "the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact"
      ],
      "types": [
        "algorithm",
        "image synthesis",
        "eye contact"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A system that generates synthetic images using a virtual camera.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact",
          "local_types": [
            "algorithm",
            "image synthesis",
            "eye contact"
          ],
          "iri": "Entity-the_proposed_algorithm_synthesis_image_from_a_virtual_camera_in_arbitrary_position_-lrb-_typically_located_within_the_monitor_-rrb-_to_facilitate_eye_contact-Mention-1"
        }
      ],
      "relevance": 0.74951171875
    },
    "Entity-synthesis_of_cyclopean_view": {
      "node_id": "synthesis_of_cyclopean_view",
      "disambiguation_index": 0,
      "label": "synthesis of cyclopean views",
      "aliases": [
        "synthesis of cyclopean views"
      ],
      "types": [
        "methodology",
        "algorithm"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The novel view generation algorithm's capability to synthesize images from a virtual camera in arbitrary position, typically located within the monitor.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-7",
          "local_name": "synthesis of cyclopean views",
          "local_types": [
            "methodology",
            "algorithm"
          ],
          "iri": "Entity-synthesis_of_cyclopean_view-Mention-1"
        }
      ],
      "relevance": 0.74169921875
    },
    "Entity-novel_view_generation_in_one-to-one_teleconferencing_application": {
      "node_id": "novel_view_generation_in_one-to-one_teleconferencing_application",
      "disambiguation_index": 0,
      "label": "novel view generation in one-to-one teleconferencing applications",
      "aliases": [
        "novel view generation in one-to-one teleconferencing applications"
      ],
      "types": [
        "application",
        "teleconferencing"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "An algorithm that generates novel views from virtual cameras within a computer monitor to facilitate eye contact in one-to-one teleconferencing applications.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-1",
          "local_name": "novel view generation in one-to-one teleconferencing applications",
          "local_types": [
            "application",
            "teleconferencing"
          ],
          "iri": "Entity-novel_view_generation_in_one-to-one_teleconferencing_application-Mention-1"
        }
      ],
      "relevance": 0.73681640625
    },
    "Entity-novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface": {
      "node_id": "novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface",
      "disambiguation_index": 0,
      "label": "novel-view synthesis by direct projection of the minimum-cost surface",
      "aliases": [
        "novel-view synthesis by direct projection of the minimum-cost surface"
      ],
      "types": [
        "algorithm",
        "computer vision technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A computer vision technique that synthesizes images from a virtual camera in arbitrary position using a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-4",
          "local_name": "novel-view synthesis by direct projection of the minimum-cost surface",
          "local_types": [
            "algorithm",
            "computer vision technique"
          ],
          "iri": "Entity-novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface-Mention-1"
        }
      ],
      "relevance": 0.716796875
    },
    "Entity-a_new_algorithm": {
      "node_id": "a_new_algorithm",
      "disambiguation_index": 0,
      "label": "A new algorithm",
      "aliases": [
        "A new algorithm"
      ],
      "types": [
        "algorithm"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "An improved, dynamic-programming stereo algorithm for efficient novel-view generation in one-to-one teleconferencing applications.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-1",
          "local_name": "A new algorithm",
          "local_types": [
            "algorithm"
          ],
          "iri": "Entity-a_new_algorithm-Mention-1"
        }
      ],
      "relevance": 0.701171875
    },
    "Entity-novel-view_generation": {
      "node_id": "novel-view_generation",
      "disambiguation_index": 0,
      "label": "novel-view generation",
      "aliases": [
        "novel-view generation"
      ],
      "types": [
        "task",
        "image processing task",
        "computer vision",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A computer vision task that uses a dynamic-programming-based stereo algorithm to generate images from a virtual camera in arbitrary positions, typically located within a monitor.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-3",
          "local_name": "novel-view generation",
          "local_types": [
            "task",
            "image processing task",
            "computer vision",
            "process"
          ],
          "iri": "Entity-novel-view_generation-Mention-1"
        }
      ],
      "relevance": 0.6953125
    },
    "Entity-our_technique_is_based_on_an_improved__dynamic-programming__stereo_algorithm_for_efficient_novel-view_generation": {
      "node_id": "our_technique_is_based_on_an_improved__dynamic-programming__stereo_algorithm_for_efficient_novel-view_generation",
      "disambiguation_index": 0,
      "label": "Our technique is based on an improved , dynamic-programming , stereo algorithm for efficient novel-view generation",
      "aliases": [
        "Our technique is based on an improved , dynamic-programming , stereo algorithm for efficient novel-view generation"
      ],
      "types": [
        "algorithm",
        "technique",
        "novel view generation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "An improved dynamic-programming stereo algorithm for efficiently generating novel views.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-3",
          "local_name": "Our technique is based on an improved , dynamic-programming , stereo algorithm for efficient novel-view generation",
          "local_types": [
            "algorithm",
            "technique",
            "novel view generation"
          ],
          "iri": "Entity-our_technique_is_based_on_an_improved__dynamic-programming__stereo_algorithm_for_efficient_novel-view_generation-Mention-1"
        }
      ],
      "relevance": 0.6953125
    },
    "Entity-novel_view_generation": {
      "node_id": "novel_view_generation",
      "disambiguation_index": 0,
      "label": "novel view generation",
      "aliases": [
        "novel view generation"
      ],
      "types": [
        "image processing technique",
        "computer vision application",
        "image processing",
        "computer vision",
        "technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "An image processing technique that generates images from a virtual camera in arbitrary position, typically located within a computer monitor, for facilitating eye contact in one-to-one teleconferencing applications.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-1",
          "local_name": "novel view generation",
          "local_types": [
            "image processing technique",
            "computer vision application",
            "image processing",
            "computer vision",
            "technique"
          ],
          "iri": "Entity-novel_view_generation-Mention-1"
        }
      ],
      "relevance": 0.69287109375
    },
    "Entity-this_paper": {
      "node_id": "this_paper",
      "disambiguation_index": 0,
      "label": "this paper",
      "aliases": [
        "this paper"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "This paper presents novel algorithms for temporal maintenance of background models, occlusion rendering, and cost aggregation to enhance stereo video stream processing.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "this paper",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_paper-Mention-1"
        }
      ],
      "relevance": 0.6826171875
    },
    "Entity-we": {
      "node_id": "we",
      "disambiguation_index": 0,
      "label": "We",
      "aliases": [
        "We"
      ],
      "types": [
        "author"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The authors of this paper, who are proposing an algorithm for novel view generation in one-to-one teleconferencing applications.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-8",
          "local_name": "We",
          "local_types": [
            "author"
          ],
          "iri": "Entity-we-Mention-1"
        }
      ],
      "relevance": 0.6767578125
    },
    "Entity-our_technique": {
      "node_id": "our_technique",
      "disambiguation_index": 0,
      "label": "Our technique",
      "aliases": [
        "Our technique"
      ],
      "types": [
        "technique"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A dynamic-programming-based stereo algorithm for efficiently generating novel views from video streams.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-3",
          "local_name": "Our technique",
          "local_types": [
            "technique"
          ],
          "iri": "Entity-our_technique-Mention-1"
        }
      ],
      "relevance": 0.66796875
    },
    "Entity-the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-": {
      "node_id": "the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-",
      "disambiguation_index": 0,
      "label": "the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB-",
      "aliases": [
        "the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB-"
      ],
      "types": [
        "phenomenon"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A technique for maintaining a background model over time to reduce the appearance of flickering temporal artefacts and improve the rendering of occlusions.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB-",
          "local_types": [
            "phenomenon"
          ],
          "iri": "Entity-the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb--Mention-1"
        }
      ],
      "relevance": 0.6494140625
    },
    "Entity-these": {
      "node_id": "these",
      "disambiguation_index": 0,
      "label": "These",
      "aliases": [
        "These"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Demonstrations of novel view generation for teleconferencing applications, showcasing synthesized cyclopean views and virtual camera translations.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-7",
          "local_name": "These",
          "local_types": [
            "research"
          ],
          "iri": "Entity-these-Mention-1"
        }
      ],
      "relevance": 0.642578125
    },
    "Entity-image_from_a_virtual_camera": {
      "node_id": "image_from_a_virtual_camera",
      "disambiguation_index": 0,
      "label": "images from a virtual camera",
      "aliases": [
        "images from a virtual camera"
      ],
      "types": [
        "image",
        "virtual reality"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Synthesized visual representations generated by an algorithm that combines video streams from two cameras placed on either side of a computer monitor, allowing for arbitrary positioning and facilitating eye contact.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "images from a virtual camera",
          "local_types": [
            "image",
            "virtual reality"
          ],
          "iri": "Entity-image_from_a_virtual_camera-Mention-1"
        }
      ],
      "relevance": 0.634765625
    },
    "Entity-a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model": {
      "node_id": "a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model",
      "disambiguation_index": 0,
      "label": "a novel algorithm for the temporal maintenance of a background model",
      "aliases": [
        "a novel algorithm for the temporal maintenance of a background model"
      ],
      "types": [
        "algorithm",
        "model"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A novel approach for maintaining an updated background model over time, aimed at reducing temporal artefacts and enhancing the rendering of occlusions.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "a novel algorithm for the temporal maintenance of a background model",
          "local_types": [
            "algorithm",
            "model"
          ],
          "iri": "Entity-a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model-Mention-1"
        }
      ],
      "relevance": 0.615234375
    },
    "Entity-stereo_algorithm": {
      "node_id": "stereo_algorithm",
      "disambiguation_index": 0,
      "label": "stereo algorithm",
      "aliases": [
        "stereo algorithm"
      ],
      "types": [
        "algorithm",
        "technique",
        "computer vision",
        "computer science technique"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A computer vision technique that uses a combination of algorithms and methods to calculate depth information from two or more images taken from different viewpoints.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-3",
          "local_name": "stereo algorithm",
          "local_types": [
            "algorithm",
            "technique",
            "computer vision",
            "computer science technique"
          ],
          "iri": "Entity-stereo_algorithm-Mention-1"
        }
      ],
      "relevance": 0.609375
    },
    "Entity-synthesis_from_a_freely_translating_virtual_camera": {
      "node_id": "synthesis_from_a_freely_translating_virtual_camera",
      "disambiguation_index": 0,
      "label": "synthesis from a freely translating virtual camera",
      "aliases": [
        "synthesis from a freely translating virtual camera"
      ],
      "types": [
        "method",
        "technology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The process of generating images from a virtual camera that can move freely and translate its position to facilitate novel view generation.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-8",
          "local_name": "synthesis from a freely translating virtual camera",
          "local_types": [
            "method",
            "technology"
          ],
          "iri": "Entity-synthesis_from_a_freely_translating_virtual_camera-Mention-1"
        }
      ],
      "relevance": 0.6083984375
    },
    "Entity-a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface": {
      "node_id": "a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface",
      "disambiguation_index": 0,
      "label": "a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface",
      "aliases": [
        "a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface"
      ],
      "types": [
        "methodology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A mathematical formula or procedure used to generate new views from existing images, achieved through a geometrically efficient and cost-effective process.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-4",
          "local_name": "a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface",
          "local_types": [
            "methodology"
          ],
          "iri": "Entity-a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface-Mention-1"
        }
      ],
      "relevance": 0.6064453125
    },
    "Entity-temporal_maintenance": {
      "node_id": "temporal_maintenance",
      "disambiguation_index": 0,
      "label": "temporal maintenance",
      "aliases": [
        "temporal maintenance"
      ],
      "types": [
        "maintenance process",
        "algorithmic task"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A novel algorithm for maintaining the background model over time to reduce temporal artefacts such as flicker and enhance occlusion rendering.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "temporal maintenance",
          "local_types": [
            "maintenance process",
            "algorithmic task"
          ],
          "iri": "Entity-temporal_maintenance-Mention-1"
        }
      ],
      "relevance": 0.60400390625
    },
    "Entity-new_type_of_three-plane_graph": {
      "node_id": "new_type_of_three-plane_graph",
      "disambiguation_index": 0,
      "label": "new type of three-plane graph",
      "aliases": [
        "a new type of three-plane graph",
        "new type of three-plane graph"
      ],
      "types": [
        "algorithm",
        "mathematical concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A new type of three-plane graph used in dense-stereo dynamic-programming to encourage correct occlusion labeling.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-4",
          "local_name": "new type of three-plane graph",
          "local_types": [
            "algorithm",
            "mathematical concept"
          ],
          "iri": "Entity-new_type_of_three-plane_graph-Mention-1"
        },
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-4",
          "local_name": "a new type of three-plane graph",
          "local_types": [
            "algorithm"
          ],
          "iri": "Entity-new_type_of_three-plane_graph-Mention-2"
        }
      ],
      "relevance": 0.59375
    },
    "Entity-cost_aggregation_algorithm": {
      "node_id": "cost_aggregation_algorithm",
      "disambiguation_index": 0,
      "label": "cost aggregation algorithm",
      "aliases": [
        "cost aggregation algorithm"
      ],
      "types": [
        "computing method",
        "computer vision technique",
        "algorithm",
        "algorithmic technique",
        "computer vision method",
        "research method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A method for combining or aggregating costs, typically used in computer vision applications to optimize processing and reduce errors.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "cost aggregation algorithm",
          "local_types": [
            "computing method",
            "computer vision technique",
            "algorithm",
            "algorithmic technique",
            "computer vision method",
            "research method"
          ],
          "iri": "Entity-cost_aggregation_algorithm-Mention-1"
        }
      ],
      "relevance": 0.568359375
    },
    "Entity-video_stream_acquired_by_two_camera_placed_on_either_side_of_a_computer_monitor": {
      "node_id": "video_stream_acquired_by_two_camera_placed_on_either_side_of_a_computer_monitor",
      "disambiguation_index": 0,
      "label": "video streams acquired by two cameras placed on either side of a computer monitor",
      "aliases": [
        "video streams acquired by two cameras placed on either side of a computer monitor"
      ],
      "types": [
        "data",
        "monitor",
        "stream"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Video streams captured by two cameras placed on either side of a computer monitor",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "video streams acquired by two cameras placed on either side of a computer monitor",
          "local_types": [
            "data",
            "monitor",
            "stream"
          ],
          "iri": "Entity-video_stream_acquired_by_two_camera_placed_on_either_side_of_a_computer_monitor-Mention-1"
        }
      ],
      "relevance": 0.56103515625
    },
    "Entity-demonstration_of_synthesis_of_cyclopean_view_of_extended_conversational_sequence": {
      "node_id": "demonstration_of_synthesis_of_cyclopean_view_of_extended_conversational_sequence",
      "disambiguation_index": 0,
      "label": "demonstrations of synthesis of cyclopean views of extended conversational sequences",
      "aliases": [
        "demonstrations of synthesis of cyclopean views of extended conversational sequences"
      ],
      "types": [
        "methodology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Examples or illustrations of combining multiple viewpoints to generate a comprehensive visual representation of prolonged conversations.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-7",
          "local_name": "demonstrations of synthesis of cyclopean views of extended conversational sequences",
          "local_types": [
            "methodology"
          ],
          "iri": "Entity-demonstration_of_synthesis_of_cyclopean_view_of_extended_conversational_sequence-Mention-1"
        }
      ],
      "relevance": 0.56005859375
    },
    "Entity-temporal_artefact": {
      "node_id": "temporal_artefact",
      "disambiguation_index": 0,
      "label": "temporal artefacts",
      "aliases": [
        "temporal artefacts"
      ],
      "types": [
        "artefact",
        "type"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Temporal errors or distortions that occur when rendering occlusions and novel views from long stereo video streams.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-6",
          "local_name": "temporal artefacts",
          "local_types": [
            "artefact",
            "type"
          ],
          "iri": "Entity-temporal_artefact-Mention-1"
        }
      ],
      "relevance": 0.55517578125
    },
    "Entity-a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space": {
      "node_id": "a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space",
      "disambiguation_index": 0,
      "label": "a cost aggregation algorithm that acts directly on our three-dimensional matching cost space",
      "aliases": [
        "a cost aggregation algorithm that acts directly on our three-dimensional matching cost space"
      ],
      "types": [
        "algorithm",
        "space"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A novel algorithm for aggregating costs within the three-dimensional space of matching costs, used to facilitate efficient and accurate occlusion labeling.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "a cost aggregation algorithm that acts directly on our three-dimensional matching cost space",
          "local_types": [
            "algorithm",
            "space"
          ],
          "iri": "Entity-a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space-Mention-1"
        }
      ],
      "relevance": 0.5517578125
    },
    "Entity-compact_geometric_derivation": {
      "node_id": "compact_geometric_derivation",
      "disambiguation_index": 0,
      "label": "compact geometric derivation",
      "aliases": [
        "compact geometric derivation"
      ],
      "types": [
        "mathematical concept",
        "research method"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A mathematical concept or research method used to derive and project the minimum-cost surface for novel-view synthesis.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-4",
          "local_name": "compact geometric derivation",
          "local_types": [
            "mathematical concept",
            "research method"
          ],
          "iri": "Entity-compact_geometric_derivation-Mention-1"
        }
      ],
      "relevance": 0.55029296875
    },
    "Entity-three-plane_graph": {
      "node_id": "three-plane_graph",
      "disambiguation_index": 0,
      "label": "three-plane graph",
      "aliases": [
        "three-plane graph"
      ],
      "types": [
        "mathematical concept",
        "computer vision technique",
        "computer science concept",
        "graph theory",
        "graph",
        "data structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A type of graph used in dense-stereo dynamic-programming that encourages correct occlusion labeling.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-4",
          "local_name": "three-plane graph",
          "local_types": [
            "mathematical concept",
            "computer vision technique",
            "computer science concept",
            "graph theory",
            "graph",
            "data structure"
          ],
          "iri": "Entity-three-plane_graph-Mention-1"
        }
      ],
      "relevance": 0.54931640625
    },
    "Entity-virtual_camera": {
      "node_id": "virtual_camera",
      "disambiguation_index": 0,
      "label": "virtual camera",
      "aliases": [
        "virtual camera"
      ],
      "types": [
        "computing device",
        "camera",
        "digital imaging",
        "camera system",
        "technology",
        "computer-generated device",
        "digital camera",
        "device"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A computer-generated device that simulates a camera's view from an arbitrary location.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "virtual camera",
          "local_types": [
            "computing device",
            "camera",
            "digital imaging",
            "camera system",
            "computer-generated device",
            "digital camera",
            "device"
          ],
          "iri": "Entity-virtual_camera-Mention-1"
        },
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-8",
          "local_name": "virtual camera",
          "local_types": [
            "camera",
            "technology"
          ],
          "iri": "Entity-virtual_camera-Mention-2"
        }
      ],
      "relevance": 0.544921875
    },
    "Entity-three-dimensional_matching_cost_space": {
      "node_id": "three-dimensional_matching_cost_space",
      "disambiguation_index": 0,
      "label": "three-dimensional matching cost space",
      "aliases": [
        "three-dimensional matching cost space"
      ],
      "types": [
        "space",
        "data structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A data structure representing the costs of matching pixels in three-dimensional stereo images, used for efficient novel-view generation and occlusion labeling.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "three-dimensional matching cost space",
          "local_types": [
            "space",
            "data structure"
          ],
          "iri": "Entity-three-dimensional_matching_cost_space-Mention-1"
        }
      ],
      "relevance": 0.544921875
    },
    "Entity-long_stereo_video_stream": {
      "node_id": "long_stereo_video_stream",
      "disambiguation_index": 0,
      "label": "long stereo video streams",
      "aliases": [
        "long stereo video streams"
      ],
      "types": [
        "data type",
        "video format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A sequence of paired visual recordings, typically in a format that captures both left-eye and right-eye views simultaneously.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-6",
          "local_name": "long stereo video streams",
          "local_types": [
            "data type",
            "video format"
          ],
          "iri": "Entity-long_stereo_video_stream-Mention-1"
        }
      ],
      "relevance": 0.5439453125
    },
    "Entity-we_further_demonstrate_synthesis_from_a_freely_translating_virtual_camera": {
      "node_id": "we_further_demonstrate_synthesis_from_a_freely_translating_virtual_camera",
      "disambiguation_index": 0,
      "label": "We further demonstrate synthesis from a freely translating virtual camera",
      "aliases": [
        "We further demonstrate synthesis from a freely translating virtual camera"
      ],
      "types": [
        "demonstration",
        "camera"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A demonstration of synthesizing images from a virtual camera that can translate freely.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-8",
          "local_name": "We further demonstrate synthesis from a freely translating virtual camera",
          "local_types": [
            "demonstration",
            "camera"
          ],
          "iri": "Entity-we_further_demonstrate_synthesis_from_a_freely_translating_virtual_camera-Mention-1"
        }
      ],
      "relevance": 0.5439453125
    },
    "Entity-spatial_and_temporal_artefact": {
      "node_id": "spatial_and_temporal_artefact",
      "disambiguation_index": 0,
      "label": "spatial and temporal artefacts",
      "aliases": [
        "spatial and temporal artefacts"
      ],
      "types": [
        "noise",
        "distortion"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Temporal distortions or noise present in a sequence of stereo video frames",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-6",
          "local_name": "spatial and temporal artefacts",
          "local_types": [
            "noise",
            "distortion"
          ],
          "iri": "Entity-spatial_and_temporal_artefact-Mention-1"
        }
      ],
      "relevance": 0.533203125
    },
    "Entity-teleconferencing_application": {
      "node_id": "teleconferencing_application",
      "disambiguation_index": 0,
      "label": "teleconferencing applications",
      "aliases": [
        "teleconferencing applications"
      ],
      "types": [
        "video conferencing",
        "communication technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Software systems or platforms designed for real-time video and audio communication between multiple parties remotely.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-1",
          "local_name": "teleconferencing applications",
          "local_types": [
            "video conferencing",
            "communication technology"
          ],
          "iri": "Entity-teleconferencing_application-Mention-1"
        }
      ],
      "relevance": 0.5107421875
    },
    "Entity-novel_algorithm": {
      "node_id": "novel_algorithm",
      "disambiguation_index": 0,
      "label": "novel algorithm",
      "aliases": [
        "novel algorithm"
      ],
      "types": [
        "algorithm",
        "research method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A newly developed computational method or procedure for solving a specific problem or processing data.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "novel algorithm",
          "local_types": [
            "algorithm",
            "research method"
          ],
          "iri": "Entity-novel_algorithm-Mention-1"
        }
      ],
      "relevance": 0.5087890625
    },
    "Entity-background_model": {
      "node_id": "background_model",
      "disambiguation_index": 0,
      "label": "background model",
      "aliases": [
        "background model"
      ],
      "types": [
        "image processing data",
        "computer vision",
        "machine learning",
        "image processing concept",
        "model",
        "data structure",
        "computing concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A mathematical representation or framework used to analyze, process, or generate visual data.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "background model",
          "local_types": [
            "image processing data",
            "computer vision",
            "machine learning",
            "image processing concept",
            "model",
            "data structure",
            "computing concept"
          ],
          "iri": "Entity-background_model-Mention-1"
        }
      ],
      "relevance": 0.5
    },
    "Entity-a_computer_monitor": {
      "node_id": "a_computer_monitor",
      "disambiguation_index": 0,
      "label": "a computer monitor",
      "aliases": [
        "a computer monitor"
      ],
      "types": [
        "monitor",
        "computer component"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A display device used for viewing computer-generated images and video, typically placed on a desk or table.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "a computer monitor",
          "local_types": [
            "monitor",
            "computer component"
          ],
          "iri": "Entity-a_computer_monitor-Mention-1"
        }
      ],
      "relevance": 0.486328125
    },
    "Entity-video_stream": {
      "node_id": "video_stream",
      "disambiguation_index": 0,
      "label": "video streams",
      "aliases": [
        "video streams"
      ],
      "types": [
        "data",
        "visual data",
        "computer vision data",
        "media",
        "data stream",
        "digital media"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A sequence of video data transmitted or received, often used for communication, entertainment, or surveillance purposes.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "video streams",
          "local_types": [
            "data",
            "visual data",
            "computer vision data",
            "media",
            "data stream",
            "digital media"
          ],
          "iri": "Entity-video_stream-Mention-1"
        }
      ],
      "relevance": 0.485107421875
    },
    "Entity-one-to-one_teleconferencing_application": {
      "node_id": "one-to-one_teleconferencing_application",
      "disambiguation_index": 0,
      "label": "one-to-one teleconferencing applications",
      "aliases": [
        "one-to-one teleconferencing applications"
      ],
      "types": [
        "teleconference",
        "teleconferencing",
        "application",
        "telecommunication",
        "communication technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A type of communication technology that enables real-time video or audio conferencing between two individuals.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-1",
          "local_name": "one-to-one teleconferencing applications",
          "local_types": [
            "teleconference",
            "teleconferencing",
            "application",
            "telecommunication",
            "communication technology"
          ],
          "iri": "Entity-one-to-one_teleconferencing_application-Mention-1"
        }
      ],
      "relevance": 0.483154296875
    },
    "Entity-camera": {
      "node_id": "camera",
      "disambiguation_index": 0,
      "label": "cameras",
      "aliases": [
        "cameras"
      ],
      "types": [
        "device",
        "optical device"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Visual imaging devices used for capturing and recording images or video.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "cameras",
          "local_types": [
            "device",
            "optical device"
          ],
          "iri": "Entity-camera-Mention-1"
        }
      ],
      "relevance": 0.48291015625
    },
    "Entity-flicker": {
      "node_id": "flicker",
      "disambiguation_index": 0,
      "label": "flicker",
      "aliases": [
        "flicker"
      ],
      "types": [
        "phenomenon",
        "artifact"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Temporal artefacts, such as flicker, occurring during the rendering of occlusions and reduction",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-5",
          "local_name": "flicker",
          "local_types": [
            "phenomenon",
            "artifact"
          ],
          "iri": "Entity-flicker-Mention-1"
        }
      ],
      "relevance": 0.469482421875
    },
    "Entity-two_camera": {
      "node_id": "two_camera",
      "disambiguation_index": 0,
      "label": "two cameras",
      "aliases": [
        "two cameras"
      ],
      "types": [
        "device",
        "camera"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Two cameras are devices used for capturing visual information.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "two cameras",
          "local_types": [
            "device",
            "camera"
          ],
          "iri": "Entity-two_camera-Mention-1"
        }
      ],
      "relevance": 0.46875
    },
    "Entity-dynamic-programming": {
      "node_id": "dynamic-programming",
      "disambiguation_index": 0,
      "label": "dynamic-programming",
      "aliases": [
        "dynamic-programming"
      ],
      "types": [
        "method",
        "computational complexity"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A method of solving complex problems by breaking them down into smaller subproblems and using a recursive formula to find an optimal solution.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-3",
          "local_name": "dynamic-programming",
          "local_types": [
            "method",
            "computational complexity"
          ],
          "iri": "Entity-dynamic-programming-Mention-1"
        }
      ],
      "relevance": 0.45947265625
    },
    "Entity-correct_occlusion_labeling": {
      "node_id": "correct_occlusion_labeling",
      "disambiguation_index": 0,
      "label": "correct occlusion labeling",
      "aliases": [
        "correct occlusion labeling"
      ],
      "types": [
        "task",
        "problem statement"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process or method of accurately identifying and labeling occluded areas in an image or scene.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-4",
          "local_name": "correct occlusion labeling",
          "local_types": [
            "task",
            "problem statement"
          ],
          "iri": "Entity-correct_occlusion_labeling-Mention-1"
        }
      ],
      "relevance": 0.447998046875
    },
    "Entity-computer_monitor": {
      "node_id": "computer_monitor",
      "disambiguation_index": 0,
      "label": "computer monitor",
      "aliases": [
        "computer monitor"
      ],
      "types": [
        "device",
        "electronic device",
        "monitor",
        "electronic display",
        "display screen",
        "display technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A device that displays visual information, typically used as a component of a computer system.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "computer monitor",
          "local_types": [
            "device",
            "electronic device",
            "monitor",
            "electronic display",
            "display screen",
            "display technology"
          ],
          "iri": "Entity-computer_monitor-Mention-1"
        }
      ],
      "relevance": 0.434814453125
    },
    "Entity-minimum-cost_surface": {
      "node_id": "minimum-cost_surface",
      "disambiguation_index": 0,
      "label": "minimum-cost surface",
      "aliases": [
        "minimum-cost surface"
      ],
      "types": [
        "concept",
        "mathematics"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A mathematical concept representing the optimal surface that minimizes costs or energies.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-4",
          "local_name": "minimum-cost surface",
          "local_types": [
            "concept",
            "mathematics"
          ],
          "iri": "Entity-minimum-cost_surface-Mention-1"
        }
      ],
      "relevance": 0.429443359375
    },
    "Entity-algorithm": {
      "node_id": "algorithm",
      "disambiguation_index": 0,
      "label": "algorithm",
      "aliases": [
        "algorithm",
        "algorithms"
      ],
      "types": [
        "computing method",
        "software algorithm",
        "technique",
        "computational method",
        "method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A set of instructions used to solve a specific problem or perform a particular task",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-1",
          "local_name": "algorithm",
          "local_types": [
            "method",
            "technique",
            "computational method",
            "computing method"
          ],
          "iri": "Entity-algorithm-Mention-1"
        },
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-2",
          "local_name": "algorithm",
          "local_types": [
            "computational method",
            "software algorithm"
          ],
          "iri": "Entity-algorithm-Mention-2"
        },
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-6",
          "local_name": "algorithm",
          "local_types": [
            "computational method",
            "technique"
          ],
          "iri": "Entity-algorithm-Mention-3"
        }
      ],
      "relevance": 0.427978515625
    },
    "Entity-extended_conversational_sequence": {
      "node_id": "extended_conversational_sequence",
      "disambiguation_index": 0,
      "label": "extended conversational sequences",
      "aliases": [
        "extended conversational sequences"
      ],
      "types": [
        "data set",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A collection of conversations that are prolonged and detailed, typically involving multiple speakers.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-7",
          "local_name": "extended conversational sequences",
          "local_types": [
            "data set",
            "information"
          ],
          "iri": "Entity-extended_conversational_sequence-Mention-1"
        }
      ],
      "relevance": 0.394775390625
    },
    "Entity-technique": {
      "node_id": "technique",
      "disambiguation_index": 0,
      "label": "technique",
      "aliases": [
        "technique"
      ],
      "types": [
        "methodology",
        "approach"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A systematic method or approach used to achieve a specific goal, outcome, or result.",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-3",
          "local_name": "technique",
          "local_types": [
            "methodology",
            "approach"
          ],
          "iri": "Entity-technique-Mention-1"
        }
      ],
      "relevance": 0.389404296875
    },
    "Entity-example": {
      "node_id": "example",
      "disambiguation_index": 0,
      "label": "Examples",
      "aliases": [
        "Examples"
      ],
      "types": [
        "example",
        "data",
        "dataset",
        "illustration"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A collection of instances or cases used to illustrate a concept, process, or phenomenon",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-6",
          "local_name": "Examples",
          "local_types": [
            "example",
            "data",
            "dataset",
            "illustration"
          ],
          "iri": "Entity-example-Mention-1"
        }
      ],
      "relevance": 0.38720703125
    },
    "Entity-demonstration": {
      "node_id": "demonstration",
      "disambiguation_index": 0,
      "label": "demonstrations",
      "aliases": [
        "demonstrations"
      ],
      "types": [
        "research outcome"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Public displays or exhibitions that illustrate a concept, process, or outcome",
      "mentions": [
        {
          "reference": "Paper-65-Section-1-Paragraph-1-Sentence-7",
          "local_name": "demonstrations",
          "local_types": [
            "research outcome"
          ],
          "iri": "Entity-demonstration-Mention-1"
        }
      ],
      "relevance": 0.368896484375
    }
  },
  "summary": "A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications . Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact . Our technique is based on an improved , dynamic-programming , stereo algorithm for efficient novel-view generation . The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface . Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space . Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams . These include demonstrations of synthesis of cyclopean views of extended conversational sequences . We further demonstrate synthesis from a freely translating virtual camera .",
  "triples": [
    [
      "Entity-a_new_algorithm",
      "Predicate-proposed_for",
      "Entity-novel_view_generation"
    ],
    [
      "Entity-one-to-one_teleconferencing_application",
      "Predicate-uses",
      "Entity-novel_view_generation_in_one-to-one_teleconferencing_application"
    ],
    [
      "Entity-a_new_algorithm",
      "Predicate-proposed_for",
      "Entity-novel_view_generation_in_one-to-one_teleconferencing_application"
    ],
    [
      "Entity-video_stream",
      "Predicate-acquired_by",
      "Entity-two_camera"
    ],
    [
      "Entity-the_proposed_algorithm",
      "Predicate-synthesises",
      "Entity-image_from_a_virtual_camera"
    ],
    [
      "Entity-our_technique",
      "Predicate-based_on",
      "Entity-stereo_algorithm"
    ],
    [
      "Entity-our_technique",
      "Predicate-uses",
      "Entity-dynamic-programming"
    ],
    [
      "Entity-our_technique",
      "Predicate-employs",
      "Entity-stereo_algorithm"
    ],
    [
      "Entity-our_technique",
      "Predicate-generates",
      "Entity-novel-view_generation"
    ],
    [
      "Entity-new_type_of_three-plane_graph",
      "Predicate-encourages",
      "Entity-correct_occlusion_labeling"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model"
    ],
    [
      "Entity-the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-",
      "Predicate-enhance",
      "Entity-background_model"
    ],
    [
      "Entity-the_proposed_algorithm",
      "Predicate-is_robust_to",
      "Entity-spatial_and_temporal_artefact"
    ],
    [
      "Entity-the_proposed_algorithm",
      "Predicate-works_well_with",
      "Entity-long_stereo_video_stream"
    ],
    [
      "Entity-these",
      "Predicate-include",
      "Entity-extended_conversational_sequence"
    ],
    [
      "Entity-we",
      "Predicate-demonstrate",
      "Entity-synthesis_from_a_freely_translating_virtual_camera"
    ],
    [
      "Entity-the_two_main_contribution_of_this_paper_are__i_-rrb-_a_new_type_of_three-plane_graph_for_dense-stereo_dynamic-programming__that_encourages_correct_occlusion_labeling__ii_-rrb-_a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface",
      "Predicate-presents",
      "Entity-furthermore__this_paper_present_a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model_to_enhance_the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-__and_a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space"
    ],
    [
      "Entity-the_proposed_algorithm",
      "Predicate-presents",
      "Entity-furthermore__this_paper_present_a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model_to_enhance_the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-__and_a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space"
    ],
    [
      "Entity-the_proposed_algorithm_synthesis_image_from_a_virtual_camera_in_arbitrary_position_-lrb-_typically_located_within_the_monitor_-rrb-_to_facilitate_eye_contact",
      "Predicate-presents",
      "Entity-furthermore__this_paper_present_a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model_to_enhance_the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-__and_a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space"
    ],
    [
      "Entity-synthesis_of_cyclopean_view",
      "Predicate-presents",
      "Entity-furthermore__this_paper_present_a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model_to_enhance_the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-__and_a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space"
    ],
    [
      "Entity-the_two_main_contribution_of_this_paper_are__i_-rrb-_a_new_type_of_three-plane_graph_for_dense-stereo_dynamic-programming__that_encourages_correct_occlusion_labeling__ii_-rrb-_a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface",
      "Predicate-is_based_on",
      "Entity-the_proposed_algorithm"
    ],
    [
      "Entity-the_proposed_algorithm",
      "Predicate-synthesises",
      "Entity-the_proposed_algorithm_synthesis_image_from_a_virtual_camera_in_arbitrary_position_-lrb-_typically_located_within_the_monitor_-rrb-_to_facilitate_eye_contact"
    ],
    [
      "Entity-the_proposed_algorithm_synthesis_image_from_a_virtual_camera_in_arbitrary_position_-lrb-_typically_located_within_the_monitor_-rrb-_to_facilitate_eye_contact",
      "Predicate-facilitates",
      "Entity-the_two_main_contribution_of_this_paper_are__i_-rrb-_a_new_type_of_three-plane_graph_for_dense-stereo_dynamic-programming__that_encourages_correct_occlusion_labeling__ii_-rrb-_a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface"
    ],
    [
      "Entity-the_two_main_contribution_of_this_paper_are__i_-rrb-_a_new_type_of_three-plane_graph_for_dense-stereo_dynamic-programming__that_encourages_correct_occlusion_labeling__ii_-rrb-_a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface",
      "Predicate-enable",
      "Entity-synthesis_of_cyclopean_view"
    ],
    [
      "Entity-the_proposed_algorithm",
      "Predicate-uses",
      "Entity-synthesis_of_cyclopean_view"
    ],
    [
      "Entity-synthesis_of_cyclopean_view",
      "Predicate-synthesises",
      "Entity-the_proposed_algorithm_synthesis_image_from_a_virtual_camera_in_arbitrary_position_-lrb-_typically_located_within_the_monitor_-rrb-_to_facilitate_eye_contact"
    ]
  ],
  "triples_typing": [
    [
      "Entity-cost_aggregation_algorithm",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-stereo_algorithm",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-we_further_demonstrate_synthesis_from_a_freely_translating_virtual_camera",
      "skos:broader",
      "Entity-demonstration"
    ],
    [
      "Entity-the_two_main_contribution_of_this_paper_are__i_-rrb-_a_new_type_of_three-plane_graph_for_dense-stereo_dynamic-programming__that_encourages_correct_occlusion_labeling__ii_-rrb-_a_compact_geometric_derivation_for_novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface",
      "skos:broader",
      "Entity-dynamic-programming"
    ],
    [
      "Entity-novel_view_generation",
      "skos:broader",
      "Entity-technique"
    ],
    [
      "Entity-virtual_camera",
      "skos:broader",
      "Entity-camera"
    ],
    [
      "Entity-stereo_algorithm",
      "skos:broader",
      "Entity-technique"
    ],
    [
      "Entity-synthesis_of_cyclopean_view",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-our_technique_is_based_on_an_improved__dynamic-programming__stereo_algorithm_for_efficient_novel-view_generation",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-our_technique_is_based_on_an_improved__dynamic-programming__stereo_algorithm_for_efficient_novel-view_generation",
      "skos:broader",
      "Entity-novel_view_generation"
    ],
    [
      "Entity-new_type_of_three-plane_graph",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-a_new_algorithm",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-our_technique_is_based_on_an_improved__dynamic-programming__stereo_algorithm_for_efficient_novel-view_generation",
      "skos:broader",
      "Entity-technique"
    ],
    [
      "Entity-the_proposed_algorithm_synthesis_image_from_a_virtual_camera_in_arbitrary_position_-lrb-_typically_located_within_the_monitor_-rrb-_to_facilitate_eye_contact",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-the_proposed_algorithm",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-we_further_demonstrate_synthesis_from_a_freely_translating_virtual_camera",
      "skos:broader",
      "Entity-camera"
    ],
    [
      "Entity-a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-algorithm",
      "skos:broader",
      "Entity-technique"
    ],
    [
      "Entity-a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-furthermore__this_paper_present_a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model_to_enhance_the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-__and_a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-two_camera",
      "skos:broader",
      "Entity-camera"
    ],
    [
      "Entity-our_technique",
      "skos:broader",
      "Entity-technique"
    ],
    [
      "Entity-dynamic-programming",
      "skos:broader",
      "Entity-technique"
    ],
    [
      "Entity-novel-view_synthesis_by_direct_projection_of_the_minimum-cost_surface",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-novel_algorithm",
      "skos:broader",
      "Entity-algorithm"
    ],
    [
      "Entity-furthermore__this_paper_present_a_novel_algorithm_for_the_temporal_maintenance_of_a_background_model_to_enhance_the_rendering_of_occlusion_and_reduce_temporal_artefact_-lrb-_flicker_-rrb-__and_a_cost_aggregation_algorithm_that_act_directly_on_our_three-dimensional_matching_cost_space",
      "skos:broader",
      "Entity-background_model"
    ],
    [
      "Entity-synthesis_from_a_freely_translating_virtual_camera",
      "skos:broader",
      "Entity-technique"
    ]
  ],
  "predicates": {
    "Predicate-proposed_for": {
      "label": "proposed for",
      "description": "The predicate 'proposed for' indicates a relationship where an entity (the subject) has been suggested or put forward as being suitable or applicable to achieve, accomplish, or facilitate something else (the object).",
      "disambiguation_index": 0
    },
    "Predicate-uses": {
      "label": "uses",
      "description": "The predicate 'uses' indicates a relationship of utilization or employment between the subject and object. It suggests that the subject makes use of, relies on, or exploits the object to achieve some purpose or goal.",
      "disambiguation_index": 0
    },
    "Predicate-acquired_by": {
      "label": "acquired by",
      "description": "The predicate 'acquired by' indicates a relationship of possession or origin between the subject and object. It suggests that the subject has been obtained or produced through some means specified by the object, which can be an entity, process, or mechanism.",
      "disambiguation_index": 0
    },
    "Predicate-synthesises": {
      "label": "synthesises",
      "description": "To synthesise means to combine or generate something new by combining existing elements, often with the goal of creating a coherent and meaningful whole. In this sense, the predicate 'synthesises' connects the subject (the proposed algorithm) to the object (images from a virtual camera), indicating that the algorithm is responsible for bringing together disparate components to produce novel images.",
      "disambiguation_index": 0
    },
    "Predicate-based_on": {
      "label": "based on",
      "description": "The predicate 'based on' indicates a relationship where the subject (a concept or method) relies on or has its foundation in the object (another concept, method, or principle). This connection implies that the subject's characteristics, properties, or behavior are derived from or influenced by the object.",
      "disambiguation_index": 0
    },
    "Predicate-employs": {
      "label": "employs",
      "description": "The predicate 'employs' indicates a relationship of utilization or deployment between the subject and object. It suggests that the subject makes use of, relies on, or utilizes the object to achieve some purpose or goal.",
      "disambiguation_index": 0
    },
    "Predicate-generates": {
      "label": "generates",
      "description": "The predicate 'generates' indicates a causal relationship between the subject and object, suggesting that the subject is responsible for producing or bringing into existence the object. In this sense, it implies a creative or productive process where the subject plays an active role in shaping or creating the object.",
      "disambiguation_index": 0
    },
    "Predicate-encourages": {
      "label": "encourages",
      "description": "The predicate 'encourages' indicates a causal relationship between the subject and object, suggesting that the subject facilitates or promotes the occurrence of the object. In this sense, it implies a positive influence on the outcome or process described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-presents": {
      "label": "presents",
      "description": "The predicate 'presents' indicates that the subject provides or offers something to someone or something else. It implies a sense of introduction, offering, or making available, which connects the subject and object in terms of sharing knowledge, ideas, or concepts.",
      "disambiguation_index": 0
    },
    "Predicate-enhance": {
      "label": "enhance",
      "description": "To enhance means to improve or amplify something's quality, clarity, or effectiveness by adding value, detail, or insight. In a general sense, it connects the subject and object by indicating that the subject has an impact on the object, making it more desirable, accurate, or useful.",
      "disambiguation_index": 0
    },
    "Predicate-is_robust_to": {
      "label": "is robust to",
      "description": "The predicate 'is robust to' indicates that a subject (e.g., an algorithm, model, or system) can withstand or tolerate certain types of disturbances, errors, or uncertainties represented by the object. In general, this predicate describes the ability of the subject to maintain its performance, accuracy, or stability in the presence of the specified challenges.",
      "disambiguation_index": 0
    },
    "Predicate-works_well_with": {
      "label": "works well with",
      "description": "The predicate 'works well with' indicates a relationship between two entities where one entity (the subject) effectively interacts or functions alongside another entity (the object), resulting in a harmonious, efficient, and/or successful outcome.",
      "disambiguation_index": 0
    },
    "Predicate-include": {
      "label": "include",
      "description": "The predicate 'include' indicates that the subject encompasses or comprises a part of the object. It suggests a relationship where the subject contains, embodies, or has as its scope the information, characteristics, or features described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-demonstrate": {
      "label": "demonstrate",
      "description": "To demonstrate means to show or illustrate something through action, explanation, or presentation. It implies providing evidence or proof of an idea, concept, or process by making it tangible and comprehensible. The predicate 'demonstrate' connects the subject (the entity performing the demonstration) with the object (what is being demonstrated), highlighting a relationship where the subject clarifies or illustrates the meaning of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_based_on": {
      "label": "is based on",
      "description": "The predicate 'is based on' indicates that the subject's existence or validity relies on a specific foundation, principle, method, or theory represented by the object. It implies a causal relationship where the subject's properties or behavior are derived from or grounded in the characteristics of the object.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates": {
      "label": "facilitates",
      "description": "The predicate 'facilitates' indicates that the subject enables or makes easier the occurrence, development, or achievement of the object. It implies a supportive role for the subject in facilitating the process, outcome, or interaction described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-enable": {
      "label": "enable",
      "description": "The predicate 'enable' indicates that the subject has the capability or authority to facilitate or make possible the occurrence of the object. It suggests a causal relationship between the subject and the object, where the subject's presence or action allows for or enables the object to happen.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' indicates that the subject is a specific instance or example of a more general category or concept represented by the object. It establishes a hierarchical relationship between the two, where the subject is a narrower or more specialized version of the object.",
      "disambiguation_index": 0
    }
  }
}