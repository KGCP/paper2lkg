{
  "iri": "Paper-52",
  "title": "CVPR_2016_413_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-52-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-52-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-52-Section-1-Paragraph-1-Sentence-1",
              "text": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision ."
            },
            {
              "iri": "Paper-52-Section-1-Paragraph-1-Sentence-2",
              "text": "However , acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction , active sensing devices and/or synthetic scenes ."
            },
            {
              "iri": "Paper-52-Section-1-Paragraph-1-Sentence-3",
              "text": "To overcome this problem , we propose a new , flexible , and scalable way for generating training data that only requires a set of stereo images as input ."
            },
            {
              "iri": "Paper-52-Section-1-Paragraph-1-Sentence-4",
              "text": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm ."
            },
            {
              "iri": "Paper-52-Section-1-Paragraph-1-Sentence-5",
              "text": "This enables us to generate a huge amount of training data in a fully automated manner ."
            },
            {
              "iri": "Paper-52-Section-1-Paragraph-1-Sentence-6",
              "text": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.00022172927856445312,
    15.264280319213867,
    25.31361746788025,
    22.855702877044678,
    0.021120309829711914,
    9.1552734375e-05,
    0.0001163482666015625,
    44.50458884239197,
    56.368438959121704,
    1.6969215869903564,
    1.1969292163848877,
    0.01092076301574707,
    0.00021696090698242188,
    32.90467071533203,
    1.0840044021606445,
    0.021131515502929688,
    1.0869574546813965,
    3.6238863468170166,
    7.6949803829193115,
    9.657043933868408,
    36.66675090789795,
    3.2989814281463623,
    21.717552423477173,
    1.1528573036193848,
    0.0008108615875244141,
    0.012651205062866211
  ],
  "nodes": {
    "Entity-the_kitti2012_dataset": {
      "node_id": "the_kitti2012_dataset",
      "disambiguation_index": 0,
      "label": "the KITTI2012 dataset",
      "aliases": [
        "the KITTI2012 dataset"
      ],
      "types": [
        "dataset"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The KITTI2012 dataset refers to a collection of stereo images used for evaluating the performance of learned confidence measures in outlier removal and quality improvement tasks.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-6",
          "local_name": "the KITTI2012 dataset",
          "local_types": [
            "dataset"
          ],
          "iri": "Entity-the_kitti2012_dataset-Mention-1"
        }
      ],
      "relevance": 0.71875
    },
    "Entity-we_propose_a_new__flexible__and_scalable_way_for_generating_training_data_that_only_requires_a_set_of_stereo_image_a_input": {
      "node_id": "we_propose_a_new__flexible__and_scalable_way_for_generating_training_data_that_only_requires_a_set_of_stereo_image_a_input",
      "disambiguation_index": 0,
      "label": "we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input",
      "aliases": [
        "we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input"
      ],
      "types": [
        "methodology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A methodology for automatically generating training data using a set of stereo images.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-3",
          "local_name": "we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input",
          "local_types": [
            "methodology"
          ],
          "iri": "Entity-we_propose_a_new__flexible__and_scalable_way_for_generating_training_data_that_only_requires_a_set_of_stereo_image_a_input-Mention-1"
        }
      ],
      "relevance": 0.71337890625
    },
    "Entity-the_performance_of_three_learned_confidence_measure": {
      "node_id": "the_performance_of_three_learned_confidence_measure",
      "disambiguation_index": 0,
      "label": "the performance of three learned confidence measures",
      "aliases": [
        "the performance of three learned confidence measures"
      ],
      "types": [
        "performance"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The evaluation results of three learned confidence measures used for outlier removal and quality improvement in stereo vision.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-6",
          "local_name": "the performance of three learned confidence measures",
          "local_types": [
            "performance"
          ],
          "iri": "Entity-the_performance_of_three_learned_confidence_measure-Mention-1"
        }
      ],
      "relevance": 0.68701171875
    },
    "Entity-our_approach": {
      "node_id": "our_approach",
      "disambiguation_index": 0,
      "label": "our approach",
      "aliases": [
        "our approach"
      ],
      "types": [
        "approach"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A method for generating training data for stereo vision using different view points to reason about contradictions and consistencies between multiple depth maps.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-6",
          "local_name": "our approach",
          "local_types": [
            "approach"
          ],
          "iri": "Entity-our_approach-Mention-1"
        }
      ],
      "relevance": 0.6796875
    },
    "Entity-this": {
      "node_id": "this",
      "disambiguation_index": 0,
      "label": "This",
      "aliases": [
        "This"
      ],
      "types": [
        "method"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A method for generating training data that only requires a set of stereo images as input, enabling automatic generation of a large amount of training data.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-5",
          "local_name": "This",
          "local_types": [
            "method"
          ],
          "iri": "Entity-this-Mention-1"
        }
      ],
      "relevance": 0.66943359375
    },
    "Entity-a_new__flexible__and_scalable_way_for_generating_training_data": {
      "node_id": "a_new__flexible__and_scalable_way_for_generating_training_data",
      "disambiguation_index": 0,
      "label": "a new, flexible, and scalable way for generating training data",
      "aliases": [
        "a new, flexible, and scalable way for generating training data"
      ],
      "types": [
        "method"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A method for automatically generating training data using stereo images.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-3",
          "local_name": "a new, flexible, and scalable way for generating training data",
          "local_types": [
            "method"
          ],
          "iri": "Entity-a_new__flexible__and_scalable_way_for_generating_training_data-Mention-1"
        }
      ],
      "relevance": 0.6611328125
    },
    "Entity-three_learned_confidence_measure_on_the_kitti2012_dataset": {
      "node_id": "three_learned_confidence_measure_on_the_kitti2012_dataset",
      "disambiguation_index": 0,
      "label": "three learned confidence measures on the KITTI2012 dataset",
      "aliases": [
        "three learned confidence measures on the KITTI2012 dataset"
      ],
      "types": [
        "experiment"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Three learned confidence measures that were trained and evaluated on the KITTI2012 dataset.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-6",
          "local_name": "three learned confidence measures on the KITTI2012 dataset",
          "local_types": [
            "experiment"
          ],
          "iri": "Entity-three_learned_confidence_measure_on_the_kitti2012_dataset-Mention-1"
        }
      ],
      "relevance": 0.6533203125
    },
    "Entity-way": {
      "node_id": "way",
      "disambiguation_index": 0,
      "label": "way",
      "aliases": [
        "way"
      ],
      "types": [
        "method"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A method for generating training data for stereo vision using sets of stereo images.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-3",
          "local_name": "way",
          "local_types": [
            "method"
          ],
          "iri": "Entity-way-Mention-1"
        }
      ],
      "relevance": 0.64599609375
    },
    "Entity-a_huge_amount_of_training_data": {
      "node_id": "a_huge_amount_of_training_data",
      "disambiguation_index": 0,
      "label": "a huge amount of training data",
      "aliases": [
        "a huge amount of training data"
      ],
      "types": [
        "data",
        "training_data"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A large quantity of training data generated automatically using different view points for reasoning about contradictions and consistencies between multiple depth maps.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-5",
          "local_name": "a huge amount of training data",
          "local_types": [
            "data",
            "training_data"
          ],
          "iri": "Entity-a_huge_amount_of_training_data-Mention-1"
        }
      ],
      "relevance": 0.64306640625
    },
    "Entity-learned_confidence_measure": {
      "node_id": "learned_confidence_measure",
      "disambiguation_index": 0,
      "label": "Learned confidence measures",
      "aliases": [
        "Learned confidence measures"
      ],
      "types": [
        "algorithm",
        "technique",
        "concept",
        "method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A method or technique used to measure and quantify the level of confidence in a learned outcome, often applied to improve accuracy and robustness.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-1",
          "local_name": "Learned confidence measures",
          "local_types": [
            "algorithm",
            "technique",
            "concept",
            "method"
          ],
          "iri": "Entity-learned_confidence_measure-Mention-1"
        }
      ],
      "relevance": 0.63671875
    },
    "Entity-active_sensing_device_andor_synthetic_scene": {
      "node_id": "active_sensing_device_andor_synthetic_scene",
      "disambiguation_index": 0,
      "label": "active sensing devices and/or synthetic scenes",
      "aliases": [
        "active sensing devices and/or synthetic scenes"
      ],
      "types": [
        "technique"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Methods or tools used to generate training data for stereo vision algorithms, either through manual interaction with physical sensors (devices) or simulated environments (scenes).",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-2",
          "local_name": "active sensing devices and/or synthetic scenes",
          "local_types": [
            "technique"
          ],
          "iri": "Entity-active_sensing_device_andor_synthetic_scene-Mention-1"
        }
      ],
      "relevance": 0.6337890625
    },
    "Entity-the_key_idea_of_our_approach": {
      "node_id": "the_key_idea_of_our_approach",
      "disambiguation_index": 0,
      "label": "The key idea of our approach",
      "aliases": [
        "The key idea of our approach"
      ],
      "types": [
        "idea"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Using different viewpoints for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-4",
          "local_name": "The key idea of our approach",
          "local_types": [
            "idea"
          ],
          "iri": "Entity-the_key_idea_of_our_approach-Mention-1"
        }
      ],
      "relevance": 0.6328125
    },
    "Entity-to_overcome_this_problem": {
      "node_id": "to_overcome_this_problem",
      "disambiguation_index": 0,
      "label": "To overcome this problem",
      "aliases": [
        "To overcome this problem"
      ],
      "types": [
        "problem"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The tedious task of acquiring necessary training data for outlier removal and quality improvement in stereo vision.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-3",
          "local_name": "To overcome this problem",
          "local_types": [
            "problem"
          ],
          "iri": "Entity-to_overcome_this_problem-Mention-1"
        }
      ],
      "relevance": 0.62646484375
    },
    "Entity-manual_interaction__active_sensing_device_andor_synthetic_scene": {
      "node_id": "manual_interaction__active_sensing_device_andor_synthetic_scene",
      "disambiguation_index": 0,
      "label": "manual interaction, active sensing devices and/or synthetic scenes",
      "aliases": [
        "manual interaction, active sensing devices and/or synthetic scenes"
      ],
      "types": [
        "approach"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Methods or techniques used to acquire training data in stereo vision applications.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-2",
          "local_name": "manual interaction, active sensing devices and/or synthetic scenes",
          "local_types": [
            "approach"
          ],
          "iri": "Entity-manual_interaction__active_sensing_device_andor_synthetic_scene-Mention-1"
        }
      ],
      "relevance": 0.62255859375
    },
    "Entity-different_view_point_for_reasoning_about_contradiction_and_consistency_between_multiple_depth_map_generated_with_the_same_stereo_algorithm": {
      "node_id": "different_view_point_for_reasoning_about_contradiction_and_consistency_between_multiple_depth_map_generated_with_the_same_stereo_algorithm",
      "disambiguation_index": 0,
      "label": "different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm",
      "aliases": [
        "different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm"
      ],
      "types": [
        "approach",
        "methodology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A methodology using different viewpoints to analyze inconsistencies and contradictions in multiple depth maps produced by the same stereo algorithm.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-4",
          "local_name": "different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm",
          "local_types": [
            "approach",
            "methodology"
          ],
          "iri": "Entity-different_view_point_for_reasoning_about_contradiction_and_consistency_between_multiple_depth_map_generated_with_the_same_stereo_algorithm-Mention-1"
        }
      ],
      "relevance": 0.6220703125
    },
    "Entity-acquiring_the_necessary_training_data": {
      "node_id": "acquiring_the_necessary_training_data",
      "disambiguation_index": 0,
      "label": "acquiring the necessary training data",
      "aliases": [
        "acquiring the necessary training data"
      ],
      "types": [
        "task",
        "problem"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The process of obtaining the required dataset for training machine learning models, typically involving manual interaction, active sensing devices, and/or synthetic scenes.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-2",
          "local_name": "acquiring the necessary training data",
          "local_types": [
            "task",
            "problem"
          ],
          "iri": "Entity-acquiring_the_necessary_training_data-Mention-1"
        }
      ],
      "relevance": 0.61376953125
    },
    "Entity-stereo_image_a_input": {
      "node_id": "stereo_image_a_input",
      "disambiguation_index": 0,
      "label": "stereo images as input",
      "aliases": [
        "stereo images as input"
      ],
      "types": [
        "input"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of paired two-dimensional images used to generate depth information.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-3",
          "local_name": "stereo images as input",
          "local_types": [
            "input"
          ],
          "iri": "Entity-stereo_image_a_input-Mention-1"
        }
      ],
      "relevance": 0.59375
    },
    "Entity-stereo_algorithm": {
      "node_id": "stereo_algorithm",
      "disambiguation_index": 0,
      "label": "stereo algorithm",
      "aliases": [
        "stereo algorithm"
      ],
      "types": [
        "technique",
        "method of image processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A computer vision technique used for processing and analyzing images by combining information from multiple views or perspectives.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-4",
          "local_name": "stereo algorithm",
          "local_types": [
            "technique",
            "method of image processing"
          ],
          "iri": "Entity-stereo_algorithm-Mention-1"
        }
      ],
      "relevance": 0.591796875
    },
    "Entity-stereo_vision": {
      "node_id": "stereo_vision",
      "disambiguation_index": 0,
      "label": "stereo vision",
      "aliases": [
        "stereo vision"
      ],
      "types": [
        "image processing",
        "computer vision",
        "field of study",
        "field",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A computer-based technology that uses two cameras or sensors to capture images from different angles, allowing for depth perception and three-dimensional reconstruction.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-1",
          "local_name": "stereo vision",
          "local_types": [
            "image processing",
            "computer vision",
            "field of study",
            "field",
            "technology"
          ],
          "iri": "Entity-stereo_vision-Mention-1"
        }
      ],
      "relevance": 0.58984375
    },
    "Entity-approach": {
      "node_id": "approach",
      "disambiguation_index": 0,
      "label": "approach",
      "aliases": [
        "approach"
      ],
      "types": [
        "methodology",
        "research strategy"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A methodology or research strategy for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-4",
          "local_name": "approach",
          "local_types": [
            "methodology",
            "research strategy"
          ],
          "iri": "Entity-approach-Mention-1"
        }
      ],
      "relevance": 0.5830078125
    },
    "Entity-three_learned_confidence_measure": {
      "node_id": "three_learned_confidence_measure",
      "disambiguation_index": 0,
      "label": "three learned confidence measures",
      "aliases": [
        "three learned confidence measures"
      ],
      "types": [
        "algorithm",
        "machine learning model"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Three machine learning models that estimate the confidence in their predictions.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-6",
          "local_name": "three learned confidence measures",
          "local_types": [
            "algorithm",
            "machine learning model"
          ],
          "iri": "Entity-three_learned_confidence_measure-Mention-1"
        }
      ],
      "relevance": 0.5791015625
    },
    "Entity-stereo_image": {
      "node_id": "stereo_image",
      "disambiguation_index": 0,
      "label": "stereo images",
      "aliases": [
        "stereo images"
      ],
      "types": [
        "image dataset",
        "visual data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A pair or collection of two-dimensional visual representations taken from different angles or perspectives, often used to capture depth information.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-3",
          "local_name": "stereo images",
          "local_types": [
            "image dataset",
            "visual data"
          ],
          "iri": "Entity-stereo_image-Mention-1"
        }
      ],
      "relevance": 0.57861328125
    },
    "Entity-kitti2012": {
      "node_id": "kitti2012",
      "disambiguation_index": 0,
      "label": "KITTI2012",
      "aliases": [
        "KITTI2012"
      ],
      "types": [
        "dataset"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The KITTI2012 dataset, a collection of visual and sensorimotor data used for testing autonomous driving algorithms.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-6",
          "local_name": "KITTI2012",
          "local_types": [
            "dataset"
          ],
          "iri": "Entity-kitti2012-Mention-1"
        }
      ],
      "relevance": 0.57568359375
    },
    "Entity-outlier_removal_and_quality_improvement_in_stereo_vision": {
      "node_id": "outlier_removal_and_quality_improvement_in_stereo_vision",
      "disambiguation_index": 0,
      "label": "outlier removal and quality improvement in stereo vision",
      "aliases": [
        "outlier removal and quality improvement in stereo vision"
      ],
      "types": [
        "application",
        "stereo vision"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A technique or process that removes outliers and improves the quality of data generated from stereo vision systems.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-1",
          "local_name": "outlier removal and quality improvement in stereo vision",
          "local_types": [
            "application",
            "stereo vision"
          ],
          "iri": "Entity-outlier_removal_and_quality_improvement_in_stereo_vision-Mention-1"
        }
      ],
      "relevance": 0.56494140625
    },
    "Entity-kitti2012_dataset": {
      "node_id": "kitti2012_dataset",
      "disambiguation_index": 0,
      "label": "KITTI2012 dataset",
      "aliases": [
        "KITTI2012 dataset"
      ],
      "types": [
        "dataset",
        "resource",
        "benchmarking tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A widely-used benchmarking tool and dataset for testing autonomous driving algorithms, particularly in urban environments.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-6",
          "local_name": "KITTI2012 dataset",
          "local_types": [
            "dataset",
            "resource",
            "benchmarking tool"
          ],
          "iri": "Entity-kitti2012_dataset-Mention-1"
        }
      ],
      "relevance": 0.56396484375
    },
    "Entity-quality_improvement_in_stereo_vision": {
      "node_id": "quality_improvement_in_stereo_vision",
      "disambiguation_index": 0,
      "label": "quality improvement in stereo vision",
      "aliases": [
        "quality improvement in stereo vision"
      ],
      "types": [
        "goal"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The enhancement or upgrading of the accuracy, precision, or effectiveness of a system that uses stereoscopic vision to perceive its environment.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-1",
          "local_name": "quality improvement in stereo vision",
          "local_types": [
            "goal"
          ],
          "iri": "Entity-quality_improvement_in_stereo_vision-Mention-1"
        }
      ],
      "relevance": 0.55615234375
    },
    "Entity-laser_ground_truth_data": {
      "node_id": "laser_ground_truth_data",
      "disambiguation_index": 0,
      "label": "laser ground truth data",
      "aliases": [
        "laser ground truth data"
      ],
      "types": [
        "data source",
        "ground truth"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Precise measurements or annotations used as a reference standard for evaluating the accuracy of sensors, such as lidar systems.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-6",
          "local_name": "laser ground truth data",
          "local_types": [
            "data source",
            "ground truth"
          ],
          "iri": "Entity-laser_ground_truth_data-Mention-1"
        }
      ],
      "relevance": 0.52587890625
    },
    "Entity-training_data": {
      "node_id": "training_data",
      "disambiguation_index": 0,
      "label": "training data",
      "aliases": [
        "training data"
      ],
      "types": [
        "data collection",
        "data set",
        "dataset"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of examples or instances used to train machine learning models",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-2",
          "local_name": "training data",
          "local_types": [
            "data collection",
            "data set",
            "dataset"
          ],
          "iri": "Entity-training_data-Mention-1"
        },
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-3",
          "local_name": "training data",
          "local_types": [
            "dataset",
            "data set"
          ],
          "iri": "Entity-training_data-Mention-2"
        },
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-5",
          "local_name": "training data",
          "local_types": [
            "dataset"
          ],
          "iri": "Entity-training_data-Mention-3"
        }
      ],
      "relevance": 0.52099609375
    },
    "Entity-multiple_depth_map": {
      "node_id": "multiple_depth_map",
      "disambiguation_index": 0,
      "label": "multiple depth maps",
      "aliases": [
        "multiple depth maps"
      ],
      "types": [
        "data sets",
        "images"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of images or data sets representing three-dimensional representations of scenes from different viewpoints.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-4",
          "local_name": "multiple depth maps",
          "local_types": [
            "data sets",
            "images"
          ],
          "iri": "Entity-multiple_depth_map-Mention-1"
        }
      ],
      "relevance": 0.5078125
    },
    "Entity-synthetic_scene": {
      "node_id": "synthetic_scene",
      "disambiguation_index": 0,
      "label": "synthetic scenes",
      "aliases": [
        "synthetic scenes"
      ],
      "types": [
        "computer-generated imagery",
        "virtual environment"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Computer-generated environments or simulations created to mimic real-world scenarios",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-2",
          "local_name": "synthetic scenes",
          "local_types": [
            "computer-generated imagery",
            "virtual environment"
          ],
          "iri": "Entity-synthetic_scene-Mention-1"
        }
      ],
      "relevance": 0.460693359375
    },
    "Entity-outlier_removal": {
      "node_id": "outlier_removal",
      "disambiguation_index": 0,
      "label": "outlier removal",
      "aliases": [
        "outlier removal"
      ],
      "types": [
        "task",
        "quality control",
        "data processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of identifying and eliminating data points that do not conform to expected patterns or norms.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-1",
          "local_name": "outlier removal",
          "local_types": [
            "task",
            "quality control",
            "data processing"
          ],
          "iri": "Entity-outlier_removal-Mention-1"
        }
      ],
      "relevance": 0.44775390625
    },
    "Entity-active_sensing_device": {
      "node_id": "active_sensing_device",
      "disambiguation_index": 0,
      "label": "active sensing devices",
      "aliases": [
        "active sensing devices"
      ],
      "types": [
        "sensing technology",
        "device"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Devices capable of actively collecting or generating data through various means.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-2",
          "local_name": "active sensing devices",
          "local_types": [
            "sensing technology",
            "device"
          ],
          "iri": "Entity-active_sensing_device-Mention-1"
        }
      ],
      "relevance": 0.4423828125
    },
    "Entity-fully_automated_manner": {
      "node_id": "fully_automated_manner",
      "disambiguation_index": 0,
      "label": "fully automated manner",
      "aliases": [
        "fully automated manner"
      ],
      "types": [
        "method",
        "methodology",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A way or approach that uses machines and algorithms without human intervention",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-5",
          "local_name": "fully automated manner",
          "local_types": [
            "method",
            "methodology",
            "process"
          ],
          "iri": "Entity-fully_automated_manner-Mention-1"
        }
      ],
      "relevance": 0.423095703125
    },
    "Entity-reasoning": {
      "node_id": "reasoning",
      "disambiguation_index": 0,
      "label": "reasoning",
      "aliases": [
        "reasoning"
      ],
      "types": [
        "logical process",
        "inference"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of drawing conclusions or making logical connections between pieces of information.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-4",
          "local_name": "reasoning",
          "local_types": [
            "logical process",
            "inference"
          ],
          "iri": "Entity-reasoning-Mention-1"
        }
      ],
      "relevance": 0.421875
    },
    "Entity-contradiction_and_consistency": {
      "node_id": "contradiction_and_consistency",
      "disambiguation_index": 0,
      "label": "contradictions and consistencies",
      "aliases": [
        "contradictions and consistencies"
      ],
      "types": [
        "differences",
        "similarities"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The phenomenon of inconsistencies or contradictions between different perspectives, views, or representations.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-4",
          "local_name": "contradictions and consistencies",
          "local_types": [
            "differences",
            "similarities"
          ],
          "iri": "Entity-contradiction_and_consistency-Mention-1"
        }
      ],
      "relevance": 0.406494140625
    },
    "Entity-manual_interaction": {
      "node_id": "manual_interaction",
      "disambiguation_index": 0,
      "label": "manual interaction",
      "aliases": [
        "manual interaction"
      ],
      "types": [
        "method",
        "human-computer interaction"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of using one's hands or other body parts to interact with something",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-2",
          "local_name": "manual interaction",
          "local_types": [
            "method",
            "human-computer interaction"
          ],
          "iri": "Entity-manual_interaction-Mention-1"
        }
      ],
      "relevance": 0.399169921875
    },
    "Entity-view_point": {
      "node_id": "view_point",
      "disambiguation_index": 0,
      "label": "view points",
      "aliases": [
        "view points"
      ],
      "types": [
        "perspective",
        "angle of view"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A perspective or angle of view from which something is considered, evaluated, or perceived.",
      "mentions": [
        {
          "reference": "Paper-52-Section-1-Paragraph-1-Sentence-4",
          "local_name": "view points",
          "local_types": [
            "perspective",
            "angle of view"
          ],
          "iri": "Entity-view_point-Mention-1"
        }
      ],
      "relevance": 0.394775390625
    }
  },
  "summary": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision . However , acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction , active sensing devices and/or synthetic scenes . To overcome this problem , we propose a new , flexible , and scalable way for generating training data that only requires a set of stereo images as input . The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm . This enables us to generate a huge amount of training data in a fully automated manner . Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
  "triples": [
    [
      "Entity-learned_confidence_measure",
      "Predicate-contribute_to",
      "Entity-outlier_removal_and_quality_improvement_in_stereo_vision"
    ],
    [
      "Entity-acquiring_the_necessary_training_data",
      "Predicate-involves",
      "Entity-manual_interaction__active_sensing_device_andor_synthetic_scene"
    ],
    [
      "Entity-to_overcome_this_problem",
      "Predicate-propose",
      "Entity-a_new__flexible__and_scalable_way_for_generating_training_data"
    ],
    [
      "Entity-we_propose_a_new__flexible__and_scalable_way_for_generating_training_data_that_only_requires_a_set_of_stereo_image_a_input",
      "Predicate-requires",
      "Entity-stereo_image_a_input"
    ],
    [
      "Entity-the_key_idea_of_our_approach",
      "Predicate-is_to_use",
      "Entity-different_view_point_for_reasoning_about_contradiction_and_consistency_between_multiple_depth_map_generated_with_the_same_stereo_algorithm"
    ],
    [
      "Entity-approach",
      "Predicate-use",
      "Entity-different_view_point_for_reasoning_about_contradiction_and_consistency_between_multiple_depth_map_generated_with_the_same_stereo_algorithm"
    ],
    [
      "Entity-our_approach",
      "Predicate-use",
      "Entity-different_view_point_for_reasoning_about_contradiction_and_consistency_between_multiple_depth_map_generated_with_the_same_stereo_algorithm"
    ],
    [
      "Entity-this",
      "Predicate-enables_us_to_generate_a_huge_amount_of",
      "Entity-training_data"
    ],
    [
      "Entity-our_approach",
      "Predicate-boosts",
      "Entity-the_performance_of_three_learned_confidence_measure"
    ],
    [
      "Entity-three_learned_confidence_measure",
      "Predicate-compared_to",
      "Entity-laser_ground_truth_data"
    ],
    [
      "Entity-we_propose_a_new__flexible__and_scalable_way_for_generating_training_data_that_only_requires_a_set_of_stereo_image_a_input",
      "Predicate-use",
      "Entity-the_kitti2012_dataset"
    ],
    [
      "Entity-the_kitti2012_dataset",
      "Predicate-boost",
      "Entity-the_performance_of_three_learned_confidence_measure"
    ],
    [
      "Entity-we_propose_a_new__flexible__and_scalable_way_for_generating_training_data_that_only_requires_a_set_of_stereo_image_a_input",
      "Predicate-boosts",
      "Entity-the_performance_of_three_learned_confidence_measure"
    ]
  ],
  "triples_typing": [
    [
      "Entity-different_view_point_for_reasoning_about_contradiction_and_consistency_between_multiple_depth_map_generated_with_the_same_stereo_algorithm",
      "skos:broader",
      "Entity-approach"
    ],
    [
      "Entity-a_huge_amount_of_training_data",
      "skos:broader",
      "Entity-training_data"
    ],
    [
      "Entity-our_approach",
      "skos:broader",
      "Entity-approach"
    ],
    [
      "Entity-outlier_removal_and_quality_improvement_in_stereo_vision",
      "skos:broader",
      "Entity-stereo_vision"
    ],
    [
      "Entity-outlier_removal_and_quality_improvement_in_stereo_vision",
      "skos:broader",
      "Entity-stereo_image"
    ],
    [
      "Entity-manual_interaction__active_sensing_device_andor_synthetic_scene",
      "skos:broader",
      "Entity-approach"
    ]
  ],
  "predicates": {
    "Predicate-contribute_to": {
      "label": "contribute to",
      "description": "To indicate that the subject has a causal or influential relationship with the object, where the subject's presence, properties, or actions directly impact or facilitate the occurrence of the object. This predicate suggests a positive correlation between the subject and object, implying that the subject plays a role in bringing about or enabling the object.",
      "disambiguation_index": 0
    },
    "Predicate-involves": {
      "label": "involves",
      "description": "The predicate 'involves' indicates that the subject (an activity or process) requires or necessitates the object(s), which can be a set of actions, methods, tools, or other entities. In general, it suggests a causal relationship between the subject and the object(s), implying that one cannot occur without the other.",
      "disambiguation_index": 0
    },
    "Predicate-propose": {
      "label": "propose",
      "description": "Propose connects the subject to an idea or solution that addresses a particular issue or challenge. It implies offering or suggesting something as a potential remedy, alternative, or approach.",
      "disambiguation_index": 0
    },
    "Predicate-requires": {
      "label": "requires",
      "description": "The predicate 'requires' indicates a necessary condition or prerequisite for something to happen, exist, or be done. It implies that the subject needs or demands the object as an essential input, resource, or circumstance to fulfill its purpose.",
      "disambiguation_index": 0
    },
    "Predicate-is_to_use": {
      "label": "is to use",
      "description": "Indicates a plan or intention to employ a particular method, approach, strategy, or resource in order to achieve a specific goal or outcome.",
      "disambiguation_index": 0
    },
    "Predicate-use": {
      "label": "use",
      "description": "To employ or apply a particular method, technique, or perspective in order to achieve a specific goal or understanding. The predicate 'use' indicates that the subject is utilizing the object as a means of accomplishing something, often involving reasoning, analysis, or problem-solving.",
      "disambiguation_index": 0
    },
    "Predicate-enables_us_to_generate_a_huge_amount_of": {
      "label": "enables us to generate a huge amount of",
      "description": "The predicate 'enables us to generate a huge amount of' indicates that the subject has the capacity or provides the means for producing an extensive quantity of something, which is described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-boosts": {
      "label": "boosts",
      "description": "The predicate 'boosts' indicates a causal relationship between the subject and object, suggesting that the subject has a positive impact on or enhances the state or quality of the object. In general, it implies an increase in magnitude, effectiveness, or efficiency.",
      "disambiguation_index": 0
    },
    "Predicate-compared_to": {
      "label": "compared to",
      "description": "The predicate 'compared to' indicates a relationship of similarity or equivalence between two entities. It suggests that the subject and object are being evaluated against each other, with the goal of highlighting their differences or similarities.",
      "disambiguation_index": 0
    },
    "Predicate-boost": {
      "label": "boost",
      "description": "To boost means to significantly enhance or improve something's effectiveness, accuracy, or overall quality. The predicate 'boost' indicates a causal relationship between the subject and object, suggesting that the subject has a positive impact on the object, resulting in its enhancement or improvement.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' indicates that the subject is a specific instance or example of a more general concept or category represented by the object. The relationship between the subject and object is one of instantiation, where the subject exemplifies or embodies the characteristics of the broader term.",
      "disambiguation_index": 0
    }
  }
}