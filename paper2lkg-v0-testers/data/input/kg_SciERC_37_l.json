{
  "iri": "Paper-37",
  "title": "ECCV_2006_13_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-37-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-37-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-37-Section-1-Paragraph-1-Sentence-1",
              "text": "In spite of over two decades of intense research , illumination and pose invariance remain prohibitively challenging aspects of face recognition for most practical applications ."
            },
            {
              "iri": "Paper-37-Section-1-Paragraph-1-Sentence-2",
              "text": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution ."
            },
            {
              "iri": "Paper-37-Section-1-Paragraph-1-Sentence-3",
              "text": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video ."
            },
            {
              "iri": "Paper-37-Section-1-Paragraph-1-Sentence-4",
              "text": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation ."
            },
            {
              "iri": "Paper-37-Section-1-Paragraph-1-Sentence-5",
              "text": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.0002307891845703125,
    20.36600399017334,
    25.89478373527527,
    21.58295464515686,
    0.03937888145446777,
    9.489059448242188e-05,
    0.00012445449829101562,
    43.42473530769348,
    65.10513210296631,
    1.879906415939331,
    1.1958715915679932,
    0.011120796203613281,
    0.0002143383026123047,
    32.673019886016846,
    5.46597695350647,
    0.03969740867614746,
    1.0845887660980225,
    3.539222478866577,
    8.049328804016113,
    8.856520175933838,
    50.159250259399414,
    4.2512452602386475,
    16.392590761184692,
    1.024263620376587,
    0.0006384849548339844,
    0.012995243072509766
  ],
  "nodes": {
    "Entity-we_describe": {
      "node_id": "we_describe",
      "disambiguation_index": 0,
      "label": "We describe",
      "aliases": [
        "We describe"
      ],
      "types": [
        "author"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A fully automatic face recognition system based on the proposed method, evaluated on a dataset of 171 individuals and over 1300 video sequences with extreme illumination, pose, and head motion variation.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "We describe",
          "local_types": [
            "author"
          ],
          "iri": "Entity-we_describe-Mention-1"
        }
      ],
      "relevance": 0.72314453125
    },
    "Entity-our_system": {
      "node_id": "our_system",
      "disambiguation_index": 0,
      "label": "our system",
      "aliases": [
        "our system"
      ],
      "types": [
        "system"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A fully automatic face recognition system that uses video sequences for training and recognition input, capable of achieving nearly perfect recognition rates in challenging scenarios with extreme illumination, pose, and head motion variation.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-5",
          "local_name": "our system",
          "local_types": [
            "system"
          ],
          "iri": "Entity-our_system-Mention-1"
        }
      ],
      "relevance": 0.72216796875
    },
    "Entity-recognize_face_using_video_sequence": {
      "node_id": "recognize_face_using_video_sequence",
      "disambiguation_index": 0,
      "label": "recognize faces using video sequences",
      "aliases": [
        "recognize faces using video sequences"
      ],
      "types": [
        "task",
        "face recognition"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The task of recognizing faces using video sequences involves identifying individuals from both training and recognition inputs in a realistic, unconstrained setup with varying lighting, pose, and user motion patterns.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "recognize faces using video sequences",
          "local_types": [
            "task",
            "face recognition"
          ],
          "iri": "Entity-recognize_face_using_video_sequence-Mention-1"
        }
      ],
      "relevance": 0.7197265625
    },
    "Entity-the_objective_of_this_work": {
      "node_id": "the_objective_of_this_work",
      "disambiguation_index": 0,
      "label": "The objective of this work",
      "aliases": [
        "The objective of this work"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The objective of this work refers to recognizing faces using video sequences for both training and recognition input in a realistic, unconstrained setup with varying lighting, pose, and user motion patterns.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "The objective of this work",
          "local_types": [
            "research"
          ],
          "iri": "Entity-the_objective_of_this_work-Mention-1"
        }
      ],
      "relevance": 0.7109375
    },
    "Entity-based_on_the_proposed_method": {
      "node_id": "based_on_the_proposed_method",
      "disambiguation_index": 0,
      "label": "based on the proposed method",
      "aliases": [
        "based on the proposed method"
      ],
      "types": [
        "method",
        "approach"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A fully automatic face recognition system that uses the proposed method for recognizing faces using video sequences.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "based on the proposed method",
          "local_types": [
            "method",
            "approach"
          ],
          "iri": "Entity-based_on_the_proposed_method-Mention-1"
        }
      ],
      "relevance": 0.67578125
    },
    "Entity-a_fully_automatic_recognition_system": {
      "node_id": "a_fully_automatic_recognition_system",
      "disambiguation_index": 0,
      "label": "a fully automatic recognition system",
      "aliases": [
        "a fully automatic recognition system"
      ],
      "types": [
        "system",
        "technology"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A fully automatic recognition system based on the proposed method for recognizing faces using video sequences both for training and recognition input.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "a fully automatic recognition system",
          "local_types": [
            "system",
            "technology"
          ],
          "iri": "Entity-a_fully_automatic_recognition_system-Mention-1"
        }
      ],
      "relevance": 0.67236328125
    },
    "Entity-illumination_and_pose_invariance": {
      "node_id": "illumination_and_pose_invariance",
      "disambiguation_index": 0,
      "label": "illumination and pose invariance",
      "aliases": [
        "illumination and pose invariance"
      ],
      "types": [
        "challenge",
        "problem statement"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The ability to recognize faces regardless of variations in lighting conditions or facial poses.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-1",
          "local_name": "illumination and pose invariance",
          "local_types": [
            "challenge",
            "problem statement"
          ],
          "iri": "Entity-illumination_and_pose_invariance-Mention-1"
        }
      ],
      "relevance": 0.66552734375
    },
    "Entity-on_171_individual_and_over_1300_video_sequence_with_extreme_illumination__pose_and_head_motion_variation": {
      "node_id": "on_171_individual_and_over_1300_video_sequence_with_extreme_illumination__pose_and_head_motion_variation",
      "disambiguation_index": 0,
      "label": "on 171 individuals and over 1300 video sequences with extreme illumination, pose and head motion variation",
      "aliases": [
        "on 171 individuals and over 1300 video sequences with extreme illumination, pose and head motion variation"
      ],
      "types": [
        "dataset",
        "data"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A dataset of video sequences featuring faces from 171 individuals under various conditions of extreme illumination, pose, and head motion.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "on 171 individuals and over 1300 video sequences with extreme illumination, pose and head motion variation",
          "local_types": [
            "dataset",
            "data"
          ],
          "iri": "Entity-on_171_individual_and_over_1300_video_sequence_with_extreme_illumination__pose_and_head_motion_variation-Mention-1"
        }
      ],
      "relevance": 0.65673828125
    },
    "Entity-an_extensive_evaluation": {
      "node_id": "an_extensive_evaluation",
      "disambiguation_index": 0,
      "label": "an extensive evaluation",
      "aliases": [
        "an extensive evaluation"
      ],
      "types": [
        "evaluation",
        "study"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A comprehensive assessment of the proposed face recognition system's performance on a large dataset comprising over 1300 video sequences with varying lighting conditions, poses, and head motions.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "an extensive evaluation",
          "local_types": [
            "evaluation",
            "study"
          ],
          "iri": "Entity-an_extensive_evaluation-Mention-1"
        }
      ],
      "relevance": 0.65576171875
    },
    "Entity-which_lighting__pose_and_user_motion_pattern_have_a_wide_variability": {
      "node_id": "which_lighting__pose_and_user_motion_pattern_have_a_wide_variability",
      "disambiguation_index": 0,
      "label": "which lighting, pose and user motion pattern have a wide variability",
      "aliases": [
        "which lighting, pose and user motion pattern have a wide variability"
      ],
      "types": [
        "characteristic",
        "condition"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The characteristics or conditions that describe the facial recognition problem addressed by this work, including variations in lighting, pose, and user motion patterns.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "which lighting, pose and user motion pattern have a wide variability",
          "local_types": [
            "characteristic",
            "condition"
          ],
          "iri": "Entity-which_lighting__pose_and_user_motion_pattern_have_a_wide_variability-Mention-1"
        }
      ],
      "relevance": 0.6337890625
    },
    "Entity-in_a_realistic__unconstrained_setup": {
      "node_id": "in_a_realistic__unconstrained_setup",
      "disambiguation_index": 0,
      "label": "in a realistic, unconstrained setup",
      "aliases": [
        "in a realistic, unconstrained setup"
      ],
      "types": [
        "environment"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A scenario where faces are recognized using video sequences with varying lighting conditions, poses, and user motions, mimicking real-world situations.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "in a realistic, unconstrained setup",
          "local_types": [
            "environment"
          ],
          "iri": "Entity-in_a_realistic__unconstrained_setup-Mention-1"
        }
      ],
      "relevance": 0.62646484375
    },
    "Entity-face_recognition": {
      "node_id": "face_recognition",
      "disambiguation_index": 0,
      "label": "face recognition",
      "aliases": [
        "face recognition"
      ],
      "types": [
        "research area",
        "field of study",
        "computer vision",
        "field",
        "technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process or technology used to identify and verify individuals based on their facial features.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-1",
          "local_name": "face recognition",
          "local_types": [
            "research area",
            "field of study",
            "computer vision",
            "field",
            "technology"
          ],
          "iri": "Entity-face_recognition-Mention-1"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-for_training_and_recognition_input": {
      "node_id": "for_training_and_recognition_input",
      "disambiguation_index": 0,
      "label": "for training and recognition input",
      "aliases": [
        "for training and recognition input"
      ],
      "types": [
        "purpose"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Data used for both training and recognizing faces from video sequences.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "for training and recognition input",
          "local_types": [
            "purpose"
          ],
          "iri": "Entity-for_training_and_recognition_input-Mention-1"
        }
      ],
      "relevance": 0.60107421875
    },
    "Entity-statistical_model_of_generic_face_appearance_variation": {
      "node_id": "statistical_model_of_generic_face_appearance_variation",
      "disambiguation_index": 0,
      "label": "statistical model of generic face appearance variation",
      "aliases": [
        "statistical model of generic face appearance variation"
      ],
      "types": [
        "machine learning concept",
        "algorithm",
        "machine learning",
        "technology",
        "model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A statistical model that captures general variations in human facial appearance, used for machine learning and image processing applications.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-3",
          "local_name": "statistical model of generic face appearance variation",
          "local_types": [
            "machine learning concept",
            "algorithm",
            "machine learning",
            "technology",
            "model"
          ],
          "iri": "Entity-statistical_model_of_generic_face_appearance_variation-Mention-1"
        }
      ],
      "relevance": 0.6005859375
    },
    "Entity-fully_automatic_recognition_system": {
      "node_id": "fully_automatic_recognition_system",
      "disambiguation_index": 0,
      "label": "fully automatic recognition system",
      "aliases": [
        "fully automatic recognition system"
      ],
      "types": [
        "system",
        "technology",
        "machine learning application"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "An automated technology that uses machine learning to recognize or identify entities without human intervention.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "fully automatic recognition system",
          "local_types": [
            "system",
            "technology",
            "machine learning application"
          ],
          "iri": "Entity-fully_automatic_recognition_system-Mention-1"
        }
      ],
      "relevance": 0.5830078125
    },
    "Entity-and_face_image_are_of_low_resolution": {
      "node_id": "and_face_image_are_of_low_resolution",
      "disambiguation_index": 0,
      "label": "and face images are of low resolution",
      "aliases": [
        "and face images are of low resolution"
      ],
      "types": [
        "constraint"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The quality or sharpness of facial images used for recognition purposes.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "and face images are of low resolution",
          "local_types": [
            "constraint"
          ],
          "iri": "Entity-and_face_image_are_of_low_resolution-Mention-1"
        }
      ],
      "relevance": 0.580078125
    },
    "Entity-photometric_model_of_image_formation": {
      "node_id": "photometric_model_of_image_formation",
      "disambiguation_index": 0,
      "label": "photometric model of image formation",
      "aliases": [
        "photometric model of image formation"
      ],
      "types": [
        "computer vision technique",
        "algorithm",
        "computer vision",
        "technology",
        "model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A mathematical framework that simulates how images are formed, used for computer vision applications such as facial recognition and image processing.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-3",
          "local_name": "photometric model of image formation",
          "local_types": [
            "computer vision technique",
            "algorithm",
            "computer vision",
            "technology",
            "model"
          ],
          "iri": "Entity-photometric_model_of_image_formation-Mention-1"
        }
      ],
      "relevance": 0.5712890625
    },
    "Entity-video_sequence": {
      "node_id": "video_sequence",
      "disambiguation_index": 0,
      "label": "video sequences",
      "aliases": [
        "video sequences"
      ],
      "types": [
        "input data",
        "input",
        "data set",
        "input type",
        "media content",
        "data type"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A collection of video recordings or segments, often used as input data for various applications such as facial recognition.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "video sequences",
          "local_types": [
            "input data",
            "input",
            "data set",
            "input type",
            "data type"
          ],
          "iri": "Entity-video_sequence-Mention-1"
        },
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "video sequences",
          "local_types": [
            "data set",
            "media content"
          ],
          "iri": "Entity-video_sequence-Mention-2"
        }
      ],
      "relevance": 0.5615234375
    },
    "Entity-face_image": {
      "node_id": "face_image",
      "disambiguation_index": 0,
      "label": "face images",
      "aliases": [
        "face images"
      ],
      "types": [
        "input data",
        "data set",
        "input",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Visual representations or digital captures of human faces",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "face images",
          "local_types": [
            "input data",
            "data set",
            "input",
            "data type"
          ],
          "iri": "Entity-face_image-Mention-1"
        }
      ],
      "relevance": 0.560546875
    },
    "Entity-lighting__pose_and_user_motion_pattern": {
      "node_id": "lighting__pose_and_user_motion_pattern",
      "disambiguation_index": 0,
      "label": "lighting, pose and user motion pattern",
      "aliases": [
        "lighting, pose and user motion pattern"
      ],
      "types": [
        "variable",
        "parameter"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A set of factors influencing visual data quality or appearance",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "lighting, pose and user motion pattern",
          "local_types": [
            "variable",
            "parameter"
          ],
          "iri": "Entity-lighting__pose_and_user_motion_pattern-Mention-1"
        }
      ],
      "relevance": 0.5517578125
    },
    "Entity-same-identity_likelihood": {
      "node_id": "same-identity_likelihood",
      "disambiguation_index": 0,
      "label": "same-identity likelihood",
      "aliases": [
        "same-identity likelihood"
      ],
      "types": [
        "machine learning concept",
        "likelihood",
        "concept",
        "machine learning",
        "probability",
        "statistics",
        "statistical measure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A measure of probability that a person's identity remains unchanged despite changes in head pose.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-3",
          "local_name": "same-identity likelihood",
          "local_types": [
            "machine learning concept",
            "likelihood",
            "concept",
            "machine learning",
            "probability",
            "statistics",
            "statistical measure"
          ],
          "iri": "Entity-same-identity_likelihood-Mention-1"
        }
      ],
      "relevance": 0.5458984375
    },
    "Entity-pose_invariance": {
      "node_id": "pose_invariance",
      "disambiguation_index": 0,
      "label": "pose invariance",
      "aliases": [
        "pose invariance"
      ],
      "types": [
        "aspect",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The ability to recognize or classify entities without being affected by their orientation or posture.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-1",
          "local_name": "pose invariance",
          "local_types": [
            "aspect",
            "property"
          ],
          "iri": "Entity-pose_invariance-Mention-1"
        }
      ],
      "relevance": 0.54052734375
    },
    "Entity-geodesically_local_appearance_manifold_structure": {
      "node_id": "geodesically_local_appearance_manifold_structure",
      "disambiguation_index": 0,
      "label": "geodesically local appearance manifold structure",
      "aliases": [
        "geodesically local appearance manifold structure"
      ],
      "types": [
        "mathematical concept",
        "concept",
        "structure",
        "mathematical framework",
        "mathematics",
        "computer science"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A mathematical framework that describes the smooth structure of local appearance variations in faces, used for achieving pose invariance and illumination robustness.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-3",
          "local_name": "geodesically local appearance manifold structure",
          "local_types": [
            "mathematical concept",
            "concept",
            "structure",
            "mathematical framework",
            "mathematics",
            "computer science"
          ],
          "iri": "Entity-geodesically_local_appearance_manifold_structure-Mention-1"
        }
      ],
      "relevance": 0.53271484375
    },
    "Entity-recognition_system": {
      "node_id": "recognition_system",
      "disambiguation_index": 0,
      "label": "recognition system",
      "aliases": [
        "recognition system"
      ],
      "types": [
        "technology",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "An automated technology that identifies or classifies entities based on input data.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "recognition system",
          "local_types": [
            "technology",
            "system"
          ],
          "iri": "Entity-recognition_system-Mention-1"
        }
      ],
      "relevance": 0.5302734375
    },
    "Entity-1300_video_sequence": {
      "node_id": "1300_video_sequence",
      "disambiguation_index": 0,
      "label": "1300 video sequences",
      "aliases": [
        "over 1300 video sequences",
        "1300 video sequences"
      ],
      "types": [
        "data set size",
        "collection",
        "number",
        "number of videos"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A collection of approximately 1,300 video recordings",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "1300 video sequences",
          "local_types": [
            "number",
            "collection"
          ],
          "iri": "Entity-1300_video_sequence-Mention-1"
        },
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "over 1300 video sequences",
          "local_types": [
            "number of videos",
            "data set size"
          ],
          "iri": "Entity-1300_video_sequence-Mention-2"
        }
      ],
      "relevance": 0.5146484375
    },
    "Entity-face": {
      "node_id": "face",
      "disambiguation_index": 0,
      "label": "faces",
      "aliases": [
        "faces"
      ],
      "types": [
        "biometric feature"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "human facial features",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "faces",
          "local_types": [
            "biometric feature"
          ],
          "iri": "Entity-face-Mention-1"
        }
      ],
      "relevance": 0.513671875
    },
    "Entity--lrb-_i_-rrb-": {
      "node_id": "-lrb-_i_-rrb-",
      "disambiguation_index": 0,
      "label": "-LRB- i -RRB-",
      "aliases": [
        "-LRB- i -RRB-"
      ],
      "types": [
        "novelty",
        "area"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A region or area of novelty",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-3",
          "local_name": "-LRB- i -RRB-",
          "local_types": [
            "novelty",
            "area"
          ],
          "iri": "Entity--lrb-_i_-rrb--Mention-1"
        }
      ],
      "relevance": 0.50927734375
    },
    "Entity-pose": {
      "node_id": "pose",
      "disambiguation_index": 0,
      "label": "pose",
      "aliases": [
        "pose"
      ],
      "types": [
        "challenge",
        "aspect",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The angle or orientation of a person's head or facial features",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-1",
          "local_name": "pose",
          "local_types": [
            "challenge",
            "aspect",
            "property"
          ],
          "iri": "Entity-pose-Mention-1"
        }
      ],
      "relevance": 0.49755859375
    },
    "Entity-training_and_recognition_input": {
      "node_id": "training_and_recognition_input",
      "disambiguation_index": 0,
      "label": "training and recognition input",
      "aliases": [
        "training and recognition input"
      ],
      "types": [
        "dataset",
        "input data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of data used for both training machine learning models and recognizing or classifying entities, typically in an automated process.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-2",
          "local_name": "training and recognition input",
          "local_types": [
            "dataset",
            "input data"
          ],
          "iri": "Entity-training_and_recognition_input-Mention-1"
        }
      ],
      "relevance": 0.49609375
    },
    "Entity-171_individual": {
      "node_id": "171_individual",
      "disambiguation_index": 0,
      "label": "171 individuals",
      "aliases": [
        "171 individuals"
      ],
      "types": [
        "data set size",
        "group",
        "number",
        "number of people"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A group of people",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "171 individuals",
          "local_types": [
            "data set size",
            "group",
            "number",
            "number of people"
          ],
          "iri": "Entity-171_individual-Mention-1"
        }
      ],
      "relevance": 0.4697265625
    },
    "Entity-illumination": {
      "node_id": "illumination",
      "disambiguation_index": 0,
      "label": "illumination",
      "aliases": [
        "illumination"
      ],
      "types": [
        "challenge",
        "aspect",
        "property"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The provision or availability of light",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-1",
          "local_name": "illumination",
          "local_types": [
            "challenge",
            "aspect",
            "property"
          ],
          "iri": "Entity-illumination-Mention-1"
        }
      ],
      "relevance": 0.46875
    },
    "Entity-proposed_method": {
      "node_id": "proposed_method",
      "disambiguation_index": 0,
      "label": "proposed method",
      "aliases": [
        "proposed method"
      ],
      "types": [
        "algorithm",
        "approach"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A systematic approach or algorithm for solving a problem or achieving a goal.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "proposed method",
          "local_types": [
            "algorithm",
            "approach"
          ],
          "iri": "Entity-proposed_method-Mention-1"
        }
      ],
      "relevance": 0.453857421875
    },
    "Entity-system": {
      "node_id": "system",
      "disambiguation_index": 0,
      "label": "system",
      "aliases": [
        "system"
      ],
      "types": [
        "algorithm",
        "software system"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A computerized process or program that uses algorithms to perform specific tasks",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-5",
          "local_name": "system",
          "local_types": [
            "algorithm",
            "software system"
          ],
          "iri": "Entity-system-Mention-1"
        }
      ],
      "relevance": 0.440673828125
    },
    "Entity-individual": {
      "node_id": "individual",
      "disambiguation_index": 0,
      "label": "individuals",
      "aliases": [
        "individuals"
      ],
      "types": [
        "people",
        "humans"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Human beings",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-4",
          "local_name": "individuals",
          "local_types": [
            "people",
            "humans"
          ],
          "iri": "Entity-individual-Mention-1"
        }
      ],
      "relevance": 0.427978515625
    },
    "Entity-data_set": {
      "node_id": "data_set",
      "disambiguation_index": 0,
      "label": "data set",
      "aliases": [
        "data set"
      ],
      "types": [
        "dataset",
        "research data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of data used for research or testing purposes",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-5",
          "local_name": "data set",
          "local_types": [
            "dataset",
            "research data"
          ],
          "iri": "Entity-data_set-Mention-1"
        }
      ],
      "relevance": 0.408203125
    },
    "Entity-state-of-the-art_commercial_software": {
      "node_id": "state-of-the-art_commercial_software",
      "disambiguation_index": 0,
      "label": "state-of-the-art commercial software",
      "aliases": [
        "state-of-the-art commercial software"
      ],
      "types": [
        "commercial tool",
        "software product",
        "software"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The most advanced and widely used commercial computer programs available in the market.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-5",
          "local_name": "state-of-the-art commercial software",
          "local_types": [
            "commercial tool",
            "software product",
            "software"
          ],
          "iri": "Entity-state-of-the-art_commercial_software-Mention-1"
        }
      ],
      "relevance": 0.396728515625
    },
    "Entity-method_from_the_literature": {
      "node_id": "method_from_the_literature",
      "disambiguation_index": 0,
      "label": "methods from the literature",
      "aliases": [
        "methods from the literature"
      ],
      "types": [
        "research methodology",
        "methodology",
        "literature",
        "academic approach"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of research approaches or techniques that have been previously published in academic papers.",
      "mentions": [
        {
          "reference": "Paper-37-Section-1-Paragraph-1-Sentence-5",
          "local_name": "methods from the literature",
          "local_types": [
            "research methodology",
            "methodology",
            "literature",
            "academic approach"
          ],
          "iri": "Entity-method_from_the_literature-Mention-1"
        }
      ],
      "relevance": 0.355712890625
    }
  },
  "summary": "In spite of over two decades of intense research , illumination and pose invariance remain prohibitively challenging aspects of face recognition for most practical applications . The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution . In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video . We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation . On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
  "triples": [
    [
      "Entity-the_objective_of_this_work",
      "Predicate-is_to",
      "Entity-recognize_face_using_video_sequence"
    ],
    [
      "Entity-face",
      "Predicate-be_recognized_by",
      "Entity-the_objective_of_this_work"
    ],
    [
      "Entity-photometric_model_of_image_formation",
      "Predicate-can_be_combined_with",
      "Entity-statistical_model_of_generic_face_appearance_variation"
    ],
    [
      "Entity-our_system",
      "Predicate-describe",
      "Entity-we_describe"
    ],
    [
      "Entity-our_system",
      "Predicate-achieve",
      "Entity-recognize_face_using_video_sequence"
    ],
    [
      "Entity-we_describe",
      "Predicate-describe",
      "Entity-recognize_face_using_video_sequence"
    ]
  ],
  "triples_typing": [
    [
      "Entity-our_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-face_image",
      "skos:broader",
      "Entity-data_set"
    ],
    [
      "Entity-based_on_the_proposed_method",
      "skos:broader",
      "Entity-proposed_method"
    ],
    [
      "Entity-a_fully_automatic_recognition_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-recognition_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-recognize_face_using_video_sequence",
      "skos:broader",
      "Entity-face_recognition"
    ],
    [
      "Entity-fully_automatic_recognition_system",
      "skos:broader",
      "Entity-system"
    ],
    [
      "Entity-video_sequence",
      "skos:broader",
      "Entity-data_set"
    ]
  ],
  "predicates": {
    "Predicate-is_to": {
      "label": "is to",
      "description": "Indicates a purpose or intention that connects the subject (objective) with an action or goal described by the object. The predicate 'is to' specifies what the subject aims to achieve, accomplish, or attain.",
      "disambiguation_index": 0
    },
    "Predicate-be_recognized_by": {
      "label": "be recognized by",
      "description": "The predicate 'be recognized by' indicates a relationship where the subject (e.g. faces) has its identity or characteristics acknowledged and understood by someone or something, as represented by the object (e.g. The objective of this work). This connection implies that there is an external entity that perceives, interprets, or validates the subject's features, attributes, or essence.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_combined_with": {
      "label": "can be combined with",
      "description": "The predicate 'can be combined with' indicates a relationship where two entities (the subject and object) are capable of being integrated, merged, or unified to form a new entity or concept. This integration can result in a more comprehensive understanding, improved accuracy, or enhanced insights.",
      "disambiguation_index": 0
    },
    "Predicate-describe": {
      "label": "describe",
      "description": "To describe a predicate that conveys the act of providing information or characteristics about something. It establishes a connection between the subject and object by conveying knowledge, details, or features about the object from the perspective of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-achieve": {
      "label": "achieve",
      "description": "To achieve means to successfully accomplish or attain a goal, objective, or outcome. The predicate 'achieve' indicates that the subject has reached its intended target or result, often through effort, planning, and execution.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "Indicates that the subject concept is a more specific instance of the object concept. The predicate establishes a hierarchical relationship between the two concepts, where the subject is a narrower term or specialization of the broader term represented by the object.",
      "disambiguation_index": 0
    }
  }
}