{
  "iri": "Paper-3",
  "title": "INTERSPEECH_2013_21_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-3-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-3-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-3-Section-1-Paragraph-1-Sentence-1",
              "text": "This work proposes a new research direction to address the lack of structures in traditional n-gram models ."
            },
            {
              "iri": "Paper-3-Section-1-Paragraph-1-Sentence-2",
              "text": "It is based on a weakly supervised dependency parser that can model speech syntax without relying on any annotated training corpus ."
            },
            {
              "iri": "Paper-3-Section-1-Paragraph-1-Sentence-3",
              "text": "Labeled data is replaced by a few hand-crafted rules that encode basic syntactic knowledge ."
            },
            {
              "iri": "Paper-3-Section-1-Paragraph-1-Sentence-4",
              "text": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus ."
            },
            {
              "iri": "Paper-3-Section-1-Paragraph-1-Sentence-5",
              "text": "This posterior encodes sparse se-lectional preferences between a head word and its dependents ."
            },
            {
              "iri": "Paper-3-Section-1-Paragraph-1-Sentence-6",
              "text": "The model is evaluated on English and Czech newspaper texts , and is then validated on French broadcast news transcriptions ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.00010418891906738281,
    15.268004894256592,
    35.12400794029236,
    40.65215802192688,
    0.05131101608276367,
    0.00011992454528808594,
    0.00014901161193847656,
    33.22381520271301,
    49.454894065856934,
    4.017578363418579,
    0.08647775650024414,
    0.01324915885925293,
    0.0002560615539550781,
    28.25658893585205,
    0.001477956771850586,
    0.03888893127441406,
    0.002624988555908203,
    4.823310136795044,
    2.7209620475769043,
    9.37035608291626,
    99.57185387611389,
    8.12044095993042,
    49.13786482810974,
    2.8397727012634277,
    0.0012350082397460938,
    0.03475594520568848
  ],
  "nodes": {
    "Entity-a_new_research_direction": {
      "node_id": "a_new_research_direction",
      "disambiguation_index": 0,
      "label": "a new research direction",
      "aliases": [
        "a new research direction"
      ],
      "types": [
        "research direction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A new research direction that utilizes a weakly supervised dependency parser to enhance traditional n-gram models by modeling speech syntax without annotated training data, employing hand-crafted rules and Bayesian inference to create complex tree structures.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-1",
          "local_name": "a new research direction",
          "local_types": [
            "research direction"
          ],
          "iri": "Entity-a_new_research_direction-Mention-1"
        }
      ],
      "relevance": 0.78125
    },
    "Entity-this_work": {
      "node_id": "this_work",
      "disambiguation_index": 0,
      "label": "This work",
      "aliases": [
        "This work"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This work refers to a research initiative that introduces a novel approach to enhance traditional n-gram models by utilizing a weakly supervised dependency parser to model speech syntax without annotated training data.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-1",
          "local_name": "This work",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_work-Mention-1"
        }
      ],
      "relevance": 0.75732421875
    },
    "Entity-the_model": {
      "node_id": "the_model",
      "disambiguation_index": 0,
      "label": "The model",
      "aliases": [
        "The model"
      ],
      "types": [
        "model"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The model refers to a weakly supervised dependency parser that utilizes Bayesian inference to create complex tree structures for modeling speech syntax without relying on annotated training data.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "The model",
          "local_types": [
            "model"
          ],
          "iri": "Entity-the_model-Mention-1"
        }
      ],
      "relevance": 0.72998046875
    },
    "Entity-structure": {
      "node_id": "structure",
      "disambiguation_index": 0,
      "label": "structures",
      "aliases": [
        "structures"
      ],
      "types": [
        "concept",
        "framework"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'structures' refers to the complex tree structures created by a weakly supervised dependency parser to model speech syntax in the context of improving traditional n-gram models.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-1",
          "local_name": "structures",
          "local_types": [
            "concept",
            "framework"
          ],
          "iri": "Entity-structure-Mention-1"
        }
      ],
      "relevance": 0.705078125
    },
    "Entity-model": {
      "node_id": "model",
      "disambiguation_index": 0,
      "label": "model",
      "aliases": [
        "model"
      ],
      "types": [
        "machine learning model",
        "evaluation subject"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The model refers to a weakly supervised dependency parser designed to analyze speech syntax and evaluate its performance on English and Czech newspaper texts, as well as French broadcast news transcriptions.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "model",
          "local_types": [
            "machine learning model",
            "evaluation subject"
          ],
          "iri": "Entity-model-Mention-1"
        }
      ],
      "relevance": 0.6962890625
    },
    "Entity-complex_tree_structure": {
      "node_id": "complex_tree_structure",
      "disambiguation_index": 0,
      "label": "complex tree structures",
      "aliases": [
        "complex tree structures"
      ],
      "types": [
        "syntactic representation",
        "structure",
        "tree structure",
        "model representation",
        "data structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Complex tree structures refer to intricate hierarchical representations generated by a weakly supervised dependency parser, which are used to model speech syntax and maximize the posterior of a discriminative model on an unlabeled corpus.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-4",
          "local_name": "complex tree structures",
          "local_types": [
            "syntactic representation",
            "structure",
            "tree structure",
            "model representation",
            "data structure"
          ],
          "iri": "Entity-complex_tree_structure-Mention-1"
        }
      ],
      "relevance": 0.67529296875
    },
    "Entity-the_lack_of_structure_in_traditional_n-gram_model": {
      "node_id": "the_lack_of_structure_in_traditional_n-gram_model",
      "disambiguation_index": 0,
      "label": "the lack of structures in traditional n-gram models",
      "aliases": [
        "the lack of structures in traditional n-gram models"
      ],
      "types": [
        "issue",
        "n-gram model"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The lack of structures in traditional n-gram models refers to the absence of syntactic and hierarchical organization in the way these models represent language, which limits their ability to capture complex linguistic relationships and dependencies.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-1",
          "local_name": "the lack of structures in traditional n-gram models",
          "local_types": [
            "issue",
            "n-gram model"
          ],
          "iri": "Entity-the_lack_of_structure_in_traditional_n-gram_model-Mention-1"
        }
      ],
      "relevance": 0.67529296875
    },
    "Entity-work": {
      "node_id": "work",
      "disambiguation_index": 0,
      "label": "work",
      "aliases": [
        "work"
      ],
      "types": [
        "research paper",
        "academic contribution"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'work' refers to a research paper that introduces a novel approach to enhance traditional n-gram models by utilizing a weakly supervised dependency parser to model speech syntax without annotated training data.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-1",
          "local_name": "work",
          "local_types": [
            "research paper",
            "academic contribution"
          ],
          "iri": "Entity-work-Mention-1"
        }
      ],
      "relevance": 0.66845703125
    },
    "Entity-target_unlabeled_corpus": {
      "node_id": "target_unlabeled_corpus",
      "disambiguation_index": 0,
      "label": "target unlabeled corpus",
      "aliases": [
        "target unlabeled corpus"
      ],
      "types": [
        "data set",
        "text corpus",
        "unlabeled corpus",
        "data",
        "unlabeled data",
        "corpus"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'target unlabeled corpus' refers to a collection of unannotated text data used to evaluate a weakly supervised dependency parser's ability to model speech syntax without relying on labeled training data.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-4",
          "local_name": "target unlabeled corpus",
          "local_types": [
            "data set",
            "text corpus",
            "unlabeled corpus",
            "data",
            "unlabeled data",
            "corpus"
          ],
          "iri": "Entity-target_unlabeled_corpus-Mention-1"
        }
      ],
      "relevance": 0.66552734375
    },
    "Entity-speech_syntax": {
      "node_id": "speech_syntax",
      "disambiguation_index": 0,
      "label": "speech syntax",
      "aliases": [
        "speech syntax"
      ],
      "types": [
        "syntax",
        "linguistic structure",
        "language feature"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Speech syntax refers to the structural aspects of spoken language that can be modeled using a weakly supervised dependency parser, which does not require annotated training data and instead utilizes hand-crafted rules to capture basic syntactic knowledge.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-2",
          "local_name": "speech syntax",
          "local_types": [
            "syntax",
            "linguistic structure",
            "language feature"
          ],
          "iri": "Entity-speech_syntax-Mention-1"
        }
      ],
      "relevance": 0.6572265625
    },
    "Entity-n-gram_model": {
      "node_id": "n-gram_model",
      "disambiguation_index": 0,
      "label": "n-gram models",
      "aliases": [
        "n-gram models",
        "traditional n-gram models"
      ],
      "types": [
        "n-gram model",
        "model",
        "language model",
        "statistical model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "N-gram models are statistical language models that predict the probability of a sequence of words based on the occurrence of n consecutive words in a given text.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-1",
          "local_name": "n-gram models",
          "local_types": [
            "language model",
            "statistical model"
          ],
          "iri": "Entity-n-gram_model-Mention-1"
        },
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-1",
          "local_name": "traditional n-gram models",
          "local_types": [
            "n-gram model",
            "model",
            "language model",
            "statistical model"
          ],
          "iri": "Entity-n-gram_model-Mention-2"
        }
      ],
      "relevance": 0.646484375
    },
    "Entity-rule": {
      "node_id": "rule",
      "disambiguation_index": 0,
      "label": "rules",
      "aliases": [
        "rules"
      ],
      "types": [
        "theoretical framework",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'rules' refers to hand-crafted syntactic rules that encode basic syntactic knowledge, which are used in a weakly supervised dependency parser to model speech syntax.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-4",
          "local_name": "rules",
          "local_types": [
            "theoretical framework",
            "concept"
          ],
          "iri": "Entity-rule-Mention-1"
        }
      ],
      "relevance": 0.64013671875
    },
    "Entity-weakly_supervised_dependency_parser": {
      "node_id": "weakly_supervised_dependency_parser",
      "disambiguation_index": 0,
      "label": "weakly supervised dependency parser",
      "aliases": [
        "weakly supervised dependency parser",
        "a weakly supervised dependency parser"
      ],
      "types": [
        "parser",
        "natural language processing tool",
        "dependency parser"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A weakly supervised dependency parser is a type of natural language processing tool that analyzes the grammatical structure of sentences by identifying dependencies between words, using limited or no annotated training data.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-2",
          "local_name": "weakly supervised dependency parser",
          "local_types": [
            "parser",
            "natural language processing tool",
            "dependency parser"
          ],
          "iri": "Entity-weakly_supervised_dependency_parser-Mention-1"
        },
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-2",
          "local_name": "a weakly supervised dependency parser",
          "local_types": [
            "parser",
            "dependency parser"
          ],
          "iri": "Entity-weakly_supervised_dependency_parser-Mention-2"
        }
      ],
      "relevance": 0.626953125
    },
    "Entity-this_posterior": {
      "node_id": "this_posterior",
      "disambiguation_index": 0,
      "label": "This posterior",
      "aliases": [
        "This posterior"
      ],
      "types": [
        "statistical model"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This posterior refers to the output of a discriminative model that captures sparse selectional preferences between a head word and its dependents in the context of a weakly supervised dependency parsing framework.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-5",
          "local_name": "This posterior",
          "local_types": [
            "statistical model"
          ],
          "iri": "Entity-this_posterior-Mention-1"
        }
      ],
      "relevance": 0.61962890625
    },
    "Entity-posterior": {
      "node_id": "posterior",
      "disambiguation_index": 0,
      "label": "posterior",
      "aliases": [
        "posterior"
      ],
      "types": [
        "statistical term",
        "probability distribution",
        "statistical concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of Bayesian inference, the term 'posterior' refers to the probability distribution that represents the updated beliefs about a model's parameters after observing the data, specifically in relation to maximizing a discriminative model's performance on an unlabeled corpus.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-4",
          "local_name": "posterior",
          "local_types": [
            "statistical term"
          ],
          "iri": "Entity-posterior-Mention-1"
        },
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-5",
          "local_name": "posterior",
          "local_types": [
            "statistical concept",
            "probability distribution"
          ],
          "iri": "Entity-posterior-Mention-2"
        }
      ],
      "relevance": 0.61865234375
    },
    "Entity-czech_newspaper_text": {
      "node_id": "czech_newspaper_text",
      "disambiguation_index": 0,
      "label": "Czech newspaper texts",
      "aliases": [
        "Czech newspaper texts"
      ],
      "types": [
        "text corpus",
        "language data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Czech newspaper texts refer to written articles and reports published in newspapers in the Czech language, used as a corpus for evaluating a weakly supervised dependency parser in the context of speech syntax modeling.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "Czech newspaper texts",
          "local_types": [
            "text corpus",
            "language data"
          ],
          "iri": "Entity-czech_newspaper_text-Mention-1"
        }
      ],
      "relevance": 0.59716796875
    },
    "Entity-english_and_czech_newspaper_text": {
      "node_id": "english_and_czech_newspaper_text",
      "disambiguation_index": 0,
      "label": "English and Czech newspaper texts",
      "aliases": [
        "English and Czech newspaper texts"
      ],
      "types": [
        "text",
        "text corpus",
        "language data",
        "newspaper",
        "newspaper text"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A collection of newspaper articles written in English and Czech used for evaluating a weakly supervised dependency parser model.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "English and Czech newspaper texts",
          "local_types": [
            "text",
            "text corpus",
            "language data",
            "newspaper",
            "newspaper text"
          ],
          "iri": "Entity-english_and_czech_newspaper_text-Mention-1"
        }
      ],
      "relevance": 0.5966796875
    },
    "Entity-basic_syntactic_knowledge": {
      "node_id": "basic_syntactic_knowledge",
      "disambiguation_index": 0,
      "label": "basic syntactic knowledge",
      "aliases": [
        "basic syntactic knowledge"
      ],
      "types": [
        "knowledge",
        "syntactic knowledge"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Basic syntactic knowledge refers to fundamental principles and rules of syntax that are encoded in hand-crafted rules, which are used to guide the parsing of language structures in the absence of annotated training data.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-3",
          "local_name": "basic syntactic knowledge",
          "local_types": [
            "knowledge",
            "syntactic knowledge"
          ],
          "iri": "Entity-basic_syntactic_knowledge-Mention-1"
        }
      ],
      "relevance": 0.58837890625
    },
    "Entity-annotated_training_corpus": {
      "node_id": "annotated_training_corpus",
      "disambiguation_index": 0,
      "label": "annotated training corpus",
      "aliases": [
        "annotated training corpus"
      ],
      "types": [
        "data set",
        "training corpus",
        "training resource",
        "training data",
        "corpus"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "An annotated training corpus is a collection of text data that has been labeled with specific information to facilitate the training of machine learning models, particularly in natural language processing tasks.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-2",
          "local_name": "annotated training corpus",
          "local_types": [
            "data set",
            "training corpus",
            "training resource",
            "training data",
            "corpus"
          ],
          "iri": "Entity-annotated_training_corpus-Mention-1"
        }
      ],
      "relevance": 0.56689453125
    },
    "Entity-it_dependent": {
      "node_id": "it_dependent",
      "disambiguation_index": 0,
      "label": "its dependents",
      "aliases": [
        "its dependents"
      ],
      "types": [
        "dependent"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'its dependents' refers to the words or phrases that are syntactically related to and dependent on a head word in the context of a dependency parser used for modeling speech syntax.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-5",
          "local_name": "its dependents",
          "local_types": [
            "dependent"
          ],
          "iri": "Entity-it_dependent-Mention-1"
        }
      ],
      "relevance": 0.55419921875
    },
    "Entity-dependent": {
      "node_id": "dependent",
      "disambiguation_index": 0,
      "label": "dependents",
      "aliases": [
        "dependents"
      ],
      "types": [
        "linguistic term",
        "dependency",
        "grammar"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of dependency grammar, 'dependents' refers to the words or phrases that are syntactically related to a head word, providing additional information or context within a sentence structure.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-5",
          "local_name": "dependents",
          "local_types": [
            "linguistic term",
            "dependency",
            "grammar"
          ],
          "iri": "Entity-dependent-Mention-1"
        }
      ],
      "relevance": 0.54833984375
    },
    "Entity-bayesian_inference": {
      "node_id": "bayesian_inference",
      "disambiguation_index": 0,
      "label": "Bayesian inference",
      "aliases": [
        "Bayesian inference"
      ],
      "types": [
        "inference technique",
        "statistical method",
        "method",
        "statistical technique",
        "inference"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Bayesian inference is a statistical method that applies Bayes' theorem to update the probability of a hypothesis as more evidence or information becomes available.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Bayesian inference",
          "local_types": [
            "inference technique",
            "statistical method",
            "method",
            "statistical technique",
            "inference"
          ],
          "iri": "Entity-bayesian_inference-Mention-1"
        }
      ],
      "relevance": 0.5458984375
    },
    "Entity-discriminative_model": {
      "node_id": "discriminative_model",
      "disambiguation_index": 0,
      "label": "discriminative model",
      "aliases": [
        "discriminative model"
      ],
      "types": [
        "discriminative model",
        "model",
        "statistical model",
        "machine learning model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A discriminative model is a type of statistical model used in machine learning that focuses on modeling the decision boundary between different classes, rather than modeling the distribution of each class.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-4",
          "local_name": "discriminative model",
          "local_types": [
            "discriminative model",
            "model",
            "statistical model",
            "machine learning model"
          ],
          "iri": "Entity-discriminative_model-Mention-1"
        }
      ],
      "relevance": 0.54150390625
    },
    "Entity-labeled_data": {
      "node_id": "labeled_data",
      "disambiguation_index": 0,
      "label": "Labeled data",
      "aliases": [
        "Labeled data"
      ],
      "types": [
        "data",
        "dataset"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Labeled data refers to a dataset that includes input-output pairs where each input is associated with a specific label or category, used primarily for training machine learning models.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-3",
          "local_name": "Labeled data",
          "local_types": [
            "data",
            "dataset"
          ],
          "iri": "Entity-labeled_data-Mention-1"
        }
      ],
      "relevance": 0.5087890625
    },
    "Entity-french_broadcast_news_transcription": {
      "node_id": "french_broadcast_news_transcription",
      "disambiguation_index": 0,
      "label": "French broadcast news transcriptions",
      "aliases": [
        "French broadcast news transcriptions"
      ],
      "types": [
        "broadcast news",
        "text",
        "text corpus",
        "transcription",
        "language data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "French broadcast news transcriptions are written records of spoken content from news broadcasts in the French language, serving as a textual representation of audio or video news segments.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "French broadcast news transcriptions",
          "local_types": [
            "broadcast news",
            "text",
            "text corpus",
            "transcription",
            "language data"
          ],
          "iri": "Entity-french_broadcast_news_transcription-Mention-1"
        }
      ],
      "relevance": 0.499267578125
    },
    "Entity-syntactic_knowledge": {
      "node_id": "syntactic_knowledge",
      "disambiguation_index": 0,
      "label": "syntactic knowledge",
      "aliases": [
        "syntactic knowledge"
      ],
      "types": [
        "knowledge",
        "linguistic knowledge"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Syntactic knowledge refers to the understanding and awareness of the rules and structures that govern the formation of sentences in a language.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-3",
          "local_name": "syntactic knowledge",
          "local_types": [
            "knowledge",
            "linguistic knowledge"
          ],
          "iri": "Entity-syntactic_knowledge-Mention-1"
        }
      ],
      "relevance": 0.49755859375
    },
    "Entity-hand-crafted_rule": {
      "node_id": "hand-crafted_rule",
      "disambiguation_index": 0,
      "label": "hand-crafted rules",
      "aliases": [
        "hand-crafted rules"
      ],
      "types": [
        "syntactic knowledge",
        "rule-based system",
        "rules",
        "rule"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Hand-crafted rules are manually created guidelines or instructions that define specific behaviors or processes within a system, often based on expert knowledge or predefined criteria.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-3",
          "local_name": "hand-crafted rules",
          "local_types": [
            "syntactic knowledge",
            "rule-based system",
            "rules",
            "rule"
          ],
          "iri": "Entity-hand-crafted_rule-Mention-1"
        }
      ],
      "relevance": 0.4873046875
    },
    "Entity-broadcast_news_transcription": {
      "node_id": "broadcast_news_transcription",
      "disambiguation_index": 0,
      "label": "broadcast news transcriptions",
      "aliases": [
        "broadcast news transcriptions"
      ],
      "types": [
        "text data",
        "media content"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Broadcast news transcriptions are written records of spoken content from news broadcasts, capturing the dialogue and information presented in television or radio news programs.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "broadcast news transcriptions",
          "local_types": [
            "text data",
            "media content"
          ],
          "iri": "Entity-broadcast_news_transcription-Mention-1"
        }
      ],
      "relevance": 0.486328125
    },
    "Entity-french": {
      "node_id": "french",
      "disambiguation_index": 0,
      "label": "French",
      "aliases": [
        "French"
      ],
      "types": [
        "language"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "French refers to the French language, which is used in the context of validating a model on broadcast news transcriptions in France.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "French",
          "local_types": [
            "language"
          ],
          "iri": "Entity-french-Mention-1"
        }
      ],
      "relevance": 0.480712890625
    },
    "Entity-head_word": {
      "node_id": "head_word",
      "disambiguation_index": 0,
      "label": "head word",
      "aliases": [
        "head word"
      ],
      "types": [
        "linguistic term",
        "grammar",
        "word"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A head word is a central word in a phrase that determines the grammatical nature of the entire phrase and governs the syntactic relationship with its dependents.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-5",
          "local_name": "head word",
          "local_types": [
            "linguistic term",
            "grammar",
            "word"
          ],
          "iri": "Entity-head_word-Mention-1"
        }
      ],
      "relevance": 0.469970703125
    },
    "Entity-a_head_word": {
      "node_id": "a_head_word",
      "disambiguation_index": 0,
      "label": "a head word",
      "aliases": [
        "a head word"
      ],
      "types": [
        "word"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A head word is the main word in a phrase that determines the syntactic type and meaning of that phrase, serving as the central element to which other words (dependents) relate.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-5",
          "local_name": "a head word",
          "local_types": [
            "word"
          ],
          "iri": "Entity-a_head_word-Mention-1"
        }
      ],
      "relevance": 0.46435546875
    },
    "Entity-newspaper_text": {
      "node_id": "newspaper_text",
      "disambiguation_index": 0,
      "label": "newspaper texts",
      "aliases": [
        "newspaper texts"
      ],
      "types": [
        "text data",
        "media content"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Newspaper texts refer to written articles, reports, and other content published in newspapers, typically covering news, opinions, and various topics of interest to the public.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "newspaper texts",
          "local_types": [
            "text data",
            "media content"
          ],
          "iri": "Entity-newspaper_text-Mention-1"
        }
      ],
      "relevance": 0.440673828125
    },
    "Entity-english": {
      "node_id": "english",
      "disambiguation_index": 0,
      "label": "English",
      "aliases": [
        "English"
      ],
      "types": [
        "language"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "English is a West Germanic language that is primarily spoken in England and is widely used as a global lingua franca.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "English",
          "local_types": [
            "language"
          ],
          "iri": "Entity-english-Mention-1"
        }
      ],
      "relevance": 0.416748046875
    },
    "Entity-research_direction": {
      "node_id": "research_direction",
      "disambiguation_index": 0,
      "label": "research direction",
      "aliases": [
        "research direction"
      ],
      "types": [
        "academic focus",
        "research focus",
        "academic strategy",
        "research concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A research direction refers to a specific area of inquiry or focus within academic or scientific research that guides the objectives and methodologies of studies.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-1",
          "local_name": "research direction",
          "local_types": [
            "academic focus",
            "research focus",
            "academic strategy",
            "research concept"
          ],
          "iri": "Entity-research_direction-Mention-1"
        }
      ],
      "relevance": 0.405517578125
    },
    "Entity-czech": {
      "node_id": "czech",
      "disambiguation_index": 0,
      "label": "Czech",
      "aliases": [
        "Czech"
      ],
      "types": [
        "language"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Czech refers to the West Slavic language spoken primarily in the Czech Republic.",
      "mentions": [
        {
          "reference": "Paper-3-Section-1-Paragraph-1-Sentence-6",
          "local_name": "Czech",
          "local_types": [
            "language"
          ],
          "iri": "Entity-czech-Mention-1"
        }
      ],
      "relevance": 0.383544921875
    }
  },
  "summary": "This work proposes a new research direction to address the lack of structures in traditional n-gram models . It is based on a weakly supervised dependency parser that can model speech syntax without relying on any annotated training corpus . Labeled data is replaced by a few hand-crafted rules that encode basic syntactic knowledge . Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus . This posterior encodes sparse se-lectional preferences between a head word and its dependents . The model is evaluated on English and Czech newspaper texts , and is then validated on French broadcast news transcriptions .",
  "triples": [
    [
      "Entity-this_work",
      "Predicate-proposes",
      "Entity-a_new_research_direction"
    ],
    [
      "Entity-a_new_research_direction",
      "Predicate-addresses",
      "Entity-the_lack_of_structure_in_traditional_n-gram_model"
    ],
    [
      "Entity-weakly_supervised_dependency_parser",
      "Predicate-is_based_on",
      "Entity-weakly_supervised_dependency_parser"
    ],
    [
      "Entity-weakly_supervised_dependency_parser",
      "Predicate-can_model",
      "Entity-speech_syntax"
    ],
    [
      "Entity-weakly_supervised_dependency_parser",
      "Predicate-without_relying_on",
      "Entity-annotated_training_corpus"
    ],
    [
      "Entity-labeled_data",
      "Predicate-is_replaced_by",
      "Entity-hand-crafted_rule"
    ],
    [
      "Entity-hand-crafted_rule",
      "Predicate-encode",
      "Entity-basic_syntactic_knowledge"
    ],
    [
      "Entity-bayesian_inference",
      "Predicate-samples",
      "Entity-rule"
    ],
    [
      "Entity-rule",
      "Predicate-create",
      "Entity-complex_tree_structure"
    ],
    [
      "Entity-head_word",
      "Predicate-has",
      "Entity-it_dependent"
    ],
    [
      "Entity-a_head_word",
      "Predicate-has",
      "Entity-it_dependent"
    ],
    [
      "Entity-the_model",
      "Predicate-is_evaluated_on",
      "Entity-english_and_czech_newspaper_text"
    ],
    [
      "Entity-the_model",
      "Predicate-is_validated_on",
      "Entity-french_broadcast_news_transcription"
    ],
    [
      "Entity-a_new_research_direction",
      "Predicate-utilizes",
      "Entity-the_model"
    ],
    [
      "Entity-this_work",
      "Predicate-introduces",
      "Entity-the_model"
    ]
  ],
  "triples_typing": [
    [
      "Entity-the_model",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-discriminative_model",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-it_dependent",
      "skos:broader",
      "Entity-dependent"
    ],
    [
      "Entity-the_lack_of_structure_in_traditional_n-gram_model",
      "skos:broader",
      "Entity-n-gram_model"
    ],
    [
      "Entity-hand-crafted_rule",
      "skos:broader",
      "Entity-basic_syntactic_knowledge"
    ],
    [
      "Entity-n-gram_model",
      "skos:broader",
      "Entity-model"
    ],
    [
      "Entity-hand-crafted_rule",
      "skos:broader",
      "Entity-syntactic_knowledge"
    ],
    [
      "Entity-hand-crafted_rule",
      "skos:broader",
      "Entity-rule"
    ],
    [
      "Entity-english_and_czech_newspaper_text",
      "skos:broader",
      "Entity-newspaper_text"
    ],
    [
      "Entity-complex_tree_structure",
      "skos:broader",
      "Entity-structure"
    ],
    [
      "Entity-basic_syntactic_knowledge",
      "skos:broader",
      "Entity-syntactic_knowledge"
    ],
    [
      "Entity-a_new_research_direction",
      "skos:broader",
      "Entity-research_direction"
    ]
  ],
  "predicates": {
    "Predicate-proposes": {
      "label": "proposes",
      "description": "The predicate 'proposes' indicates that the subject puts forward an idea, plan, or suggestion for consideration or action, which is represented by the object. It establishes a relationship where the subject is actively advocating for the object as a potential course of action or thought.",
      "disambiguation_index": 0
    },
    "Predicate-addresses": {
      "label": "addresses",
      "description": "The predicate 'addresses' indicates that the subject is focused on or concerned with the object, often implying an attempt to resolve, discuss, or provide insight into the issues or topics represented by the object. It suggests a relationship where the subject actively engages with the object to highlight its significance or to propose solutions.",
      "disambiguation_index": 0
    },
    "Predicate-is_based_on": {
      "label": "is based on",
      "description": "The predicate 'is based on' indicates a foundational relationship where the subject derives its principles, methods, or structure from the object. It suggests that the subject is built upon, influenced by, or fundamentally connected to the object, which serves as a source or reference point for the subject's development or functioning.",
      "disambiguation_index": 0
    },
    "Predicate-can_model": {
      "label": "can model",
      "description": "The predicate 'can model' indicates the capability of the subject to represent, simulate, or understand the characteristics, structures, or behaviors of the object. It implies that the subject possesses the necessary features or mechanisms to effectively capture the essence of the object in a meaningful way.",
      "disambiguation_index": 0
    },
    "Predicate-without_relying_on": {
      "label": "without relying on",
      "description": "The predicate 'without relying on' indicates that the subject operates independently of the object, suggesting that the subject does not depend on or utilize the object as a resource or support in its functioning or process.",
      "disambiguation_index": 0
    },
    "Predicate-is_replaced_by": {
      "label": "is replaced by",
      "description": "The predicate 'is replaced by' indicates a relationship where the subject is substituted or superseded by the object, suggesting that the object serves as an alternative or new version that takes the place of the subject in a particular context or process.",
      "disambiguation_index": 0
    },
    "Predicate-encode": {
      "label": "encode",
      "description": "The predicate 'encode' signifies the process of transforming or representing information from one form into another. In the context of the subject and object, it indicates that the subject is responsible for the systematic conversion or formulation of the object into a specific format or structure, thereby facilitating understanding, storage, or transmission of the underlying information.",
      "disambiguation_index": 0
    },
    "Predicate-samples": {
      "label": "samples",
      "description": "The predicate 'samples' indicates a relationship where the subject is generating, selecting, or extracting instances or examples from a broader set or distribution, which are represented by the object. This connection implies that the subject is involved in a process that involves obtaining specific data points or elements that exemplify or represent the characteristics of the object.",
      "disambiguation_index": 0
    },
    "Predicate-create": {
      "label": "create",
      "description": "The predicate 'create' signifies the action of bringing something into existence or forming it from existing elements. In the context of a subject and an object, it indicates that the subject is responsible for the generation or construction of the object, which represents the new entity or concept being formed. This relationship highlights the transformative process where the subject applies knowledge, skills, or resources to produce the object.",
      "disambiguation_index": 0
    },
    "Predicate-has": {
      "label": "has",
      "description": "The predicate 'has' establishes a relationship of possession or association between the subject and the object, indicating that the subject contains, possesses, or is characterized by the object. In the context of the example triple, it signifies that the 'head word' possesses or is associated with its 'dependents', which can include various elements that provide additional information or context related to the head word.",
      "disambiguation_index": 0
    },
    "Predicate-is_evaluated_on": {
      "label": "is evaluated on",
      "description": "The predicate 'is evaluated on' establishes a relationship where the subject undergoes an assessment or analysis based on the criteria or data represented by the object. This indicates that the performance, effectiveness, or quality of the subject is measured using the specific context or materials denoted by the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_validated_on": {
      "label": "is validated on",
      "description": "The predicate 'is validated on' establishes a relationship where the subject undergoes a process of verification or assessment using the object as a basis or reference. It indicates that the subject, typically a model or system, is tested or confirmed for its effectiveness, accuracy, or reliability in relation to the specific data or context represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-utilizes": {
      "label": "utilizes",
      "description": "The predicate 'utilizes' indicates that the subject employs or makes use of the object in a practical or functional manner. It suggests an active engagement where the subject leverages the capabilities, features, or resources of the object to achieve a specific purpose or outcome.",
      "disambiguation_index": 0
    },
    "Predicate-introduces": {
      "label": "introduces",
      "description": "The predicate 'introduces' signifies the act of presenting or bringing forth a new concept, idea, or entity (the object) to an audience or context (the subject). It implies a relationship where the subject plays a role in making the object known or accessible, often for the first time, thereby facilitating understanding or awareness of the object.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' establishes a hierarchical relationship between the subject and the object, indicating that the subject is a specific instance or example that falls under a more general category represented by the object. This relationship suggests that the object encompasses a wider scope or range of concepts, of which the subject is a part.",
      "disambiguation_index": 0
    }
  }
}