{
  "iri": "Paper-27",
  "title": "ICCV_2013_25_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-27-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-27-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-27-Section-1-Paragraph-1-Sentence-1",
              "text": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry ."
            },
            {
              "iri": "Paper-27-Section-1-Paragraph-1-Sentence-2",
              "text": "Subpixel accuracy is achieved by considering several zero-crossings defined by the difference between pairs of unstructured patterns ."
            },
            {
              "iri": "Paper-27-Section-1-Paragraph-1-Sentence-3",
              "text": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities ."
            },
            {
              "iri": "Paper-27-Section-1-Paragraph-1-Sentence-4",
              "text": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems ."
            },
            {
              "iri": "Paper-27-Section-1-Paragraph-1-Sentence-5",
              "text": "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.00020647048950195312,
    15.268794298171997,
    24.608947277069092,
    21.800703048706055,
    0.02536606788635254,
    8.511543273925781e-05,
    0.00010371208190917969,
    33.17869305610657,
    44.668598651885986,
    1.5118770599365234,
    1.4071791172027588,
    0.009303569793701172,
    0.00018858909606933594,
    27.97354483604431,
    4.757891654968262,
    0.019691944122314453,
    1.108386754989624,
    3.3879432678222656,
    3.0573067665100098,
    3.1548829078674316,
    37.81414079666138,
    3.106165647506714,
    15.392512321472168,
    1.0090196132659912,
    0.0005996227264404297,
    0.010983705520629883
  ],
  "nodes": {
    "Entity-scanning_method": {
      "node_id": "scanning_method",
      "disambiguation_index": 0,
      "label": "scanning method",
      "aliases": [
        "scanning method"
      ],
      "types": [
        "algorithm",
        "technique",
        "method"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A novel algorithm for recovering dense, high-precision correspondences between a camera and projector system's sub-pixel patterns without requiring photometric calibration or prior geometric knowledge.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-1",
          "local_name": "scanning method",
          "local_types": [
            "algorithm",
            "technique",
            "method"
          ],
          "iri": "Entity-scanning_method-Mention-1"
        }
      ],
      "relevance": 0.81005859375
    },
    "Entity-we_present_a_scanning_method": {
      "node_id": "we_present_a_scanning_method",
      "disambiguation_index": 0,
      "label": "We present a scanning method",
      "aliases": [
        "We present a scanning method"
      ],
      "types": [
        "method",
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A novel approach to recovering dense, high-precision correspondences between a camera and projector system without relying on photometric calibration or prior geometric knowledge.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-1",
          "local_name": "We present a scanning method",
          "local_types": [
            "method",
            "research"
          ],
          "iri": "Entity-we_present_a_scanning_method-Mention-1"
        }
      ],
      "relevance": 0.80517578125
    },
    "Entity-scanning_method_that_recovers_dense_sub-pixel_camera-projector_correspondence": {
      "node_id": "scanning_method_that_recovers_dense_sub-pixel_camera-projector_correspondence",
      "disambiguation_index": 0,
      "label": "scanning method that recovers dense sub-pixel camera-projector correspondence",
      "aliases": [
        "scanning method that recovers dense sub-pixel camera-projector correspondence",
        "a scanning method that recovers dense sub-pixel camera-projector correspondence"
      ],
      "types": [
        "method",
        "technique",
        "correspondence",
        "technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A scanning technology that accurately matches pixel-level correspondences between a camera and projector, enabling dense sub-pixel reconstruction.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-1",
          "local_name": "scanning method that recovers dense sub-pixel camera-projector correspondence",
          "local_types": [
            "method",
            "technology"
          ],
          "iri": "Entity-scanning_method_that_recovers_dense_sub-pixel_camera-projector_correspondence-Mention-1"
        },
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-1",
          "local_name": "a scanning method that recovers dense sub-pixel camera-projector correspondence",
          "local_types": [
            "technique",
            "correspondence"
          ],
          "iri": "Entity-scanning_method_that_recovers_dense_sub-pixel_camera-projector_correspondence-Mention-2"
        }
      ],
      "relevance": 0.7802734375
    },
    "Entity-mi-cro_phase_shifting": {
      "node_id": "mi-cro_phase_shifting",
      "disambiguation_index": 0,
      "label": "mi-cro phase shifting",
      "aliases": [
        "mi-cro phase shifting",
        "mi-cro phase shifting and modulated phase shifting"
      ],
      "types": [
        "method",
        "technique",
        "algorithm"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "A method or technique for recovering dense sub-pixel camera-projector correspondence",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-5",
          "local_name": "mi-cro phase shifting",
          "local_types": [
            "method",
            "technique",
            "algorithm"
          ],
          "iri": "Entity-mi-cro_phase_shifting-Mention-1"
        },
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-5",
          "local_name": "mi-cro phase shifting and modulated phase shifting",
          "local_types": [
            "technique",
            "algorithm"
          ],
          "iri": "Entity-mi-cro_phase_shifting-Mention-2"
        }
      ],
      "relevance": 0.7685546875
    },
    "Entity-without_requiring_any_photometric_calibration_nor_preliminary_knowledge_of_their_relative_geometry": {
      "node_id": "without_requiring_any_photometric_calibration_nor_preliminary_knowledge_of_their_relative_geometry",
      "disambiguation_index": 0,
      "label": "without requiring any photometric calibration nor preliminary knowledge of their relative geometry",
      "aliases": [
        "without requiring any photometric calibration nor preliminary knowledge of their relative geometry"
      ],
      "types": [
        "constraint"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A constraint on recovering dense sub-pixel camera-projector correspondence that does not require photometric calibration or prior knowledge of the relative geometry between cameras and projectors.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-1",
          "local_name": "without requiring any photometric calibration nor preliminary knowledge of their relative geometry",
          "local_types": [
            "constraint"
          ],
          "iri": "Entity-without_requiring_any_photometric_calibration_nor_preliminary_knowledge_of_their_relative_geometry-Mention-1"
        }
      ],
      "relevance": 0.7470703125
    },
    "Entity-modulated_phase_shifting": {
      "node_id": "modulated_phase_shifting",
      "disambiguation_index": 0,
      "label": "modulated phase shifting",
      "aliases": [
        "modulated phase shifting"
      ],
      "types": [
        "method",
        "technique",
        "algorithm"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "A method or technique used for recovering dense sub-pixel camera-projector correspondence, which involves modulating the phase of patterns to achieve high precision.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-5",
          "local_name": "modulated phase shifting",
          "local_types": [
            "method",
            "technique",
            "algorithm"
          ],
          "iri": "Entity-modulated_phase_shifting-Mention-1"
        }
      ],
      "relevance": 0.736328125
    },
    "Entity-we": {
      "node_id": "we",
      "disambiguation_index": 0,
      "label": "We",
      "aliases": [
        "We"
      ],
      "types": [
        "author"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The authors who developed a scanning method for recovering dense sub-pixel camera-projector correspondence.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-5",
          "local_name": "We",
          "local_types": [
            "author"
          ],
          "iri": "Entity-we-Mention-1"
        }
      ],
      "relevance": 0.7265625
    },
    "Entity-gray-level_band-pass_white_noise_pattern_that_increase_robustness_to_indirect_lighting_and_scene_discontinuity": {
      "node_id": "gray-level_band-pass_white_noise_pattern_that_increase_robustness_to_indirect_lighting_and_scene_discontinuity",
      "disambiguation_index": 0,
      "label": "gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities",
      "aliases": [
        "gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities"
      ],
      "types": [
        "pattern"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Unstructured gray-level band-pass white noise patterns used for sub-pixel camera-projector correspondence recovery, enhancing robustness against indirect lighting and scene discontinuities.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-3",
          "local_name": "gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities",
          "local_types": [
            "pattern"
          ],
          "iri": "Entity-gray-level_band-pass_white_noise_pattern_that_increase_robustness_to_indirect_lighting_and_scene_discontinuity-Mention-1"
        }
      ],
      "relevance": 0.71240234375
    },
    "Entity-simulated_and_experimental_result": {
      "node_id": "simulated_and_experimental_result",
      "disambiguation_index": 0,
      "label": "Simulated and experimental results",
      "aliases": [
        "Simulated and experimental results"
      ],
      "types": [
        "results"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The combined outcomes from simulated scenarios and actual experiments demonstrating the effectiveness of a scanning method for recovering dense camera-projector correspondence with high subpixel precision.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Simulated and experimental results",
          "local_types": [
            "results"
          ],
          "iri": "Entity-simulated_and_experimental_result-Mention-1"
        }
      ],
      "relevance": 0.71142578125
    },
    "Entity-camera-projector_correspondence": {
      "node_id": "camera-projector_correspondence",
      "disambiguation_index": 0,
      "label": "camera-Projector correspondence",
      "aliases": [
        "camera-Projector correspondence",
        "camera-projector correspondence"
      ],
      "types": [
        "computer vision",
        "technology",
        "concept",
        "image processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A technique for establishing a precise relationship between the positions and orientations of cameras and projectors, enabling sub-pixel accurate scene reconstruction.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-1",
          "local_name": "camera-Projector correspondence",
          "local_types": [
            "computer vision",
            "technology",
            "concept",
            "image processing"
          ],
          "iri": "Entity-camera-projector_correspondence-Mention-1"
        }
      ],
      "relevance": 0.68408203125
    },
    "Entity-we_compare_our_result_to_state_of_the_art_method_such_a_mi-cro_phase_shifting_and_modulated_phase_shifting": {
      "node_id": "we_compare_our_result_to_state_of_the_art_method_such_a_mi-cro_phase_shifting_and_modulated_phase_shifting",
      "disambiguation_index": 0,
      "label": "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting",
      "aliases": [
        "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting"
      ],
      "types": [
        "comparison"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Micro-phase shifting and Modulated Phase Shifting, two state-of-the-art methods for camera-projector correspondence recovery",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-5",
          "local_name": "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting",
          "local_types": [
            "comparison"
          ],
          "iri": "Entity-we_compare_our_result_to_state_of_the_art_method_such_a_mi-cro_phase_shifting_and_modulated_phase_shifting-Mention-1"
        }
      ],
      "relevance": 0.68310546875
    },
    "Entity-several_zero-crossings_defined_by_the_difference_between_pair_of_unstructured_pattern": {
      "node_id": "several_zero-crossings_defined_by_the_difference_between_pair_of_unstructured_pattern",
      "disambiguation_index": 0,
      "label": "several zero-crossings defined by the difference between pairs of unstructured patterns",
      "aliases": [
        "several zero-crossings defined by the difference between pairs of unstructured patterns"
      ],
      "types": [
        "pattern",
        "algorithm"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A set of points where the intensity differences between two random noise patterns intersect, used for achieving subpixel accuracy in camera-projector correspondence recovery.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-2",
          "local_name": "several zero-crossings defined by the difference between pairs of unstructured patterns",
          "local_types": [
            "pattern",
            "algorithm"
          ],
          "iri": "Entity-several_zero-crossings_defined_by_the_difference_between_pair_of_unstructured_pattern-Mention-1"
        }
      ],
      "relevance": 0.6787109375
    },
    "Entity-indirect_lighting_and_scene_discontinuity": {
      "node_id": "indirect_lighting_and_scene_discontinuity",
      "disambiguation_index": 0,
      "label": "indirect lighting and scene discontinuities",
      "aliases": [
        "indirect lighting and scene discontinuities"
      ],
      "types": [
        "phenomenon"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The phenomenon of using gray-level band-pass white noise patterns to enhance the robustness of camera-projector correspondence recovery against variations caused by indirect lighting and scene discontinuities.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-3",
          "local_name": "indirect lighting and scene discontinuities",
          "local_types": [
            "phenomenon"
          ],
          "iri": "Entity-indirect_lighting_and_scene_discontinuity-Mention-1"
        }
      ],
      "relevance": 0.67724609375
    },
    "Entity-scene_geometry_with_high_subpixel_precision": {
      "node_id": "scene_geometry_with_high_subpixel_precision",
      "disambiguation_index": 0,
      "label": "scene geometry with high subpixel precision",
      "aliases": [
        "scene geometry with high subpixel precision"
      ],
      "types": [
        "geometry",
        "precision"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A technique for accurately recovering the geometric structure of a scene at a resolution higher than one pixel.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-4",
          "local_name": "scene geometry with high subpixel precision",
          "local_types": [
            "geometry",
            "precision"
          ],
          "iri": "Entity-scene_geometry_with_high_subpixel_precision-Mention-1"
        }
      ],
      "relevance": 0.6748046875
    },
    "Entity-gray-level_band-pass_white_noise_pattern": {
      "node_id": "gray-level_band-pass_white_noise_pattern",
      "disambiguation_index": 0,
      "label": "gray-level band-pass white noise patterns",
      "aliases": [
        "gray-level band-pass white noise patterns"
      ],
      "types": [
        "signal processing",
        "noise pattern",
        "image analysis",
        "pattern",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A type of signal used for increasing robustness to indirect lighting and scene discontinuities in camera-projector correspondence scanning methods.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-3",
          "local_name": "gray-level band-pass white noise patterns",
          "local_types": [
            "signal processing",
            "noise pattern",
            "image analysis",
            "pattern",
            "data type"
          ],
          "iri": "Entity-gray-level_band-pass_white_noise_pattern-Mention-1"
        }
      ],
      "relevance": 0.64501953125
    },
    "Entity-active_reconstruction_system": {
      "node_id": "active_reconstruction_system",
      "disambiguation_index": 0,
      "label": "active reconstruction systems",
      "aliases": [
        "active reconstruction systems"
      ],
      "types": [
        "system",
        "data analysis",
        "computational simulation",
        "technology",
        "reconstruction system"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Systems capable of actively reconstructing scenes or geometries using various methods such as scanning, photometric calibration-free approaches, and computational simulations.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-4",
          "local_name": "active reconstruction systems",
          "local_types": [
            "system",
            "data analysis",
            "computational simulation",
            "technology",
            "reconstruction system"
          ],
          "iri": "Entity-active_reconstruction_system-Mention-1"
        }
      ],
      "relevance": 0.5908203125
    },
    "Entity-photometric_calibration": {
      "node_id": "photometric_calibration",
      "disambiguation_index": 0,
      "label": "photometric calibration",
      "aliases": [
        "photometric calibration"
      ],
      "types": [
        "technique",
        "measurement technique",
        "process",
        "calibration process"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A process or technique used to adjust and align optical measurements, such as camera-projector correspondences.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-1",
          "local_name": "photometric calibration",
          "local_types": [
            "technique",
            "measurement technique",
            "process",
            "calibration process"
          ],
          "iri": "Entity-photometric_calibration-Mention-1"
        }
      ],
      "relevance": 0.57568359375
    },
    "Entity-subpixel_accuracy": {
      "node_id": "subpixel_accuracy",
      "disambiguation_index": 0,
      "label": "Subpixel accuracy",
      "aliases": [
        "Subpixel accuracy"
      ],
      "types": [
        "performance measure",
        "accuracy",
        "metric"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A measure of precision or correctness, typically used to evaluate the quality of image processing or computer vision algorithms.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-2",
          "local_name": "Subpixel accuracy",
          "local_types": [
            "performance measure",
            "accuracy",
            "metric"
          ],
          "iri": "Entity-subpixel_accuracy-Mention-1"
        }
      ],
      "relevance": 0.56396484375
    },
    "Entity-pair_of_unstructured_pattern": {
      "node_id": "pair_of_unstructured_pattern",
      "disambiguation_index": 0,
      "label": "pairs of unstructured patterns",
      "aliases": [
        "pairs of unstructured patterns"
      ],
      "types": [
        "data set",
        "pattern recognition input"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Gray-level band-pass white noise patterns used as input for pattern recognition.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-2",
          "local_name": "pairs of unstructured patterns",
          "local_types": [
            "data set",
            "pattern recognition input"
          ],
          "iri": "Entity-pair_of_unstructured_pattern-Mention-1"
        }
      ],
      "relevance": 0.5595703125
    },
    "Entity-zero-crossings": {
      "node_id": "zero-crossings",
      "disambiguation_index": 0,
      "label": "zero-crossings",
      "aliases": [
        "zero-crossings"
      ],
      "types": [
        "mathematical concept",
        "signal processing technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A point in a signal where the sign or polarity changes, used as a mathematical concept and technique in signal processing.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-2",
          "local_name": "zero-crossings",
          "local_types": [
            "mathematical concept",
            "signal processing technique"
          ],
          "iri": "Entity-zero-crossings-Mention-1"
        }
      ],
      "relevance": 0.54931640625
    },
    "Entity-scene_discontinuity": {
      "node_id": "scene_discontinuity",
      "disambiguation_index": 0,
      "label": "scene discontinuities",
      "aliases": [
        "scene discontinuities"
      ],
      "types": [
        "image feature",
        "computer vision",
        "image processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Unwanted changes or inconsistencies between different parts of an image, caused by factors such as indirect lighting.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-3",
          "local_name": "scene discontinuities",
          "local_types": [
            "image feature",
            "computer vision",
            "image processing"
          ],
          "iri": "Entity-scene_discontinuity-Mention-1"
        }
      ],
      "relevance": 0.54638671875
    },
    "Entity-scene_geometry": {
      "node_id": "scene_geometry",
      "disambiguation_index": 0,
      "label": "scene geometry",
      "aliases": [
        "scene geometry"
      ],
      "types": [
        "domain knowledge",
        "computer vision",
        "concept",
        "image processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The spatial arrangement or structure of a visual environment",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-4",
          "local_name": "scene geometry",
          "local_types": [
            "domain knowledge",
            "computer vision",
            "concept",
            "image processing"
          ],
          "iri": "Entity-scene_geometry-Mention-1"
        }
      ],
      "relevance": 0.50439453125
    },
    "Entity-our_result": {
      "node_id": "our_result",
      "disambiguation_index": 0,
      "label": "our results",
      "aliases": [
        "our results"
      ],
      "types": [
        "result",
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The experimental or simulated outcomes obtained from applying the proposed scanning method, which are compared with existing state-of-the-art methods.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-5",
          "local_name": "our results",
          "local_types": [
            "result",
            "research"
          ],
          "iri": "Entity-our_result-Mention-1"
        }
      ],
      "relevance": 0.50390625
    },
    "Entity-relative_geometry": {
      "node_id": "relative_geometry",
      "disambiguation_index": 0,
      "label": "relative geometry",
      "aliases": [
        "relative geometry"
      ],
      "types": [
        "geometry",
        "mathematics"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The study and application of geometric transformations between objects or frames, often used to describe spatial relationships.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-1",
          "local_name": "relative geometry",
          "local_types": [
            "geometry",
            "mathematics"
          ],
          "iri": "Entity-relative_geometry-Mention-1"
        }
      ],
      "relevance": 0.470458984375
    },
    "Entity-indirect_lighting": {
      "node_id": "indirect_lighting",
      "disambiguation_index": 0,
      "label": "indirect lighting",
      "aliases": [
        "indirect lighting"
      ],
      "types": [
        "lighting",
        "physics",
        "lighting condition"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Light emitted or reflected from a source other than directly overhead",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-3",
          "local_name": "indirect lighting",
          "local_types": [
            "lighting",
            "physics",
            "lighting condition"
          ],
          "iri": "Entity-indirect_lighting-Mention-1"
        }
      ],
      "relevance": 0.4287109375
    },
    "Entity-our_method": {
      "node_id": "our_method",
      "disambiguation_index": 0,
      "label": "our method",
      "aliases": [
        "our method"
      ],
      "types": [
        "algorithm",
        "technique",
        "method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A computational approach or technique used to achieve a specific goal or solve a particular problem.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-4",
          "local_name": "our method",
          "local_types": [
            "algorithm",
            "technique",
            "method"
          ],
          "iri": "Entity-our_method-Mention-1"
        }
      ],
      "relevance": 0.423095703125
    },
    "Entity-state_of_the_art_method": {
      "node_id": "state_of_the_art_method",
      "disambiguation_index": 0,
      "label": "state of the art methods",
      "aliases": [
        "state of the art methods"
      ],
      "types": [
        "research area",
        "methodology",
        "research approach",
        "art",
        "computational technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The most advanced or current techniques used in a particular field",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-5",
          "local_name": "state of the art methods",
          "local_types": [
            "research area",
            "methodology",
            "research approach",
            "art",
            "computational technique"
          ],
          "iri": "Entity-state_of_the_art_method-Mention-1"
        }
      ],
      "relevance": 0.4033203125
    },
    "Entity-simulated": {
      "node_id": "simulated",
      "disambiguation_index": 0,
      "label": "Simulated",
      "aliases": [
        "Simulated"
      ],
      "types": [
        "method",
        "approach"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A simulated or artificial approach or methodology",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Simulated",
          "local_types": [
            "method",
            "approach"
          ],
          "iri": "Entity-simulated-Mention-1"
        }
      ],
      "relevance": 0.392822265625
    },
    "Entity-experimental_result": {
      "node_id": "experimental_result",
      "disambiguation_index": 0,
      "label": "experimental results",
      "aliases": [
        "experimental results"
      ],
      "types": [
        "measurement technique",
        "measurement outcome",
        "empirical evidence",
        "study",
        "research finding",
        "research",
        "scientific experiment",
        "data set"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Data obtained from controlled experiments or simulations to test hypotheses or validate theories.",
      "mentions": [
        {
          "reference": "Paper-27-Section-1-Paragraph-1-Sentence-4",
          "local_name": "experimental results",
          "local_types": [
            "measurement technique",
            "measurement outcome",
            "empirical evidence",
            "study",
            "research finding",
            "research",
            "scientific experiment",
            "data set"
          ],
          "iri": "Entity-experimental_result-Mention-1"
        }
      ],
      "relevance": 0.354736328125
    }
  },
  "summary": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry . Subpixel accuracy is achieved by considering several zero-crossings defined by the difference between pairs of unstructured patterns . We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities . Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems . We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting .",
  "triples": [
    [
      "Entity-we_present_a_scanning_method",
      "Predicate-presents",
      "Entity-scanning_method_that_recovers_dense_sub-pixel_camera-projector_correspondence"
    ],
    [
      "Entity-scanning_method_that_recovers_dense_sub-pixel_camera-projector_correspondence",
      "Predicate-presents",
      "Entity-we"
    ],
    [
      "Entity-several_zero-crossings_defined_by_the_difference_between_pair_of_unstructured_pattern",
      "Predicate-achieves",
      "Entity-subpixel_accuracy"
    ],
    [
      "Entity-our_method",
      "Predicate-recovers",
      "Entity-scene_geometry"
    ],
    [
      "Entity-our_method",
      "Predicate-recovers",
      "Entity-scene_geometry_with_high_subpixel_precision"
    ],
    [
      "Entity-state_of_the_art_method",
      "Predicate-compared_to",
      "Entity-mi-cro_phase_shifting"
    ],
    [
      "Entity-we_compare_our_result_to_state_of_the_art_method_such_a_mi-cro_phase_shifting_and_modulated_phase_shifting",
      "Predicate-compare",
      "Entity-our_result"
    ],
    [
      "Entity-we_present_a_scanning_method",
      "Predicate-present",
      "Entity-scanning_method"
    ]
  ],
  "triples_typing": [
    [
      "Entity-we_present_a_scanning_method",
      "skos:broader",
      "Entity-our_method"
    ],
    [
      "Entity-scanning_method",
      "skos:broader",
      "Entity-our_method"
    ],
    [
      "Entity-scanning_method_that_recovers_dense_sub-pixel_camera-projector_correspondence",
      "skos:broader",
      "Entity-our_method"
    ],
    [
      "Entity-simulated",
      "skos:broader",
      "Entity-our_method"
    ],
    [
      "Entity-mi-cro_phase_shifting",
      "skos:broader",
      "Entity-our_method"
    ],
    [
      "Entity-modulated_phase_shifting",
      "skos:broader",
      "Entity-our_method"
    ]
  ],
  "predicates": {
    "Predicate-presents": {
      "label": "presents",
      "description": "The predicate 'presents' indicates the act of introducing or making available a concept, idea, or method to others. It implies that the subject has taken an active role in sharing or showcasing something new, and the object represents what is being presented.",
      "disambiguation_index": 0
    },
    "Predicate-achieves": {
      "label": "achieves",
      "description": "The predicate 'achieves' indicates that a subject has successfully attained or reached a certain level of quality, precision, or performance in relation to an object. It implies a sense of accomplishment, fulfillment, or satisfaction with the outcome.",
      "disambiguation_index": 0
    },
    "Predicate-recovers": {
      "label": "recovers",
      "description": "The predicate 'recovers' indicates that the subject (a process or system) restores or regains something it had previously lost, damaged, or compromised. The object represents what was recovered, which can be a state, property, functionality, or overall condition.",
      "disambiguation_index": 0
    },
    "Predicate-compared_to": {
      "label": "compared to",
      "description": "The predicate 'compared to' indicates a relationship between two entities where one entity (the subject) is being evaluated or contrasted with another entity (the object). This connection implies that the subject and object share some common characteristics, properties, or attributes, allowing for an analysis of their similarities and differences.",
      "disambiguation_index": 0
    },
    "Predicate-compare": {
      "label": "compare",
      "description": "The predicate 'compare' indicates a relationship between two entities where one entity (the subject) is evaluated or matched against another entity (the object), often to identify similarities, differences, or equivalencies.",
      "disambiguation_index": 0
    },
    "Predicate-present": {
      "label": "present",
      "description": "The predicate 'present' indicates that the subject is introducing or offering something to others. It implies a sense of sharing or making available information, ideas, methods, or other concepts to an audience.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "Indicates that the subject refers to a specific instance or example of a more general concept or category denoted by the object.",
      "disambiguation_index": 0
    }
  }
}