{
  "iri": "Paper-99",
  "title": "CVPR_2003_30_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-99-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-99-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-1",
              "text": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-2",
              "text": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-3",
              "text": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-4",
              "text": "Preliminary modeling and recognition results are presented ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    5.6743621826171875e-05,
    52.17356324195862,
    52.86009120941162,
    61.784361839294434,
    0.029323816299438477,
    7.43865966796875e-05,
    9.131431579589844e-05,
    191.2286298274994,
    207.90172147750854,
    1.3052189350128174,
    0.04557919502258301,
    0.007002115249633789,
    0.0001659393310546875,
    53.75329637527466,
    0.000244140625,
    0.02035999298095703,
    0.0006985664367675781,
    2.131013870239258,
    0.8155422210693359,
    10.249139785766602,
    691.2549350261688,
    3.7117819786071777,
    131.08413195610046,
    1.0625224113464355,
    0.0005543231964111328,
    0.00964975357055664
  ],
  "nodes": {
    "Entity-this_paper": {
      "node_id": "this_paper",
      "disambiguation_index": 0,
      "label": "This paper",
      "aliases": [
        "this paper",
        "This paper"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "This paper introduces a novel method for representing three-dimensional objects using affine-invariant image patches and their spatial relationships, facilitating the matching and reconstruction of 3D models from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "This paper",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_paper-Mention-1"
        }
      ],
      "relevance": 0.8623046875
    },
    "Entity-approach": {
      "node_id": "approach",
      "disambiguation_index": 0,
      "label": "approach",
      "aliases": [
        "approach",
        "The proposed approach"
      ],
      "types": [
        "technique",
        "approach",
        "method"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The approach refers to a novel method for representing three-dimensional objects using affine-invariant image patches and their spatial relationships, which facilitates matching and reconstruction without the need for separate segmentation, making it suitable for cluttered scenes.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "approach",
          "local_types": [
            "method",
            "technique"
          ],
          "iri": "Entity-approach-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "The proposed approach",
          "local_types": [
            "method",
            "approach"
          ],
          "iri": "Entity-approach-Mention-2"
        }
      ],
      "relevance": 0.81103515625
    },
    "Entity-a_novel_representation_for_three-dimensional_object": {
      "node_id": "a_novel_representation_for_three-dimensional_object",
      "disambiguation_index": 0,
      "label": "a novel representation for three-dimensional objects",
      "aliases": [
        "a novel representation for three-dimensional objects"
      ],
      "types": [
        "representation",
        "three-dimensional object"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A novel representation for three-dimensional objects refers to a method that utilizes affine-invariant image patches and their spatial relationships to facilitate the matching and reconstruction of three-dimensional models from multiple images, enabling recognition from arbitrary viewpoints without the need for separate segmentation.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "a novel representation for three-dimensional objects",
          "local_types": [
            "representation",
            "three-dimensional object"
          ],
          "iri": "Entity-a_novel_representation_for_three-dimensional_object-Mention-1"
        }
      ],
      "relevance": 0.8095703125
    },
    "Entity-group_of_patch": {
      "node_id": "group_of_patch",
      "disambiguation_index": 0,
      "label": "groups of patches",
      "aliases": [
        "groups of patches"
      ],
      "types": [
        "image processing",
        "patch",
        "data structure",
        "group"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Groups of patches refer to collections of affine-invariant image patches that are used in the context of three-dimensional object representation and recognition, where their spatial relationships and appearance are leveraged to facilitate matching and reconstruction from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "groups of patches",
          "local_types": [
            "image processing",
            "patch",
            "data structure",
            "group"
          ],
          "iri": "Entity-group_of_patch-Mention-1"
        }
      ],
      "relevance": 0.783203125
    },
    "Entity-affine-invariant_image_patch": {
      "node_id": "affine-invariant_image_patch",
      "disambiguation_index": 0,
      "label": "affine-invariant image patches",
      "aliases": [
        "affine-invariant image patches"
      ],
      "types": [
        "image feature",
        "image representation",
        "visual descriptor",
        "affine-invariant",
        "image patch",
        "computer vision concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Affine-invariant image patches are localized regions of an image that maintain their characteristics under affine transformations, making them useful for robust feature extraction and matching in computer vision applications.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "affine-invariant image patches",
          "local_types": [
            "image feature",
            "image representation",
            "visual descriptor",
            "affine-invariant",
            "image patch",
            "computer vision concept"
          ],
          "iri": "Entity-affine-invariant_image_patch-Mention-1"
        }
      ],
      "relevance": 0.74853515625
    },
    "Entity-three-dimensional_affine_and_euclidean_model": {
      "node_id": "three-dimensional_affine_and_euclidean_model",
      "disambiguation_index": 0,
      "label": "three-dimensional affine and Euclidean models",
      "aliases": [
        "three-dimensional affine and Euclidean models",
        "true three-dimensional affine and Euclidean models"
      ],
      "types": [
        "3D model",
        "Euclidean",
        "mathematical model",
        "three-dimensional",
        "geometric model",
        "model",
        "affine"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Three-dimensional affine and Euclidean models are mathematical representations used to describe geometric shapes and transformations in a three-dimensional space, incorporating both affine and Euclidean properties.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "three-dimensional affine and Euclidean models",
          "local_types": [
            "3D model",
            "Euclidean",
            "three-dimensional",
            "affine",
            "geometric model",
            "model",
            "mathematical model"
          ],
          "iri": "Entity-three-dimensional_affine_and_euclidean_model-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "true three-dimensional affine and Euclidean models",
          "local_types": [
            "three-dimensional",
            "affine",
            "model",
            "Euclidean"
          ],
          "iri": "Entity-three-dimensional_affine_and_euclidean_model-Mention-2"
        }
      ],
      "relevance": 0.73095703125
    },
    "Entity-preliminary_modeling_and_recognition_result": {
      "node_id": "preliminary_modeling_and_recognition_result",
      "disambiguation_index": 0,
      "label": "Preliminary modeling and recognition results",
      "aliases": [
        "Preliminary modeling and recognition results"
      ],
      "types": [
        "research findings",
        "experimental results",
        "recognition",
        "modeling",
        "results",
        "result"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'Preliminary modeling and recognition results' refers to the initial findings and outcomes derived from the application of a novel method for recognizing and modeling three-dimensional objects using affine-invariant image patches, as discussed in the paper.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Preliminary modeling and recognition results",
          "local_types": [
            "research findings",
            "experimental results",
            "recognition",
            "modeling",
            "results",
            "result"
          ],
          "iri": "Entity-preliminary_modeling_and_recognition_result-Mention-1"
        }
      ],
      "relevance": 0.7265625
    },
    "Entity-multi-view_constraint": {
      "node_id": "multi-view_constraint",
      "disambiguation_index": 0,
      "label": "Multi-view constraints",
      "aliases": [
        "Multi-view constraints"
      ],
      "types": [
        "multi-view",
        "concept",
        "computer vision technique",
        "constraint",
        "methodology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Multi-view constraints refer to the relationships and conditions applied to groups of image patches in computer vision, which facilitate the matching and reconstruction of three-dimensional models from multiple images taken from different viewpoints.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "Multi-view constraints",
          "local_types": [
            "multi-view",
            "concept",
            "computer vision technique",
            "constraint",
            "methodology"
          ],
          "iri": "Entity-multi-view_constraint-Mention-1"
        }
      ],
      "relevance": 0.7158203125
    },
    "Entity-normalized_representation": {
      "node_id": "normalized_representation",
      "disambiguation_index": 0,
      "label": "normalized representation",
      "aliases": [
        "normalized representation"
      ],
      "types": [
        "representation",
        "image processing",
        "image processing technique",
        "data representation",
        "normalized"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'normalized representation' refers to a method of standardizing the appearance of image patches in a way that facilitates the matching and reconstruction of three-dimensional models from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "normalized representation",
          "local_types": [
            "representation",
            "image processing",
            "image processing technique",
            "data representation",
            "normalized"
          ],
          "iri": "Entity-normalized_representation-Mention-1"
        }
      ],
      "relevance": 0.71337890625
    },
    "Entity-appearance": {
      "node_id": "appearance",
      "disambiguation_index": 0,
      "label": "appearance",
      "aliases": [
        "appearance"
      ],
      "types": [
        "visual characteristic",
        "image property",
        "appearance"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'appearance' refers to a normalized representation of the visual characteristics of image patches used to facilitate the matching and reconstruction of three-dimensional models from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "appearance",
          "local_types": [
            "visual characteristic",
            "image property",
            "appearance"
          ],
          "iri": "Entity-appearance-Mention-1"
        }
      ],
      "relevance": 0.7080078125
    },
    "Entity-recognition_result": {
      "node_id": "recognition_result",
      "disambiguation_index": 0,
      "label": "recognition results",
      "aliases": [
        "recognition results"
      ],
      "types": [
        "outcome",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'recognition results' refers to the initial outcomes of the proposed method for identifying and reconstructing three-dimensional objects from multiple images, demonstrating the effectiveness of the approach in recognizing objects in cluttered scenes.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "recognition results",
          "local_types": [
            "outcome",
            "data"
          ],
          "iri": "Entity-recognition_result-Mention-1"
        }
      ],
      "relevance": 0.66650390625
    },
    "Entity-modeling": {
      "node_id": "modeling",
      "disambiguation_index": 0,
      "label": "modeling",
      "aliases": [
        "modeling"
      ],
      "types": [
        "process",
        "methodology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'modeling' refers to the process of creating representations of three-dimensional objects based on their appearance and spatial relationships, as demonstrated through preliminary results in the context of matching and recognition from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "modeling",
          "local_types": [
            "process",
            "methodology"
          ],
          "iri": "Entity-modeling-Mention-1"
        }
      ],
      "relevance": 0.6650390625
    },
    "Entity-matching_and_reconstruction": {
      "node_id": "matching_and_reconstruction",
      "disambiguation_index": 0,
      "label": "matching and reconstruction",
      "aliases": [
        "matching and reconstruction"
      ],
      "types": [
        "process",
        "image processing",
        "reconstruction",
        "image processing task",
        "matching",
        "computer vision task"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Matching and reconstruction refers to the process of aligning and reconstructing three-dimensional models from multiple two-dimensional images by utilizing multi-view constraints and normalized appearance representations.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "matching and reconstruction",
          "local_types": [
            "process",
            "image processing",
            "reconstruction",
            "image processing task",
            "matching",
            "computer vision task"
          ],
          "iri": "Entity-matching_and_reconstruction-Mention-1"
        }
      ],
      "relevance": 0.66455078125
    },
    "Entity-multiple_image": {
      "node_id": "multiple_image",
      "disambiguation_index": 0,
      "label": "multiple images",
      "aliases": [
        "multiple images"
      ],
      "types": [
        "image set",
        "data source",
        "multiple",
        "image data",
        "image",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "multiple images refers to a collection of photographs taken from different viewpoints that are used to reconstruct and recognize three-dimensional models in the context of the paper.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "multiple images",
          "local_types": [
            "image set",
            "data source",
            "multiple",
            "image data",
            "image",
            "data type"
          ],
          "iri": "Entity-multiple_image-Mention-1"
        }
      ],
      "relevance": 0.66064453125
    },
    "Entity-cluttered_scene": {
      "node_id": "cluttered_scene",
      "disambiguation_index": 0,
      "label": "cluttered scenes",
      "aliases": [
        "cluttered scenes"
      ],
      "types": [
        "environment",
        "cluttered",
        "scene",
        "visual context",
        "context"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Cluttered scenes refer to complex visual environments characterized by a high density of objects and details, which pose challenges for image processing and recognition tasks.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "cluttered scenes",
          "local_types": [
            "environment",
            "cluttered",
            "scene",
            "visual context",
            "context"
          ],
          "iri": "Entity-cluttered_scene-Mention-1"
        }
      ],
      "relevance": 0.638671875
    },
    "Entity-segmentation_stage": {
      "node_id": "segmentation_stage",
      "disambiguation_index": 0,
      "label": "segmentation stage",
      "aliases": [
        "segmentation stage"
      ],
      "types": [
        "step",
        "process",
        "image processing step",
        "stage",
        "computer vision process",
        "segmentation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'segmentation stage' refers to a distinct phase in image processing where an image is divided into segments or regions, but in this context, the proposed method eliminates the need for such a separate phase, allowing for direct processing of cluttered scenes.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "segmentation stage",
          "local_types": [
            "step",
            "process",
            "image processing step",
            "stage",
            "computer vision process",
            "segmentation"
          ],
          "iri": "Entity-segmentation_stage-Mention-1"
        }
      ],
      "relevance": 0.63232421875
    },
    "Entity-three-dimensional_object": {
      "node_id": "three-dimensional_object",
      "disambiguation_index": 0,
      "label": "three-dimensional objects",
      "aliases": [
        "three-dimensional objects"
      ],
      "types": [
        "object type",
        "3D model",
        "object",
        "geometric object",
        "three-dimensional",
        "geometric entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Three-dimensional objects are physical or abstract entities that possess length, width, and height, allowing them to occupy space and be represented in three-dimensional geometry.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "three-dimensional objects",
          "local_types": [
            "object type",
            "3D model",
            "object",
            "geometric object",
            "three-dimensional",
            "geometric entity"
          ],
          "iri": "Entity-three-dimensional_object-Mention-1"
        }
      ],
      "relevance": 0.61328125
    },
    "Entity-arbitrary_viewpoint": {
      "node_id": "arbitrary_viewpoint",
      "disambiguation_index": 0,
      "label": "arbitrary viewpoint",
      "aliases": [
        "arbitrary viewpoint"
      ],
      "types": [
        "arbitrary",
        "perspective",
        "viewpoint",
        "viewing angle"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'arbitrary viewpoint' refers to any perspective or angle from which a photograph can be taken, allowing for the recognition and reconstruction of three-dimensional models without the need for a specific or predetermined viewpoint.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "arbitrary viewpoint",
          "local_types": [
            "arbitrary",
            "perspective",
            "viewpoint",
            "viewing angle"
          ],
          "iri": "Entity-arbitrary_viewpoint-Mention-1"
        }
      ],
      "relevance": 0.6123046875
    },
    "Entity-a_separate_segmentation_stage": {
      "node_id": "a_separate_segmentation_stage",
      "disambiguation_index": 0,
      "label": "a separate segmentation stage",
      "aliases": [
        "a separate segmentation stage"
      ],
      "types": [
        "process",
        "segmentation"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A separate segmentation stage refers to an independent process in image analysis where an image is divided into segments or regions, which is not needed in the proposed approach of the paper, allowing for direct processing of images without prior segmentation.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "a separate segmentation stage",
          "local_types": [
            "process",
            "segmentation"
          ],
          "iri": "Entity-a_separate_segmentation_stage-Mention-1"
        }
      ],
      "relevance": 0.58642578125
    },
    "Entity-single_photograph": {
      "node_id": "single_photograph",
      "disambiguation_index": 0,
      "label": "single photograph",
      "aliases": [
        "single photograph"
      ],
      "types": [
        "photography",
        "single",
        "photograph",
        "image",
        "visual data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A single photograph is a standalone image captured by a camera, representing a moment in time and space, typically consisting of visual data that conveys a scene or subject.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "single photograph",
          "local_types": [
            "photography",
            "single",
            "photograph",
            "image",
            "visual data"
          ],
          "iri": "Entity-single_photograph-Mention-1"
        }
      ],
      "relevance": 0.55224609375
    },
    "Entity-spatial_relationship": {
      "node_id": "spatial_relationship",
      "disambiguation_index": 0,
      "label": "spatial relationships",
      "aliases": [
        "spatial relationships"
      ],
      "types": [
        "relationship",
        "geometric relationship",
        "spatial",
        "mathematical concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Spatial relationships refer to the ways in which objects or points are positioned and related to one another in a given space, often described in terms of distance, direction, and arrangement.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "spatial relationships",
          "local_types": [
            "relationship",
            "geometric relationship",
            "spatial",
            "mathematical concept"
          ],
          "iri": "Entity-spatial_relationship-Mention-1"
        }
      ],
      "relevance": 0.5322265625
    },
    "Entity-paper": {
      "node_id": "paper",
      "disambiguation_index": 0,
      "label": "paper",
      "aliases": [
        "paper"
      ],
      "types": [
        "academic work",
        "research document"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A paper is a written work that presents research findings, theories, or analyses, typically in an academic or scholarly context.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "paper",
          "local_types": [
            "academic work",
            "research document"
          ],
          "iri": "Entity-paper-Mention-1"
        }
      ],
      "relevance": 0.457763671875
    }
  },
  "summary": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships . Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint . The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes . Preliminary modeling and recognition results are presented .",
  "triples": [
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-a_novel_representation_for_three-dimensional_object"
    ],
    [
      "Entity-a_novel_representation_for_three-dimensional_object",
      "Predicate-is_for",
      "Entity-three-dimensional_object"
    ],
    [
      "Entity-affine-invariant_image_patch",
      "Predicate-are_related_to",
      "Entity-spatial_relationship"
    ],
    [
      "Entity-multi-view_constraint",
      "Predicate-are_combined_with",
      "Entity-normalized_representation"
    ],
    [
      "Entity-normalized_representation",
      "Predicate-guides",
      "Entity-matching_and_reconstruction"
    ],
    [
      "Entity-matching_and_reconstruction",
      "Predicate-allow_the_acquisition_of",
      "Entity-three-dimensional_affine_and_euclidean_model"
    ],
    [
      "Entity-three-dimensional_affine_and_euclidean_model",
      "Predicate-are_recognized_in",
      "Entity-single_photograph"
    ],
    [
      "Entity-multiple_image",
      "Predicate-are_taken_from",
      "Entity-arbitrary_viewpoint"
    ],
    [
      "Entity-approach",
      "Predicate-does_not_require",
      "Entity-a_separate_segmentation_stage"
    ],
    [
      "Entity-approach",
      "Predicate-is_applicable_to",
      "Entity-cluttered_scene"
    ],
    [
      "Entity-preliminary_modeling_and_recognition_result",
      "Predicate-are_presented",
      "Entity-modeling"
    ],
    [
      "Entity-preliminary_modeling_and_recognition_result",
      "Predicate-are_presented",
      "Entity-recognition_result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-approach"
    ]
  ],
  "triples_typing": [
    [
      "Entity-a_novel_representation_for_three-dimensional_object",
      "skos:broader",
      "Entity-three-dimensional_object"
    ],
    [
      "Entity-preliminary_modeling_and_recognition_result",
      "skos:broader",
      "Entity-modeling"
    ],
    [
      "Entity-three-dimensional_affine_and_euclidean_model",
      "skos:broader",
      "Entity-three-dimensional_object"
    ]
  ],
  "predicates": {
    "Predicate-presents": {
      "label": "presents",
      "description": "The predicate 'presents' indicates that the subject is introducing, showcasing, or making known the object, which typically represents an idea, concept, or item. This connection implies that the subject is actively communicating or delivering information about the object to an audience, often with the intention of informing, explaining, or demonstrating its significance or relevance.",
      "disambiguation_index": 0
    },
    "Predicate-is_for": {
      "label": "is for",
      "description": "The predicate 'is for' indicates a purpose, function, or intended use of the subject in relation to the object. It establishes a connection where the subject serves or is designed to fulfill a specific role or need associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_related_to": {
      "label": "are related to",
      "description": "The predicate 'are related to' indicates a connection or association between the subject and the object, suggesting that they share a commonality, influence, or relevance in a particular context. This relationship can encompass various forms of interaction, such as causal, functional, or conceptual links, highlighting how the two entities interact or contribute to a broader understanding of a topic.",
      "disambiguation_index": 0
    },
    "Predicate-are_combined_with": {
      "label": "are combined with",
      "description": "The predicate 'are combined with' indicates a relationship where the subject and object are brought together or integrated to form a unified entity or concept. This combination suggests that the characteristics or functionalities of both the subject and object interact or enhance each other, resulting in a new or improved outcome.",
      "disambiguation_index": 0
    },
    "Predicate-guides": {
      "label": "guides",
      "description": "The predicate 'guides' indicates a directional influence or support provided by the subject towards the object, suggesting that the subject plays a role in leading, directing, or facilitating the process or understanding of the object. In this context, it implies that the subject helps to shape or inform the actions or outcomes associated with the object.",
      "disambiguation_index": 0
    },
    "Predicate-allow_the_acquisition_of": {
      "label": "allow the acquisition of",
      "description": "The predicate 'allow the acquisition of' indicates that the subject facilitates or enables the process of obtaining or gaining possession of the object. It suggests a relationship where the actions or processes represented by the subject create conditions or opportunities for the object to be acquired, emphasizing the enabling role of the subject in relation to the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_recognized_in": {
      "label": "are recognized in",
      "description": "The predicate 'are recognized in' indicates a relationship where the subject is acknowledged or identified within the context of the object. It suggests that the subject has a notable presence or significance that is observable or discernible in the specified object, implying a connection or relevance between the two.",
      "disambiguation_index": 0
    },
    "Predicate-are_taken_from": {
      "label": "are taken from",
      "description": "The predicate 'are taken from' indicates a source or origin relationship between the subject and the object, suggesting that the subject derives or is obtained from the object. It implies that the subject is a result of a process or action that involves the object as its starting point or reference.",
      "disambiguation_index": 0
    },
    "Predicate-does_not_require": {
      "label": "does not require",
      "description": "The predicate 'does not require' indicates that the subject is capable of functioning or achieving its purpose without the necessity of the object. It implies that the object is not essential for the subject's operation or effectiveness, suggesting an alternative method or process that can be employed.",
      "disambiguation_index": 0
    },
    "Predicate-is_applicable_to": {
      "label": "is applicable to",
      "description": "The predicate 'is applicable to' establishes a relationship where the subject is relevant or suitable for the context or conditions represented by the object. It indicates that the subject can be effectively used, implemented, or considered in relation to the object, suggesting a functional or contextual compatibility.",
      "disambiguation_index": 0
    },
    "Predicate-are_presented": {
      "label": "are presented",
      "description": "The predicate 'are presented' indicates that the subject is being shown, displayed, or introduced in relation to the object. It signifies a communicative act where information, findings, or results (the subject) are made available or revealed to an audience or context, often to convey knowledge or insights about the object.",
      "disambiguation_index": 0
    },
    "Predicate-introduces": {
      "label": "introduces",
      "description": "The predicate 'introduces' signifies an action where the subject presents or brings forth the object, typically in a context that aims to inform or familiarize the audience with the object. It implies a transition from a state of unawareness to awareness regarding the object, often highlighting its significance, characteristics, or relevance.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' establishes a hierarchical relationship between the subject and the object, indicating that the subject is a specific instance or concept that falls under the wider category represented by the object. This relationship implies that the object encompasses a broader scope or generalization that includes the subject within its definition.",
      "disambiguation_index": 0
    }
  }
}