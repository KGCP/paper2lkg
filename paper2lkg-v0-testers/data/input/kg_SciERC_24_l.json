{
  "iri": "Paper-24",
  "title": "CVPR_2006_10_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-24-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-24-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-1",
              "text": "In this paper we discuss object detection when only a small number of training examples are given ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-2",
              "text": "Specifically , we show how to incorporate a simple prior on the distribution of natural images into support vector machines ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-3",
              "text": "SVMs are known to be robust to overfitting ; however , a few training examples usually do not represent well the structure of the class ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-4",
              "text": "Thus the resulting detectors are not robust and highly depend on the choice of the training examples ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-5",
              "text": "We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin , but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB- ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-6",
              "text": "Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples , and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.00020265579223632812,
    14.962122440338135,
    23.90872550010681,
    20.75806999206543,
    0.015741348266601562,
    8.344650268554688e-05,
    0.00010824203491210938,
    29.726696729660034,
    35.77634143829346,
    1.3841571807861328,
    1.3612232208251953,
    0.008278369903564453,
    0.0001819133758544922,
    29.1031494140625,
    12.614992141723633,
    0.02380204200744629,
    1.100205659866333,
    3.3843071460723877,
    2.679609775543213,
    3.3566439151763916,
    33.953670263290405,
    2.8351004123687744,
    15.093184232711792,
    0.9849834442138672,
    0.0005593299865722656,
    0.010018110275268555
  ],
  "nodes": {
    "Entity-the_resulting_detector_(1)": {
      "node_id": "the_resulting_detector_(1)",
      "disambiguation_index": 1,
      "label": "the resulting detector",
      "aliases": [
        "the resulting detector"
      ],
      "types": [
        "detector"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A support vector machine-based object detection model that is more robust to the choice of training examples, obtained by incorporating a prior on natural images into the SVM.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-6",
          "local_name": "the resulting detector",
          "local_types": [
            "detector"
          ],
          "iri": "Entity-the_resulting_detector_(1)-Mention-1"
        }
      ],
      "relevance": 0.73388671875
    },
    "Entity-a_simple_prior_on_the_distribution_of_natural_image": {
      "node_id": "a_simple_prior_on_the_distribution_of_natural_image",
      "disambiguation_index": 0,
      "label": "a simple prior on the distribution of natural images",
      "aliases": [
        "a simple prior on the distribution of natural images",
        "the prior on natural images"
      ],
      "types": [
        "prior",
        "image"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A probabilistic model that assumes a certain structure or pattern in the distribution of natural images, used as a constraint to improve object detection when only a small number of training examples are available.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-2",
          "local_name": "a simple prior on the distribution of natural images",
          "local_types": [
            "prior",
            "image"
          ],
          "iri": "Entity-a_simple_prior_on_the_distribution_of_natural_image-Mention-1"
        },
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-5",
          "local_name": "the prior on natural images",
          "local_types": [
            "prior"
          ],
          "iri": "Entity-a_simple_prior_on_the_distribution_of_natural_image-Mention-2"
        }
      ],
      "relevance": 0.71484375
    },
    "Entity-our_experiment": {
      "node_id": "our_experiment",
      "disambiguation_index": 0,
      "label": "Our experiments",
      "aliases": [
        "Our experiments"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Experiments conducted by the authors using real data sets to evaluate the performance of a detector that incorporates a prior on natural images into support vector machines.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-6",
          "local_name": "Our experiments",
          "local_types": [
            "research"
          ],
          "iri": "Entity-our_experiment-Mention-1"
        }
      ],
      "relevance": 0.64697265625
    },
    "Entity-the_resulting_detector": {
      "node_id": "the_resulting_detector",
      "disambiguation_index": 0,
      "label": "the resulting detectors",
      "aliases": [
        "the resulting detectors"
      ],
      "types": [
        "detector"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Object detection models trained with a small number of positive and negative examples, which lack robustness due to overfitting.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-4",
          "local_name": "the resulting detectors",
          "local_types": [
            "detector"
          ],
          "iri": "Entity-the_resulting_detector-Mention-1"
        }
      ],
      "relevance": 0.64208984375
    },
    "Entity-10_positive_and_10_negative_example": {
      "node_id": "10_positive_and_10_negative_example",
      "disambiguation_index": 0,
      "label": "10 positive and 10 negative examples",
      "aliases": [
        "10 positive and 10 negative examples"
      ],
      "types": [
        "dataset"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A dataset consisting of 20 labeled images (10 positive and 10 negative) used to train object detectors in support vector machines.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-6",
          "local_name": "10 positive and 10 negative examples",
          "local_types": [
            "dataset"
          ],
          "iri": "Entity-10_positive_and_10_negative_example-Mention-1"
        }
      ],
      "relevance": 0.63037109375
    },
    "Entity-the_background": {
      "node_id": "the_background",
      "disambiguation_index": 0,
      "label": "the background",
      "aliases": [
        "the background"
      ],
      "types": [
        "background"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The set of all possible natural images, used as a prior in support vector machines for object detection.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-5",
          "local_name": "the background",
          "local_types": [
            "background"
          ],
          "iri": "Entity-the_background-Mention-1"
        }
      ],
      "relevance": 0.6279296875
    },
    "Entity-we": {
      "node_id": "we",
      "disambiguation_index": 0,
      "label": "we",
      "aliases": [
        "we"
      ],
      "types": [
        "author"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The authors who are discussing object detection when only a small number of training examples are given.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-2",
          "local_name": "we",
          "local_types": [
            "author"
          ],
          "iri": "Entity-we-Mention-1"
        }
      ],
      "relevance": 0.62451171875
    },
    "Entity-a_few_training_example": {
      "node_id": "a_few_training_example",
      "disambiguation_index": 0,
      "label": "a few training examples",
      "aliases": [
        "a few training examples"
      ],
      "types": [
        "data"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A small number of object detection training instances",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-3",
          "local_name": "a few training examples",
          "local_types": [
            "data"
          ],
          "iri": "Entity-a_few_training_example-Mention-1"
        }
      ],
      "relevance": 0.61181640625
    },
    "Entity-svms": {
      "node_id": "svms",
      "disambiguation_index": 0,
      "label": "SVMs",
      "aliases": [
        "SVMs"
      ],
      "types": [
        "machine learning model",
        "abbreviation",
        "algorithm",
        "machine learning",
        "model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A type of machine learning model that uses a hyperplane or set of hyperplanes to classify data.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-3",
          "local_name": "SVMs",
          "local_types": [
            "machine learning model",
            "abbreviation",
            "algorithm",
            "machine learning",
            "model"
          ],
          "iri": "Entity-svms-Mention-1"
        }
      ],
      "relevance": 0.60986328125
    },
    "Entity-support_vector_machine": {
      "node_id": "support_vector_machine",
      "disambiguation_index": 0,
      "label": "support vector machines",
      "aliases": [
        "support vector machines"
      ],
      "types": [
        "algorithm",
        "computational method",
        "machine learning",
        "machine learning algorithm"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A type of machine learning algorithm that uses hyperplanes or decision boundaries to classify data.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-2",
          "local_name": "support vector machines",
          "local_types": [
            "algorithm",
            "computational method",
            "machine learning",
            "machine learning algorithm"
          ],
          "iri": "Entity-support_vector_machine-Mention-1"
        }
      ],
      "relevance": 0.59375
    },
    "Entity-when_only_a_small_number_of_training_example_are_given": {
      "node_id": "when_only_a_small_number_of_training_example_are_given",
      "disambiguation_index": 0,
      "label": "when only a small number of training examples are given",
      "aliases": [
        "when only a small number of training examples are given"
      ],
      "types": [
        "condition"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A situation where there are limited available training data for an object detection task.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-1",
          "local_name": "when only a small number of training examples are given",
          "local_types": [
            "condition"
          ],
          "iri": "Entity-when_only_a_small_number_of_training_example_are_given-Mention-1"
        }
      ],
      "relevance": 0.587890625
    },
    "Entity-svm": {
      "node_id": "svm",
      "disambiguation_index": 0,
      "label": "SVM",
      "aliases": [
        "SVM"
      ],
      "types": [
        "algorithm",
        "supervised machine learning algorithm",
        "machine learning model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A type of supervised machine learning algorithm",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-6",
          "local_name": "SVM",
          "local_types": [
            "algorithm",
            "supervised machine learning algorithm",
            "machine learning model"
          ],
          "iri": "Entity-svm-Mention-1"
        }
      ],
      "relevance": 0.5791015625
    },
    "Entity-in_this_paper": {
      "node_id": "in_this_paper",
      "disambiguation_index": 0,
      "label": "In this paper",
      "aliases": [
        "In this paper"
      ],
      "types": [
        "paper"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "This description refers to the entire research paper, which discusses object detection with limited training data.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-1",
          "local_name": "In this paper",
          "local_types": [
            "paper"
          ],
          "iri": "Entity-in_this_paper-Mention-1"
        }
      ],
      "relevance": 0.548828125
    },
    "Entity-overfitting": {
      "node_id": "overfitting",
      "disambiguation_index": 0,
      "label": "overfitting",
      "aliases": [
        "overfitting"
      ],
      "types": [
        "problem in machine learning",
        "phenomenon"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The phenomenon where a machine learning model becomes too specialized in its training data and fails to generalize well to new, unseen instances.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-3",
          "local_name": "overfitting",
          "local_types": [
            "problem in machine learning",
            "phenomenon"
          ],
          "iri": "Entity-overfitting-Mention-1"
        }
      ],
      "relevance": 0.54296875
    },
    "Entity-object_detection": {
      "node_id": "object_detection",
      "disambiguation_index": 0,
      "label": "object detection",
      "aliases": [
        "object detection"
      ],
      "types": [
        "computer vision technique",
        "field of study",
        "detection",
        "task",
        "technique",
        "topic",
        "computer vision task"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process or technique used to identify and locate specific objects within an image, video, or other visual data.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-1",
          "local_name": "object detection",
          "local_types": [
            "computer vision technique",
            "field of study",
            "detection",
            "task",
            "technique",
            "topic",
            "computer vision task"
          ],
          "iri": "Entity-object_detection-Mention-1"
        }
      ],
      "relevance": 0.54150390625
    },
    "Entity-training_example": {
      "node_id": "training_example",
      "disambiguation_index": 0,
      "label": "training examples",
      "aliases": [
        "training examples"
      ],
      "types": [
        "dataset",
        "data",
        "input data",
        "data set",
        "example"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of instances used to train or test machine learning models",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-1",
          "local_name": "training examples",
          "local_types": [
            "dataset",
            "data set",
            "data"
          ],
          "iri": "Entity-training_example-Mention-1"
        },
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-4",
          "local_name": "training examples",
          "local_types": [
            "dataset",
            "data set"
          ],
          "iri": "Entity-training_example-Mention-2"
        },
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-6",
          "local_name": "training examples",
          "local_types": [
            "input data",
            "data set",
            "example"
          ],
          "iri": "Entity-training_example-Mention-3"
        }
      ],
      "relevance": 0.537109375
    },
    "Entity-separating_hyperplane": {
      "node_id": "separating_hyperplane",
      "disambiguation_index": 0,
      "label": "separating hyperplane",
      "aliases": [
        "separating hyperplane"
      ],
      "types": [
        "mathematical concept",
        "algorithmic component",
        "hyperplane"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A mathematical concept or algorithmic component that divides a space into two distinct regions, typically used for classification purposes.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-5",
          "local_name": "separating hyperplane",
          "local_types": [
            "mathematical concept",
            "algorithmic component",
            "hyperplane"
          ],
          "iri": "Entity-separating_hyperplane-Mention-1"
        }
      ],
      "relevance": 0.529296875
    },
    "Entity-detector": {
      "node_id": "detector",
      "disambiguation_index": 0,
      "label": "detectors",
      "aliases": [
        "detector",
        "detectors"
      ],
      "types": [
        "algorithm",
        "machine learning model",
        "model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Automated systems or models that identify, classify, or detect specific patterns, objects, or phenomena.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-4",
          "local_name": "detectors",
          "local_types": [
            "algorithm",
            "model"
          ],
          "iri": "Entity-detector-Mention-1"
        },
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-6",
          "local_name": "detector",
          "local_types": [
            "algorithm",
            "machine learning model"
          ],
          "iri": "Entity-detector-Mention-2"
        }
      ],
      "relevance": 0.52099609375
    },
    "Entity-prior": {
      "node_id": "prior",
      "disambiguation_index": 0,
      "label": "prior",
      "aliases": [
        "prior"
      ],
      "types": [
        "mathematical concept",
        "statistical model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A statistical assumption or probability distribution used as a basis for inference or decision-making.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-2",
          "local_name": "prior",
          "local_types": [
            "mathematical concept",
            "statistical model"
          ],
          "iri": "Entity-prior-Mention-1"
        }
      ],
      "relevance": 0.513671875
    },
    "Entity-the_choice_of_the_training_example": {
      "node_id": "the_choice_of_the_training_example",
      "disambiguation_index": 0,
      "label": "the choice of the training examples",
      "aliases": [
        "the choice of the training examples"
      ],
      "types": [
        "training example selection"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The selection or decision made when choosing which specific training examples to use.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-4",
          "local_name": "the choice of the training examples",
          "local_types": [
            "training example selection"
          ],
          "iri": "Entity-the_choice_of_the_training_example-Mention-1"
        }
      ],
      "relevance": 0.490478515625
    },
    "Entity-real_data_set": {
      "node_id": "real_data_set",
      "disambiguation_index": 0,
      "label": "real data sets",
      "aliases": [
        "real data sets"
      ],
      "types": [
        "data set",
        "dataset"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of actual or authentic datasets used to test, evaluate, or train models.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-6",
          "local_name": "real data sets",
          "local_types": [
            "data set",
            "dataset"
          ],
          "iri": "Entity-real_data_set-Mention-1"
        }
      ],
      "relevance": 0.475341796875
    },
    "Entity-natural_image": {
      "node_id": "natural_image",
      "disambiguation_index": 0,
      "label": "natural images",
      "aliases": [
        "natural images"
      ],
      "types": [
        "image data",
        "dataset",
        "image data set",
        "images",
        "concept",
        "visual content",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection or dataset of photographs taken in their natural environment without artificial manipulation.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-2",
          "local_name": "natural images",
          "local_types": [
            "image data",
            "dataset",
            "image data set",
            "concept",
            "visual content"
          ],
          "iri": "Entity-natural_image-Mention-1"
        },
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-5",
          "local_name": "natural images",
          "local_types": [
            "data type",
            "dataset",
            "images"
          ],
          "iri": "Entity-natural_image-Mention-2"
        }
      ],
      "relevance": 0.470947265625
    },
    "Entity-margin": {
      "node_id": "margin",
      "disambiguation_index": 0,
      "label": "margin",
      "aliases": [
        "margin"
      ],
      "types": [
        "performance metric",
        "evaluation criterion"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A measure of the difference or gap between two sets, often used as an evaluation criterion.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-5",
          "local_name": "margin",
          "local_types": [
            "performance metric",
            "evaluation criterion"
          ],
          "iri": "Entity-margin-Mention-1"
        }
      ],
      "relevance": 0.453369140625
    },
    "Entity-background": {
      "node_id": "background",
      "disambiguation_index": 0,
      "label": "background",
      "aliases": [
        "background"
      ],
      "types": [
        "contextual information",
        "environmental factor"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The general setting or surroundings in which something exists or occurs.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-5",
          "local_name": "background",
          "local_types": [
            "contextual information",
            "environmental factor"
          ],
          "iri": "Entity-background-Mention-1"
        }
      ],
      "relevance": 0.4423828125
    },
    "Entity-positive_half_space": {
      "node_id": "positive_half_space",
      "disambiguation_index": 0,
      "label": "positive half space",
      "aliases": [
        "positive half space"
      ],
      "types": [
        "geometric concept",
        "mathematical construct"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The region of Euclidean space where all points satisfy certain conditions or constraints.",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-5",
          "local_name": "positive half space",
          "local_types": [
            "geometric concept",
            "mathematical construct"
          ],
          "iri": "Entity-positive_half_space-Mention-1"
        }
      ],
      "relevance": 0.437255859375
    },
    "Entity-the_class": {
      "node_id": "the_class",
      "disambiguation_index": 0,
      "label": "the class",
      "aliases": [
        "the class"
      ],
      "types": [
        "category"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "a group or category of individuals or things with shared characteristics",
      "mentions": [
        {
          "reference": "Paper-24-Section-1-Paragraph-1-Sentence-3",
          "local_name": "the class",
          "local_types": [
            "category"
          ],
          "iri": "Entity-the_class-Mention-1"
        }
      ],
      "relevance": 0.404541015625
    }
  },
  "summary": "In this paper we discuss object detection when only a small number of training examples are given . Specifically , we show how to incorporate a simple prior on the distribution of natural images into support vector machines . SVMs are known to be robust to overfitting ; however , a few training examples usually do not represent well the structure of the class . Thus the resulting detectors are not robust and highly depend on the choice of the training examples . We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin , but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB- . Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples , and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples .",
  "triples": [
    [
      "Entity-object_detection",
      "Predicate-discuss",
      "Entity-when_only_a_small_number_of_training_example_are_given"
    ],
    [
      "Entity-we",
      "Predicate-discuss",
      "Entity-object_detection"
    ],
    [
      "Entity-prior",
      "Predicate-show_how_to_incorporate_into",
      "Entity-support_vector_machine"
    ],
    [
      "Entity-a_simple_prior_on_the_distribution_of_natural_image",
      "Predicate-be_a_part_of",
      "Entity-natural_image"
    ],
    [
      "Entity-we",
      "Predicate-show_how_to_incorporate_a_simple_prior_on_the_distribution_of_natural_images_into",
      "Entity-support_vector_machine"
    ],
    [
      "Entity-svms",
      "Predicate-are_known_to_be_robust_to",
      "Entity-overfitting"
    ],
    [
      "Entity-a_few_training_example",
      "Predicate-usually_do_not_represent_well_the_structure_of",
      "Entity-the_class"
    ],
    [
      "Entity-the_resulting_detector",
      "Predicate-are_not_robust_due_to_dependence_on",
      "Entity-the_choice_of_the_training_example"
    ],
    [
      "Entity-a_simple_prior_on_the_distribution_of_natural_image",
      "Predicate-obtained_by",
      "Entity-the_resulting_detector_(1)"
    ]
  ],
  "triples_typing": [
    [
      "Entity-a_simple_prior_on_the_distribution_of_natural_image",
      "skos:broader",
      "Entity-prior"
    ],
    [
      "Entity-the_background",
      "skos:broader",
      "Entity-background"
    ],
    [
      "Entity-the_resulting_detector",
      "skos:broader",
      "Entity-detector"
    ],
    [
      "Entity-the_resulting_detector_(1)",
      "skos:broader",
      "Entity-detector"
    ]
  ],
  "predicates": {
    "Predicate-discuss": {
      "label": "discuss",
      "description": "To discuss means to engage in an exchange or conversation about something with someone, often involving consideration and examination of ideas, concepts, or issues. In this context, it implies a thoughtful exploration and analysis of the object (in this case, 'when only a small number of training examples are given') from different perspectives, potentially leading to insights, conclusions, or recommendations.",
      "disambiguation_index": 0
    },
    "Predicate-show_how_to_incorporate_into": {
      "label": "show how to incorporate into",
      "description": "To 'show how to incorporate into' means to demonstrate a way of integrating or merging one concept, technique, or framework with another. This predicate connects the subject (prior) and object (support vector machines), indicating that the prior knowledge or method should be combined with support vector machines in some manner.",
      "disambiguation_index": 0
    },
    "Predicate-be_a_part_of": {
      "label": "be a part of",
      "description": "The predicate 'be a part of' indicates that the subject has some inherent or essential connection to the object. This connection can take many forms, such as being an integral component, having a relationship with, or being contained within the object. The subject and object are linked in a way that suggests the subject is not independent from the object, but rather is closely tied to it.",
      "disambiguation_index": 0
    },
    "Predicate-show_how_to_incorporate_a_simple_prior_on_the_distribution_of_natural_images_into": {
      "label": "show how to incorporate a simple prior on the distribution of natural images into",
      "description": "This predicate describes the process of integrating a basic assumption about the characteristics of natural images into a given framework or system. The subject is responsible for providing guidance on how to incorporate this prior knowledge, which is typically based on statistical patterns and regularities in natural image distributions.",
      "disambiguation_index": 0
    },
    "Predicate-are_known_to_be_robust_to": {
      "label": "are known to be robust to",
      "description": "This predicate indicates that the subject has a property or characteristic that makes it resistant or immune to the effects of the object. In other words, the subject is able to withstand or tolerate the presence of the object without being significantly impacted.",
      "disambiguation_index": 0
    },
    "Predicate-usually_do_not_represent_well_the_structure_of": {
      "label": "usually do not represent well the structure of",
      "description": "This predicate indicates that there is a mismatch or inaccuracy between the subject and object. The subject (in this case, 'a few training examples') does not accurately capture or reflect the structure of the object ('the class'). This can imply a lack of representativeness, relevance, or correspondence between the two.",
      "disambiguation_index": 0
    },
    "Predicate-are_not_robust_due_to_dependence_on": {
      "label": "are not robust due to dependence on",
      "description": "This predicate indicates that a subject's property or characteristic (in this case, being 'robust') is compromised or impaired because it relies heavily on another entity or factor represented by the object. The dependence can be direct or indirect, and may involve various degrees of influence or control.",
      "disambiguation_index": 0
    },
    "Predicate-obtained_by": {
      "label": "obtained by",
      "description": "Indicates a causal or generative relationship between the subject and object, suggesting that the subject was created, derived, or produced through some process or method described by the object.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "Indicates that the subject concept is more general or encompassing than the object concept.",
      "disambiguation_index": 0
    }
  }
}