{
  "iri": "Paper-87",
  "title": "N03-1033",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-87-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-87-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-87-Section-1-Paragraph-1-Sentence-1",
              "text": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features ."
            },
            {
              "iri": "Paper-87-Section-1-Paragraph-1-Sentence-2",
              "text": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result ."
            }
          ]
        }
      ]
    }
  ]
}